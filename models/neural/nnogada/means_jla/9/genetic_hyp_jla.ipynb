{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-18 19:23:48.307860: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-12-18 19:23:48.493506: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-12-18 19:23:48.493566: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2022-12-18 19:23:49.728273: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2022-12-18 19:23:49.728421: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2022-12-18 19:23:49.728435: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import time, os\n",
    "import random\n",
    "import seaborn as sns\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Input, Dense, LeakyReLU\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorboard.plugins.hparams import api as hp\n",
    "\n",
    "from tensorflow.keras import activations\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "import random\n",
    "from math import floor\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import optimizers\n",
    "from scipy.integrate import odeint\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split as split\n",
    "from scipy.stats import bernoulli\n",
    "\n",
    "# import deap\n",
    "from deap import base, creator, tools, algorithms\n",
    "\n",
    "from bitstring import BitArray\n",
    "\n",
    "# from elitism import eaSimpleWithElitism, main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "\n",
    "# tf.config.optimizer.set_jit(True)\n",
    "# scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "url = 'https://raw.githubusercontent.com/igomezv/nnogada/main/data/jla.csv'\n",
    "df=pd.read_csv(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = len(df.values)\n",
    "randomize = np.random.permutation(N)\n",
    "data = df.values[randomize]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(740, 2)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N = len(df.values)\n",
    "z = data[:,0] \n",
    "y = data[:,1:3] ### coge el resto de variables a predecir \n",
    "y[:,1] = y[:,1]**2+data[:,2]\n",
    "np.shape(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "scalerz = StandardScaler()\n",
    "scalerz.fit(z.reshape(-1,1))\n",
    "z = scalerz.transform(z.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((592, 1), (148, 1), (592, 2), (148, 2))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Modificar para incluir phanteon como test\n",
    "split = 0.8\n",
    "ntrain = int(split * len(z))\n",
    "indx = [ntrain]\n",
    "X_train, X_val = np.split(z, indx)\n",
    "Y_train, Y_val = np.split(y, indx)\n",
    "# X_train, X_test = np.split(z, indx)\n",
    "# Y_train, Y_test = np.split(y, indx)\n",
    "np.shape(X_train), np.shape(X_val), Y_train.shape, Y_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "SC_DEEP       = np.array([1,2,3,4])                           # Number of deep layers (8)\n",
    "SC_NUM_UNITS  = np.array([50,100,150,200]) # Number of fully conected neurons (16)\n",
    "SC_LEARNING   = np.array([1e-4,1e-3])   # Learning rates (8)\n",
    "SC_BATCH      = np.array([2, 4, 8, 16])                            # Batch sizes (4)\n",
    "# SC_ACTIVATION = [f1, f2, f3, f4]                                      # Activation function layers (2)\n",
    "\n",
    "my_callbacks = [tf.keras.callbacks.EarlyStopping(\n",
    "                               monitor='val_loss', mode='min',\n",
    "                               min_delta=0, \n",
    "                               patience=200,\n",
    "                               verbose=1,\n",
    "                            #    baseline=0,\n",
    "                               restore_best_weights=True)\n",
    "#                 keras.callbacks.TensorBoard(\n",
    "#                                log_dir='./logs'),\n",
    "#                 keras.callbacks.ReduceLROnPlateau(\n",
    "#                                monitor='val_loss', factor=0.5,\n",
    "#                                patience=6, min_lr=0,\n",
    "#                                verbose=1)\n",
    "               ] \n",
    "    \n",
    "epochs = 200\n",
    "# epochs = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_evaluate(ga_individual_solution):   \n",
    "    t = time.time()\n",
    "    t_total = 0\n",
    "    \n",
    "    # Decode GA solution to integer for window_size and num_units\n",
    "    deep_layers_bits   = BitArray(ga_individual_solution[0:2])     # (8)\n",
    "    num_units_bits     = BitArray(ga_individual_solution[2:4])     # (16)\n",
    "    learning_rate_bits = BitArray(ga_individual_solution[4:5])    # (8)\n",
    "    batch_size_bits    = BitArray(ga_individual_solution[5:7])   # (4)\n",
    "# #     activation_f_bits  = BitArray(ga_individual_solution[12:13])   # (2)   Solo se consideran las 2 primeras\n",
    "    \n",
    "    deep_layers   = SC_DEEP[deep_layers_bits.uint]\n",
    "    num_units     = SC_NUM_UNITS[num_units_bits.uint]\n",
    "    learning_rate = SC_LEARNING[learning_rate_bits.uint]\n",
    "    batch_size   = SC_BATCH[batch_size_bits.uint]\n",
    "#     activation_f  = SC_ACTIVATION[activation_f_bits.uint]\n",
    "\n",
    "    \n",
    "    print('\\n--------------- Starting trial:', population_size*(max_generations+1)-len(ss), \"---------------\")\n",
    "    print('Deep layers:',deep_layers,', Number of neurons:',num_units,\", Learning rate:\",learning_rate)\n",
    "#     print(\"-------------------------------------------------\")\n",
    "    \n",
    "    # Train model and predict on validation set\n",
    "    model = tf.keras.Sequential()\n",
    "#     model.add(Input(shape=(int(X_train.shape[1]),)))\n",
    "    model.add(Dense(int(X_train.shape[1])))\n",
    "    \n",
    "    for i in range(deep_layers):        \n",
    "        model.add(Dense(num_units, activation='relu'))\n",
    "#             model.add(keras.layers.Dropout(0.3))\n",
    "    model.add(Dense(2, activation='linear'))\n",
    "    \n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate, beta_1=0.9, beta_2=0.999, epsilon=1e-3)\n",
    "    model.compile(optimizer=optimizer, loss='mse', metrics=['mean_squared_error'])\n",
    "    model.fit(X_train, Y_train, epochs=epochs, validation_data=(X_val, Y_val),\n",
    "              callbacks=my_callbacks, batch_size=batch_size, shuffle=False, verbose=0)\n",
    "    \n",
    "    loss, score = model.evaluate(X_val, Y_val)    \n",
    "    t = time.time()-t\n",
    "    ss.pop(0)\n",
    "    print(\"Loss:\", score, \", Elapsed time:\", t)\n",
    "    print(\"-------------------------------------------------\\n\")\n",
    "#     print(loss, score)\n",
    "\n",
    "    datos.append([deep_layers, num_units, learning_rate, batch_size, loss, score, t])\n",
    "    \n",
    "    return loss,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deap import tools\n",
    "from deap import algorithms\n",
    "\n",
    "def eaSimpleWithElitism(population, toolbox, cxpb, mutpb, ngen, stats=None,\n",
    "             halloffame=None, verbose=__debug__):\n",
    "    \"\"\"This algorithm is similar to DEAP eaSimple() algorithm, with the modification that\n",
    "    halloffame is used to implement an elitism mechanism. The individuals contained in the\n",
    "    halloffame are directly injected into the next generation and are not subject to the\n",
    "    genetic operators of selection, crossover and mutation.\n",
    "    \"\"\"\n",
    "    logbook = tools.Logbook()\n",
    "    logbook.header = ['gen', 'nevals'] + (stats.fields if stats else [])\n",
    "\n",
    "    # Evaluate the individuals with an invalid fitness\n",
    "    invalid_ind = [ind for ind in population if not ind.fitness.valid]\n",
    "    fitnesses = toolbox.map(toolbox.evaluate, invalid_ind)\n",
    "    for ind, fit in zip(invalid_ind, fitnesses):\n",
    "        ind.fitness.values = fit\n",
    "\n",
    "    if halloffame is None:\n",
    "        raise ValueError(\"halloffame parameter must not be empty!\")\n",
    "\n",
    "    halloffame.update(population)\n",
    "    hof_size = len(halloffame.items) if halloffame.items else 0\n",
    "\n",
    "    record = stats.compile(population) if stats else {}\n",
    "    logbook.record(gen=0, nevals=len(invalid_ind), **record)\n",
    "    if verbose:\n",
    "        print(logbook.stream)\n",
    "\n",
    "    # Begin the generational process\n",
    "    for gen in range(1, ngen + 1):\n",
    "\n",
    "        # Select the next generation individuals\n",
    "        offspring = toolbox.select(population, len(population) - hof_size)\n",
    "\n",
    "        # Vary the pool of individuals\n",
    "        offspring = algorithms.varAnd(offspring, toolbox, cxpb, mutpb)\n",
    "\n",
    "        # Evaluate the individuals with an invalid fitness\n",
    "        invalid_ind = [ind for ind in offspring if not ind.fitness.valid]\n",
    "        fitnesses = toolbox.map(toolbox.evaluate, invalid_ind)\n",
    "        for ind, fit in zip(invalid_ind, fitnesses):\n",
    "            ind.fitness.values = fit\n",
    "\n",
    "        # add the best back to population:\n",
    "        offspring.extend(halloffame.items)\n",
    "\n",
    "        # Update the hall of fame with the generated individuals\n",
    "        halloffame.update(offspring)\n",
    "\n",
    "        # Replace the current population by the offspring\n",
    "        population[:] = offspring\n",
    "\n",
    "        # Append the current generation statistics to the logbook\n",
    "        record = stats.compile(population) if stats else {}\n",
    "        logbook.record(gen=gen, nevals=len(invalid_ind), **record)\n",
    "        if verbose:\n",
    "            print(logbook.stream)\n",
    "\n",
    "    return population, logbook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def geneticAlgorithm_with_elitism(population_size, max_generations, gene_length, k):\n",
    "    \n",
    "    # Genetic Algorithm constants:\n",
    "    P_CROSSOVER = 0.5        # probability for crossover\n",
    "    P_MUTATION = 0.5         # probability for mutating an individual\n",
    "    HALL_OF_FAME_SIZE = 1    # Best individuals that pass to the other generation\n",
    "    \n",
    "    # set the random seed:\n",
    "    toolbox = base.Toolbox()\n",
    "\n",
    "    # As we are trying to minimize the RMSE score, that's why using -1.0. \n",
    "    # In case, when you want to maximize accuracy for instance, use 1.0\n",
    "    creator.create('FitnessMin', base.Fitness, weights = [-1.0])\n",
    "    creator.create('Individual', list , fitness = creator.FitnessMin)\n",
    "\n",
    "    # create the individual operator to fill up an Individual instance:\n",
    "    toolbox.register('binary', bernoulli.rvs, 0.5)\n",
    "    toolbox.register('individual', tools.initRepeat, creator.Individual, toolbox.binary, n = gene_length)\n",
    "\n",
    "    # create the population operator to generate a list of individuals:\n",
    "    toolbox.register('population', tools.initRepeat, list , toolbox.individual)\n",
    "\n",
    "    # genetic operators:\n",
    "    toolbox.register('evaluate', train_evaluate)\n",
    "    toolbox.register('select', tools.selTournament, tournsize = 2)\n",
    "    toolbox.register('mutate', tools.mutFlipBit, indpb = 0.11)\n",
    "    toolbox.register('mate', tools.cxUniform, indpb = 0.5)\n",
    "    \n",
    "    # create initial population (generation 0):\n",
    "    population = toolbox.population(n=population_size)\n",
    "\n",
    "    # prepare the statistics object:\n",
    "    stats = tools.Statistics(lambda ind: ind.fitness.values)\n",
    "    stats.register(\"min\", np.min)\n",
    "    stats.register(\"avg\", np.mean)\n",
    "    stats.register(\"max\", np.max)\n",
    "\n",
    "    # define the hall-of-fame object:\n",
    "    hof = tools.HallOfFame(HALL_OF_FAME_SIZE)\n",
    "\n",
    "    # Genetic Algorithm flow with elitism:\n",
    "    population, logbook = eaSimpleWithElitism(population, toolbox, cxpb=P_CROSSOVER, mutpb=P_MUTATION,\n",
    "                                              ngen=max_generations, stats=stats, halloffame=hof, verbose=True)\n",
    "\n",
    "    # print info for best solution found:\n",
    "    best = hof.items[0]\n",
    "    print(\"-- Best Individual = \", best)\n",
    "    print(\"-- Best Fitness = \", best.fitness.values[0])\n",
    "\n",
    "    # extract statistics:\n",
    "    minFitnessValues, meanFitnessValues, maxFitnessValues = logbook.select(\"min\", \"max\", \"avg\")\n",
    "\n",
    "    # plot statistics:\n",
    "    sns.set_style(\"whitegrid\")\n",
    "    plt.plot(minFitnessValues, color='blue', label=\"Min\")\n",
    "    plt.plot(meanFitnessValues, color='green', label=\"Mean\")\n",
    "    plt.plot(maxFitnessValues, color='red', label=\"Max\")\n",
    "    plt.xlabel('Generation'); plt.ylabel('Max / Min / Average Fitness')\n",
    "    plt.legend()\n",
    "    plt.title('Max, Min and Average fitness over Generations')\n",
    "    plt.show()\n",
    "    \n",
    "    best_population = tools.selBest(population,k = k)\n",
    "    return best_population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------------- Starting trial: 1 ---------------\n",
      "Deep layers: 3 , Number of neurons: 100 , Learning rate: 0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-18 19:23:51.129153: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-18 19:23:51.129484: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-12-18 19:23:51.129586: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory\n",
      "2022-12-18 19:23:51.129885: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory\n",
      "2022-12-18 19:23:51.129986: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcufft.so.10'; dlerror: libcufft.so.10: cannot open shared object file: No such file or directory\n",
      "2022-12-18 19:23:51.130066: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcurand.so.10'; dlerror: libcurand.so.10: cannot open shared object file: No such file or directory\n",
      "2022-12-18 19:23:51.130142: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory\n",
      "2022-12-18 19:23:51.130220: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory\n",
      "2022-12-18 19:23:51.130294: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2022-12-18 19:23:51.130314: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1934] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2022-12-18 19:23:51.130883: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0938 - mean_squared_error: 0.0938\n",
      "Loss: 0.09384886920452118 , Elapsed time: 136.26514387130737\n",
      "-------------------------------------------------\n",
      "\n",
      "\n",
      "--------------- Starting trial: 2 ---------------\n",
      "Deep layers: 2 , Number of neurons: 200 , Learning rate: 0.0001\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0549 - mean_squared_error: 0.0549\n",
      "Loss: 0.0548514723777771 , Elapsed time: 34.55266571044922\n",
      "-------------------------------------------------\n",
      "\n",
      "\n",
      "--------------- Starting trial: 3 ---------------\n",
      "Deep layers: 4 , Number of neurons: 200 , Learning rate: 0.001\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0604 - mean_squared_error: 0.0604\n",
      "Loss: 0.06036277115345001 , Elapsed time: 34.880829095840454\n",
      "-------------------------------------------------\n",
      "\n",
      "\n",
      "--------------- Starting trial: 4 ---------------\n",
      "Deep layers: 1 , Number of neurons: 100 , Learning rate: 0.0001\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1064 - mean_squared_error: 0.1064\n",
      "Loss: 0.10637365281581879 , Elapsed time: 51.86579871177673\n",
      "-------------------------------------------------\n",
      "\n",
      "\n",
      "--------------- Starting trial: 5 ---------------\n",
      "Deep layers: 2 , Number of neurons: 100 , Learning rate: 0.0001\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0373 - mean_squared_error: 0.0373\n",
      "Loss: 0.03730440139770508 , Elapsed time: 83.14853501319885\n",
      "-------------------------------------------------\n",
      "\n",
      "gen\tnevals\tmin      \tavg      \tmax     \n",
      "0  \t5     \t0.0373044\t0.0705482\t0.106374\n",
      "\n",
      "--------------- Starting trial: 6 ---------------\n",
      "Deep layers: 4 , Number of neurons: 200 , Learning rate: 0.001\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0672 - mean_squared_error: 0.0672\n",
      "Loss: 0.06719721108675003 , Elapsed time: 34.09452962875366\n",
      "-------------------------------------------------\n",
      "\n",
      "\n",
      "--------------- Starting trial: 7 ---------------\n",
      "Deep layers: 4 , Number of neurons: 200 , Learning rate: 0.001\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0660 - mean_squared_error: 0.0660\n",
      "Loss: 0.06597232073545456 , Elapsed time: 35.19860053062439\n",
      "-------------------------------------------------\n",
      "\n",
      "1  \t2     \t0.0373044\t0.0638349\t0.0938489\n",
      "\n",
      "--------------- Starting trial: 8 ---------------\n",
      "Deep layers: 2 , Number of neurons: 200 , Learning rate: 0.0001\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0362 - mean_squared_error: 0.0362\n",
      "Loss: 0.03618522733449936 , Elapsed time: 47.56580710411072\n",
      "-------------------------------------------------\n",
      "\n",
      "2  \t1     \t0.0361852\t0.0463236\t0.0659723\n",
      "\n",
      "--------------- Starting trial: 9 ---------------\n",
      "Deep layers: 2 , Number of neurons: 200 , Learning rate: 0.001\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0360 - mean_squared_error: 0.0360\n",
      "Loss: 0.035960473120212555 , Elapsed time: 42.107138872146606\n",
      "-------------------------------------------------\n",
      "\n",
      "\n",
      "--------------- Starting trial: 10 ---------------\n",
      "Deep layers: 2 , Number of neurons: 100 , Learning rate: 0.0001\n",
      "5/5 [==============================] - 1s 2ms/step - loss: 0.0378 - mean_squared_error: 0.0378\n",
      "Loss: 0.037828195840120316 , Elapsed time: 83.62041068077087\n",
      "-------------------------------------------------\n",
      "\n",
      "\n",
      "--------------- Starting trial: 11 ---------------\n",
      "Deep layers: 2 , Number of neurons: 100 , Learning rate: 0.0001\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0396 - mean_squared_error: 0.0396\n",
      "Loss: 0.039561834186315536 , Elapsed time: 83.57485771179199\n",
      "-------------------------------------------------\n",
      "\n",
      "3  \t3     \t0.0359605\t0.037368 \t0.0395618\n",
      "\n",
      "--------------- Starting trial: 12 ---------------\n",
      "Deep layers: 2 , Number of neurons: 200 , Learning rate: 0.001\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0327 - mean_squared_error: 0.0327\n",
      "Loss: 0.032738588750362396 , Elapsed time: 46.380308389663696\n",
      "-------------------------------------------------\n",
      "\n",
      "\n",
      "--------------- Starting trial: 13 ---------------\n",
      "Deep layers: 2 , Number of neurons: 50 , Learning rate: 0.0001\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0469 - mean_squared_error: 0.0469\n",
      "Loss: 0.04690074175596237 , Elapsed time: 41.930126905441284\n",
      "-------------------------------------------------\n",
      "\n",
      "4  \t2     \t0.0327386\t0.0375041\t0.0469007\n",
      "\n",
      "--------------- Starting trial: 14 ---------------\n",
      "Deep layers: 2 , Number of neurons: 200 , Learning rate: 0.001\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0368 - mean_squared_error: 0.0368\n",
      "Loss: 0.0368463359773159 , Elapsed time: 50.957324504852295\n",
      "-------------------------------------------------\n",
      "\n",
      "\n",
      "--------------- Starting trial: 15 ---------------\n",
      "Deep layers: 2 , Number of neurons: 200 , Learning rate: 0.001\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0328 - mean_squared_error: 0.0328\n",
      "Loss: 0.03278999403119087 , Elapsed time: 43.7207145690918\n",
      "-------------------------------------------------\n",
      "\n",
      "\n",
      "--------------- Starting trial: 16 ---------------\n",
      "Deep layers: 4 , Number of neurons: 200 , Learning rate: 0.001\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0537 - mean_squared_error: 0.0537\n",
      "Loss: 0.05367303639650345 , Elapsed time: 32.84605956077576\n",
      "-------------------------------------------------\n",
      "\n",
      "\n",
      "--------------- Starting trial: 17 ---------------\n",
      "Deep layers: 2 , Number of neurons: 200 , Learning rate: 0.001\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0327 - mean_squared_error: 0.0327\n",
      "Loss: 0.0327189564704895 , Elapsed time: 45.44192552566528\n",
      "-------------------------------------------------\n",
      "\n",
      "5  \t4     \t0.032719 \t0.0383978\t0.053673 \n",
      "\n",
      "--------------- Starting trial: 18 ---------------\n",
      "Deep layers: 2 , Number of neurons: 200 , Learning rate: 0.0001\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0362 - mean_squared_error: 0.0362\n",
      "Loss: 0.03620028868317604 , Elapsed time: 83.13252711296082\n",
      "-------------------------------------------------\n",
      "\n",
      "6  \t1     \t0.032719 \t0.0340919\t0.0362003\n",
      "\n",
      "--------------- Starting trial: 19 ---------------\n",
      "Deep layers: 1 , Number of neurons: 150 , Learning rate: 0.001\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0381 - mean_squared_error: 0.0381\n",
      "Loss: 0.03811682388186455 , Elapsed time: 48.882195234298706\n",
      "-------------------------------------------------\n",
      "\n",
      "\n",
      "--------------- Starting trial: 20 ---------------\n",
      "Deep layers: 2 , Number of neurons: 200 , Learning rate: 0.001\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0818 - mean_squared_error: 0.0818\n",
      "Loss: 0.08175906538963318 , Elapsed time: 154.25604104995728\n",
      "-------------------------------------------------\n",
      "\n",
      "7  \t2     \t0.032719 \t0.0449511\t0.0817591\n",
      "\n",
      "--------------- Starting trial: 21 ---------------\n",
      "Deep layers: 2 , Number of neurons: 150 , Learning rate: 0.001\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0455 - mean_squared_error: 0.0455\n",
      "Loss: 0.04547211155295372 , Elapsed time: 83.41753959655762\n",
      "-------------------------------------------------\n",
      "\n",
      "\n",
      "--------------- Starting trial: 22 ---------------\n",
      "Deep layers: 2 , Number of neurons: 200 , Learning rate: 0.001\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0353 - mean_squared_error: 0.0353\n",
      "Loss: 0.03532431274652481 , Elapsed time: 44.13502287864685\n",
      "-------------------------------------------------\n",
      "\n",
      "\n",
      "--------------- Starting trial: 23 ---------------\n",
      "Deep layers: 2 , Number of neurons: 150 , Learning rate: 0.001\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0420 - mean_squared_error: 0.0420\n",
      "Loss: 0.0420386902987957 , Elapsed time: 43.36511516571045\n",
      "-------------------------------------------------\n",
      "\n",
      "8  \t3     \t0.0353243\t0.0389512\t0.0454721\n",
      "\n",
      "--------------- Starting trial: 24 ---------------\n",
      "Deep layers: 2 , Number of neurons: 200 , Learning rate: 0.001\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0325 - mean_squared_error: 0.0325\n",
      "Loss: 0.032485611736774445 , Elapsed time: 45.786667585372925\n",
      "-------------------------------------------------\n",
      "\n",
      "\n",
      "--------------- Starting trial: 25 ---------------\n",
      "Deep layers: 2 , Number of neurons: 200 , Learning rate: 0.001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0302 - mean_squared_error: 0.0302\n",
      "Loss: 0.030214080587029457 , Elapsed time: 39.94380068778992\n",
      "-------------------------------------------------\n",
      "\n",
      "\n",
      "--------------- Starting trial: 26 ---------------\n",
      "Deep layers: 2 , Number of neurons: 150 , Learning rate: 0.001\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0388 - mean_squared_error: 0.0388\n",
      "Loss: 0.03880550339818001 , Elapsed time: 23.172847032546997\n",
      "-------------------------------------------------\n",
      "\n",
      "9  \t3     \t0.0302141\t0.0346852\t0.0388055\n",
      "\n",
      "--------------- Starting trial: 27 ---------------\n",
      "Deep layers: 2 , Number of neurons: 200 , Learning rate: 0.001\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0379 - mean_squared_error: 0.0379\n",
      "Loss: 0.037893425673246384 , Elapsed time: 40.66186308860779\n",
      "-------------------------------------------------\n",
      "\n",
      "\n",
      "--------------- Starting trial: 28 ---------------\n",
      "Deep layers: 2 , Number of neurons: 200 , Learning rate: 0.001\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0345 - mean_squared_error: 0.0345\n",
      "Loss: 0.03448120504617691 , Elapsed time: 42.99660134315491\n",
      "-------------------------------------------------\n",
      "\n",
      "\n",
      "--------------- Starting trial: 29 ---------------\n",
      "Deep layers: 2 , Number of neurons: 200 , Learning rate: 0.001\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0357 - mean_squared_error: 0.0357\n",
      "Loss: 0.03567051142454147 , Elapsed time: 83.25770711898804\n",
      "-------------------------------------------------\n",
      "\n",
      "\n",
      "--------------- Starting trial: 30 ---------------\n",
      "Deep layers: 2 , Number of neurons: 200 , Learning rate: 0.0001\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0366 - mean_squared_error: 0.0366\n",
      "Loss: 0.0365997739136219 , Elapsed time: 44.19799280166626\n",
      "-------------------------------------------------\n",
      "\n",
      "10 \t4     \t0.0344812\t0.0361211\t0.0378934\n",
      "-- Best Individual =  [0, 1, 1, 1, 1, 1, 0]\n",
      "-- Best Fitness =  0.035960473120212555\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total elapsed time: 28.42744961977005 minutes\n"
     ]
    }
   ],
   "source": [
    "population_size = 5   # max of individuals per generation\n",
    "max_generations = 10  # number of generations\n",
    "gene_length = 7      # lenght of the gene, depends on how many hiperparameters are tested  \n",
    "k = 1;                 # num. of finalist individuals\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    t = time.time(); \n",
    "    datos = [];\n",
    "    ss = [i for i in range(1,population_size*(max_generations+1))]\n",
    "    best_population = geneticAlgorithm_with_elitism(population_size, max_generations, gene_length, k)\n",
    "    print(\"Total elapsed time:\", (time.time()-t)/60, \"minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k= 1 \n",
      "Deep layers: 1 , Number of neurons: 100\n",
      "Batch size 4 , Learning rate: 0.001\n"
     ]
    }
   ],
   "source": [
    "best_deep_layers   = []\n",
    "best_num_units     = []\n",
    "best_learning_rate = []\n",
    "best_batch_size    = []\n",
    "# best_activation_f  = []\n",
    "best_f_names       = []\n",
    "\n",
    "t = 0\n",
    "\n",
    "for bi in best_population:\n",
    "    deep_layers_bits   = BitArray(bi[0:1])    # (8)\n",
    "    num_units_bits     = BitArray(bi[1:2])    # (16)\n",
    "    learning_rate_bits = BitArray(bi[2:3])   # (8)\n",
    "    batch_size_bits    = BitArray(bi[3:4])  # (4)\n",
    "#     activation_f_bits  = BitArray(bi[12:13])  # (2)\n",
    "    t += 1 \n",
    "    \n",
    "    best_deep_layers.append(SC_DEEP[deep_layers_bits.uint])\n",
    "    best_num_units.append(SC_NUM_UNITS[num_units_bits.uint])\n",
    "    best_learning_rate.append(SC_LEARNING[learning_rate_bits.uint])\n",
    "    best_batch_size.append(SC_BATCH[batch_size_bits.uint])\n",
    "#     best_activation_f.append(SC_ACTIVATION[activation_f_bits.uint])\n",
    "#     best_f_names.append(f_names[activation_f_bits.uint])\n",
    "    print('k=',t,'\\nDeep layers:', best_deep_layers[-1], ', Number of neurons:', best_num_units[-1])\n",
    "    print('Batch size', best_batch_size[-1], ', Learning rate:', best_learning_rate[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Deep layers</th>\n",
       "      <th>Num units</th>\n",
       "      <th>Learning rate</th>\n",
       "      <th>Batch size</th>\n",
       "      <th>Loss</th>\n",
       "      <th>Score</th>\n",
       "      <th>Elapsed time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>200</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>8</td>\n",
       "      <td>0.030214</td>\n",
       "      <td>0.030214</td>\n",
       "      <td>39.943801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>200</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>8</td>\n",
       "      <td>0.032486</td>\n",
       "      <td>0.032486</td>\n",
       "      <td>45.786668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>200</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>8</td>\n",
       "      <td>0.032719</td>\n",
       "      <td>0.032719</td>\n",
       "      <td>45.441926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>200</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>8</td>\n",
       "      <td>0.032739</td>\n",
       "      <td>0.032739</td>\n",
       "      <td>46.380308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>200</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>8</td>\n",
       "      <td>0.032790</td>\n",
       "      <td>0.032790</td>\n",
       "      <td>43.720715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>200</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>8</td>\n",
       "      <td>0.034481</td>\n",
       "      <td>0.034481</td>\n",
       "      <td>42.996601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2</td>\n",
       "      <td>200</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>8</td>\n",
       "      <td>0.035324</td>\n",
       "      <td>0.035324</td>\n",
       "      <td>44.135023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2</td>\n",
       "      <td>200</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>8</td>\n",
       "      <td>0.035671</td>\n",
       "      <td>0.035671</td>\n",
       "      <td>83.257707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2</td>\n",
       "      <td>200</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>8</td>\n",
       "      <td>0.035960</td>\n",
       "      <td>0.035960</td>\n",
       "      <td>42.107139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2</td>\n",
       "      <td>200</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>8</td>\n",
       "      <td>0.036185</td>\n",
       "      <td>0.036185</td>\n",
       "      <td>47.565807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2</td>\n",
       "      <td>200</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>8</td>\n",
       "      <td>0.036200</td>\n",
       "      <td>0.036200</td>\n",
       "      <td>83.132527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2</td>\n",
       "      <td>200</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>8</td>\n",
       "      <td>0.036600</td>\n",
       "      <td>0.036600</td>\n",
       "      <td>44.197993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2</td>\n",
       "      <td>200</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>8</td>\n",
       "      <td>0.036846</td>\n",
       "      <td>0.036846</td>\n",
       "      <td>50.957325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>4</td>\n",
       "      <td>0.037304</td>\n",
       "      <td>0.037304</td>\n",
       "      <td>83.148535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>4</td>\n",
       "      <td>0.037828</td>\n",
       "      <td>0.037828</td>\n",
       "      <td>83.620411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2</td>\n",
       "      <td>200</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>8</td>\n",
       "      <td>0.037893</td>\n",
       "      <td>0.037893</td>\n",
       "      <td>40.661863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1</td>\n",
       "      <td>150</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>8</td>\n",
       "      <td>0.038117</td>\n",
       "      <td>0.038117</td>\n",
       "      <td>48.882195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2</td>\n",
       "      <td>150</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>16</td>\n",
       "      <td>0.038806</td>\n",
       "      <td>0.038806</td>\n",
       "      <td>23.172847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>4</td>\n",
       "      <td>0.039562</td>\n",
       "      <td>0.039562</td>\n",
       "      <td>83.574858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2</td>\n",
       "      <td>150</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>8</td>\n",
       "      <td>0.042039</td>\n",
       "      <td>0.042039</td>\n",
       "      <td>43.365115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2</td>\n",
       "      <td>150</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>8</td>\n",
       "      <td>0.045472</td>\n",
       "      <td>0.045472</td>\n",
       "      <td>83.417540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>8</td>\n",
       "      <td>0.046901</td>\n",
       "      <td>0.046901</td>\n",
       "      <td>41.930127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>4</td>\n",
       "      <td>200</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>16</td>\n",
       "      <td>0.053673</td>\n",
       "      <td>0.053673</td>\n",
       "      <td>32.846060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2</td>\n",
       "      <td>200</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>16</td>\n",
       "      <td>0.054851</td>\n",
       "      <td>0.054851</td>\n",
       "      <td>34.552666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>4</td>\n",
       "      <td>200</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>16</td>\n",
       "      <td>0.060363</td>\n",
       "      <td>0.060363</td>\n",
       "      <td>34.880829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>4</td>\n",
       "      <td>200</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>16</td>\n",
       "      <td>0.065972</td>\n",
       "      <td>0.065972</td>\n",
       "      <td>35.198601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>4</td>\n",
       "      <td>200</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>16</td>\n",
       "      <td>0.067197</td>\n",
       "      <td>0.067197</td>\n",
       "      <td>34.094530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2</td>\n",
       "      <td>200</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>2</td>\n",
       "      <td>0.081759</td>\n",
       "      <td>0.081759</td>\n",
       "      <td>154.256041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>2</td>\n",
       "      <td>0.093849</td>\n",
       "      <td>0.093849</td>\n",
       "      <td>136.265144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>4</td>\n",
       "      <td>0.106374</td>\n",
       "      <td>0.106374</td>\n",
       "      <td>51.865799</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Deep layers  Num units  Learning rate  Batch size      Loss     Score  \\\n",
       "0             2        200         0.0010           8  0.030214  0.030214   \n",
       "1             2        200         0.0010           8  0.032486  0.032486   \n",
       "2             2        200         0.0010           8  0.032719  0.032719   \n",
       "3             2        200         0.0010           8  0.032739  0.032739   \n",
       "4             2        200         0.0010           8  0.032790  0.032790   \n",
       "5             2        200         0.0010           8  0.034481  0.034481   \n",
       "6             2        200         0.0010           8  0.035324  0.035324   \n",
       "7             2        200         0.0010           8  0.035671  0.035671   \n",
       "8             2        200         0.0010           8  0.035960  0.035960   \n",
       "9             2        200         0.0001           8  0.036185  0.036185   \n",
       "10            2        200         0.0001           8  0.036200  0.036200   \n",
       "11            2        200         0.0001           8  0.036600  0.036600   \n",
       "12            2        200         0.0010           8  0.036846  0.036846   \n",
       "13            2        100         0.0001           4  0.037304  0.037304   \n",
       "14            2        100         0.0001           4  0.037828  0.037828   \n",
       "15            2        200         0.0010           8  0.037893  0.037893   \n",
       "16            1        150         0.0010           8  0.038117  0.038117   \n",
       "17            2        150         0.0010          16  0.038806  0.038806   \n",
       "18            2        100         0.0001           4  0.039562  0.039562   \n",
       "19            2        150         0.0010           8  0.042039  0.042039   \n",
       "20            2        150         0.0010           8  0.045472  0.045472   \n",
       "21            2         50         0.0001           8  0.046901  0.046901   \n",
       "22            4        200         0.0010          16  0.053673  0.053673   \n",
       "23            2        200         0.0001          16  0.054851  0.054851   \n",
       "24            4        200         0.0010          16  0.060363  0.060363   \n",
       "25            4        200         0.0010          16  0.065972  0.065972   \n",
       "26            4        200         0.0010          16  0.067197  0.067197   \n",
       "27            2        200         0.0010           2  0.081759  0.081759   \n",
       "28            3        100         0.0010           2  0.093849  0.093849   \n",
       "29            1        100         0.0001           4  0.106374  0.106374   \n",
       "\n",
       "    Elapsed time  \n",
       "0      39.943801  \n",
       "1      45.786668  \n",
       "2      45.441926  \n",
       "3      46.380308  \n",
       "4      43.720715  \n",
       "5      42.996601  \n",
       "6      44.135023  \n",
       "7      83.257707  \n",
       "8      42.107139  \n",
       "9      47.565807  \n",
       "10     83.132527  \n",
       "11     44.197993  \n",
       "12     50.957325  \n",
       "13     83.148535  \n",
       "14     83.620411  \n",
       "15     40.661863  \n",
       "16     48.882195  \n",
       "17     23.172847  \n",
       "18     83.574858  \n",
       "19     43.365115  \n",
       "20     83.417540  \n",
       "21     41.930127  \n",
       "22     32.846060  \n",
       "23     34.552666  \n",
       "24     34.880829  \n",
       "25     35.198601  \n",
       "26     34.094530  \n",
       "27    154.256041  \n",
       "28    136.265144  \n",
       "29     51.865799  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename = \"historial_genetic_jla1.txt\"\n",
    "df = pd.DataFrame(datos, columns = [\"Deep layers\", \"Num units\", \"Learning rate\", \"Batch size\", \"Loss\", \"Score\", \"Elapsed time\"])\n",
    "\n",
    "df.sort_values(by=[\"Loss\", \"Elapsed time\"], ascending=[True, True], ignore_index=True, inplace=True)\n",
    "\n",
    "df.to_csv(filename, header=True, index=False, sep='\\t', mode='w') # a=append, w=overwrite\n",
    "df.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time 28.423 minutes\n"
     ]
    }
   ],
   "source": [
    "total_time = float(np.sum(df[[\"Elapsed time\"]])/60)\n",
    "\n",
    "print(\"Elapsed time {:.3f} minutes\".format(total_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
