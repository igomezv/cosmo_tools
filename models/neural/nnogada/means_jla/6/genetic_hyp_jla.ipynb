{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-18 17:44:04.543012: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-12-18 17:44:04.726240: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-12-18 17:44:04.726295: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2022-12-18 17:44:05.954631: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2022-12-18 17:44:05.954797: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2022-12-18 17:44:05.954812: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import time, os\n",
    "import random\n",
    "import seaborn as sns\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Input, Dense, LeakyReLU\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorboard.plugins.hparams import api as hp\n",
    "\n",
    "from tensorflow.keras import activations\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "import random\n",
    "from math import floor\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import optimizers\n",
    "from scipy.integrate import odeint\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split as split\n",
    "from scipy.stats import bernoulli\n",
    "\n",
    "# import deap\n",
    "from deap import base, creator, tools, algorithms\n",
    "\n",
    "from bitstring import BitArray\n",
    "\n",
    "# from elitism import eaSimpleWithElitism, main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "\n",
    "# tf.config.optimizer.set_jit(True)\n",
    "# scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "url = 'https://raw.githubusercontent.com/igomezv/nnogada/main/data/jla.csv'\n",
    "df=pd.read_csv(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = len(df.values)\n",
    "randomize = np.random.permutation(N)\n",
    "data = df.values[randomize]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(740, 2)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N = len(df.values)\n",
    "z = data[:,0] \n",
    "y = data[:,1:3] ### coge el resto de variables a predecir \n",
    "y[:,1] = y[:,1]**2+data[:,2]\n",
    "np.shape(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "scalerz = StandardScaler()\n",
    "scalerz.fit(z.reshape(-1,1))\n",
    "z = scalerz.transform(z.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((592, 1), (148, 1), (592, 2), (148, 2))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Modificar para incluir phanteon como test\n",
    "split = 0.8\n",
    "ntrain = int(split * len(z))\n",
    "indx = [ntrain]\n",
    "X_train, X_val = np.split(z, indx)\n",
    "Y_train, Y_val = np.split(y, indx)\n",
    "# X_train, X_test = np.split(z, indx)\n",
    "# Y_train, Y_test = np.split(y, indx)\n",
    "np.shape(X_train), np.shape(X_val), Y_train.shape, Y_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "SC_DEEP       = np.array([1,2,3,4])                           # Number of deep layers (8)\n",
    "SC_NUM_UNITS  = np.array([50,100,150,200]) # Number of fully conected neurons (16)\n",
    "SC_LEARNING   = np.array([1e-4,1e-3])   # Learning rates (8)\n",
    "SC_BATCH      = np.array([2, 4, 8, 16])                            # Batch sizes (4)\n",
    "# SC_ACTIVATION = [f1, f2, f3, f4]                                      # Activation function layers (2)\n",
    "\n",
    "my_callbacks = [tf.keras.callbacks.EarlyStopping(\n",
    "                               monitor='val_loss', mode='min',\n",
    "                               min_delta=0, \n",
    "                               patience=200,\n",
    "                               verbose=1,\n",
    "                            #    baseline=0,\n",
    "                               restore_best_weights=True)\n",
    "#                 keras.callbacks.TensorBoard(\n",
    "#                                log_dir='./logs'),\n",
    "#                 keras.callbacks.ReduceLROnPlateau(\n",
    "#                                monitor='val_loss', factor=0.5,\n",
    "#                                patience=6, min_lr=0,\n",
    "#                                verbose=1)\n",
    "               ] \n",
    "    \n",
    "epochs = 200\n",
    "# epochs = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_evaluate(ga_individual_solution):   \n",
    "    t = time.time()\n",
    "    t_total = 0\n",
    "    \n",
    "    # Decode GA solution to integer for window_size and num_units\n",
    "    deep_layers_bits   = BitArray(ga_individual_solution[0:2])     # (8)\n",
    "    num_units_bits     = BitArray(ga_individual_solution[2:4])     # (16)\n",
    "    learning_rate_bits = BitArray(ga_individual_solution[4:5])    # (8)\n",
    "    batch_size_bits    = BitArray(ga_individual_solution[5:7])   # (4)\n",
    "# #     activation_f_bits  = BitArray(ga_individual_solution[12:13])   # (2)   Solo se consideran las 2 primeras\n",
    "    \n",
    "    deep_layers   = SC_DEEP[deep_layers_bits.uint]\n",
    "    num_units     = SC_NUM_UNITS[num_units_bits.uint]\n",
    "    learning_rate = SC_LEARNING[learning_rate_bits.uint]\n",
    "    batch_size   = SC_BATCH[batch_size_bits.uint]\n",
    "#     activation_f  = SC_ACTIVATION[activation_f_bits.uint]\n",
    "\n",
    "    \n",
    "    print('\\n--------------- Starting trial:', population_size*(max_generations+1)-len(ss), \"---------------\")\n",
    "    print('Deep layers:',deep_layers,', Number of neurons:',num_units,\", Learning rate:\",learning_rate)\n",
    "#     print(\"-------------------------------------------------\")\n",
    "    \n",
    "    # Train model and predict on validation set\n",
    "    model = tf.keras.Sequential()\n",
    "#     model.add(Input(shape=(int(X_train.shape[1]),)))\n",
    "    model.add(Dense(int(X_train.shape[1])))\n",
    "    \n",
    "    for i in range(deep_layers):        \n",
    "        model.add(Dense(num_units, activation='relu'))\n",
    "#             model.add(keras.layers.Dropout(0.3))\n",
    "    model.add(Dense(2, activation='linear'))\n",
    "    \n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate, beta_1=0.9, beta_2=0.999, epsilon=1e-3)\n",
    "    model.compile(optimizer=optimizer, loss='mse', metrics=['mean_squared_error'])\n",
    "    model.fit(X_train, Y_train, epochs=epochs, validation_data=(X_val, Y_val),\n",
    "              callbacks=my_callbacks, batch_size=batch_size, shuffle=False, verbose=0)\n",
    "    \n",
    "    loss, score = model.evaluate(X_val, Y_val)    \n",
    "    t = time.time()-t\n",
    "    ss.pop(0)\n",
    "    print(\"Loss:\", score, \", Elapsed time:\", t)\n",
    "    print(\"-------------------------------------------------\\n\")\n",
    "#     print(loss, score)\n",
    "\n",
    "    datos.append([deep_layers, num_units, learning_rate, batch_size, loss, score, t])\n",
    "    \n",
    "    return loss,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deap import tools\n",
    "from deap import algorithms\n",
    "\n",
    "def eaSimpleWithElitism(population, toolbox, cxpb, mutpb, ngen, stats=None,\n",
    "             halloffame=None, verbose=__debug__):\n",
    "    \"\"\"This algorithm is similar to DEAP eaSimple() algorithm, with the modification that\n",
    "    halloffame is used to implement an elitism mechanism. The individuals contained in the\n",
    "    halloffame are directly injected into the next generation and are not subject to the\n",
    "    genetic operators of selection, crossover and mutation.\n",
    "    \"\"\"\n",
    "    logbook = tools.Logbook()\n",
    "    logbook.header = ['gen', 'nevals'] + (stats.fields if stats else [])\n",
    "\n",
    "    # Evaluate the individuals with an invalid fitness\n",
    "    invalid_ind = [ind for ind in population if not ind.fitness.valid]\n",
    "    fitnesses = toolbox.map(toolbox.evaluate, invalid_ind)\n",
    "    for ind, fit in zip(invalid_ind, fitnesses):\n",
    "        ind.fitness.values = fit\n",
    "\n",
    "    if halloffame is None:\n",
    "        raise ValueError(\"halloffame parameter must not be empty!\")\n",
    "\n",
    "    halloffame.update(population)\n",
    "    hof_size = len(halloffame.items) if halloffame.items else 0\n",
    "\n",
    "    record = stats.compile(population) if stats else {}\n",
    "    logbook.record(gen=0, nevals=len(invalid_ind), **record)\n",
    "    if verbose:\n",
    "        print(logbook.stream)\n",
    "\n",
    "    # Begin the generational process\n",
    "    for gen in range(1, ngen + 1):\n",
    "\n",
    "        # Select the next generation individuals\n",
    "        offspring = toolbox.select(population, len(population) - hof_size)\n",
    "\n",
    "        # Vary the pool of individuals\n",
    "        offspring = algorithms.varAnd(offspring, toolbox, cxpb, mutpb)\n",
    "\n",
    "        # Evaluate the individuals with an invalid fitness\n",
    "        invalid_ind = [ind for ind in offspring if not ind.fitness.valid]\n",
    "        fitnesses = toolbox.map(toolbox.evaluate, invalid_ind)\n",
    "        for ind, fit in zip(invalid_ind, fitnesses):\n",
    "            ind.fitness.values = fit\n",
    "\n",
    "        # add the best back to population:\n",
    "        offspring.extend(halloffame.items)\n",
    "\n",
    "        # Update the hall of fame with the generated individuals\n",
    "        halloffame.update(offspring)\n",
    "\n",
    "        # Replace the current population by the offspring\n",
    "        population[:] = offspring\n",
    "\n",
    "        # Append the current generation statistics to the logbook\n",
    "        record = stats.compile(population) if stats else {}\n",
    "        logbook.record(gen=gen, nevals=len(invalid_ind), **record)\n",
    "        if verbose:\n",
    "            print(logbook.stream)\n",
    "\n",
    "    return population, logbook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def geneticAlgorithm_with_elitism(population_size, max_generations, gene_length, k):\n",
    "    \n",
    "    # Genetic Algorithm constants:\n",
    "    P_CROSSOVER = 0.5        # probability for crossover\n",
    "    P_MUTATION = 0.5         # probability for mutating an individual\n",
    "    HALL_OF_FAME_SIZE = 1    # Best individuals that pass to the other generation\n",
    "    \n",
    "    # set the random seed:\n",
    "    toolbox = base.Toolbox()\n",
    "\n",
    "    # As we are trying to minimize the RMSE score, that's why using -1.0. \n",
    "    # In case, when you want to maximize accuracy for instance, use 1.0\n",
    "    creator.create('FitnessMin', base.Fitness, weights = [-1.0])\n",
    "    creator.create('Individual', list , fitness = creator.FitnessMin)\n",
    "\n",
    "    # create the individual operator to fill up an Individual instance:\n",
    "    toolbox.register('binary', bernoulli.rvs, 0.5)\n",
    "    toolbox.register('individual', tools.initRepeat, creator.Individual, toolbox.binary, n = gene_length)\n",
    "\n",
    "    # create the population operator to generate a list of individuals:\n",
    "    toolbox.register('population', tools.initRepeat, list , toolbox.individual)\n",
    "\n",
    "    # genetic operators:\n",
    "    toolbox.register('evaluate', train_evaluate)\n",
    "    toolbox.register('select', tools.selTournament, tournsize = 2)\n",
    "    toolbox.register('mutate', tools.mutFlipBit, indpb = 0.11)\n",
    "    toolbox.register('mate', tools.cxUniform, indpb = 0.5)\n",
    "    \n",
    "    # create initial population (generation 0):\n",
    "    population = toolbox.population(n=population_size)\n",
    "\n",
    "    # prepare the statistics object:\n",
    "    stats = tools.Statistics(lambda ind: ind.fitness.values)\n",
    "    stats.register(\"min\", np.min)\n",
    "    stats.register(\"avg\", np.mean)\n",
    "    stats.register(\"max\", np.max)\n",
    "\n",
    "    # define the hall-of-fame object:\n",
    "    hof = tools.HallOfFame(HALL_OF_FAME_SIZE)\n",
    "\n",
    "    # Genetic Algorithm flow with elitism:\n",
    "    population, logbook = eaSimpleWithElitism(population, toolbox, cxpb=P_CROSSOVER, mutpb=P_MUTATION,\n",
    "                                              ngen=max_generations, stats=stats, halloffame=hof, verbose=True)\n",
    "\n",
    "    # print info for best solution found:\n",
    "    best = hof.items[0]\n",
    "    print(\"-- Best Individual = \", best)\n",
    "    print(\"-- Best Fitness = \", best.fitness.values[0])\n",
    "\n",
    "    # extract statistics:\n",
    "    minFitnessValues, meanFitnessValues, maxFitnessValues = logbook.select(\"min\", \"max\", \"avg\")\n",
    "\n",
    "    # plot statistics:\n",
    "    sns.set_style(\"whitegrid\")\n",
    "    plt.plot(minFitnessValues, color='blue', label=\"Min\")\n",
    "    plt.plot(meanFitnessValues, color='green', label=\"Mean\")\n",
    "    plt.plot(maxFitnessValues, color='red', label=\"Max\")\n",
    "    plt.xlabel('Generation'); plt.ylabel('Max / Min / Average Fitness')\n",
    "    plt.legend()\n",
    "    plt.title('Max, Min and Average fitness over Generations')\n",
    "    plt.show()\n",
    "    \n",
    "    best_population = tools.selBest(population,k = k)\n",
    "    return best_population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------------- Starting trial: 1 ---------------\n",
      "Deep layers: 3 , Number of neurons: 100 , Learning rate: 0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-18 17:44:07.294336: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-18 17:44:07.294690: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-12-18 17:44:07.294786: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory\n",
      "2022-12-18 17:44:07.294859: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory\n",
      "2022-12-18 17:44:07.294929: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcufft.so.10'; dlerror: libcufft.so.10: cannot open shared object file: No such file or directory\n",
      "2022-12-18 17:44:07.294998: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcurand.so.10'; dlerror: libcurand.so.10: cannot open shared object file: No such file or directory\n",
      "2022-12-18 17:44:07.295070: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory\n",
      "2022-12-18 17:44:07.295138: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory\n",
      "2022-12-18 17:44:07.295203: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2022-12-18 17:44:07.295217: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1934] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2022-12-18 17:44:07.296837: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0705 - mean_squared_error: 0.0705\n",
      "Loss: 0.07051800191402435 , Elapsed time: 131.97185349464417\n",
      "-------------------------------------------------\n",
      "\n",
      "\n",
      "--------------- Starting trial: 2 ---------------\n",
      "Deep layers: 2 , Number of neurons: 200 , Learning rate: 0.0001\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0531 - mean_squared_error: 0.0531\n",
      "Loss: 0.05305209010839462 , Elapsed time: 42.10730481147766\n",
      "-------------------------------------------------\n",
      "\n",
      "\n",
      "--------------- Starting trial: 3 ---------------\n",
      "Deep layers: 4 , Number of neurons: 200 , Learning rate: 0.001\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0611 - mean_squared_error: 0.0611\n",
      "Loss: 0.0611095055937767 , Elapsed time: 36.93574833869934\n",
      "-------------------------------------------------\n",
      "\n",
      "\n",
      "--------------- Starting trial: 4 ---------------\n",
      "Deep layers: 1 , Number of neurons: 100 , Learning rate: 0.0001\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0773 - mean_squared_error: 0.0773\n",
      "Loss: 0.07729305326938629 , Elapsed time: 82.99246978759766\n",
      "-------------------------------------------------\n",
      "\n",
      "\n",
      "--------------- Starting trial: 5 ---------------\n",
      "Deep layers: 2 , Number of neurons: 100 , Learning rate: 0.0001\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0376 - mean_squared_error: 0.0376\n",
      "Loss: 0.03761541098356247 , Elapsed time: 83.13248181343079\n",
      "-------------------------------------------------\n",
      "\n",
      "gen\tnevals\tmin      \tavg      \tmax      \n",
      "0  \t5     \t0.0376154\t0.0599176\t0.0772931\n",
      "\n",
      "--------------- Starting trial: 6 ---------------\n",
      "Deep layers: 2 , Number of neurons: 100 , Learning rate: 0.0001\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0363 - mean_squared_error: 0.0363\n",
      "Loss: 0.03629078343510628 , Elapsed time: 64.97287559509277\n",
      "-------------------------------------------------\n",
      "\n",
      "\n",
      "--------------- Starting trial: 7 ---------------\n",
      "Deep layers: 2 , Number of neurons: 100 , Learning rate: 0.001\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0414 - mean_squared_error: 0.0414\n",
      "Loss: 0.04137326404452324 , Elapsed time: 74.3640067577362\n",
      "-------------------------------------------------\n",
      "\n",
      "\n",
      "--------------- Starting trial: 8 ---------------\n",
      "Deep layers: 2 , Number of neurons: 100 , Learning rate: 0.0001\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0384 - mean_squared_error: 0.0384\n",
      "Loss: 0.038395706564188004 , Elapsed time: 59.036834716796875\n",
      "-------------------------------------------------\n",
      "\n",
      "\n",
      "--------------- Starting trial: 9 ---------------\n",
      "Deep layers: 2 , Number of neurons: 100 , Learning rate: 0.0001\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0359 - mean_squared_error: 0.0359\n",
      "Loss: 0.035871248692274094 , Elapsed time: 58.48614430427551\n",
      "-------------------------------------------------\n",
      "\n",
      "1  \t4     \t0.0358712\t0.0379093\t0.0413733\n",
      "\n",
      "--------------- Starting trial: 10 ---------------\n",
      "Deep layers: 2 , Number of neurons: 100 , Learning rate: 0.0001\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0317 - mean_squared_error: 0.0317\n",
      "Loss: 0.03168009966611862 , Elapsed time: 124.55173373222351\n",
      "-------------------------------------------------\n",
      "\n",
      "\n",
      "--------------- Starting trial: 11 ---------------\n",
      "Deep layers: 2 , Number of neurons: 100 , Learning rate: 0.0001\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0348 - mean_squared_error: 0.0348\n",
      "Loss: 0.03481781855225563 , Elapsed time: 84.04839563369751\n",
      "-------------------------------------------------\n",
      "\n",
      "\n",
      "--------------- Starting trial: 12 ---------------\n",
      "Deep layers: 2 , Number of neurons: 100 , Learning rate: 0.0001\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0608 - mean_squared_error: 0.0608\n",
      "Loss: 0.06075116619467735 , Elapsed time: 21.988516807556152\n",
      "-------------------------------------------------\n",
      "\n",
      "\n",
      "--------------- Starting trial: 13 ---------------\n",
      "Deep layers: 2 , Number of neurons: 100 , Learning rate: 0.0001\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0352 - mean_squared_error: 0.0352\n",
      "Loss: 0.03521953523159027 , Elapsed time: 64.1614682674408\n",
      "-------------------------------------------------\n",
      "\n",
      "2  \t4     \t0.0316801\t0.0400168\t0.0607512\n",
      "\n",
      "--------------- Starting trial: 14 ---------------\n",
      "Deep layers: 2 , Number of neurons: 100 , Learning rate: 0.0001\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0368 - mean_squared_error: 0.0368\n",
      "Loss: 0.0367731936275959 , Elapsed time: 83.10196685791016\n",
      "-------------------------------------------------\n",
      "\n",
      "\n",
      "--------------- Starting trial: 15 ---------------\n",
      "Deep layers: 2 , Number of neurons: 100 , Learning rate: 0.0001\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0314 - mean_squared_error: 0.0314\n",
      "Loss: 0.031374990940093994 , Elapsed time: 124.22580480575562\n",
      "-------------------------------------------------\n",
      "\n",
      "\n",
      "--------------- Starting trial: 16 ---------------\n",
      "Deep layers: 2 , Number of neurons: 100 , Learning rate: 0.0001\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0368 - mean_squared_error: 0.0368\n",
      "Loss: 0.03683008253574371 , Elapsed time: 71.71314907073975\n",
      "-------------------------------------------------\n",
      "\n",
      "\n",
      "--------------- Starting trial: 17 ---------------\n",
      "Deep layers: 2 , Number of neurons: 100 , Learning rate: 0.0001\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0313 - mean_squared_error: 0.0313\n",
      "Loss: 0.03128954395651817 , Elapsed time: 123.86458015441895\n",
      "-------------------------------------------------\n",
      "\n",
      "3  \t4     \t0.0312895\t0.0335896\t0.0368301\n",
      "\n",
      "--------------- Starting trial: 18 ---------------\n",
      "Deep layers: 4 , Number of neurons: 100 , Learning rate: 0.0001\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0445 - mean_squared_error: 0.0445\n",
      "Loss: 0.044468365609645844 , Elapsed time: 43.986427783966064\n",
      "-------------------------------------------------\n",
      "\n",
      "\n",
      "--------------- Starting trial: 19 ---------------\n",
      "Deep layers: 4 , Number of neurons: 100 , Learning rate: 0.0001\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0353 - mean_squared_error: 0.0353\n",
      "Loss: 0.03528303653001785 , Elapsed time: 157.14062690734863\n",
      "-------------------------------------------------\n",
      "\n",
      "\n",
      "--------------- Starting trial: 20 ---------------\n",
      "Deep layers: 2 , Number of neurons: 100 , Learning rate: 0.0001\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0313 - mean_squared_error: 0.0313\n",
      "Loss: 0.031325340270996094 , Elapsed time: 138.1097948551178\n",
      "-------------------------------------------------\n",
      "\n",
      "\n",
      "--------------- Starting trial: 21 ---------------\n",
      "Deep layers: 2 , Number of neurons: 100 , Learning rate: 0.001\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0544 - mean_squared_error: 0.0544\n",
      "Loss: 0.05442046374082565 , Elapsed time: 129.38268899917603\n",
      "-------------------------------------------------\n",
      "\n",
      "4  \t4     \t0.0313253\t0.0394355\t0.0544205\n",
      "\n",
      "--------------- Starting trial: 22 ---------------\n",
      "Deep layers: 2 , Number of neurons: 100 , Learning rate: 0.0001\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0312 - mean_squared_error: 0.0312\n",
      "Loss: 0.03122062049806118 , Elapsed time: 143.87008690834045\n",
      "-------------------------------------------------\n",
      "\n",
      "\n",
      "--------------- Starting trial: 23 ---------------\n",
      "Deep layers: 2 , Number of neurons: 100 , Learning rate: 0.0001\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0320 - mean_squared_error: 0.0320\n",
      "Loss: 0.0319841094315052 , Elapsed time: 118.01686501502991\n",
      "-------------------------------------------------\n",
      "\n",
      "\n",
      "--------------- Starting trial: 24 ---------------\n",
      "Deep layers: 2 , Number of neurons: 100 , Learning rate: 0.0001\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0315 - mean_squared_error: 0.0315\n",
      "Loss: 0.03147375211119652 , Elapsed time: 110.12098789215088\n",
      "-------------------------------------------------\n",
      "\n",
      "\n",
      "--------------- Starting trial: 25 ---------------\n",
      "Deep layers: 4 , Number of neurons: 100 , Learning rate: 0.0001\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0384 - mean_squared_error: 0.0384\n",
      "Loss: 0.03838874027132988 , Elapsed time: 119.12649345397949\n",
      "-------------------------------------------------\n",
      "\n",
      "5  \t4     \t0.0312206\t0.0329495\t0.0383887\n",
      "\n",
      "--------------- Starting trial: 26 ---------------\n",
      "Deep layers: 2 , Number of neurons: 100 , Learning rate: 0.0001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0315 - mean_squared_error: 0.0315\n",
      "Loss: 0.031510017812252045 , Elapsed time: 112.54294085502625\n",
      "-------------------------------------------------\n",
      "\n",
      "\n",
      "--------------- Starting trial: 27 ---------------\n",
      "Deep layers: 2 , Number of neurons: 100 , Learning rate: 0.0001\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0315 - mean_squared_error: 0.0315\n",
      "Loss: 0.031542159616947174 , Elapsed time: 102.96316623687744\n",
      "-------------------------------------------------\n",
      "\n",
      "\n",
      "--------------- Starting trial: 28 ---------------\n",
      "Deep layers: 2 , Number of neurons: 100 , Learning rate: 0.0001\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0302 - mean_squared_error: 0.0302\n",
      "Loss: 0.03024234250187874 , Elapsed time: 102.09113335609436\n",
      "-------------------------------------------------\n",
      "\n",
      "\n",
      "--------------- Starting trial: 29 ---------------\n",
      "Deep layers: 4 , Number of neurons: 100 , Learning rate: 0.0001\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0340 - mean_squared_error: 0.0340\n",
      "Loss: 0.0339990109205246 , Elapsed time: 60.671294927597046\n",
      "-------------------------------------------------\n",
      "\n",
      "6  \t4     \t0.0302423\t0.0317947\t0.033999 \n",
      "\n",
      "--------------- Starting trial: 30 ---------------\n",
      "Deep layers: 4 , Number of neurons: 100 , Learning rate: 0.0001\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0357 - mean_squared_error: 0.0357\n",
      "Loss: 0.03570356220006943 , Elapsed time: 38.58480739593506\n",
      "-------------------------------------------------\n",
      "\n",
      "\n",
      "--------------- Starting trial: 31 ---------------\n",
      "Deep layers: 2 , Number of neurons: 100 , Learning rate: 0.0001\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0330 - mean_squared_error: 0.0330\n",
      "Loss: 0.032966408878564835 , Elapsed time: 93.91533851623535\n",
      "-------------------------------------------------\n",
      "\n",
      "7  \t2     \t0.0316801\t0.0332058\t0.0357036\n",
      "\n",
      "--------------- Starting trial: 32 ---------------\n",
      "Deep layers: 2 , Number of neurons: 100 , Learning rate: 0.0001\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0323 - mean_squared_error: 0.0323\n",
      "Loss: 0.0323028601706028 , Elapsed time: 80.19778752326965\n",
      "-------------------------------------------------\n",
      "\n",
      "8  \t1     \t0.0316801\t0.0320619\t0.0329664\n",
      "\n",
      "--------------- Starting trial: 33 ---------------\n",
      "Deep layers: 2 , Number of neurons: 100 , Learning rate: 0.0001\n",
      "5/5 [==============================] - 1s 2ms/step - loss: 0.0316 - mean_squared_error: 0.0316\n",
      "Loss: 0.031596411019563675 , Elapsed time: 76.19845461845398\n",
      "-------------------------------------------------\n",
      "\n",
      "\n",
      "--------------- Starting trial: 34 ---------------\n",
      "Deep layers: 1 , Number of neurons: 50 , Learning rate: 0.0001\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0693 - mean_squared_error: 0.0693\n",
      "Loss: 0.0692535862326622 , Elapsed time: 64.96837115287781\n",
      "-------------------------------------------------\n",
      "\n",
      "\n",
      "--------------- Starting trial: 35 ---------------\n",
      "Deep layers: 2 , Number of neurons: 100 , Learning rate: 0.0001\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0314 - mean_squared_error: 0.0314\n",
      "Loss: 0.03136984258890152 , Elapsed time: 70.83247065544128\n",
      "-------------------------------------------------\n",
      "\n",
      "9  \t3     \t0.0313698\t0.039116 \t0.0692536\n",
      "\n",
      "--------------- Starting trial: 36 ---------------\n",
      "Deep layers: 2 , Number of neurons: 200 , Learning rate: 0.001\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0341 - mean_squared_error: 0.0341\n",
      "Loss: 0.0341290608048439 , Elapsed time: 25.646225214004517\n",
      "-------------------------------------------------\n",
      "\n",
      "\n",
      "--------------- Starting trial: 37 ---------------\n",
      "Deep layers: 2 , Number of neurons: 100 , Learning rate: 0.0001\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0319 - mean_squared_error: 0.0319\n",
      "Loss: 0.03186865523457527 , Elapsed time: 65.89750480651855\n",
      "-------------------------------------------------\n",
      "\n",
      "10 \t2     \t0.0313698\t0.0321288\t0.0341291\n",
      "-- Best Individual =  [0, 1, 0, 1, 0, 0, 0]\n",
      "-- Best Fitness =  0.03168009966611862\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEWCAYAAAB8LwAVAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAABvCUlEQVR4nO2dd1hT1xvHvwkbAQVkg1uGOECCSquiKKIiiIID62pr66ijjlprq+Juf67WrdWq1FbrhCputOBEAYEquEVlK6DsEJLz++M2ESSQAJlwPs+TB5J77jnvyU3yvee857wvixBCQKFQKBTKB7CVbQCFQqFQVBMqEBQKhUIRCxUICoVCoYiFCgSFQqFQxEIFgkKhUChioQJBoVAoFLFQgWikZGRkwNXVFXw+X9mmwMvLCzdu3FC2GQrlzz//xEcffQRXV1fk5+fD1dUVr169UrZZFDkwZcoUnDx5UtlmyAUqEHXEy8sLnTt3Rl5eXpXXhw8fDgcHB6Slpcm1/RMnTsDBwQFr166t8vqlS5fg4OCARYsWAQCsra1x9+5daGhoyNUeWbFlyxY4ODggKSlJ2aY0GB6Phx9//BG//fYb7t69C2NjY9y9exd2dnYAgEWLFmHTpk1KtlJ1+PfffzF16lS4u7uDw+Fg6NCh2LRpE969e6ds06qxZcsWLFiwoMpre/bswYgRI5RkkXyhAlEPbGxsEBERIXr+8OFDlJWVKaz9Vq1a4cyZM6ioqBC9FhYWhjZt2ijMBllCCEF4eDhatGghtzsxRY6kcnNzweVy0aFDB4W1qQ5U/rwKiY+Px8SJE9G9e3ecPXsWsbGx2LNnDzQ0NPDgwQOl29fUoQJRD4YPH46wsDDR87CwMAQEBFQp888//yAgIADdu3eHp6cntmzZIjp25swZDBgwAEVFRQCAqKgofPzxx9VGJTXRsmVL2Nvb49q1awCAt2/f4u7du/Dy8hKVSUtLg4ODg+hDP2HCBPz8888YO3YsXF1d8dlnn9XY3rt37zB16lT06tUL7u7umDp1KrKyskTHJdUVFhaG/v37o2fPntixY4fE/sTGxiInJweLFy/GmTNnUF5eDgD4/PPPcfDgwSpl/f39ceHCBQDA06dP8emnn6JHjx7w8fHBmTNnROUWLVqEZcuW4YsvvoCLiwtiYmJqvSYf2r1t27YqU2MCgQC7d+/GwIED0bNnT8yZMwdv376t1pfnz59j8ODBAAB3d3dMnDgRAODg4IAXL17gr7/+wqlTp7B37164urpi2rRpAJiR6d69e+Hn5wc3Nzd8/fXX4HK5onqvXLmC4cOHg8PhYOzYsVV+PHfv3o0+ffrA1dUVPj4+uHnzJgAgKSkJI0eORPfu3fHRRx9VG3VW5siRI/D29kaPHj0wbdo0ZGdnAwCWLl2Kn376qUrZ6dOnY9++fQCA7OxszJo1C7169YKXlxdCQ0NF5bZs2YLZs2djwYIF6N69u1jxX7duHUaOHImpU6eiZcuWAJjR7+zZs9GzZ09RuWPHjmHIkCFwd3fH559/jvT0dNExBwcHHDp0CIMGDYK7uzuWL1+OygEiJJ37xx9/YNCgQRg0aBAAYNWqVfD09ET37t0xcuRIxMbGAgCio6Oxa9cunD17Fq6urvD39wfAfB+OHj0KgPmcbN++Hf3794eHhwcWLlyIwsJCAO+/kydPnkS/fv2qfT/qcr0UBqHUif79+5Pr16+TQYMGkSdPnpCKigrSt29fkpaWRuzt7cmrV68IIYTcunWLPHjwgPD5fJKSkkI8PDzIxYsXRfXMmzePfPvttyQvL498/PHH5PLly1K1f/z4cTJ27Fjy999/kzlz5hBCCDl48CBZsmQJ2bhxI/n2228JIYS8evWK2NvbEx6PRwghZPz48WTAgAHk2bNnpLS0lIwfP56sW7dObBt5eXnk3LlzpKSkhBQWFpJZs2aR6dOni47XVtfjx4+Ji4sLuX37NuFyuWTNmjXEycmJXL9+vcY+fffdd2T27NmkvLyc9OjRg5w/f54QQsjJkyfJmDFjROUeP35M3NzcCJfLJcXFxaRv377k2LFjhMfjkXv37pEePXqQR48eEUII+fbbb0n37t1JbGws4fP5pKysrNZrIrT7zp07hMvlkh9//JF06tRJZPe+ffvIqFGjSGZmJuFyuWTJkiVk7ty5Yvvz4XtPCCH29vYkNTVVZNvGjRurnNO/f38SGBhIsrKySH5+Phk8eDD5888/CSGE3Lt3j/Tq1YskJCSQiooKcuLECdK/f3/C5XLJ06dPSd++fUlWVpao7RcvXhBCCBk9ejQ5efIkIYSQoqIicvfuXbH23rhxg/To0YPcu3ePcLlcsmLFCjJu3DhCCCG3b98mffv2JQKBgBBCyNu3b0mXLl1IVlYW4fP5ZMSIEWTLli2Ey+WSly9fEi8vLxIdHU0IIWTz5s2kU6dO5OLFi4TP55PS0tIq7RYXFxNHR0dy69YtsXYJuXjxIhk4cCB58uQJ4fF4ZNu2bVU+F/b29uTLL78k7969I+np6aRnz54kKipK6nMnT55M8vPzRfaFhYWRvLw8wuPxyN69e8lHH31EysrKRH2aP39+FfvGjx9Pjhw5Qggh5OjRo2TgwIHk5cuXpKioiHz11VdkwYIFomtjb29Pvv/+e1JaWkpSUlKIs7MzefLkSZ2ulyKhI4h6IhxFXL9+He3atYOFhUWV4z179oSDgwPYbDYcHR3h6+uL27dvi44vW7YMt27dwsSJE+Hl5YX+/fvXqX1vb2/cvn0bhYWFCA8Px/DhwyWeM3LkSLRt2xa6uroYPHgwUlJSxJYzNjaGj48P9PT0YGBggOnTp+POnTtS1XXu3Dn069cP7u7u0NbWxpw5c8Bm1/wxKy0txblz5+Dn5wctLS34+PiI7jQHDhyIBw8eiO74Tp06BW9vb2hra+Off/6BjY0NAgMDoampCWdnZ/j4+OD8+fOiugcMGAA3Nzew2Wzo6OjUek3OnTuH/v37g8PhQFtbG7NnzwaLxRLV9ddff2Hu3LmwtLSEtrY2Zs6cifPnz8t0WmLChAmwsLBAixYt0L9/f9F7euTIEYwZMwbdunWDhoYGRowYAS0tLSQkJEBDQwPl5eV4+vQpeDwebG1t0apVKwCApqYmXr58iby8PDRr1gwuLi5i2z116hQCAwPh7OwMbW1tzJs3DwkJCUhLSwOHwwGLxRLdRZ8/fx4uLi6wsLDAv//+i7y8PMycORPa2tqws7PD6NGjq4zkXFxcMHDgQLDZbOjq6lZpt6CgAAKBQDRyAID//e9/4HA4cHFxwfbt2wEAhw8fxpdffon27dtDU1MT06ZNQ0pKSpWRwBdffAEjIyNYW1ujZ8+eohGWNOd++eWXaNGihci+4cOHw9jYGJqamvjss89QXl6O58+fS3UNT506hcmTJ8POzg7NmjXDvHnzqk0Hz5w5E7q6unB0dISjo6PIVmmvlyLRVLYB6srw4cMxfvx4pKWlif1xTkxMxPr16/H48WPweDyUl5eLph4AwMjICIMHD8a+ffuwefPmOrevq6sLT09PbN++Hfn5+XBzc0N0dHSt55iZmYn+19PTQ0lJidhypaWlWLt2La5evSpyFBYXF4PP54uc3jXVlZOTA0tLS9ExfX19tGjRokabLl68CE1NTfTt2xcA4Ofnh08//RR5eXkwMTGBp6cnIiIi8OWXXyIiIgIrV64EAKSnpyMpKQkcDkdUF5/PFw37AcDKyqpKW7Vdkw/t1tPTq2J3RkYGvvrqqypix2azkZubW+3moL58+J7m5OSI2g4LC6sy3cbj8ZCTk4MePXpg8eLF2LJlC548eYLevXtj0aJFsLCwwOrVq7F582YMGTIEtra2mDlzptgbkZycHDg7O4ueN2vWDC1atEB2djZsbW0xdOhQnD59Gu7u7jh16pToPU5PT0dOTk61a1D5eeX39EOMjIzAZrPx+vVrtG/fHgCwcOFCLFy4EAsWLBD5jTIyMrBmzZoqU12EEGRnZ8PGxkbse1dcXCz1uR9+Tn777TccPXoUOTk5YLFYKCoqQn5+fo39qExOTo6oXoDxV1ZUVCA3N1f0WmVBrPzdkfZ6KRIqEPXExsYGtra2iIqKwurVq6sdnz9/PsaPH489e/ZAR0cHq1evrvIhS0lJwfHjxzFs2DCsWrUKe/furbMNAQEBmDRpEmbOnNmgvnzIb7/9hufPn+PIkSMwMzNDSkoKAgICqszr1oS5uTmePn0qel5aWip2rl5IWFgYSkpKRF8EQgh4PB5Onz6NiRMnYtiwYdi6dSvc3d1RVlYmmpe2srKCu7u7aC5cGmq7Jubm5lXuEsvKyqrYbWlpiTVr1sDNzU3q9mqi8shEGqysrDBt2jRMnz5d7HE/Pz/4+fmhqKgIS5cuxfr167Fu3Tq0adMGGzduhEAgwIULFzB79mzExMRAX1+/yvnm5uZV7qhLSkrw9u1bkfANGzYMn332Gb788kskJSVh27ZtIrtsbW1FPqG69lVfXx/dunXDxYsX0atXL4n9ryz+0iLNuZVtjI2Nxa+//or9+/ejY8eOYLPZcHd3F332JV27D9/LjIwMaGpqwtTUtIofTxzSXi9FQqeYGsDq1atx4MABsRewuLgYzZs3h46ODpKSknD69GnRMS6Xi2+++QZz587F2rVrkZOTgz/++EN0fMKECdUcqOLo0aMH9u3bh/Hjx8umQ5Vs19HRgZGREd6+fYutW7dKfa6Pjw/++ecfxMbGory8HJs3b4ZAIBBbNjs7Gzdv3sTOnTsRFhaGsLAwhIeH44svvhAtAvD09ERGRgY2b96MoUOHiu7g+/Xrh9TUVISFhYHH44HH4yEpKamKOInrV03XxMfHB5cvX0Z8fLzI7sqCGBwcjJ9//ln05c/Ly8OlS5ekfl8qY2pqWqfl0KNGjcLhw4eRmJgIQghKSkrwzz//oKioCM+ePcPNmzdRXl4ObW1t6OjoiEZ54eHhyMvLA5vNhpGREQCIXfbs5+eHEydOICUlBeXl5di4cSO6du0KW1tbAECnTp1gYmKCH374Ab179xbV1bVrVxgYGGD37t0oKysDn8/Ho0eP6rRUecGCBTh+/Dh2794tusvOysqq8v6MHTsWu3fvxuPHjwEAhYWFOHv2rFT11/Xc4uJiaGhowMTEBBUVFdi6datoMQnAXLv09PQaP9PDhg3DgQMH8OrVKxQXF2PTpk0YMmQINDUl34tLe70UCRWIBtCqVSt06dJF7LFly5Zh8+bNcHV1xbZt2zBkyBDRsQ0bNsDCwgLjxo2DtrY21q1bh19++QWpqakAgMzMTHTv3l1i+ywWCx4eHrVO4dSHSZMmgcvlolevXhgzZgz69Okj9bkdO3bE0qVLsWDBAvTp0wdGRkY1TjOEh4fDyckJvXv3hpmZmegxYcIEPHz4EI8ePYK2tja8vb1x48YNDBs2THSugYEB9u7dizNnzqBPnz7o3bs31q9fL1oBJY7arknHjh2xZMkSzJs3D3369EGzZs1gYmICbW1tABD5ij777DO4urpi9OjR9d6zERQUhCdPnoDD4WDGjBkSy3fp0gUrV67EihUr4O7ujkGDBuHEiRMAgPLycmzYsAE9e/ZE7969kZeXh7lz5wIArl69Cl9fX7i6umL16tXYtGkTdHR0qtXv4eGBOXPmYNasWejduzdevXpVbZ+Gr69vtWugoaGBHTt24MGDBxgwYAB69eqFH374ocoPqiQ4HA4OHDiAO3fuwMfHBxwOB1OmTEHPnj1FNz7e3t6YMmUK5s2bh+7du2PYsGESp1OF1PXc3r17o2/fvvDx8YGXlxd0dHSqTEEJpyR79uwpdu9DYGAg/P39MX78eAwYMADa2tpYsmSJVLZKe70UCYtIM29AURhZWVmYM2cO/vrrL2Wb0qQpLi6Gu7s7zp8/L9rgRqE0NahAUCj/cfnyZXh4eIAQgh9//BFJSUk4efJknX0GFEpjgU4xUSj/ERkZiT59+qBPnz548eIFNm7cSMWB0qShIwgKhUKhiIWOICgUCoUilka1DyIhIaHeXn8ul6v0FQOKhva58dPU+gvQPtfn3Jp2bTcqgdDR0YGTk1O9zk1JSan3ueoK7XPjp6n1F6B9rs+5NUGnmCgUCoUiFioQFAqFQhELFQgKhUKhiKVR+SAolJrg8XhIS0sDj8erdc61scHj8fD8+XPY2tpCS0tL2eZQ1AwqEJQmQVpaGgwNDWFhYaHU6JiKpqSkBCUlJUhLS0Pbtm2VbQ5FzaBTTJQmQVlZGUxNTZvczmgWiwVTU1OF5kynNB6oQFCaDE1NHIQ01X5TGg4VCACnH51GZkmmss2gUCgUlYIKBIAZETOw4/4OZZtBaeQ4ODjgm2++ET2vqKhAr169MHXqVABMsMDdu3cryzwKpRrUSQ2gk1kn3Mu9p2wzKI0cfX19PH78GGVlZdDV1cX169er5LMeMGAABgwYoEQLKZSq0BEEADcrNzx59wSlvFJlm0Jp5PTt2xf//PMPACAiIgK+vr6iYydOnMCKFSsAAIsWLcKqVaswduxYDBgwAOfOnVOGuZQmDh1BAOBYc1BBKpCUnYSetj2VbQ5FzoSGAr/9Jts6P/sMmDhRcrmhQ4di+/bt6N+/Px4+fIjAwEDExcWJLZuTk4M///wTz549w/Tp00XpLikURUFHEADcrN0AAHGZ4r+oFIqscHR0RFpaGk6fPg1PT89ayw4cOBBsNhsdOnTAmzdvFGQhhfIeOoIAYGdkBxMdE8RmxCrbFIoCmDhRurt9eeHl5YX//e9/CA0Nxdu3b2ssp62trTijKBQxUIEAs07c2diZjiAoCiEoKAiGhoZwcHBATEyMss2hUGqETjH9h7OxM+7n3EcJr0TZplAaOZaWlpg0aZKyzaBQJEJHEP/hbOIMPuEjMSsRHnYeyjaH0gi5e/dutdd69uyJnj2ZhREjR47EyJEjAQA//vijxHMpFHlDRxD/0dm4MwDqqKZQKBQhVCD+w1zPHBbNLKijmkKhUP6DCsR/sFgscKw5VCAoFArlP6hAVIJjzUHKmxQUlxcr2xQKhUJROlQgKuFm5QYBESAhK0HZplAoFIrSoQJRCbqjmkKhUN5DBaIS1obWsDKwon4IilyQFO6bQlE1qEB8AHVUU+RF5XDfAKqF+6ZQVA0qEB/AsebgwZsHKCovUrYplEZIbeG+S0pK8N133yEwMBABAQG4dOkSACAtLQ3jxo3DiBEjMGLECMTHxwMAYmJiMGHCBMyePRuDBw/G/PnzQQhReJ8ojRe6k/oD3KzcQEBwN/Mu+rTuo2xzKHIgNDEUv92Vbbzvz1w/w8RukiMA1hbue+fOnejVqxfWrl2LgoICjBo1Ch999BFMTU2xb98+6OjoIDU1FfPmzcOJEycAAMnJyYiIiIC5uTmCg4MRFxcHDocj075Rmi5UID5A6KiOzYilAkGRObWF+7527RouX76M3/5LVsHlcpGZmQlzc3OsWLECDx48AJvNRmpqquicrl27wtLSUlR3eno6FQiKzKAC8QGWBpawNbKlK5kaMRO7TZTqbl9e1Bbue/PmzWjXrl2V17Zs2YKWLVsiPDwcAoEAXbt2FR2rHBJcQ0MDfD5frrZTmhbUByEGNys36qimyI2goCDMmDEDDg4OVV7v3bs3Dh48KPIjJCcnAwAKCwthZmYGNpuN8PBwKgIUhUEFQgwcaw4e5j5EAbdA2aZQGiE1hfueMWMGKioq4O/vj2HDhuGXX34BAIwbNw4nT57E6NGjkZqaCn19fUWbTGmi0CkmMXCsmTncu5l34dmm9rSQFIq0SAr3raurixUrVlQr06ZNG5w6dUr0fP78+dXOBYClS5fK2mRKE4eOIMTgZvXeUU2hUChNFSoQYjBrZoZWzVtRRzWFQmnSUIGoAeqoplAoTR0qEDXAsebgcd5jvCt7p2xTKBQKRSnIVSCio6Ph4+MDb29v7N69u9pxQghWrVoFb29v+Pn54f79+wCAZ8+eYfjw4aJH9+7dsX//fnmaWg2hozo+M16h7VIoFIqqILdVTHw+HytWrMC+fftgYWGBoKAgeHl5oUOHDqIy0dHRSE1NxYULF5CYmIiQkBAcPXoU7dq1Q3h4uKievn37wtvbW16miqWyo7p/2/4KbZtCoVBUAbmNIJKSktC6dWvY2dlBW1sbvr6+iIyMrFImMjISAQEBYLFYcHFxQUFBAXJycqqUuXnzJuzs7GBjYyMvU8Viqm+KNi3aIDaT+iEosoGG+6aoG3IbQWRnZ4tixACAhYUFkpKSai1jaWmJ7OxsmJubi16LiIjAsGHDpGqTy+UiJSWlXvaWlZVVO9fewB43X9ysd52qjrg+N1Z4PB5KS0tBCEFpaalSbNDT08PDhw+Rn58PXV1dXLt2DWZmZuDz+XKzSdhfHo/XZK51U/pcC5FXn+skEAKBACUlJTAwMJBYVlzYYRaLVacy5eXluHz5smhjkCR0dHTg5OQkVdkPSUlJqXZu/9z+uBB5AZZtLGGsZ1yvelUZcX1urKSkpEBPTw+lpaXQ09NTig0sFgv9+vVDTEwMBg8ejIsXL8LPzw9xcXHQ09NDUlIS1qxZg7KyMujq6mLNmjVo164d9u3bh0ePHmHt2rV4+PAh5s+fj6NHj0rVD2F/tbS0mtS1bip9FdKQPtcmLBIFYv78+Vi+fDnYbDZGjhyJoqIiTJ48GVOmTKn1PEtLS2RlZYmefzgyEFcmKyurSpno6Gg4OzujZcuWksyUC5Ud1QPaDVCKDRQ5EBoK/CbbcN/47DNgYsPCfbdr1w4HDx6EpqYmbty4gU2bNmHLli2YNGkSJkyYgIsXL2LHjh1Yvny50kSOIh4BEWD++fmY0G0Cult1V7Y5MkOiD+LJkycwMDDApUuX4OnpiStXrogcyLXRpUsXpKam4tWrVygvL0dERAS8vLyqlPHy8kJYWBgIIUhISIChoWG16aXKCVUUjfBC0/0QFFlRW7jvwsJCzJkzB8OGDcPatWvx+PFjAACbzcaPP/6IhQsXokePHnBzc1OG6ZRaeJr3FD/H/Iy98XuVbYpMkTiCqKioAI/Hw6VLlzB+/HhoaWlVmyoSW7GmJpYuXYopU6aAz+cjMDAQHTt2xKFDhwAAwcHB8PT0RFRUFLy9vaGnp4c1a9aIzi8tLcWNGzfExqZRFCZ6Jmhn3I46qhsbEydKdbcvL2oK9/3LL7+gZ8+e2LZtG9LS0jCxko3CIH0fLuKgqAbCqAt3Mu4o2RLZIlEgxowZAy8vLzg6OsLd3R3p6elS+SAAwNPTs9pdUnBwsOh/FouFZcuWiT1XT08PMTExUrUjTzjWHNxJb1wXnaJcgoKCYGhoCAcHhyqf8cLCQlGO6pMnT1Z5ffXq1Th48CBWrlyJc+fOYfDgwQq3m1IzcRmMQCRmJ6KcXw5tDW0JZ6gHEqeYJk6ciKtXr+LXX38Fi8WCjY0NQkNDFWGbSuBm5Ybnb58jtyRX2aZQGgk1hfueMmUKNm7ciLFjx1bJ+bBmzRqMGzcObdu2xerVq7Fhwwbk5tLPoyoRlxkHFlgo55cjKTtJ8glqgkSBOHDgAIqKikAIweLFizFixAjcunVLEbapBEJHNQ3cR2koNYX73rVrFwDA1dUV58+fx+HDh/H111/j8uXLAIC1a9eKppusrKxw8eJFmJqaKs5wSq0IiABxmXHw6eADAI1qxkGiQBw/fhwGBga4du0a8vLysHbtWmzYsEERtqkEQke1cAhJoVAolXma9xQF3AIEOgXCVM+0US1qkSgQwr0KUVFRCAwMhKOjo9j9C42VFrot0MGkA3VUUygUsQhnFzjWHLjbuDcqR7VEgejcuTM+++wzREdHo3fv3igqKgKb3bSCwHKsOY3qrqCp0pRubCrTVPutKOIy4qCjoQNnM2e4W7vj/uv7KC4vVrZZMkHiL/3q1asxf/58HDt2DHp6euDxeFWWozYFOFYcvHz3Eq+LXyvbFEo90dXVRW5ubpP7sSSEIDc3F7q6uso2pdESlxmHrhZdoaWhBXdrdwiIAHezqvub1BGJy1xZLBaePHmCK1euYObMmSgtLUV5ebkibFMZ3KyZjUlxmXEY3IEuL1RHbG1tkZaWhoyMDGhpaSnbHIXB4/FgaGgIW1tbZZvSKCGEID4zHsGdmeX7wkUtd9LvoHer3so0TSZIFIiQkBCw2WzcunULM2fORLNmzTBr1iwcP35cEfapBJUd1VQg1BMtLS20bdu2ycXpSUlJQdu2bZVtRqPlaf5TvOO+E91EWhlawcbQptH4LCVOMSUlJWHZsmXQ0dEBADRv3hw8Hk/uhqkSRjpGsDe1bzQXnUKhyAbh6kZh/hgAjKO6kSx1lSgQmpqa4PP5ovAaeXl5Tc5JDVBHNYVCqU5cZhy0NbThbO4ses3d2h2P8x7jbdlb5RkmIyT+0k+YMAFfffUVcnNzsWnTJgQHBzfJBCccKw7SCtKQXZStbFMoFIqKIHRQVw6t4W7tDqBxBPmU6IPw9/eHs7Mzbt26BUIItm/fjvbt2yvCNpWisqN6aMehSraGQqEoG0II4jLiMLbz2CqvV3ZUD2w3UBmmyQypEga1adMGBgYGovgwGRkZsLa2lqthqoarpStYYCE2I5YKBIVCETmohYIgxFjPGO2N2zcKn6VEgfj999+xdetWtGzZsorv4dSpU3I1TNUw1DGEY0tHGpOJQqEAEO+gFuJu447rL68r2iSZI1EgQkNDce7cORgbN76Um3XFzdoNl59fVrYZFApFBRDnoBbibu2Ow/cOI7soGxYGFkqwTjZIdFJbWlrC0NBQEbaoPBwrDjIKM5BZmKlsUygUipIR56AWInRUq3tcJokjCDs7O0yYMAH9+vWDtvb7N+LTTz+Vq2GqSOXQ38MMhynZGgqFoiyEO6jHOI8Re9zVyhVsFht30u9gmL36/lZIHEFYW1vj448/Bo/HQ3FxsejRFHGxdAGbxW4Uy9coFEr9eZb/DG/L3or1PwCAgbYBnFo6qb2jWuIIon379hgyZEiV186ePSs3g1SZZtrN4NTSiTqqKZQmjvA3QLj8XRzuNu6IeBQBQohoo7G6IXEEsXv3bqleayq4WbshNiO2yUUFpVAo74nLYBzUnc0711jG3dodr0te4+W7lwq0TLbUOIKIiopCdHQ0srOzsWrVKtHrRUVF0NDQUIhxqgjHioPQxFBkFGbAxshG2eZQKBQlEJsZiy7mXcQ6qIVUdlS3btFaUabJlBpHEBYWFujcuTN0dHTg7Owsenh5eWHv3r2KtFGloDmqKZSmjdBB/eEGuQ/patEVWmwttQ7cV+MIwtHREY6OjvDz84OmplQbrpsE3Sy7iRzV/g7+yjaHQqEoGEkOaiE6mjroZtlNrR3VNf7yz5kzB7/88gtGjBgh9nhT20ktRF9LH85mznQlE4XSRJHGQS2EY8XBn/f+hIAIwGapXxTsGgVi0aJFAICdO3cqzBh1gWPNQcRj9V6dQKFQ6oc0Dmoh7jbu2Bm3E49zH8OhpYMCrJMtNUrajBkzAAA2Njb47bffYGNjU+XRlHGzckNOcQ7SCtKUbQqFQlEwcZlxEh3UQtR9R3WNAlF5GWd8fLxCjFEXqKOaQmmaCB3UkvwPQpzMnKCvpa+2juoaBYJOndRMV4uu0GBpUD8EhdLEeP72OfLL8qXyPwCAJlsT3a26q62jukYfxLNnz+Dn5wcAePnypeh/IU3VSQ0Aelp66GzemQoEhdLEqC3Ed01wrDjYFbcLFYIKaLLVa0VojdaeOXNGkXaoHRxrDsIfhlNHNYXShIjLjIMWW0sqB7UQdxt3/BzzM+7n3Ec3y25ytE721CgQTd0RLQk3KzfsvbsXL9+9VNtdkhQKpW7EZsSii0UX6GjqSH1OZUe1ugmE+i3MVRGEjmo6zUShNA1EO6itat9B/SEdTDqghW4LtXRUU4GoJ8Jt9Oq4kim3JBdtfm6Dy+k0Ox6FIi11dVALYbFY4Fhz1NJRLZVAlJWV4dmzZ3WuPDo6Gj4+PvD29hYbAZYQglWrVsHb2xt+fn64f/++6FhBQQFmz56NwYMHY8iQIbh7926d25cnOpo6auuoPnTvEF68e4Hw1HBlm0KhqA31cVAL4VhxkJSdhLKKMlmbJVckCsTly5cxfPhwTJkyBQCQkpKCadOmSayYz+djxYoV2LNnDyIiInD69Gk8efKkSpno6GikpqbiwoULWLlyJUJCQkTHVq9ejT59+uDcuXMIDw9H+/bt69g1+cOx5iAuM07tQn8fSDwAALiWfU3tPrAUirKoj4NaiLuNOyoEFUjMSpSDZfJDokBs3boVx44dg5GREQDAyckJ6enpEitOSkpC69atYWdnB21tbfj6+iIyMrJKmcjISAQEBIDFYsHFxQUFBQXIyclBUVER7ty5g6CgIACAtra2qH25cOoUNDPrnmeaY81BXmkeUt+myt4mOXEv5x5iM2Lh094HpRWluPL8irJNolDUgrjMuDo7qIWo645qiYtyNTQ0YGhoWOeKs7OzYWlpKXpuYWGBpKSkWstYWloiOzsbmpqaMDExwXfffYcHDx7A2dkZ33//PfT19Wttk8vlIiUlpc62tps1Cy07dkSKlVWdzjMpMwEAhN0Jw2C7wXVuVxlsTNwITZYmFjotRHRqNEJjQtGmoo2yzVIYZWVl9fqMqCtNrb+AfPpMCMHttNvwsfWpV92EEJjqmuJS8iUMMBwgU9sA+V1niQLRsWNHnDp1Cnw+H6mpqfj999/h6uoqsWJx0y4f7heoqUxFRQWSk5OxZMkSdOvWDatWrcLu3bvx9ddf19qmjo4OnJycJNpWDV9faO3bB+PWrQEJIlSZdhXtoH1FG9ns7Pq1q2AqBBU4e+YshjkMg5ebFz6++zGuvb4GR0fHJrOXIyUlRS2ulaxoav0F5NPn5/nPUVBegAFOA+pdt0eiBx7nP5bL9WhIn2sTFolTTEuWLMGTJ0+gra2NefPmwcDAAN9//73ERi0tLZGVlSV6np2dDXNz81rLZGVlwdzcHJaWlrC0tES3bsya4cGDByM5OVlim/UmKAjs0lKgjrm2dTR10MW8i9o4qi88vYCsoixM6jYJANDPuh/SCtKQkJWgXMMoFBWnLiG+a4JjxUHK6xQUcgtlZZbckSgQenp6mDt3Lo4fP44TJ05g7ty50NGRPAfXpUsXpKam4tWrVygvL0dERAS8vLyqlPHy8kJYWBgIIUhISIChoSHMzc1hZmYGS0tL0cqpmzdvytdJ3acPKkxMgGPH6nyqOjmq9yfsR0v9lhjacSgAwNPKEyyw8PfDv5VsGYWi2sRmxEKLrYUu5l3qXYe7jTsImL0U6oLEKSZxK5YMDQ3RuXNnjB07tkax0NTUxNKlSzFlyhTw+XwEBgaiY8eOOHToEAAgODgYnp6eiIqKgre3N/T09LBmzRrR+UuWLMGCBQvA4/FgZ2eHtWvX1rePktHUROGAATA+fRooLQX09KQ+lWPNxFl5lv8M7U1Ub6WVkLzSPIQ/DMd0znRRmGJTXVP0su2FU49OYVm/ZUq2kEJRXRrioBZS2VHt2cZTVqbJFYkCYWtri/z8fPj6+gJgYjS1bNkSqamp+OGHH7Bu3boaz/X09ISnZ9U3Ijg4WPQ/i8XCsmXif5icnJxw4sQJqTohCwp8fGB89Chw4QIwfLjU5wnXRMdmxKq0QPx17y+U88sx2WVyldf9HfzxXeR3SC9Ih40RDa9CoXwIIQRxGXEI6hTUoHrMmpmhdfPWarWSSeIUU0pKCjZs2AAvLy94eXlh/fr1SEpKwrJly+TrF1AwJe7ugKkpcPRonc5zNneGjoaOyvsh9ifuR1eLrnCxdKnyup89E6X39KPTSrCKQlF9Ut+mMjuo67FB7kPcbdxV/reiMhIFIi8vDxkZGaLnGRkZyM/PBwBoaWnJzzJFo6UFBAQAf/8NcLlSn6atoY1ult1UOuRGyusU3E6/jcndJlc71smsE9oZt8Pfj6gfgkIRhywc1EI4Vhw8y3+G3JLcBtelCCQKxKJFizBu3DhMmDABEyZMwCeffIKFCxeipKQEAQEBCjBRgQQFAYWFwMWLdTrNzcoNcZlxEBCBnAxrGAcSD0CTrYlPun5S7RiLxYKfvR8in0WiuLxYCdZRKKpNXEZcgx3UQtxtGD+EuowiJAqEp6cnLly4gO+//x6LFy/GuXPn0K9fP+jr62Py5MkKMFGBDBgAGBvXeZqJY81BAbcAT/Oeysmw+sMX8PF70u8Y0mEIzJuZiy3j7+APLp+Li8/qJowUSlMgLjMOnc07N8hBLUQ4TaUufgipgvWlpqbi2bNnePjwIc6ePYuwsDA5m6UktLQYB3V4OFBeLvVpqhz6++Kzi8gozKjmnK5Mn1Z90FynOU49bLpZAikUcRBCEJcZJxP/AwA0120OB1OHxiMQW7duxcqVK7Fq1SrExMRg3bp1uHy5EYeJDgoC3r0DPogbVRudzDpBV1NXJQVif8J+mOqZYpj9sBrLaGloYUjHITj9+LTKTpNRKMrgxbsXyCvNk4n/QYg6OaolCsT58+dx4MABtGzZEmvXrkV4eDjK63B3rXYMHAgYGdVp05wmWxMuli4q56h+W/YWYQ/CENw5WLT3oSb87f2RU5yD2+m3FWQdhaL6CH/IZTWCABhHdUZhBjIKMyQXVjISBUJHRwdsNhuampooKiqCqakpXr16pQjblIOODjPNFBYG8HhSn6aKjuq/7v0FLp9b6/SSkMEdBkODpUF3VVMolYjLiIMmWxNdLBruoBYidFSrQ4Y5iQLRuXNnFBQUYNSoURg5ciRGjBiBrl27KsI25REUBOTlAVekD4XNseagqLwIj3IfydGwurE/cT86m3dGd6vuEssa6xmjb+u+VCAolErEZcahi3kX6GrqyqxOF0sXaLA01MIPUetOakIIpk6dCiMjIwQHB6NPnz4oKiqCo6OjouxTDoMGAQYGzDTToEFSnSJ0VMdlxMGxpfLfn4dvHuJW2i2s914vdaRWP3s/zLswD8/yn6GdcTs5W0ihqDZCB/VIx5EyrVdfSx+dzTurhUDUOoJgsVj46quvRM9tbW0bvzgAgK4u4OcHnDwJVFRIdYpjS0foaeqpjPPpQOIBaLA0xO59qAl/B38AoKuZKBTIx0EtxN2acVSrepBPiVNM3bp1q5bop0kwahTw5g0QFSVVcU22JlytXFXCUc0X8BGaGIrBHQbD0sBS8gn/0d6kPZxaOuHUIyoQFEpDclBLQpiN8vnb5zKvW5ZIFIiYmBiMGTMGAwcOhJ+fn+jR6Bk8GGjWrE6rmThWHMRnxoMv4MvRMMlEPo9EemG6VM7pD/F38EfUiyi8K3sne8MoFDUiLlP2Dmoh6uKolhjN9ddff1WEHaqHnh7g6wucOAFs3QpoaEg8xc3aDZtvb8bD3IfoZNZJAUaK50DiARjrGosC8dUFP3s//HT9J5x7cg5jOo+Rg3UUinog3EEtSwe1kC7mXaCjoYM7GXdU+nsmcQRhY2ODzMxM3Lp1CzY2NtDT04NAoDpLOeXKqFFATg5w9apUxSs7qpXFu7J3OJFyAsGdg+sVGqCXbS+01G9Jg/dRmjTCEN/ymF4CmM2pLpYuKu+olmon9Z49e7B7924AAI/HwzfffCN3w1SCIUOYkYSU00wOpg5optVMqY7qI/ePoKyirF7TSwCgwdaAb0dfnHl8Bjy+9PtAKJTGxMt3L5Fbmis3gQAYR7UqTEnXhkSBuHjxInbs2AG9/7KsWVhYoLi4iUT9bNYMGDoUOH4ckGLUpMHWgKuVK2IzlScQBxIPwKmlk2g0Ux/8Hfzxtuwtrr+6LkPLlIuACBD2IAw8ARU9imREO6jlsIJJiHDv1MPch3Jro6FIFAgtLS2wWCzRWvqSkhK5G6VSBAUBWVnAjRtSFedYcZCQlYAKgXTLY2XJ49zHuP7qOia7TJZ674M4BrUfBG0N7Ua13PXI/SMY8dcIHHpySNmmUNQAoYO6q4X8NgWrg6NaokAMGTIES5cuRUFBAY4cOYJPP/0Uo0ePVoRtqoGvL7MvQsoQ4G7WbijhleDBmwdyNqw6BxIPgM1iY3zX8Q2qx0DbAF5tvfD3o79Vfp22tGy/sx0AEPooVCniTVEv5OmgFuJg6gADbQOV9kNIFIjPP/8cPj4+GDRoEJ4/f47Zs2djwoQJirBNNTA0ZJa8SjnNpKzQ3wIiQGhiKHza+8Da0LrB9fnZ++FJ3hOVHv5Ky72ce7j68ir6temHjJIMHE8+rmyTKCqMvB3UQjTYGnCzclNvgdi/fz/at2+Pb7/9Ft9++y0+/vhjRdilWgQFAenpQEyMxKL2pvYw0DZQ+EqmK8+v4FXBK0zqNkkm9QmXyDaG2Ew7Y3dCR0MHfwX9hdYGrbHh5oZGMzKiyB5FOKiFuFu7IzErEeV81YyQLVEgioqK8Pnnn2PcuHH4448/8ObNG0XYpVoMGwZoa0u1monNYqO7VXeFO6r3J+5Hc53mGO44XCb12TW3g6ulq9oLRFF5EUITQzHKeRTMm5ljkv0k3Mm4g6svpVu6TGl6yDIHtSQ41hxw+Vzcy7kn97bqg0SBmDlzJiIiIrB06VLk5ORg/PjxjS/VqCSaNwd8fBiBkOLOU9GO6gJuAY4nH0dw52CZzpn62fvhZtpNvC5+LbM6Fc0fSX+gsLwQMzgzAADD2wxHS/2WWH9jvZIto6gqwhDf8nRQC1F1R7VUKUcBwNTUFC1btkSLFi2Qm5srT5tUk6Ag4OVL4I7kC8mx5qCsogzJr5MVYBhwLPkYSitKMclFNtNLQvwd/CEgApx5fEam9SoKQgi2x25HN4tu6GXbCwCgp6mHGZwZOPXoFB6+UX//CkX2xGXGwdnMWa4OaiFtW7SFqZ6pyvohJArEn3/+iQkTJmDy5MnIz8/HqlWrcOpU41n+KDV+fkzOaimmmYRDU0U5qvcn7IeDqQN62vSUab3drbrD2tBabYP33Uy7iaTsJMxwn1Fl2e9XPb6CjoYONt7cqETrKKqIrHNQS4LFYoFjzVFfgcjIyMDixYsRERGB2bNnw87ODmfPnlWEbaqFsTGTjvToUYnTTB1MOsBIx0ghjuqneU9x9eXVBu99EAeLxYKfvR/OPz0PbgVXpnUrgu13tsNQ2xDjuoyr8rp5M3NM6jYJBxIPIKc4R0nWUVSRl+9e4k3JG4X4H4S4W7vjfs59lPBUb4+ZRIFYsGAB7O3tERUVhYULF6J///5NUyAAJjZTaioQH19rMUU6qkMTQ8ECq8F7H2rCz94PReVF+Cf1H7nULy9eF7/G0eSjmNRtEgy0Daodn+sxF1w+V7Q/gkIBKjmoFTSCAJgpaT7hIyErQWFtSkutAnHnzh0sXboUXl5eOHbsGK5fv47IyEhs3rxZUfapFsOHA5qaUk0zcaw4SMxKlGs8IwER4EDiAXi394atka1c2vBq6wV9LX21W820L2EfyvnlmMaZJva4Y0tH+Nn7YdudbSp550ZRDop0UAtRZUd1jQLRt29fbNiwAd27d0dERAS2bNkCHR0dUUymJomJCeDlJdVqJuHytfuv78vNnKjUKLx49wKTu02WWxt6WnrwbueNU49Oqc3eAQERYGfsTni29oSzuXON5RZ8tABvSt4gNDFUgdZRVBmhg1pPS3G/c9aG1rA2tFZJP0SNAjFo0CBkZ2fj7NmzuHLlCkpKSmQ+x62WBAUBT54AiYm1FlOEo3p/4n4Y6RghwDFAbm0AzGqmVwWvkJhde59VhfNPzuP52+eYzplea7k+rfqAY83BxpsbISBNJIQ9pUYU7aCujLu1u3oJxA8//IDLly9j8uTJiImJgY+PD/Ly8nDmzJmmE81VHCNGMMmDJEwztTduj+Y6zeXmqC4qL8Lx5OMY4zxG7nc7vh19wQJLbYL3bY/dDotmFhjhNKLWciwWCws8FuBx3mO16RtFfrwqeKVwB7UQd2t3PMp9pHKZHGv1QbBYLHh4eGDVqlW4fPkyNmzYgMjISHh5eSnKPtWjZUugXz+Jq5mEy9fk5ag+lnwMxbzieud9qAsWBhboadtTLZIIpb5NRcSjCEzpPgXaGtoSywd2CkTr5q2x/ibdONfUkWcOakmIko2pQE77yki9UU5LSwteXl7YsGEDoqKi5GmT6hMUBDx6BNyv3b/gZuWGpOwkucRZ2Z+wHx1NOsLD1kPmdYvDz94PsRmxyCjMUEh79WV33G6wWCx86falVOU12ZqY22surr28hpg0ybG2KI2XuMw4aLA0FOqgFiIUCFVzVEstEJXR1ZVuh2F0dDR8fHzg7e0tykhXGUIIVq1aBW9vb/j5+eF+pR9cLy8v+Pn5Yfjw4Rg5cmR9zJQfI0YAbLbEEOAcaw7K+eUyj7PyPP85ol5EYVK3SQrzC/k7+AMATj86rZD26kM5vxx77+7FMPthaNW8ldTnfeb6GZrrNMeGmxvkaB1F1YnLjIOzuWId1EJM9U3Rzridyvkh6iUQ0sDn87FixQrs2bMHEREROH36NJ48eVKlTHR0NFJTU3HhwgWsXLkSISEhVY4fOHAA4eHhOHHihLzMrB8WFkDfvhL9EPIK/S3c+zChm+LCrjubOaNNizYqvav6RMoJ5BTnSHROf4ihjiGmcabheMpxPMt/JifrKKqMokJ814YqOqprFIhdu3YhObn+sYSSkpLQunVr2NnZQVtbG76+voiMjKxSJjIyEgEBAWCxWHBxcUFBQQFyctRkZ2tQEJCczDxqoE2LNjDWNZapQAj3PgxoN6BOd8kNhcViwd/eH5eeXUJxuWouUth+ZzvaGbfDoPaD6nzurB6zoMHSwM+3fpa9YRSV51XBK7wuea10gXj57qVK7e7XrOmAra0tQkND8eDBAzg6OqJv3774+OOP0bx5c6kqzs7OhqWlpei5hYUFkpKSai1jaWmJ7OxsmJubA2CSFbFYLIwZMwZjxoyR2CaXy0VKSopU9n1IWVlZnc7V7NwZHVgsvNmxA29mzKixnFNzJ1x/fr3edn3InZw7eP72OaY6TG1wnXXtc1e9riirKMO+6H0YYDOgQW3LmsfvHuPqy6uY33U+Hj6oOQhfbX0eajcUe+L3INgqGC10WsjJUsVS12vcGKhPny+lXQIAmJabKu39MuOZAQBOxJyAp5Vnnc6V13WuUSB8fX3h6+sLAEhOTsbVq1cxc+ZMCAQCeHh4oG/fvujatWZnjrhNVR/Ol9dW5tChQ7CwsEBubi4+/fRTtGvXDu7u7rV2RkdHB05OTrWWqYmUlJS6nevkBHz8McyiomC2ZUuNxfqm98WGmxvQtmNbmUSHXPdoHQy1DTHTayaaaTdrUF117XN7+/aYd2seEkoSMNNpZoPaljVbI7ZCR0MHi3wWoaV+yxrL1dbnFSYrEL4zHP8U/oPvXL6Tk6WKpc6f60ZAffr8R+Yf0GBpYHjP4UrxQQCAbTtbTP5nMrLZ2XW2vyHXuTZhkcoH0alTJ0ydOhW///47du3ahY4dO+KoBAetpaUlsrKyRM8rjwxqKpOVlSUqY2FhAYAJM+7t7V1t9KESjBoF/Psv8LDmO1aONQc8AQ//Zv/b4OaKyotw5P4RjHYe3WBxqA/aGtoY0mEITj86rVIby4rKi/B70u8Y7Ty6VnGQRFeLrhjUfhA2396slsEJKfVHmQ5qIYY6hnAyc1IpP0SdndQGBgbw8fHBypUray3XpUsXpKam4tWrVygvL0dERES1/RNeXl4ICwsDIQQJCQkwNDSEubk5SkpKUFRUBAAoKSnB9evX0bFjx7qaKn+Eq6uO15zjWJbrm0+knFDY3oea8LP3Q3ZxtkotxxMmBaqrc1oc8z3mI6soC4fuHZKBZRR1QBUc1EKEjmpVCWsjt1VMmpqaWLp0KaZMmYKhQ4diyJAh6NixIw4dOoRDh5gvn6enJ+zs7ODt7Y0lS5Zg2bJlAIDc3FyMGzcO/v7+GDVqFDw9PdG3b195mVp/bG0BD49al7u2at4KpnqmMnFUH0g8gPbG7fGxnfLygg/pOAQaLA2VCd4nTArkYukiSgrUELzbeaOLeResv7FeZb6kFPmSVpCmdAe1EHdrd+QU5yCtIE3ZpgCoxQchCzw9PeHpWdXZEhwcLPqfxWKJRKEydnZ2+Ptv1fgBksioUcC8eUx8pg4dqh0W7qhu6AjixdsXuPz8Mlb0W6HUmFgmeibo3ao3Tj06hdUDVivNDiHCpEC7hu2SyfvCYrGw4KMFmBQ2CeefnsfgDoNlYCVFlVFkDmpJiCK7ZtyBXXM7JVsj5QgiOzsb8fHxuHPnjuhB+Y/AQOavhGmmezn3UMorrXczwoijE7tNrHcdssLfwR//5vyL1LepyjYF2+9sh5GOUbWkQA1hbOexsDa0phvnmghxGcwO6m4W3ZRtCrpadIUmW1NlpnAlCsS6desQHByMHTt2YO/evaIH5T9atQJ69Kh105yblRsqBBVIyq6fo50QggOJB9C/TX+0btG6vpbKDD97PwBQeoA7YVKgiV0nik0KVF+0NbQxu8dsXHp2SSWTuFBkS1xmHDqZdVKqg1qIrqYuulp0VRlHtUSBuHTpEs6dO4dff/0VO3fuFD0olQgKAmJjgefPxR5uqKP6+qvreJr/VKnO6cp0NO0Ix5aOSg/e99vd32pNCtQQpnKmwkDbgI4iGjmEEMRmxKrE9JIQd2t3xGbEqsRKQYkCYWdnBx5PflnRGgVBQczfGqaZbI1sYd7MvN6O6v0J+2GgbYBAp8D6Wihz/Oz9EJUapbTwxAIiwK64XRKTAtWXFrotMMV1Cg7fO6wyDkOK7FElB7UQd2t3vOO+w9O8p8o2RbJA6OnpISAgAEuXLsWqVatED0ol2rYF3NxqnGZisVhws3Krl0CU8Epw5P4RBHUKUsreh5rwd/AHT8DD+afnldK+tEmBGsKcXnMgIAJsjmmiKXabAMJRvXCUrwpUdlQrG4kC4eXlhRkzZsDV1RXOzs6iB+UDgoKAmBjg5UuxhznWHCS/Tq5z/uOTKSdRWF4o17Si9cHD1gOmeqZKC94nbVKghtCmRRuM6jQKu+J2oYBbILd2KMpDlRzUQjqZdYKepp5KOKolLnMdMUJ+X8BGRVAQ8N13zDTT3LnVDrtZuYFP+EjMSoSHnfQ5HPYn7kfbFm3Rp3UfWVrbYDTYGvC198Wph6dQIaiAJluuK6arIEwKtLjPYqmSAjWEBR8twF/3/8Le+L2Y61H9ulLUG1VyUAvRZGvC1cpVtUcQc+bMAQD4+fmJfVA+oEMHwMWlxmmm+jiqX757ichnkZjYbSLYLLntaaw3fvZ+yC/Lx41XNxTabl2TAjUEjjUHfVv3xc8xP4PHp764xoQoB7UKOaiFuFu7Iz4zHhWCCqXaUeNt3/fffw8AdMVSXQgKAn74AUhPB2xsqhyyNrSGpYFlnfwQvyf+DgKiEnsfxOHT3gfaGtr4++Hf6NtaMTvduRXceiUFaggLPBbA/7A/jiUfQ3CXYMknUNSC9MJ05BTnqJSDWoi7tTt+ifkFKa9T0MWii9LsqPG2VBg0z8bGRuyDIoZaVjPV1VEt3Pvg2doT7YzbydJKmWGoY4h+bfopNOxGfZMCNQRfe184mDpg/U0afqMxocwc1JJQFUd1jQLh6uqK7t27ix7C58K/FDE4OACdO9c6zZTyJkWqhDs3027icd5jldn7UBP+9v54nPcYD9/UHNFWluyI3VHvpED1hc1iY57HPMRnxiPqRRPPx96IiMuMA5vFRjdL1XFQC+lg0gFGOkZKd1TXKBAeHh7o0KEDpk+fjtOnT+Pu3buIj48X/aXUwKhRwLVrQGZmtUMcaw4ERCDV7tz9Cfuhr6WvUnsfxDHMfhgAKGQUcS/nHq6+vIppbtMU7pOZ0HUCzPTNsP7GeoW2S5EfsRmx6GTWCfpa+so2pRpsFhsca47qjiC2b9+OvXv3wsTEBEuWLMH48ePxxx9/4O3btwo0Tw0JCgIIAU6erHZIOJSVNM1UyivFX/f/QlCnIBjqGMrFTFnRukVrdLPoppDlrjvu7ICOhg4+df1U7m19iJ6WHmb2mImIxxFIed20MrQ1RkQOahWcXhLibu2OpOwkpeYmqfU2zNDQEIGBgfj1118xduxYbN68GSfF/PBRKtGpE5NtTkwIcCtDK1gbWktcyRT2IAwF3AKV2/tQE/4O/rj+6jpyS3Ll1kYht1AmSYEawnTOdOhq6mLjzY1KaZ8iO4QOalXaIPch7tbu4Al4SMxOVJoNtQpEfHw8Vq5ciREjRiA+Ph7btm3Dp58q/u5N7QgKAqKjgezsaoekcVTvT9yP1s1bw7NN3fLSKgs/ez8IiABnHp+RWxt//MskBZrhXnP+b3lj1swMk7tNRmhSKLKLql9bivqgyg5qIUJHtSxyydSXGgXCy8sLy5cvh4WFBVauXInAwEDo6enh/v37uH//viJtVD9GjQIEAiAsrNohjjUHD948QCG3UOyp6QXpuPTsksrufRCHm7UbrAys5Ba8jxCCHbE74GLpgp42PeXShrTM9ZgLHp+HbXe2KdUOSsNQZQe1EDsjO5jpmynVD1HjPgjhUtarV6/i2rVrVZb3sVgshIaGyt86daVzZ8Denplmmjq1yiGONQcEBAlZCWJ3R/+e9DsERIBJ3SYpytoGw2axMcx+GA7fOwxuBRc6mjoyrf/GqxsyTQrUEOxN7THccTi23dmGRb0XqaSDkyIZ4Q5qVb5+LBYL7jbuSl3JVKNA/P7774q0o3HBYjHTTD/9BLx+DZiZiQ5VdlR/KBCEEOxP2I/erXqjvUl7hZrcUPwd/PFr/K+IehEl8yWoO2J3yDwpUEOY7zEfYQ/CsD9hv1KnvCj1Q5iDWh2yBbpbu+Pck3MoKi+Sac4TaVGPOQx1JCgI4POB8PAqL1sYWMDWyFasozomPQYPcx+qjXO6MgPaDoCepp7MkwjJKylQQ/jY7mP0tOmJTbc2gS/gK9scSh3JKMxAdnG2SvsfhLhbu0NABIjPVM7WAioQ8sLFBWjfXuymOY41R6zj6UDCAehp6mGU8ygFGChb9LT04N3eG38/+lumu42FSYGmuytu57QkhHmrn+Q9UegucopsUKUc1JIQrrJSlqO6RoGoqFBukCi1RzjNFBkJ5OVVOeRm5YaHuQ+rhJAuqyjDoXuHENgpEEY6Roq2Vib42fvh5buX+DfnX5nUxxfwRUmBOpl1kkmdsmKE4wi0bdEW62/SjXPqRlwG46B2sXRRtikSsTCwgJ2RndIc1TUKxOjRozFjxgwcOnQIaWk0o1a9CAoCKiqqTTMJ7wruZt4VvRb+IBzvuO/Uyjn9IbLeVX3+KZMUSBXn+TXYGpjbay5uvLqBm69uKtscSh2IzYyFU0snlXZQV0aZjuoaBeLEiROiiK5r1qxBYGAg1qxZg2vXrqG8vFxhBqo1bm5AmzbVppnE7ag+kHgAdkZ26N+mvyItlCmWBpboYdNDZgKxI3YHLJpZIMAxQCb1yZpPXT+Fsa4xzVutRggd1Kq8Qe5D3K3d8TT/KfJK8yQXljG1+iBsbGwQHByM7du34/Dhw+jfvz9u3LiBcePG4csv5R+LX+0RTjNdvAhUClFi1swMrZq3QmwmIxAZhRk4//Q8JnabCA22hpKMlQ3+9v64k3EHmYXVY1HVBWFSoC+6fyH3pED1xUDbANM403Ai5YRK5A+mSEadHNRC3K2Vt2FOaie1lpYWPDw8sHDhQhw7dgwrV66Up12Nh6AggMcD/q56V82x5oh2cx5MOggBEahs3oe64OfAJJM6/eh0g+pRZFKghjCrxyxosjXx862flW0KRQrUyUEtRGirSgvEh1hYWMjSjsZLjx6AnZ3YaabHeY/xtuwt9ifsx0d2H8He1F5JRsqOLuZd0Lp56wYF76ucFMiuuZ0MrZM9VoZWGN91PH5L+E2usagoskGdHNRCWui2QEeTjkpxVNNlrvJGOM10/jxQ8H7VknAOdHfcbqS8SVHLvQ/iYLFY8LP3w8VnF1HCK6lXHcKkQDM4quecFsc8j3ko4ZVgZyzNvqjqxGXGqZWDWoiyHNUSBYLLrR5qNi9P8c4StSYoCCgvB069v6sWzoGujF4JXU1djHYerSzrZI6/gz/KKsoQ+SyyXufviN2B9sbt4d3eW8aWyYfO5p0xuMNgbLm9RamhmSmSUdUc1JJwt3ZHemF6g317dUWiQAQFBSEhIUH0/Pz58wgOpnl560SvXoC1dZVpJlN9U7Rp0QZF5UUY4TgCzXWbK9FA2eLZxhOG2ob1Ws30b/a/TFIgjuKTAjWEBR4LkF2cjT/+/UPZplBqIKMwA1lFWWrloBYidFQrepqpxlhMQtavX4/FixejR48eyMnJwdu3b3HgwAFF2NZ4YLOBwEBg926gsBAwZJIAcaw5SH2bqvJpReuKtoY2BncYjNOPT0NABHX6od8Zu5NJCuSiXmHlvdp6wcXSBetvrMdkl8lqJW5NBXUI8V0TrlauYLPYiM2Ihb+Dv8LalfgpdnBwwPTp03H48GHExMRg6dKlsLS0VIRtjYtRowAuFzjzPmfCWOexGNxhMAa0HaBEw+SDv4M/soqy6rTyQpgUaEznMTDVN5WjdbKHxWJhvsd8pLxJwbkn55RtDkUMsRmxauegFqKvpQ9nM2eFjyAkCsTixYtx4MAB/P3331i7di2mTZuGP/6gw+g689FHgKVllUxzgZ0CcfaTs2q/90EcQzoMAZvFrlPwPmFSoOkc1Ym7VBfGOI+BjaEN3TinosRlxsGxpSOaaTdTtin1wt2acVTLMtaZJCQKhL29PUJDQ2FnZ4c+ffrgyJEjNGFQfdDQAEaOZEYQxcXKtkbumOqboner3lInEVKlpED1RUtDC1/3+hqXn19WWvRNSs3EZarXDuoPcbdxR25pLlLfpiqsTYkCMXny5CpJWgwNDbFmzRqpKo+OjoaPjw+8vb2xe/fuascJIVi1ahW8vb3h5+dXTXj4fD4CAgIw9YOkO2pLUBBQWgqcPatsSxSCn70fkrKT8OLtC4llhUmBZnBmKD0pUEP4ovsXMNQ2pKMIFUOdHdRClOGoligQqampmD17NoYOHYoBAwaIHpLg8/lYsWIF9uzZg4iICJw+fRpPnjypUiY6Ohqpqam4cOECVq5ciZCQkCrHQ0ND0b69eiXOqZW+fZnkQWJCgDdGhM40aTbNqVpSoPrSXLc5vuj+Bf669xdevXulbHMo/6HODmohXSy6QFtDW6E7qiUKxHfffYfg4GBoaGggNDQUAQEBGD58uMSKk5KS0Lp1a9jZ2UFbWxu+vr6IjKy6Lj4yMhIBAQFgsVhwcXFBQUEBcnJyAABZWVn4559/EBQUVM+uqSDCaabTp5mRhKIpLmb2YkybBri6osXhw3Jtzt7UHvam9hIFQpgUaFK3SWo7P1yZOb3mAAB+iflFyZZQhAhzUKujg1qItoY2ull0U+gIQuIyVy6XCw8PDwBM8L5Zs2Zh3LhxmD17dq3nZWdnV1ntZGFhgaSkpFrLWFpaIjs7G+bm5lizZg2++eYbFNdhvp7L5SIlJUXq8pUpKyur97l1Qd/dHa137ULanj0oHDhQ7u1pvXwJg6goGFy9Cv3bt8EuLwdfXx8VVlawWrECbzIy8HruXGbHtxz4uOXH+P3x77iTdAcGWuIzwu1J2YNyfjm8jb3lfg0UdZ0H2w3Gzjs7MdpiNAy1DeXeXk0oqr+qhLg+Rz2KQlvDtnj59KWSrJINHfQ64O8Xf+N+8v0qS6nldZ0lCoS2tjYEAgFat26NgwcPwsLCArm5kmPOiPO0fzi3XFOZK1euwMTEBJ07d0ZMTIzEtoTo6OjAyclJ6vKVSUlJqfe5daJjR+Dbb2F76xYwa5bs6+dygatXGWd4RATw6BHzuoMDMHMmMHQoNPr0gQabjfxx49Byzx60LCsD9u4FtGUfNXWy/mTse7gPqRqpGOVUPVMeX8DHyQsn0a9NP/j18pN5+yJKS4GjR/GwUyc4KOA6L2++HJxfObhafBXzu82Xe3s1obDPtQohrs8PzzzEwHYD1f69GMQdhENPD4FtxoaT2fu+NOQ61yYsUi1zLS0txQ8//ID79+8jPDwcP/30k8RGLS0tkZWVJXouHBnUViYrKwvm5uaIj4/H5cuX4eXlhXnz5uHWrVtYsGCBxDbVAk1NYMQIZqqnrEw2daanA7/+ytTbsiXg7Q1s3w60awds3gw8eQI8eABs2AAMGMAIgaYmskJCgJUrgYMHAV/fKrGiZMVHdh/BRM+kxmkmYVIguS5tffkS6N0bmDQJrSZNAip95uSFm7Ub+rfpj59jfgaPz5N7e5SaySzMRGZRpvz9DwqYNla4o5rICR6PR7y8vMjLly8Jl8slfn5+5NGjR1XKXLlyhXz++edEIBCQu3fvksDAwGr13Lp1i3z55ZdStZmcnFxvextybp05d44QgJDw8Pqdz+MRcu0aIYsXE9KtG1MXQEirVoRMn07IqVOEFBdLrEbU5337CNHQYOpKT6+fTbUw/sR4YvKTCeHxedWODftzGLFYZ0G4FVyZt0sIISQqihAzM0KMjAhZvpzw9fQIaduWkA8+i/Lg9MPTBCEgBxMPyr2tmlDo51pF+LDPpx6eIggBufriqvwavXiRkGbNCPnkE+b7KScq+BWk2epmZNaZWVVel9dvX41TTNOmTatVWHburD1ypaamJpYuXYopU6aAz+cjMDAQHTt2xKFDhwAAwcHB8PT0RFRUFLy9vaGnpyf18lm1x8sLMDZmVjP5S7lt/s0b4Nw5Zuro3DkgP59xevfuDfz0EzMC6NSpfr6EyZMBKysmHIiHB1O/DIfi/vb+OJh0EDdf3USf1n1ErwuTAn3f53vZJwUihBlFff010L49k/bVwQEvHBzQduZMZuNiRAQTjl1ODOk4BE4tnbDh5gaM6zJOrZfvqjOxGbFggSU/B/XZs8zo3cQE+OMPZiRx6JBcpmw12BrobtVd+SOInj17koCAAPLrr7+S27dvk5iYmCoPVURtRhCEEDJ5MiHNmxNSVib+uEBASFwcIStXEtKrFyEsFjNKMDcnZNIkQo4cISQ/v0EmVOtzXBwhFhaEGBsTclV2d1vvyt4RrRVaZMH5BVVe/+7Sd4S9nE1evn0ps7YIIcx7+vnnzPs1bBghb9+KDiUnJzOjh7ZtCdHXJyQiQrZtf8CeuD0EISCRzyLl2k5N0BEEM0rttK2TfBoLDydEW5sQV1dC3rwh5Oefmc+dry8hpaVyaXLeuXlEd5UuKa8oF70mr9++GgWioqKCREVFkYULF5Lhw4eTjRs3VpsiUjXUSiAiIpgP0unT7197946QY8cI+ewzQqys3k8dubsTEhJCyO3bhPD5MjNBbJ+fPSPE3p4QHR3GFhnhHepNHLY4iJ6X8cqI2f/MyPBDw2XWBiGEkIwMQjw8mPft+++rvV+iPmdlEdK9OzO19ttvsrWhEqW8UmKxzoK0+6UdufT0ktzaqQkqEIRYrbciE05MkH1Dx44RoqlJSI8ehOTlvX99507m8zdwICFFRTJv9tC/hwhCQOIz4kWvKVwgKsPlcsnx48dJz549SWhoaL0NkTdqJRBlZcwIwt+fkPXrCenfn/mwAczro0cTsn8/80MmJ2rs8+vXzI8si0XIL7/IpK3NtzYThIA8fPOQEELIn0l/EoSAnHt8Tib1E0IIuXmTEdZmzQg5elRskSp9LiggxNubec9XrmRGbXIgOjWatP+lPUEIyJijY0jauzS5tCOOpi4QGQUZBCEgP9/8WbaN/Pknc3Px0UdVRqgi9u8nhM0mpE8f5nMmQ57kPiEIAdkVu0v0mlIEgsvlkvPnz5NZs2aRkSNHkq1bt5IsOf5gNRS1EghCCJkw4f0ooXNnQr79lnGqlpdLPlcG1NrnkhJCAgIY2xYsaPDI5Xn+c4IQkPXX1xNCCOnzWx/S/pf2hC+Q0Yho715mqN+uHSFJSTUWq9ZnLpeQ8eOZfk6fTkhFhWzs+YBSXilZ/s9yorNShxisMSAbbmyoMkUgL5q6QMjFQS388e/bt/Yf/8OHGRHp2bPB08GVEQgExPhHY/LF31+IXlO4QCxcuJCMGDGCbNy4kTx8+LDejSuS+r5JX39NiI/PO7JlCyEJCTKdxamdtDTmw5aaqqAGqyLx/aqoIGTGDObHc+zYmv0lUtJlexfSd19fkpSVRBACsu76ugbVRwhhxHTmzPdD+tzcWouL7TOfT8jChUwdI0Yw4ignnuY9Jb5/+BKEgHTe3plEp0bLrS1CqECEXAkhrBAWKeQWyqbyX39lRtYDBkg3fRQW9t5H8fq1bGwgzJSty04X0XOFC4SDgwNxcXEhLi4uxNXVVfQQPldF6vsmhYQQYmlZLrqZb9GC8W3+9BMza6GgG3qFI9X7JRAQ8uOPzBvTv3+D7oS+j/yeaCzXIGOOjiE6K3XIm+I39a6LEEJITg4hnp6MbfPnS7W8sNY+//IL8+X/+GOJQtMQBAIBCUsJI602tSIIAZl4ciLJKpTPyLypC4Tfn37EaauTbCreupX5rA0eXLebiLNnCdHVJcTZmZDMTJmYsvjSYqKxXIOUlDN2KNUHoS409E1KTSUkNJSQL74gxMHh/eyPvj4hXl6MkFy+LNUWA7WgTu/X778zPpLOnQl59ape7cWkxRCEQPSj2CDi4ph9H7q6jG1SIrHPf/3F3PE5ORHy4kXDbJRAEbeIfHfpO6K1Qos0X9ucbLu9jVTwZTvF1dQFwnqDNRl/YnzDK924kfkx8Pev30g6MpLxjdnb1/v7U5mTKScJQkBuvLxBCJGfQNC8iJVo3RqYMIHJDPrgAbPh9tgxYMoUIC8PWL6c2cLQogWzjP7bb5ml9G/fKttyBTB+PLPe+8ULZq/EvXt1roJjzYGlARN7q0E7pw8dYvZ/EAJcu8bYJitGjwbOn2d2p3/0EfDvv7Kr+wOaaTfDmgFrkDQ9CRxrDr468xV67umJ2+m35dZmUyKzMBMZhRkN30H944/AvHnMPqGjRwEdnbrX4eXFfK4yM5mozqmpDTJJUTuqqUDUgoUF85n45Rfg7l1GJCIigPnzmf1omzYBw4Yx+2NcXIDZsxlByc5WtuVyYuBAIDoa4POZH+ioqDqdzmaxMcV1CgZ3GFy/pEB8PrBwITBuHMDhALGxgJscwif068fEsyIE6NOnzv2sK44tHXFxwkUcDjyMzKJM9NrTC1NPTUVuieSYZ5SaicuUQYjvFSuA774DgoOBw4cbtvnt44+ByEjmjrJPH+Dx43pXZWNkAysDK/mH/q73uEQFUfQqpuJiQq5cIWT5csZnpa//flrK3p7Zq3XgACHPn8ttBWWDqPf7lZrKTMFoazMrNRRBbi4hgwYxb+6MGczqo3pQpz6/ePG+n0eO1Ku9ulJQVkDmnZtHNJZrENOfTMmeuD0NWunVlKeYGuSgFgiYfTQAszFVlqvbEhIIadmSEEtLQu7fr3c1fn/6EcetjoQQ6oOQCmUvcy0vJ+TWLULWrSPEz49xdgsFw9aWkHHjmD009++rhmA0qM+5ucwab4CQDRtkZ5Q4/v2XkPbtCdHSYlaRNIA69zk3l1nrzmIRsnlzg9quC0lZSaT3b70JQkA89niQu5l361VPUxaIejuoBQJmaTfAOCTlsazx/n1mz07LloTcvVuvKlb8s4KwQljkXdk7KhDSoGyB+BA+n1mSv3Urs+/N0vK9YLRsyWwz2LWr3jfDDabBfS4tJSQoiOnQ11/L54t04gTj3LO0JOT69QZXV68+V94T8u23ClN3gUBADiQcIGb/MyPs5Wwy68ws8rZUzKasWmjKAlEvB7VAQMjs2cy1/uor+a55f/SIEDs75k6yHuGLzj4+SxACcvnZZSoQ0qBqAvEhAgEhjx8ze7omT2bCAQmno+QcEkgsMulzRcX7L9To0bKLP8PnE7J0KVNvjx7MnhEZUO8+V1QQMm0aY8+ECQpd+5xXkkdmnJ5BWCEsYrHOgvye+DsRSClSihSI4vJicuX5FbIyaiXx/cOXTD89ncSkxUhtq6xITk4mmYWZBCEgm25ukv5EPp+QqVOZazx3rmJuBJ4/ZzZ3GhrWOf7Z6+LXBCEgP137iQqENKi6QIgjIoIRCICQoUMJefBAcW3LrM8CARMuBGB2l1aOS1Mf3r1jlhMChHz6qUyDnjWozwIBE5IDYPwhMg6hIInY9FjS49ceBCEgnvs8yb3sexLPkefn+nXxaxKWEkYWnF9Aeu3pRbRWaBGEgLBCWMRpqxPRXaVLEALivM2ZrLu+jmQWymYPgCSSk5NFodal3ohYUcF81gBCFi1S7BxwWhqzrl5fn1kOWwfa/tyWjDoyigqENKijQBDCTDGtX8+kLNDUJGTePJnuzK8Rmff5zz8ZP0GnToS8rGeE1ocPCXF0ZEIUbN4s8y+qTPq8Zw9jn5ubXGNliYMv4JNdsbuI8Y/GRHOFJvnmwje1OmFldY0FAgF5mveUHEg4QL74+wvitNVJtKdFe6U26f1bb7Lo4iJy+uFpklfC3CC8LX1LdsXuIh57PAhCQDSWa5Bhfw4jx5OPyy//B2H6vPyf5dI7qHk8Jo8DQMiyZcpxEGZlMXuMdHQIOXNG6tNGHRlF2vzchgqENKirQAjJyiJkyhTGH2pmRsju3XILDUQIkVOfL19mlM7ampDExLqdGxHBBCo0NWXqkQMy6/Pp04To6THTA48fy6bOOvC6+DX5PPxzghAQ24225Oj9o2Kncurb3wp+BYnPiCebb20mo4+OJtYbrEWC0OLHFsT3D1+y9upacvXFVVLKkzzCS3mdQr69+C2xWm9FEAJi+pMpmX1mdr2d77WRnJxM/A/5i1b41Ep5OSGjRjHisHq1zG2pE69fMyE5tLQIOXlSqlP+d+1/BCEg1+Kv1btZKhByPlfWxMUR0rs385l1cWHi98kDufU5KYkQGxtGKKQZMgsEhKxdyyijiwszLysnZNrnW7cYMTMzY0KxK4EbL28Ql50uBCEgg34fRB69qRqSX9r+VvYf+PzuQwzXGIoEwW6jHRl3fBzZfns7ScpKatCyWx6fR848OkNGHRlFtFdqE4SAuOx0Ib/c+oW8LpZNrKLk5GRis8GGfHL8k9oLcrnvFx+sXy+TthtMfj6T/0VDQ6ol5FeeXyEIAdkZubPeTVKBkPO58kAgYD4fdnbv/b+yjukn1z6/fMnEntHSIuSPP2ouV1TEdE4YEFDOcUxk3ueHDwlp04aZP67D1IAs4fF55JdbvxCjtUZEe6U2+SHyB1JczryPNfW3Nv9Bl+1dyPTT08kfSX+QF2/lF27kTfEbsjVmK3Hb5UYQAqK1QouM/GskOfXwlNj0tNISFRdFEAKy8cbGmguVljJJfQCFLl+WioICxpfHZjPBPGsrWlZAWCEsMvPozHo3RwVCzufKk+JiJgaUnh4TdmjpUtn9hsq9z/n574Pp/fRT9bndZ88I6dqVGTmIOy4H5NLnzExmakBDg8nvrSQyCzPJJ8c/IQgBafNzG/L3g79JcnJyvfwHiiYpK4nMPTeXmP3PjCAExGKdBVlwfgG5n1P3jWQ7Lu0gCAGJSq1h6F1c/H7T5a5d4ssom+Li97lKduyotajTVifSf3f/ejdFBULO5yqCFy8IGTPm/aa7Q4ca/nuqkD6Xlb03fNas906VyEhmeqZFCybapYKQW5/fvWPCjQvnspW4E/LK8yuk07ZOBCEgXTZ3abD/QJGUV5STsJQwMvzQcKK5QpMgBKTHrz3I9tvbSX5pvlR1zDw6k7BCWKSgTMwqs6IiJioxiyXXTIIyobSUCSsNELJpU43FpoRPIfab7OvdDBUIOZ+rSKKjmZtVgIlKHRtb/7oU1mc+nwnHDRAyciSz81pDg1ntpOA0tnLtM5fLbJcXhgOR5woDCZRXlJP/XfsfcdjkIDP/gaLJLsomG29sJF22dyEIAdFZqUPGHhtLzj85X2vU2/67+4t3UL97xzj32GxCDh6Uo+UyhMslJDCQ+UytWSO2SF5JHjkTU//pTSoQcj5X0VRUMBEnzM2ZG6HPP6/fakuF93nTJsZggHEOKngfASEK6DOf/z5Mw8iRcktcLy3q9LmuCYFAQGLTY8nMiJnE+Edj0cqtxZcWV3PKE0KIxU8W1R3U+flMZjdNTYXF1ZIZPN77G48lS8SOTukyVyloKgIh5O1b5sZcU5PZiLluXd3Cdiilz6dPM7FHFJa2ryoK6/OmTbLbONgAlHKNCwuZsCjx8dJlXasDZbwycuTeETL0j6GEvZxNEALS+7feZE/cHlJQVkCyCrOqO6hzc5k9K3VYPqpyVFQwd4LCFMAfiIS8fvs05RsrliJPmjcH1q8HvviCCUH+zTdMLouNGwFfXyYkucrh66tsCxTD118DlpbAxIlMaOfDhwEnJ0BDQ9mWyZb8fCYWfnz8+8ejR0zIMSGtWwOOjkz/HR3f/29mVucPqY6mDkY5j8Io51HIKMzA74m/Y1/CPkw5NQWzz80W5Ulws/4vxPfr10yY+ocPgZMn1ffzp6HBfLl1dZkvfWkpsHkzwJZvxgYqEI0ABwfg9Gkmn8/cuYCfH+Djw+SrcHJStnVNmLFjAXNzICAA6NKFSTRjb89clMoPe3vmi6/qZGdXFYL4+KqJb1q1Arp3Z/J1uLoC5eVASgqTfSslhcmxUVLyvryx8XvRqCwebdtKJaTWhtb4tve3WPjxQsSkx2Df3X04fP8w9DT14GrpymT8GjAAePYM+PtvYNAg2b8nioTNBrZsAfT0GJEoKwN27ZLrTQcViEbEkCHMzdK2bUBICNC1KzBzJrB0KfNdpCgBLy8gKYlJFJOSwjzu3GEykwnvslks5kfxQ+FwdFTOhSMEePXqvQgIRwgZGe/LdOwI9OgBTJvGiIKrK9CyZe31CgRAWhojGELRePCAycL122/vy2lrvxfSyiMOe3ugWbNq1bJYLPSy7YVetr2wafAm3E66DcM3BYw4vHoFnDkD9O8vozdHybBYwP/+x4jEypWMSOzfL7fmqEA0MrS0mNmNTz4BfviByYZ38CCwahWTOrWxzXCoBW3aAJ9/XvW10lJmKkYoGsIfy4sXmTtvIRYW4oXDxkY2c4gCAXOH/eHIIPe/bHZsNtPmgAGMEHTvzqRPNDKqe1tsNjPKaNWq+t18fv574RCKR0ICcPw4Y6MQ4XRV5VFHpekqfS192LzlA2M8gZwcJs1n7971fXdUExaLyXSnpwcsXsyIxJIlcmmKCkQjxcyMGX1Onw7MmcPc6O3YAfz8M5NRk6Jk9PSAbt2YR2X4fOD58+rC8eefwLt378sZGr7/caz8Q9m+PaBZw9e6ooKZi68sBHfvAoWFzHEtLWYqbMSI92LQpQugry+f96AyxsZMrnMPj6qvc7nAkyfv34fapqv+ew9anz8PFBUxYtuzHqlt1YXvvmM+R3PnwkogAE6ckHkTVCAaOS4uwD//MLmyFyxgRtpBQcC6dcq2jCIWDQ2gQwfm4ef3/nVCmDn1yqKRkgJcugSEhr4vp6XFTP/8JxrGLBYzGrh7F0hMZEYuAPPD4uLCONFdXRkxcHZuWM5leaCjw9jl7Fz19Vqmq1gAM6Unj3zlqsbXXwMtW6I8Pl4u1bMIqbzcQL1JSUmBUz29sg05V10oLWV8W2vXMt8vW1suzMx0YGjIzBhUfkjzmqr9lkhDo7zO795V/aEUPp4+ZS60kdF7ERA+HBxkOt9YXMzoT1wc87h7t+qAR5HwK7ho3kIHzZpBZg9Vn5qV128fHUE0IfT0mKnKyZOZpbDJyVwAOigoANLTgYIC5lFYWHWVYk3o6FQXDWmERVeX+d16n4BVMc8BIDu7OeLjmS+8pibzkMf/bLYClxk3b85MpXw4ncLl4vHNm+jYt69Ml0MWFTHuAaEYxMUx2iR8jy0s3vutlUFeXhm0tHRQXMwIV3o6RP8LHzxe3erU0REvHPr6VZ/XNLsnb9q0MZTLikUqEE0QOztmCWxKSjqcnKo7GwUCZnpXKBhC0aj8XNxrhYVAZiYzzS18raxMCR2sFWuFtVRZMExMGPdAu3bV/5qYyElMdHRQYWHRIHEoLGRGA5XF4OHD9zcQVlbMTM6oUYwouLkB1tbK3YOTkpIBJ6fmtZbh8aqLRn0eb94AL168f17Zn65I+vY1wLx5sq+XCgSlGmw2YGDAPKwb+HvK41UXEi6X+QERPoR32/J+DgCPHj1BmzYdUFHB+IMrKiD1//U5h89n3oPXr5kZnzNnGFdCZZo3r1k87OwUd1f67l11MXj8+L0Y2NgwAjB2LPPXzY0RCHVESwto0YJ5NAZSUjIBtJB5vVQgKHJFS4u5QzYxUbYlDCUlPHTsqFwbiouZhUpPnzIrTJ8+ZR5JSUB4eNXpD01NZpWsOPFo354R8fog3ABdWQyePHl/3M6OGRGMH/9eDCwsGtRtihoiV4GIjo7G6tWrIRAIMGrUKHz55ZdVjhNCsHr1akRFRUFXVxc//vgjnJ2dweVy8cknn6C8vBx8Ph8+Pj6YPXu2PE2lUBRGs2ZA587M40P4fGbO/EPxePaM2V+Xn1+1vLl5zeIhvLvPy2NWtFYWg2fP3tfRujUjBpMnM0LQvTtTL4UiN4Hg8/lYsWIF9u3bBwsLCwQFBcHLywsdOnQQlYmOjkZqaiouXLiAxMREhISE4OjRo9DW1saBAwfQrFkz8Hg8jBs3Dn379oWLi4u8zKVQVAINjfd7ycRt/s3Pfy8clf9euwYcOlR1DlxPDzA07ICcnPevtWnDiMCUKe/FQNIGaErTRW4CkZSUhNatW8POzg4A4Ovri8jIyCoCERkZiYCAALBYLLi4uKCgoAA5OTkwNzdHs/+21FdUVKCiogIslYw8R6EoFmPj91M+H1JezjhMK4vHkyfF+OijFiIxUJWpPop6IDeByM7OhqWlpei5hYUFkpKSai1jaWmJ7OxsmJubg8/nY+TIkXj58iXGjRuHbh/uOBUDl8tFSkpKvewtKyur97nqCu1z46R1a+bRvz/TX93/AgFmZzOPxk5TuMYfIq8+y00gxO2/+3AUUFsZDQ0NhIeHo6CgAF999RUePXoEe3v7WtvU0dGhG+XqAO1z46ep9Regfa7PuTUht2DilpaWyKq0nk84MqitTFZWVrUyRkZG6NmzJ65evSovUykUCoUiBrkJRJcuXZCamopXr16hvLwcERER8PLyqlLGy8sLYWFhIIQgISEBhoaGMDc3R15eHgoKCgAwQ6cbN26gXbt28jKVQqFQKGKQ2xSTpqYmli5diilTpoDP5yMwMBAdO3bEoUOHAADBwcHw9PREVFQUvL29oaenhzVr1gAAcnJysGjRIvD5fBBCMHjwYPRvLPHcKRQKRU2Q6z4IT09PeHp6VnktODhY9D+LxcKyZcuqnefo6IiwsDB5mkahUCgUCcg3oSmFQqFQ1BYqEBQKhUIRCxUICoVCoYilUSUMSkhIgI6OjrLNoFAoFLWBy+XWGMaoUQkEhUKhUGQHnWKiUCgUilioQFAoFApFLFQgKBQKhSIWKhAUCoVCEQsVCAqFQqGIhQoEhUKhUMTS5AUiOjoaPj4+8Pb2xu7du5VtjtzJzMzEhAkTMGTIEPj6+uLAgQPKNklh8Pl8BAQEYOrUqco2RSEUFBRg9uzZGDx4MIYMGYK7d+8q2yS5s3//fvj6+mLYsGGYN28euFyusk2SOd999x08PDwwbNgw0Wtv377Fp59+ikGDBuHTTz/Fu3fvZNJWkxYIYd7sPXv2ICIiAqdPn8aTJ0+UbZZc0dDQwKJFi3D27Fn89ddf+PPPPxt9n4WEhoaiffv2yjZDYaxevRp9+vTBuXPnEB4e3uj7np2djdDQUBw/fhynT58Gn89HRESEss2SOSNHjsSePXuqvLZ79254eHjgwoUL8PDwkNnNbpMWiMp5s7W1tUV5sxsz5ubmcHZ2BgAYGBigXbt2yG4CeSizsrLwzz//ICgoSNmmKISioiLcuXNH1F9tbW0YGRkp2Sr5w+fzUVZWhoqKCpSVlVVLQNYYcHd3R/Pmzau8FhkZiYCAAABAQEAALl26JJO2mrRAiMub3RR+LIWkpaUhJSVFqnzf6s6aNWvwzTffgM1uGh/5V69ewcTEBN999x0CAgLw/fffo6SkRNlmyRULCwt89tln6N+/P3r37g0DAwP07t1b2WYphNzcXJEYCpOuyYKm8W2pAWnyZjdWiouLMXv2bCxevBgGBgbKNkeuXLlyBSYmJujcubOyTVEYFRUVSE5ORnBwMMLCwqCnp9fofWzv3r1DZGQkIiMjcfXqVZSWliI8PFzZZqk1TVogpMmb3Rjh8XiYPXs2/Pz8MGjQIGWbI3fi4+Nx+fJleHl5Yd68ebh16xYWLFigbLPkiqWlJSwtLUWjw8GDByM5OVnJVsmXGzduwNbWFiYmJtDS0sKgQYOahGMeAExNTZGTkwOAychpYmIik3qbtEBIkze7sUEIwffff4927drh008/VbY5CmH+/PmIjo7G5cuXsXHjRvTq1Qvr169XtllyxczMDJaWlnj27BkA4ObNm43eSW1tbY3ExESUlpaCENIk+izEy8tLlIUzLCwMAwYMkEm9ck05qurUlDe7MRMXF4fw8HDY29tj+PDhAIB58+ZVSw1LUX+WLFmCBQsWgMfjwc7ODmvXrlW2SXKlW7du8PHxwYgRI6CpqQknJyeMGTNG2WbJnHnz5uH27dvIz89H3759MWvWLHz55Zf4+uuvcezYMVhZWeGXX36RSVs03DeFQqFQxNKkp5goFAqFUjNUICgUCoUiFioQFAqFQhELFQgKhUKhiIUKBIVCoVDE0qSXuVIob968wdq1a5GQkIDmzZtDS0sLU6ZMgbe3t8JtiYmJgZaWFrp37w4AOHToEPT09EQxdigURUMFgtJkIYTgq6++QkBAADZs2AAASE9Px+XLl+XWZkVFBTQ1xX/tbt++DX19fZFABAcHy80OCkUa6D4ISpPl5s2b2LZtGw4ePFjtGJ/Px/r163H79m2Ul5fjk08+wdixYxETE4OtW7fC2NgYjx49grOzM9avXw8Wi4V79+7hxx9/RElJCYyNjbF27VqYm5tjwoQJcHV1RXx8PLy8vNCmTRvs2LEDPB4PLVq0wPr161FWVoYxY8aAzWbDxMQES5Yswc2bN6Gvr4/PP/8cKSkpWLZsGUpLS9GqVSusWbMGzZs3x4QJE9C1a1fExMSgsLAQq1evBofDUcK7SWmMUB8Epcny+PFjdOrUSeyxY8eOwdDQEMePH8fx48dx5MgRvHr1CgCQnJyMxYsX48yZM0hLS0NcXBx4PB5WrVqFzZs348SJEwgMDMSmTZtE9RUUFODgwYP47LPP4ObmhiNHjiAsLAy+vr7Ys2cPbG1tMXbsWEyePBnh4eHVfuQXLlyIBQsW4NSpU7C3t8fWrVtFx/h8Po4dO4bFixdXeZ1CaSh0iolC+Y/ly5cjLi4OWlpasLGxwcOHD3H+/HkAQGFhIV68eAEtLS107dpVFCbe0dER6enpMDIywqNHj0TxrQQCAczMzER1Dx06VPR/VlYW5s6di9evX6O8vBy2tra12lVYWIjCwkL06NEDADBixAjMmTNHdFzoL3F2dkZ6eroM3gkKhYEKBKXJ0rFjR1y4cEH0fNmyZcjLy0NQUBCsra3xww8/oE+fPlXOiYmJgba2tui5hoYG+Hw+CCHo2LEj/vrrL7Ft6enpif5ftWoVJk+ejAEDBoimrBqC0B42mw0+n9+guiiUytApJkqTpVevXuByufjzzz9Fr5WVlQEAevfujUOHDoHH4wEAnj9/XmvCnbZt2yIvL08UXprH4+Hx48diyxYWFsLCwgIARBE4AaBZs2YoLi6uVt7Q0BBGRkaIjY0FAISHh8Pd3b0OPaVQ6gcdQVCaLCwWC9u2bcPatWuxZ88emJiYQE9PDwsWLMDgwYORnp6OkSNHghACY2NjbN++vca6tLW1sXnzZqxatQqFhYXg8/mYNGmS2OjAM2fOxJw5c2BhYYFu3bohLS0NANC/f3/Mnj0bkZGRWLJkSZVzfvrpJ5GTuilEZqWoBnQVE4VCoVDEQqeYKBQKhSIWKhAUCoVCEQsVCAqFQqGIhQoEhUKhUMRCBYJCoVAoYqECQaFQKBSxUIGgUCgUilj+D6bpXUOp1Zh/AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total elapsed time: 53.10231747229894 minutes\n"
     ]
    }
   ],
   "source": [
    "population_size = 5   # max of individuals per generation\n",
    "max_generations = 10  # number of generations\n",
    "gene_length = 7      # lenght of the gene, depends on how many hiperparameters are tested  \n",
    "k = 1;                 # num. of finalist individuals\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    t = time.time(); \n",
    "    datos = [];\n",
    "    ss = [i for i in range(1,population_size*(max_generations+1))]\n",
    "    best_population = geneticAlgorithm_with_elitism(population_size, max_generations, gene_length, k)\n",
    "    print(\"Total elapsed time:\", (time.time()-t)/60, \"minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k= 1 \n",
      "Deep layers: 1 , Number of neurons: 100\n",
      "Batch size 4 , Learning rate: 0.0001\n"
     ]
    }
   ],
   "source": [
    "best_deep_layers   = []\n",
    "best_num_units     = []\n",
    "best_learning_rate = []\n",
    "best_batch_size    = []\n",
    "# best_activation_f  = []\n",
    "best_f_names       = []\n",
    "\n",
    "t = 0\n",
    "\n",
    "for bi in best_population:\n",
    "    deep_layers_bits   = BitArray(bi[0:1])    # (8)\n",
    "    num_units_bits     = BitArray(bi[1:2])    # (16)\n",
    "    learning_rate_bits = BitArray(bi[2:3])   # (8)\n",
    "    batch_size_bits    = BitArray(bi[3:4])  # (4)\n",
    "#     activation_f_bits  = BitArray(bi[12:13])  # (2)\n",
    "    t += 1 \n",
    "    \n",
    "    best_deep_layers.append(SC_DEEP[deep_layers_bits.uint])\n",
    "    best_num_units.append(SC_NUM_UNITS[num_units_bits.uint])\n",
    "    best_learning_rate.append(SC_LEARNING[learning_rate_bits.uint])\n",
    "    best_batch_size.append(SC_BATCH[batch_size_bits.uint])\n",
    "#     best_activation_f.append(SC_ACTIVATION[activation_f_bits.uint])\n",
    "#     best_f_names.append(f_names[activation_f_bits.uint])\n",
    "    print('k=',t,'\\nDeep layers:', best_deep_layers[-1], ', Number of neurons:', best_num_units[-1])\n",
    "    print('Batch size', best_batch_size[-1], ', Learning rate:', best_learning_rate[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Deep layers</th>\n",
       "      <th>Num units</th>\n",
       "      <th>Learning rate</th>\n",
       "      <th>Batch size</th>\n",
       "      <th>Loss</th>\n",
       "      <th>Score</th>\n",
       "      <th>Elapsed time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>2</td>\n",
       "      <td>0.030242</td>\n",
       "      <td>0.030242</td>\n",
       "      <td>102.091133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>2</td>\n",
       "      <td>0.031221</td>\n",
       "      <td>0.031221</td>\n",
       "      <td>143.870087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>2</td>\n",
       "      <td>0.031290</td>\n",
       "      <td>0.031290</td>\n",
       "      <td>123.864580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>2</td>\n",
       "      <td>0.031325</td>\n",
       "      <td>0.031325</td>\n",
       "      <td>138.109795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>2</td>\n",
       "      <td>0.031370</td>\n",
       "      <td>0.031370</td>\n",
       "      <td>70.832471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>2</td>\n",
       "      <td>0.031375</td>\n",
       "      <td>0.031375</td>\n",
       "      <td>124.225805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>2</td>\n",
       "      <td>0.031474</td>\n",
       "      <td>0.031474</td>\n",
       "      <td>110.120988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>2</td>\n",
       "      <td>0.031510</td>\n",
       "      <td>0.031510</td>\n",
       "      <td>112.542941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>2</td>\n",
       "      <td>0.031542</td>\n",
       "      <td>0.031542</td>\n",
       "      <td>102.963166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>2</td>\n",
       "      <td>0.031596</td>\n",
       "      <td>0.031596</td>\n",
       "      <td>76.198455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>2</td>\n",
       "      <td>0.031680</td>\n",
       "      <td>0.031680</td>\n",
       "      <td>124.551734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>2</td>\n",
       "      <td>0.031869</td>\n",
       "      <td>0.031869</td>\n",
       "      <td>65.897505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>2</td>\n",
       "      <td>0.031984</td>\n",
       "      <td>0.031984</td>\n",
       "      <td>118.016865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>2</td>\n",
       "      <td>0.032303</td>\n",
       "      <td>0.032303</td>\n",
       "      <td>80.197788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>2</td>\n",
       "      <td>0.032966</td>\n",
       "      <td>0.032966</td>\n",
       "      <td>93.915339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>4</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>4</td>\n",
       "      <td>0.033999</td>\n",
       "      <td>0.033999</td>\n",
       "      <td>60.671295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2</td>\n",
       "      <td>200</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>8</td>\n",
       "      <td>0.034129</td>\n",
       "      <td>0.034129</td>\n",
       "      <td>25.646225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>4</td>\n",
       "      <td>0.034818</td>\n",
       "      <td>0.034818</td>\n",
       "      <td>84.048396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>4</td>\n",
       "      <td>0.035220</td>\n",
       "      <td>0.035220</td>\n",
       "      <td>64.161468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>4</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>2</td>\n",
       "      <td>0.035283</td>\n",
       "      <td>0.035283</td>\n",
       "      <td>157.140627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>4</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>8</td>\n",
       "      <td>0.035704</td>\n",
       "      <td>0.035704</td>\n",
       "      <td>38.584807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>4</td>\n",
       "      <td>0.035871</td>\n",
       "      <td>0.035871</td>\n",
       "      <td>58.486144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>4</td>\n",
       "      <td>0.036291</td>\n",
       "      <td>0.036291</td>\n",
       "      <td>64.972876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>4</td>\n",
       "      <td>0.036773</td>\n",
       "      <td>0.036773</td>\n",
       "      <td>83.101967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>4</td>\n",
       "      <td>0.036830</td>\n",
       "      <td>0.036830</td>\n",
       "      <td>71.713149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>4</td>\n",
       "      <td>0.037615</td>\n",
       "      <td>0.037615</td>\n",
       "      <td>83.132482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>4</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>2</td>\n",
       "      <td>0.038389</td>\n",
       "      <td>0.038389</td>\n",
       "      <td>119.126493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>4</td>\n",
       "      <td>0.038396</td>\n",
       "      <td>0.038396</td>\n",
       "      <td>59.036835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>4</td>\n",
       "      <td>0.041373</td>\n",
       "      <td>0.041373</td>\n",
       "      <td>74.364007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>4</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>8</td>\n",
       "      <td>0.044468</td>\n",
       "      <td>0.044468</td>\n",
       "      <td>43.986428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>2</td>\n",
       "      <td>200</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>16</td>\n",
       "      <td>0.053052</td>\n",
       "      <td>0.053052</td>\n",
       "      <td>42.107305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>2</td>\n",
       "      <td>0.054420</td>\n",
       "      <td>0.054420</td>\n",
       "      <td>129.382689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>16</td>\n",
       "      <td>0.060751</td>\n",
       "      <td>0.060751</td>\n",
       "      <td>21.988517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>4</td>\n",
       "      <td>200</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>16</td>\n",
       "      <td>0.061110</td>\n",
       "      <td>0.061110</td>\n",
       "      <td>36.935748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>2</td>\n",
       "      <td>0.069254</td>\n",
       "      <td>0.069254</td>\n",
       "      <td>64.968371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>2</td>\n",
       "      <td>0.070518</td>\n",
       "      <td>0.070518</td>\n",
       "      <td>131.971853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>4</td>\n",
       "      <td>0.077293</td>\n",
       "      <td>0.077293</td>\n",
       "      <td>82.992470</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Deep layers  Num units  Learning rate  Batch size      Loss     Score  \\\n",
       "0             2        100         0.0001           2  0.030242  0.030242   \n",
       "1             2        100         0.0001           2  0.031221  0.031221   \n",
       "2             2        100         0.0001           2  0.031290  0.031290   \n",
       "3             2        100         0.0001           2  0.031325  0.031325   \n",
       "4             2        100         0.0001           2  0.031370  0.031370   \n",
       "5             2        100         0.0001           2  0.031375  0.031375   \n",
       "6             2        100         0.0001           2  0.031474  0.031474   \n",
       "7             2        100         0.0001           2  0.031510  0.031510   \n",
       "8             2        100         0.0001           2  0.031542  0.031542   \n",
       "9             2        100         0.0001           2  0.031596  0.031596   \n",
       "10            2        100         0.0001           2  0.031680  0.031680   \n",
       "11            2        100         0.0001           2  0.031869  0.031869   \n",
       "12            2        100         0.0001           2  0.031984  0.031984   \n",
       "13            2        100         0.0001           2  0.032303  0.032303   \n",
       "14            2        100         0.0001           2  0.032966  0.032966   \n",
       "15            4        100         0.0001           4  0.033999  0.033999   \n",
       "16            2        200         0.0010           8  0.034129  0.034129   \n",
       "17            2        100         0.0001           4  0.034818  0.034818   \n",
       "18            2        100         0.0001           4  0.035220  0.035220   \n",
       "19            4        100         0.0001           2  0.035283  0.035283   \n",
       "20            4        100         0.0001           8  0.035704  0.035704   \n",
       "21            2        100         0.0001           4  0.035871  0.035871   \n",
       "22            2        100         0.0001           4  0.036291  0.036291   \n",
       "23            2        100         0.0001           4  0.036773  0.036773   \n",
       "24            2        100         0.0001           4  0.036830  0.036830   \n",
       "25            2        100         0.0001           4  0.037615  0.037615   \n",
       "26            4        100         0.0001           2  0.038389  0.038389   \n",
       "27            2        100         0.0001           4  0.038396  0.038396   \n",
       "28            2        100         0.0010           4  0.041373  0.041373   \n",
       "29            4        100         0.0001           8  0.044468  0.044468   \n",
       "30            2        200         0.0001          16  0.053052  0.053052   \n",
       "31            2        100         0.0010           2  0.054420  0.054420   \n",
       "32            2        100         0.0001          16  0.060751  0.060751   \n",
       "33            4        200         0.0010          16  0.061110  0.061110   \n",
       "34            1         50         0.0001           2  0.069254  0.069254   \n",
       "35            3        100         0.0010           2  0.070518  0.070518   \n",
       "36            1        100         0.0001           4  0.077293  0.077293   \n",
       "\n",
       "    Elapsed time  \n",
       "0     102.091133  \n",
       "1     143.870087  \n",
       "2     123.864580  \n",
       "3     138.109795  \n",
       "4      70.832471  \n",
       "5     124.225805  \n",
       "6     110.120988  \n",
       "7     112.542941  \n",
       "8     102.963166  \n",
       "9      76.198455  \n",
       "10    124.551734  \n",
       "11     65.897505  \n",
       "12    118.016865  \n",
       "13     80.197788  \n",
       "14     93.915339  \n",
       "15     60.671295  \n",
       "16     25.646225  \n",
       "17     84.048396  \n",
       "18     64.161468  \n",
       "19    157.140627  \n",
       "20     38.584807  \n",
       "21     58.486144  \n",
       "22     64.972876  \n",
       "23     83.101967  \n",
       "24     71.713149  \n",
       "25     83.132482  \n",
       "26    119.126493  \n",
       "27     59.036835  \n",
       "28     74.364007  \n",
       "29     43.986428  \n",
       "30     42.107305  \n",
       "31    129.382689  \n",
       "32     21.988517  \n",
       "33     36.935748  \n",
       "34     64.968371  \n",
       "35    131.971853  \n",
       "36     82.992470  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename = \"historial_genetic_jla1.txt\"\n",
    "df = pd.DataFrame(datos, columns = [\"Deep layers\", \"Num units\", \"Learning rate\", \"Batch size\", \"Loss\", \"Score\", \"Elapsed time\"])\n",
    "\n",
    "df.sort_values(by=[\"Loss\", \"Elapsed time\"], ascending=[True, True], ignore_index=True, inplace=True)\n",
    "\n",
    "df.to_csv(filename, header=True, index=False, sep='\\t', mode='w') # a=append, w=overwrite\n",
    "df.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time 53.099 minutes\n"
     ]
    }
   ],
   "source": [
    "total_time = float(np.sum(df[[\"Elapsed time\"]])/60)\n",
    "\n",
    "print(\"Elapsed time {:.3f} minutes\".format(total_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
