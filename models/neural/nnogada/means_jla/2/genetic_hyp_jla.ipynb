{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-18 00:38:52.087498: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-12-18 00:38:52.283302: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-12-18 00:38:52.283359: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2022-12-18 00:38:53.612866: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2022-12-18 00:38:53.613052: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2022-12-18 00:38:53.613067: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import time, os\n",
    "import random\n",
    "import seaborn as sns\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Input, Dense, LeakyReLU\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorboard.plugins.hparams import api as hp\n",
    "\n",
    "from tensorflow.keras import activations\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "import random\n",
    "from math import floor\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import optimizers\n",
    "from scipy.integrate import odeint\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split as split\n",
    "from scipy.stats import bernoulli\n",
    "\n",
    "# import deap\n",
    "from deap import base, creator, tools, algorithms\n",
    "\n",
    "from bitstring import BitArray\n",
    "\n",
    "# from elitism import eaSimpleWithElitism, main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "\n",
    "# tf.config.optimizer.set_jit(True)\n",
    "# scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "url = 'https://raw.githubusercontent.com/igomezv/nnogada/main/data/jla.csv'\n",
    "df=pd.read_csv(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = len(df.values)\n",
    "randomize = np.random.permutation(N)\n",
    "data = df.values[randomize]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(740, 2)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N = len(df.values)\n",
    "z = data[:,0] \n",
    "y = data[:,1:3] ### coge el resto de variables a predecir \n",
    "y[:,1] = y[:,1]**2+data[:,2]\n",
    "np.shape(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "scalerz = StandardScaler()\n",
    "scalerz.fit(z.reshape(-1,1))\n",
    "z = scalerz.transform(z.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((592, 1), (148, 1), (592, 2), (148, 2))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Modificar para incluir phanteon como test\n",
    "split = 0.8\n",
    "ntrain = int(split * len(z))\n",
    "indx = [ntrain]\n",
    "X_train, X_val = np.split(z, indx)\n",
    "Y_train, Y_val = np.split(y, indx)\n",
    "# X_train, X_test = np.split(z, indx)\n",
    "# Y_train, Y_test = np.split(y, indx)\n",
    "np.shape(X_train), np.shape(X_val), Y_train.shape, Y_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "SC_DEEP       = np.array([1,2,3,4])                           # Number of deep layers (8)\n",
    "SC_NUM_UNITS  = np.array([50,100,150,200]) # Number of fully conected neurons (16)\n",
    "SC_LEARNING   = np.array([1e-4,1e-3])   # Learning rates (8)\n",
    "SC_BATCH      = np.array([2, 4, 8, 16])                            # Batch sizes (4)\n",
    "# SC_ACTIVATION = [f1, f2, f3, f4]                                      # Activation function layers (2)\n",
    "\n",
    "my_callbacks = [tf.keras.callbacks.EarlyStopping(\n",
    "                               monitor='val_loss', mode='min',\n",
    "                               min_delta=0, \n",
    "                               patience=200,\n",
    "                               verbose=1,\n",
    "                            #    baseline=0,\n",
    "                               restore_best_weights=True)\n",
    "#                 keras.callbacks.TensorBoard(\n",
    "#                                log_dir='./logs'),\n",
    "#                 keras.callbacks.ReduceLROnPlateau(\n",
    "#                                monitor='val_loss', factor=0.5,\n",
    "#                                patience=6, min_lr=0,\n",
    "#                                verbose=1)\n",
    "               ] \n",
    "    \n",
    "epochs = 200\n",
    "# epochs = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_evaluate(ga_individual_solution):   \n",
    "    t = time.time()\n",
    "    t_total = 0\n",
    "    \n",
    "    # Decode GA solution to integer for window_size and num_units\n",
    "    deep_layers_bits   = BitArray(ga_individual_solution[0:2])     # (8)\n",
    "    num_units_bits     = BitArray(ga_individual_solution[2:4])     # (16)\n",
    "    learning_rate_bits = BitArray(ga_individual_solution[4:5])    # (8)\n",
    "    batch_size_bits    = BitArray(ga_individual_solution[5:7])   # (4)\n",
    "# #     activation_f_bits  = BitArray(ga_individual_solution[12:13])   # (2)   Solo se consideran las 2 primeras\n",
    "    \n",
    "    deep_layers   = SC_DEEP[deep_layers_bits.uint]\n",
    "    num_units     = SC_NUM_UNITS[num_units_bits.uint]\n",
    "    learning_rate = SC_LEARNING[learning_rate_bits.uint]\n",
    "    batch_size   = SC_BATCH[batch_size_bits.uint]\n",
    "#     activation_f  = SC_ACTIVATION[activation_f_bits.uint]\n",
    "\n",
    "    \n",
    "    print('\\n--------------- Starting trial:', population_size*(max_generations+1)-len(ss), \"---------------\")\n",
    "    print('Deep layers:',deep_layers,', Number of neurons:',num_units,\", Learning rate:\",learning_rate)\n",
    "#     print(\"-------------------------------------------------\")\n",
    "    \n",
    "    # Train model and predict on validation set\n",
    "    model = tf.keras.Sequential()\n",
    "#     model.add(Input(shape=(int(X_train.shape[1]),)))\n",
    "    model.add(Dense(int(X_train.shape[1])))\n",
    "    \n",
    "    for i in range(deep_layers):        \n",
    "        model.add(Dense(num_units, activation='relu'))\n",
    "#             model.add(keras.layers.Dropout(0.3))\n",
    "    model.add(Dense(2, activation='linear'))\n",
    "    \n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate, beta_1=0.9, beta_2=0.999, epsilon=1e-3)\n",
    "    model.compile(optimizer=optimizer, loss='mse', metrics=['mean_squared_error'])\n",
    "    model.fit(X_train, Y_train, epochs=epochs, validation_data=(X_val, Y_val),\n",
    "              callbacks=my_callbacks, batch_size=batch_size, shuffle=False, verbose=0)\n",
    "    \n",
    "    loss, score = model.evaluate(X_val, Y_val)    \n",
    "    t = time.time()-t\n",
    "    ss.pop(0)\n",
    "    print(\"Loss:\", score, \", Elapsed time:\", t)\n",
    "    print(\"-------------------------------------------------\\n\")\n",
    "#     print(loss, score)\n",
    "\n",
    "    datos.append([deep_layers, num_units, learning_rate, batch_size, loss, score, t])\n",
    "    \n",
    "    return loss,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deap import tools\n",
    "from deap import algorithms\n",
    "\n",
    "def eaSimpleWithElitism(population, toolbox, cxpb, mutpb, ngen, stats=None,\n",
    "             halloffame=None, verbose=__debug__):\n",
    "    \"\"\"This algorithm is similar to DEAP eaSimple() algorithm, with the modification that\n",
    "    halloffame is used to implement an elitism mechanism. The individuals contained in the\n",
    "    halloffame are directly injected into the next generation and are not subject to the\n",
    "    genetic operators of selection, crossover and mutation.\n",
    "    \"\"\"\n",
    "    logbook = tools.Logbook()\n",
    "    logbook.header = ['gen', 'nevals'] + (stats.fields if stats else [])\n",
    "\n",
    "    # Evaluate the individuals with an invalid fitness\n",
    "    invalid_ind = [ind for ind in population if not ind.fitness.valid]\n",
    "    fitnesses = toolbox.map(toolbox.evaluate, invalid_ind)\n",
    "    for ind, fit in zip(invalid_ind, fitnesses):\n",
    "        ind.fitness.values = fit\n",
    "\n",
    "    if halloffame is None:\n",
    "        raise ValueError(\"halloffame parameter must not be empty!\")\n",
    "\n",
    "    halloffame.update(population)\n",
    "    hof_size = len(halloffame.items) if halloffame.items else 0\n",
    "\n",
    "    record = stats.compile(population) if stats else {}\n",
    "    logbook.record(gen=0, nevals=len(invalid_ind), **record)\n",
    "    if verbose:\n",
    "        print(logbook.stream)\n",
    "\n",
    "    # Begin the generational process\n",
    "    for gen in range(1, ngen + 1):\n",
    "\n",
    "        # Select the next generation individuals\n",
    "        offspring = toolbox.select(population, len(population) - hof_size)\n",
    "\n",
    "        # Vary the pool of individuals\n",
    "        offspring = algorithms.varAnd(offspring, toolbox, cxpb, mutpb)\n",
    "\n",
    "        # Evaluate the individuals with an invalid fitness\n",
    "        invalid_ind = [ind for ind in offspring if not ind.fitness.valid]\n",
    "        fitnesses = toolbox.map(toolbox.evaluate, invalid_ind)\n",
    "        for ind, fit in zip(invalid_ind, fitnesses):\n",
    "            ind.fitness.values = fit\n",
    "\n",
    "        # add the best back to population:\n",
    "        offspring.extend(halloffame.items)\n",
    "\n",
    "        # Update the hall of fame with the generated individuals\n",
    "        halloffame.update(offspring)\n",
    "\n",
    "        # Replace the current population by the offspring\n",
    "        population[:] = offspring\n",
    "\n",
    "        # Append the current generation statistics to the logbook\n",
    "        record = stats.compile(population) if stats else {}\n",
    "        logbook.record(gen=gen, nevals=len(invalid_ind), **record)\n",
    "        if verbose:\n",
    "            print(logbook.stream)\n",
    "\n",
    "    return population, logbook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def geneticAlgorithm_with_elitism(population_size, max_generations, gene_length, k):\n",
    "    \n",
    "    # Genetic Algorithm constants:\n",
    "    P_CROSSOVER = 0.5        # probability for crossover\n",
    "    P_MUTATION = 0.5         # probability for mutating an individual\n",
    "    HALL_OF_FAME_SIZE = 1    # Best individuals that pass to the other generation\n",
    "    \n",
    "    # set the random seed:\n",
    "    toolbox = base.Toolbox()\n",
    "\n",
    "    # As we are trying to minimize the RMSE score, that's why using -1.0. \n",
    "    # In case, when you want to maximize accuracy for instance, use 1.0\n",
    "    creator.create('FitnessMin', base.Fitness, weights = [-1.0])\n",
    "    creator.create('Individual', list , fitness = creator.FitnessMin)\n",
    "\n",
    "    # create the individual operator to fill up an Individual instance:\n",
    "    toolbox.register('binary', bernoulli.rvs, 0.5)\n",
    "    toolbox.register('individual', tools.initRepeat, creator.Individual, toolbox.binary, n = gene_length)\n",
    "\n",
    "    # create the population operator to generate a list of individuals:\n",
    "    toolbox.register('population', tools.initRepeat, list , toolbox.individual)\n",
    "\n",
    "    # genetic operators:\n",
    "    toolbox.register('evaluate', train_evaluate)\n",
    "    toolbox.register('select', tools.selTournament, tournsize = 2)\n",
    "    toolbox.register('mutate', tools.mutFlipBit, indpb = 0.11)\n",
    "    toolbox.register('mate', tools.cxUniform, indpb = 0.5)\n",
    "    \n",
    "    # create initial population (generation 0):\n",
    "    population = toolbox.population(n=population_size)\n",
    "\n",
    "    # prepare the statistics object:\n",
    "    stats = tools.Statistics(lambda ind: ind.fitness.values)\n",
    "    stats.register(\"min\", np.min)\n",
    "    stats.register(\"avg\", np.mean)\n",
    "    stats.register(\"max\", np.max)\n",
    "\n",
    "    # define the hall-of-fame object:\n",
    "    hof = tools.HallOfFame(HALL_OF_FAME_SIZE)\n",
    "\n",
    "    # Genetic Algorithm flow with elitism:\n",
    "    population, logbook = eaSimpleWithElitism(population, toolbox, cxpb=P_CROSSOVER, mutpb=P_MUTATION,\n",
    "                                              ngen=max_generations, stats=stats, halloffame=hof, verbose=True)\n",
    "\n",
    "    # print info for best solution found:\n",
    "    best = hof.items[0]\n",
    "    print(\"-- Best Individual = \", best)\n",
    "    print(\"-- Best Fitness = \", best.fitness.values[0])\n",
    "\n",
    "    # extract statistics:\n",
    "    minFitnessValues, meanFitnessValues, maxFitnessValues = logbook.select(\"min\", \"max\", \"avg\")\n",
    "\n",
    "    # plot statistics:\n",
    "    sns.set_style(\"whitegrid\")\n",
    "    plt.plot(minFitnessValues, color='blue', label=\"Min\")\n",
    "    plt.plot(meanFitnessValues, color='green', label=\"Mean\")\n",
    "    plt.plot(maxFitnessValues, color='red', label=\"Max\")\n",
    "    plt.xlabel('Generation'); plt.ylabel('Max / Min / Average Fitness')\n",
    "    plt.legend()\n",
    "    plt.title('Max, Min and Average fitness over Generations')\n",
    "    plt.show()\n",
    "    \n",
    "    best_population = tools.selBest(population,k = k)\n",
    "    return best_population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------------- Starting trial: 1 ---------------\n",
      "Deep layers: 3 , Number of neurons: 100 , Learning rate: 0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-18 00:38:54.983735: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-18 00:38:54.984050: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-12-18 00:38:54.984156: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory\n",
      "2022-12-18 00:38:54.984442: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory\n",
      "2022-12-18 00:38:54.984533: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcufft.so.10'; dlerror: libcufft.so.10: cannot open shared object file: No such file or directory\n",
      "2022-12-18 00:38:54.984602: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcurand.so.10'; dlerror: libcurand.so.10: cannot open shared object file: No such file or directory\n",
      "2022-12-18 00:38:54.984673: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory\n",
      "2022-12-18 00:38:54.984755: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory\n",
      "2022-12-18 00:38:54.984824: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2022-12-18 00:38:54.984837: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1934] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2022-12-18 00:38:54.986041: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0680 - mean_squared_error: 0.0680\n",
      "Loss: 0.06802504509687424 , Elapsed time: 203.72297835350037\n",
      "-------------------------------------------------\n",
      "\n",
      "\n",
      "--------------- Starting trial: 2 ---------------\n",
      "Deep layers: 2 , Number of neurons: 200 , Learning rate: 0.0001\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0536 - mean_squared_error: 0.0536\n",
      "Loss: 0.05361533537507057 , Elapsed time: 39.3018114566803\n",
      "-------------------------------------------------\n",
      "\n",
      "\n",
      "--------------- Starting trial: 3 ---------------\n",
      "Deep layers: 4 , Number of neurons: 200 , Learning rate: 0.001\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0617 - mean_squared_error: 0.0617\n",
      "Loss: 0.06172354146838188 , Elapsed time: 56.4754855632782\n",
      "-------------------------------------------------\n",
      "\n",
      "\n",
      "--------------- Starting trial: 4 ---------------\n",
      "Deep layers: 1 , Number of neurons: 100 , Learning rate: 0.0001\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0816 - mean_squared_error: 0.0816\n",
      "Loss: 0.08157533407211304 , Elapsed time: 83.16147232055664\n",
      "-------------------------------------------------\n",
      "\n",
      "\n",
      "--------------- Starting trial: 5 ---------------\n",
      "Deep layers: 2 , Number of neurons: 100 , Learning rate: 0.0001\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0430 - mean_squared_error: 0.0430\n",
      "Loss: 0.04299568012356758 , Elapsed time: 87.49692559242249\n",
      "-------------------------------------------------\n",
      "\n",
      "gen\tnevals\tmin      \tavg     \tmax      \n",
      "0  \t5     \t0.0429957\t0.061587\t0.0815753\n",
      "\n",
      "--------------- Starting trial: 6 ---------------\n",
      "Deep layers: 1 , Number of neurons: 100 , Learning rate: 0.0001\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0757 - mean_squared_error: 0.0757\n",
      "Loss: 0.07570178806781769 , Elapsed time: 76.74573349952698\n",
      "-------------------------------------------------\n",
      "\n",
      "\n",
      "--------------- Starting trial: 7 ---------------\n",
      "Deep layers: 2 , Number of neurons: 100 , Learning rate: 0.0001\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0378 - mean_squared_error: 0.0378\n",
      "Loss: 0.037811633199453354 , Elapsed time: 81.15719485282898\n",
      "-------------------------------------------------\n",
      "\n",
      "1  \t2     \t0.0378116\t0.0543696\t0.0757018\n",
      "\n",
      "--------------- Starting trial: 8 ---------------\n",
      "Deep layers: 2 , Number of neurons: 100 , Learning rate: 0.0001\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0366 - mean_squared_error: 0.0366\n",
      "Loss: 0.036582402884960175 , Elapsed time: 90.05338788032532\n",
      "-------------------------------------------------\n",
      "\n",
      "\n",
      "--------------- Starting trial: 9 ---------------\n",
      "Deep layers: 4 , Number of neurons: 100 , Learning rate: 0.0001\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0364 - mean_squared_error: 0.0364\n",
      "Loss: 0.03638278320431709 , Elapsed time: 202.22888159751892\n",
      "-------------------------------------------------\n",
      "\n",
      "\n",
      "--------------- Starting trial: 10 ---------------\n",
      "Deep layers: 2 , Number of neurons: 100 , Learning rate: 0.0001\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0316 - mean_squared_error: 0.0316\n",
      "Loss: 0.03156299889087677 , Elapsed time: 159.97101712226868\n",
      "-------------------------------------------------\n",
      "\n",
      "2  \t3     \t0.031563 \t0.0418495\t0.0617235\n",
      "\n",
      "--------------- Starting trial: 11 ---------------\n",
      "Deep layers: 2 , Number of neurons: 100 , Learning rate: 0.0001\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0358 - mean_squared_error: 0.0358\n",
      "Loss: 0.03581998869776726 , Elapsed time: 97.58019208908081\n",
      "-------------------------------------------------\n",
      "\n",
      "\n",
      "--------------- Starting trial: 12 ---------------\n",
      "Deep layers: 4 , Number of neurons: 100 , Learning rate: 0.0001\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0357 - mean_squared_error: 0.0357\n",
      "Loss: 0.03569189831614494 , Elapsed time: 173.70815443992615\n",
      "-------------------------------------------------\n",
      "\n",
      "\n",
      "--------------- Starting trial: 13 ---------------\n",
      "Deep layers: 4 , Number of neurons: 100 , Learning rate: 0.001\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0321 - mean_squared_error: 0.0321\n",
      "Loss: 0.03211117908358574 , Elapsed time: 144.04707217216492\n",
      "-------------------------------------------------\n",
      "\n",
      "\n",
      "--------------- Starting trial: 14 ---------------\n",
      "Deep layers: 2 , Number of neurons: 100 , Learning rate: 0.0001\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0313 - mean_squared_error: 0.0313\n",
      "Loss: 0.03129972144961357 , Elapsed time: 173.30072331428528\n",
      "-------------------------------------------------\n",
      "\n",
      "3  \t4     \t0.0312997\t0.0332972\t0.03582  \n",
      "\n",
      "--------------- Starting trial: 15 ---------------\n",
      "Deep layers: 2 , Number of neurons: 100 , Learning rate: 0.0001\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0310 - mean_squared_error: 0.0310\n",
      "Loss: 0.03103349357843399 , Elapsed time: 158.26165294647217\n",
      "-------------------------------------------------\n",
      "\n",
      "\n",
      "--------------- Starting trial: 16 ---------------\n",
      "Deep layers: 4 , Number of neurons: 100 , Learning rate: 0.0001\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0355 - mean_squared_error: 0.0355\n",
      "Loss: 0.03545232117176056 , Elapsed time: 183.7266824245453\n",
      "-------------------------------------------------\n",
      "\n",
      "\n",
      "--------------- Starting trial: 17 ---------------\n",
      "Deep layers: 4 , Number of neurons: 200 , Learning rate: 0.001\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0422 - mean_squared_error: 0.0422\n",
      "Loss: 0.04221971705555916 , Elapsed time: 204.21870303153992\n",
      "-------------------------------------------------\n",
      "\n",
      "\n",
      "--------------- Starting trial: 18 ---------------\n",
      "Deep layers: 4 , Number of neurons: 200 , Learning rate: 0.0001\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0390 - mean_squared_error: 0.0390\n",
      "Loss: 0.038988444954156876 , Elapsed time: 324.625203371048\n",
      "-------------------------------------------------\n",
      "\n",
      "4  \t4     \t0.0310335\t0.0358514\t0.0422197\n",
      "\n",
      "--------------- Starting trial: 19 ---------------\n",
      "Deep layers: 2 , Number of neurons: 100 , Learning rate: 0.0001\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0318 - mean_squared_error: 0.0318\n",
      "Loss: 0.031822193413972855 , Elapsed time: 191.67918992042542\n",
      "-------------------------------------------------\n",
      "\n",
      "\n",
      "--------------- Starting trial: 20 ---------------\n",
      "Deep layers: 4 , Number of neurons: 50 , Learning rate: 0.0001\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0319 - mean_squared_error: 0.0319\n",
      "Loss: 0.031889986246824265 , Elapsed time: 204.8936219215393\n",
      "-------------------------------------------------\n",
      "\n",
      "\n",
      "--------------- Starting trial: 21 ---------------\n",
      "Deep layers: 2 , Number of neurons: 100 , Learning rate: 0.0001\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0366 - mean_squared_error: 0.0366\n",
      "Loss: 0.03657291829586029 , Elapsed time: 204.031245470047\n",
      "-------------------------------------------------\n",
      "\n",
      "\n",
      "--------------- Starting trial: 22 ---------------\n",
      "Deep layers: 4 , Number of neurons: 100 , Learning rate: 0.0001\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0352 - mean_squared_error: 0.0352\n",
      "Loss: 0.035238564014434814 , Elapsed time: 203.9276750087738\n",
      "-------------------------------------------------\n",
      "\n",
      "5  \t4     \t0.031563 \t0.0334173\t0.0365729\n",
      "\n",
      "--------------- Starting trial: 23 ---------------\n",
      "Deep layers: 2 , Number of neurons: 100 , Learning rate: 0.0001\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0371 - mean_squared_error: 0.0371\n",
      "Loss: 0.03714333102107048 , Elapsed time: 83.17720079421997\n",
      "-------------------------------------------------\n",
      "\n",
      "\n",
      "--------------- Starting trial: 24 ---------------\n",
      "Deep layers: 2 , Number of neurons: 100 , Learning rate: 0.0001\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0321 - mean_squared_error: 0.0321\n",
      "Loss: 0.03214997798204422 , Elapsed time: 203.5100519657135\n",
      "-------------------------------------------------\n",
      "\n",
      "\n",
      "--------------- Starting trial: 25 ---------------\n",
      "Deep layers: 2 , Number of neurons: 100 , Learning rate: 0.0001\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0325 - mean_squared_error: 0.0325\n",
      "Loss: 0.032525625079870224 , Elapsed time: 131.87338542938232\n",
      "-------------------------------------------------\n",
      "\n",
      "6  \t3     \t0.031563 \t0.0330544\t0.0371433\n",
      "\n",
      "--------------- Starting trial: 26 ---------------\n",
      "Deep layers: 4 , Number of neurons: 50 , Learning rate: 0.001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0740 - mean_squared_error: 0.0740\n",
      "Loss: 0.07403586059808731 , Elapsed time: 144.24415850639343\n",
      "-------------------------------------------------\n",
      "\n",
      "\n",
      "--------------- Starting trial: 27 ---------------\n",
      "Deep layers: 2 , Number of neurons: 100 , Learning rate: 0.0001\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0310 - mean_squared_error: 0.0310\n",
      "Loss: 0.031020840629935265 , Elapsed time: 108.3087272644043\n",
      "-------------------------------------------------\n",
      "\n",
      "\n",
      "--------------- Starting trial: 28 ---------------\n",
      "Deep layers: 2 , Number of neurons: 100 , Learning rate: 0.0001\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0367 - mean_squared_error: 0.0367\n",
      "Loss: 0.03674241527915001 , Elapsed time: 105.49693131446838\n",
      "-------------------------------------------------\n",
      "\n",
      "7  \t3     \t0.0310208\t0.040985 \t0.0740359\n",
      "\n",
      "--------------- Starting trial: 29 ---------------\n",
      "Deep layers: 2 , Number of neurons: 50 , Learning rate: 0.0001\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0336 - mean_squared_error: 0.0336\n",
      "Loss: 0.03356187790632248 , Elapsed time: 94.37133717536926\n",
      "-------------------------------------------------\n",
      "\n",
      "\n",
      "--------------- Starting trial: 30 ---------------\n",
      "Deep layers: 2 , Number of neurons: 200 , Learning rate: 0.0001\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0310 - mean_squared_error: 0.0310\n",
      "Loss: 0.030999356880784035 , Elapsed time: 109.51957774162292\n",
      "-------------------------------------------------\n",
      "\n",
      "8  \t2     \t0.0309994\t0.0317416\t0.0335619\n",
      "\n",
      "--------------- Starting trial: 31 ---------------\n",
      "Deep layers: 2 , Number of neurons: 100 , Learning rate: 0.0001\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0321 - mean_squared_error: 0.0321\n",
      "Loss: 0.03214153274893761 , Elapsed time: 100.2573311328888\n",
      "-------------------------------------------------\n",
      "\n",
      "\n",
      "--------------- Starting trial: 32 ---------------\n",
      "Deep layers: 4 , Number of neurons: 100 , Learning rate: 0.0001\n",
      "5/5 [==============================] - 1s 2ms/step - loss: 0.0368 - mean_squared_error: 0.0368\n",
      "Loss: 0.036828696727752686 , Elapsed time: 86.44282174110413\n",
      "-------------------------------------------------\n",
      "\n",
      "9  \t2     \t0.0309994\t0.0325107\t0.0368287\n",
      "\n",
      "--------------- Starting trial: 33 ---------------\n",
      "Deep layers: 2 , Number of neurons: 100 , Learning rate: 0.0001\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0357 - mean_squared_error: 0.0357\n",
      "Loss: 0.03567366674542427 , Elapsed time: 41.175636291503906\n",
      "-------------------------------------------------\n",
      "\n",
      "\n",
      "--------------- Starting trial: 34 ---------------\n",
      "Deep layers: 4 , Number of neurons: 100 , Learning rate: 0.0001\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0360 - mean_squared_error: 0.0360\n",
      "Loss: 0.0360386036336422 , Elapsed time: 82.31052017211914\n",
      "-------------------------------------------------\n",
      "\n",
      "\n",
      "--------------- Starting trial: 35 ---------------\n",
      "Deep layers: 2 , Number of neurons: 100 , Learning rate: 0.0001\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0316 - mean_squared_error: 0.0316\n",
      "Loss: 0.03160010278224945 , Elapsed time: 69.29062128067017\n",
      "-------------------------------------------------\n",
      "\n",
      "10 \t3     \t0.0309994\t0.0330622\t0.0360386\n",
      "-- Best Individual =  [0, 1, 1, 1, 0, 0, 0]\n",
      "-- Best Fitness =  0.030999356880784035\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total elapsed time: 78.40921351909637 minutes\n"
     ]
    }
   ],
   "source": [
    "population_size = 5   # max of individuals per generation\n",
    "max_generations = 10  # number of generations\n",
    "gene_length = 7      # lenght of the gene, depends on how many hiperparameters are tested  \n",
    "k = 1;                 # num. of finalist individuals\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    t = time.time(); \n",
    "    datos = [];\n",
    "    ss = [i for i in range(1,population_size*(max_generations+1))]\n",
    "    best_population = geneticAlgorithm_with_elitism(population_size, max_generations, gene_length, k)\n",
    "    print(\"Total elapsed time:\", (time.time()-t)/60, \"minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k= 1 \n",
      "Deep layers: 1 , Number of neurons: 100\n",
      "Batch size 4 , Learning rate: 0.001\n"
     ]
    }
   ],
   "source": [
    "best_deep_layers   = []\n",
    "best_num_units     = []\n",
    "best_learning_rate = []\n",
    "best_batch_size    = []\n",
    "# best_activation_f  = []\n",
    "best_f_names       = []\n",
    "\n",
    "t = 0\n",
    "\n",
    "for bi in best_population:\n",
    "    deep_layers_bits   = BitArray(bi[0:1])    # (8)\n",
    "    num_units_bits     = BitArray(bi[1:2])    # (16)\n",
    "    learning_rate_bits = BitArray(bi[2:3])   # (8)\n",
    "    batch_size_bits    = BitArray(bi[3:4])  # (4)\n",
    "#     activation_f_bits  = BitArray(bi[12:13])  # (2)\n",
    "    t += 1 \n",
    "    \n",
    "    best_deep_layers.append(SC_DEEP[deep_layers_bits.uint])\n",
    "    best_num_units.append(SC_NUM_UNITS[num_units_bits.uint])\n",
    "    best_learning_rate.append(SC_LEARNING[learning_rate_bits.uint])\n",
    "    best_batch_size.append(SC_BATCH[batch_size_bits.uint])\n",
    "#     best_activation_f.append(SC_ACTIVATION[activation_f_bits.uint])\n",
    "#     best_f_names.append(f_names[activation_f_bits.uint])\n",
    "    print('k=',t,'\\nDeep layers:', best_deep_layers[-1], ', Number of neurons:', best_num_units[-1])\n",
    "    print('Batch size', best_batch_size[-1], ', Learning rate:', best_learning_rate[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Deep layers</th>\n",
       "      <th>Num units</th>\n",
       "      <th>Learning rate</th>\n",
       "      <th>Batch size</th>\n",
       "      <th>Loss</th>\n",
       "      <th>Score</th>\n",
       "      <th>Elapsed time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>200</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>2</td>\n",
       "      <td>0.030999</td>\n",
       "      <td>0.030999</td>\n",
       "      <td>109.519578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>2</td>\n",
       "      <td>0.031021</td>\n",
       "      <td>0.031021</td>\n",
       "      <td>108.308727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>2</td>\n",
       "      <td>0.031033</td>\n",
       "      <td>0.031033</td>\n",
       "      <td>158.261653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>2</td>\n",
       "      <td>0.031300</td>\n",
       "      <td>0.031300</td>\n",
       "      <td>173.300723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>2</td>\n",
       "      <td>0.031563</td>\n",
       "      <td>0.031563</td>\n",
       "      <td>159.971017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>2</td>\n",
       "      <td>0.031600</td>\n",
       "      <td>0.031600</td>\n",
       "      <td>69.290621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>2</td>\n",
       "      <td>0.031822</td>\n",
       "      <td>0.031822</td>\n",
       "      <td>191.679190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4</td>\n",
       "      <td>50</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>2</td>\n",
       "      <td>0.031890</td>\n",
       "      <td>0.031890</td>\n",
       "      <td>204.893622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>4</td>\n",
       "      <td>0.032111</td>\n",
       "      <td>0.032111</td>\n",
       "      <td>144.047072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>2</td>\n",
       "      <td>0.032142</td>\n",
       "      <td>0.032142</td>\n",
       "      <td>100.257331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>2</td>\n",
       "      <td>0.032150</td>\n",
       "      <td>0.032150</td>\n",
       "      <td>203.510052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>2</td>\n",
       "      <td>0.032526</td>\n",
       "      <td>0.032526</td>\n",
       "      <td>131.873385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>2</td>\n",
       "      <td>0.033562</td>\n",
       "      <td>0.033562</td>\n",
       "      <td>94.371337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>4</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>2</td>\n",
       "      <td>0.035239</td>\n",
       "      <td>0.035239</td>\n",
       "      <td>203.927675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>4</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>2</td>\n",
       "      <td>0.035452</td>\n",
       "      <td>0.035452</td>\n",
       "      <td>183.726682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>4</td>\n",
       "      <td>0.035674</td>\n",
       "      <td>0.035674</td>\n",
       "      <td>41.175636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>4</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>2</td>\n",
       "      <td>0.035692</td>\n",
       "      <td>0.035692</td>\n",
       "      <td>173.708154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>4</td>\n",
       "      <td>0.035820</td>\n",
       "      <td>0.035820</td>\n",
       "      <td>97.580192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>4</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>2</td>\n",
       "      <td>0.036039</td>\n",
       "      <td>0.036039</td>\n",
       "      <td>82.310520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>4</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>2</td>\n",
       "      <td>0.036383</td>\n",
       "      <td>0.036383</td>\n",
       "      <td>202.228882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>2</td>\n",
       "      <td>0.036573</td>\n",
       "      <td>0.036573</td>\n",
       "      <td>204.031245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>4</td>\n",
       "      <td>0.036582</td>\n",
       "      <td>0.036582</td>\n",
       "      <td>90.053388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>2</td>\n",
       "      <td>0.036742</td>\n",
       "      <td>0.036742</td>\n",
       "      <td>105.496931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>4</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>2</td>\n",
       "      <td>0.036829</td>\n",
       "      <td>0.036829</td>\n",
       "      <td>86.442822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>8</td>\n",
       "      <td>0.037143</td>\n",
       "      <td>0.037143</td>\n",
       "      <td>83.177201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>4</td>\n",
       "      <td>0.037812</td>\n",
       "      <td>0.037812</td>\n",
       "      <td>81.157195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>4</td>\n",
       "      <td>200</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>2</td>\n",
       "      <td>0.038988</td>\n",
       "      <td>0.038988</td>\n",
       "      <td>324.625203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>4</td>\n",
       "      <td>200</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>4</td>\n",
       "      <td>0.042220</td>\n",
       "      <td>0.042220</td>\n",
       "      <td>204.218703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>4</td>\n",
       "      <td>0.042996</td>\n",
       "      <td>0.042996</td>\n",
       "      <td>87.496926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2</td>\n",
       "      <td>200</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>16</td>\n",
       "      <td>0.053615</td>\n",
       "      <td>0.053615</td>\n",
       "      <td>39.301811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>4</td>\n",
       "      <td>200</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>16</td>\n",
       "      <td>0.061724</td>\n",
       "      <td>0.061724</td>\n",
       "      <td>56.475486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>2</td>\n",
       "      <td>0.068025</td>\n",
       "      <td>0.068025</td>\n",
       "      <td>203.722978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>4</td>\n",
       "      <td>50</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>2</td>\n",
       "      <td>0.074036</td>\n",
       "      <td>0.074036</td>\n",
       "      <td>144.244159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>4</td>\n",
       "      <td>0.075702</td>\n",
       "      <td>0.075702</td>\n",
       "      <td>76.745733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>4</td>\n",
       "      <td>0.081575</td>\n",
       "      <td>0.081575</td>\n",
       "      <td>83.161472</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Deep layers  Num units  Learning rate  Batch size      Loss     Score  \\\n",
       "0             2        200         0.0001           2  0.030999  0.030999   \n",
       "1             2        100         0.0001           2  0.031021  0.031021   \n",
       "2             2        100         0.0001           2  0.031033  0.031033   \n",
       "3             2        100         0.0001           2  0.031300  0.031300   \n",
       "4             2        100         0.0001           2  0.031563  0.031563   \n",
       "5             2        100         0.0001           2  0.031600  0.031600   \n",
       "6             2        100         0.0001           2  0.031822  0.031822   \n",
       "7             4         50         0.0001           2  0.031890  0.031890   \n",
       "8             4        100         0.0010           4  0.032111  0.032111   \n",
       "9             2        100         0.0001           2  0.032142  0.032142   \n",
       "10            2        100         0.0001           2  0.032150  0.032150   \n",
       "11            2        100         0.0001           2  0.032526  0.032526   \n",
       "12            2         50         0.0001           2  0.033562  0.033562   \n",
       "13            4        100         0.0001           2  0.035239  0.035239   \n",
       "14            4        100         0.0001           2  0.035452  0.035452   \n",
       "15            2        100         0.0001           4  0.035674  0.035674   \n",
       "16            4        100         0.0001           2  0.035692  0.035692   \n",
       "17            2        100         0.0001           4  0.035820  0.035820   \n",
       "18            4        100         0.0001           2  0.036039  0.036039   \n",
       "19            4        100         0.0001           2  0.036383  0.036383   \n",
       "20            2        100         0.0001           2  0.036573  0.036573   \n",
       "21            2        100         0.0001           4  0.036582  0.036582   \n",
       "22            2        100         0.0001           2  0.036742  0.036742   \n",
       "23            4        100         0.0001           2  0.036829  0.036829   \n",
       "24            2        100         0.0001           8  0.037143  0.037143   \n",
       "25            2        100         0.0001           4  0.037812  0.037812   \n",
       "26            4        200         0.0001           2  0.038988  0.038988   \n",
       "27            4        200         0.0010           4  0.042220  0.042220   \n",
       "28            2        100         0.0001           4  0.042996  0.042996   \n",
       "29            2        200         0.0001          16  0.053615  0.053615   \n",
       "30            4        200         0.0010          16  0.061724  0.061724   \n",
       "31            3        100         0.0010           2  0.068025  0.068025   \n",
       "32            4         50         0.0010           2  0.074036  0.074036   \n",
       "33            1        100         0.0001           4  0.075702  0.075702   \n",
       "34            1        100         0.0001           4  0.081575  0.081575   \n",
       "\n",
       "    Elapsed time  \n",
       "0     109.519578  \n",
       "1     108.308727  \n",
       "2     158.261653  \n",
       "3     173.300723  \n",
       "4     159.971017  \n",
       "5      69.290621  \n",
       "6     191.679190  \n",
       "7     204.893622  \n",
       "8     144.047072  \n",
       "9     100.257331  \n",
       "10    203.510052  \n",
       "11    131.873385  \n",
       "12     94.371337  \n",
       "13    203.927675  \n",
       "14    183.726682  \n",
       "15     41.175636  \n",
       "16    173.708154  \n",
       "17     97.580192  \n",
       "18     82.310520  \n",
       "19    202.228882  \n",
       "20    204.031245  \n",
       "21     90.053388  \n",
       "22    105.496931  \n",
       "23     86.442822  \n",
       "24     83.177201  \n",
       "25     81.157195  \n",
       "26    324.625203  \n",
       "27    204.218703  \n",
       "28     87.496926  \n",
       "29     39.301811  \n",
       "30     56.475486  \n",
       "31    203.722978  \n",
       "32    144.244159  \n",
       "33     76.745733  \n",
       "34     83.161472  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename = \"historial_genetic_jla1.txt\"\n",
    "df = pd.DataFrame(datos, columns = [\"Deep layers\", \"Num units\", \"Learning rate\", \"Batch size\", \"Loss\", \"Score\", \"Elapsed time\"])\n",
    "\n",
    "df.sort_values(by=[\"Loss\", \"Elapsed time\"], ascending=[True, True], ignore_index=True, inplace=True)\n",
    "\n",
    "df.to_csv(filename, header=True, index=False, sep='\\t', mode='w') # a=append, w=overwrite\n",
    "df.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time 78.405 minutes\n"
     ]
    }
   ],
   "source": [
    "total_time = float(np.sum(df[[\"Elapsed time\"]])/60)\n",
    "\n",
    "print(\"Elapsed time {:.3f} minutes\".format(total_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
