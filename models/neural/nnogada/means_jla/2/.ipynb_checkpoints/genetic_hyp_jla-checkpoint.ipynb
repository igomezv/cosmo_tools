{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-16 10:58:22.765808: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-12-16 10:58:22.923109: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-12-16 10:58:22.923136: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2022-12-16 10:58:24.021870: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2022-12-16 10:58:24.021962: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2022-12-16 10:58:24.021973: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import time, os\n",
    "import random\n",
    "import seaborn as sns\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Input, Dense, LeakyReLU\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorboard.plugins.hparams import api as hp\n",
    "\n",
    "from tensorflow.keras import activations\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "import random\n",
    "from math import floor\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import optimizers\n",
    "from scipy.integrate import odeint\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split as split\n",
    "from scipy.stats import bernoulli\n",
    "\n",
    "# import deap\n",
    "from deap import base, creator, tools, algorithms\n",
    "\n",
    "from bitstring import BitArray\n",
    "\n",
    "# from elitism import eaSimpleWithElitism, main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "\n",
    "# tf.config.optimizer.set_jit(True)\n",
    "# scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "url = 'https://raw.githubusercontent.com/igomezv/nnogada/main/data/jla.csv'\n",
    "df=pd.read_csv(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = len(df.values)\n",
    "randomize = np.random.permutation(N)\n",
    "data = df.values[randomize]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(740, 2)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N = len(df.values)\n",
    "z = data[:,0] \n",
    "y = data[:,1:3] ### coge el resto de variables a predecir \n",
    "y[:,1] = y[:,1]**2+data[:,2]\n",
    "np.shape(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "scalerz = StandardScaler()\n",
    "scalerz.fit(z.reshape(-1,1))\n",
    "z = scalerz.transform(z.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((592, 1), (148, 1), (592, 2), (148, 2))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Modificar para incluir phanteon como test\n",
    "split = 0.8\n",
    "ntrain = int(split * len(z))\n",
    "indx = [ntrain]\n",
    "X_train, X_val = np.split(z, indx)\n",
    "Y_train, Y_val = np.split(y, indx)\n",
    "# X_train, X_test = np.split(z, indx)\n",
    "# Y_train, Y_test = np.split(y, indx)\n",
    "np.shape(X_train), np.shape(X_val), Y_train.shape, Y_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "SC_DEEP       = np.array([1,2,3,4])                           # Number of deep layers (8)\n",
    "SC_NUM_UNITS  = np.array([50,100,150,200]) # Number of fully conected neurons (16)\n",
    "SC_LEARNING   = np.array([1e-4,5e-3])   # Learning rates (8)\n",
    "SC_BATCH      = np.array([2, 4, 8, 16])                            # Batch sizes (4)\n",
    "# SC_ACTIVATION = [f1, f2, f3, f4]                                      # Activation function layers (2)\n",
    "\n",
    "my_callbacks = [tf.keras.callbacks.EarlyStopping(\n",
    "                               monitor='val_loss', mode='min',\n",
    "                               min_delta=0, \n",
    "                               patience=200,\n",
    "                               verbose=1,\n",
    "                            #    baseline=0,\n",
    "                               restore_best_weights=True)\n",
    "#                 keras.callbacks.TensorBoard(\n",
    "#                                log_dir='./logs'),\n",
    "#                 keras.callbacks.ReduceLROnPlateau(\n",
    "#                                monitor='val_loss', factor=0.5,\n",
    "#                                patience=6, min_lr=0,\n",
    "#                                verbose=1)\n",
    "               ] \n",
    "    \n",
    "epochs = 200\n",
    "# epochs = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_evaluate(ga_individual_solution):   \n",
    "    t = time.time()\n",
    "    t_total = 0\n",
    "    \n",
    "    # Decode GA solution to integer for window_size and num_units\n",
    "    deep_layers_bits   = BitArray(ga_individual_solution[0:2])     # (8)\n",
    "    num_units_bits     = BitArray(ga_individual_solution[2:4])     # (16)\n",
    "    learning_rate_bits = BitArray(ga_individual_solution[4:5])    # (8)\n",
    "    batch_size_bits    = BitArray(ga_individual_solution[5:7])   # (4)\n",
    "# #     activation_f_bits  = BitArray(ga_individual_solution[12:13])   # (2)   Solo se consideran las 2 primeras\n",
    "    \n",
    "    deep_layers   = SC_DEEP[deep_layers_bits.uint]\n",
    "    num_units     = SC_NUM_UNITS[num_units_bits.uint]\n",
    "    learning_rate = SC_LEARNING[learning_rate_bits.uint]\n",
    "    batch_size   = SC_BATCH[batch_size_bits.uint]\n",
    "#     activation_f  = SC_ACTIVATION[activation_f_bits.uint]\n",
    "\n",
    "    \n",
    "    print('\\n--------------- Starting trial:', population_size*(max_generations+1)-len(ss), \"---------------\")\n",
    "    print('Deep layers:',deep_layers,', Number of neurons:',num_units,\", Learning rate:\",learning_rate)\n",
    "#     print(\"-------------------------------------------------\")\n",
    "    \n",
    "    # Train model and predict on validation set\n",
    "    model = tf.keras.Sequential()\n",
    "#     model.add(Input(shape=(int(X_train.shape[1]),)))\n",
    "    model.add(Dense(int(X_train.shape[1])))\n",
    "    \n",
    "    for i in range(deep_layers):        \n",
    "        model.add(Dense(num_units, activation='relu'))\n",
    "#             model.add(keras.layers.Dropout(0.3))\n",
    "    model.add(Dense(2, activation='linear'))\n",
    "    \n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate, beta_1=0.9, beta_2=0.999, epsilon=1e-3)\n",
    "    model.compile(optimizer=optimizer, loss='mse', metrics=['mean_squared_error'])\n",
    "    model.fit(X_train, Y_train, epochs=epochs, validation_data=(X_val, Y_val),\n",
    "              callbacks=my_callbacks, batch_size=batch_size, shuffle=False, verbose=0)\n",
    "    \n",
    "    loss, score = model.evaluate(X_val, Y_val)    \n",
    "    t = time.time()-t\n",
    "    ss.pop(0)\n",
    "    print(\"Loss:\", score, \", Elapsed time:\", t)\n",
    "    print(\"-------------------------------------------------\\n\")\n",
    "#     print(loss, score)\n",
    "\n",
    "    datos.append([deep_layers, num_units, learning_rate, batch_size, loss, score, t])\n",
    "    \n",
    "    return loss,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deap import tools\n",
    "from deap import algorithms\n",
    "\n",
    "def eaSimpleWithElitism(population, toolbox, cxpb, mutpb, ngen, stats=None,\n",
    "             halloffame=None, verbose=__debug__):\n",
    "    \"\"\"This algorithm is similar to DEAP eaSimple() algorithm, with the modification that\n",
    "    halloffame is used to implement an elitism mechanism. The individuals contained in the\n",
    "    halloffame are directly injected into the next generation and are not subject to the\n",
    "    genetic operators of selection, crossover and mutation.\n",
    "    \"\"\"\n",
    "    logbook = tools.Logbook()\n",
    "    logbook.header = ['gen', 'nevals'] + (stats.fields if stats else [])\n",
    "\n",
    "    # Evaluate the individuals with an invalid fitness\n",
    "    invalid_ind = [ind for ind in population if not ind.fitness.valid]\n",
    "    fitnesses = toolbox.map(toolbox.evaluate, invalid_ind)\n",
    "    for ind, fit in zip(invalid_ind, fitnesses):\n",
    "        ind.fitness.values = fit\n",
    "\n",
    "    if halloffame is None:\n",
    "        raise ValueError(\"halloffame parameter must not be empty!\")\n",
    "\n",
    "    halloffame.update(population)\n",
    "    hof_size = len(halloffame.items) if halloffame.items else 0\n",
    "\n",
    "    record = stats.compile(population) if stats else {}\n",
    "    logbook.record(gen=0, nevals=len(invalid_ind), **record)\n",
    "    if verbose:\n",
    "        print(logbook.stream)\n",
    "\n",
    "    # Begin the generational process\n",
    "    for gen in range(1, ngen + 1):\n",
    "\n",
    "        # Select the next generation individuals\n",
    "        offspring = toolbox.select(population, len(population) - hof_size)\n",
    "\n",
    "        # Vary the pool of individuals\n",
    "        offspring = algorithms.varAnd(offspring, toolbox, cxpb, mutpb)\n",
    "\n",
    "        # Evaluate the individuals with an invalid fitness\n",
    "        invalid_ind = [ind for ind in offspring if not ind.fitness.valid]\n",
    "        fitnesses = toolbox.map(toolbox.evaluate, invalid_ind)\n",
    "        for ind, fit in zip(invalid_ind, fitnesses):\n",
    "            ind.fitness.values = fit\n",
    "\n",
    "        # add the best back to population:\n",
    "        offspring.extend(halloffame.items)\n",
    "\n",
    "        # Update the hall of fame with the generated individuals\n",
    "        halloffame.update(offspring)\n",
    "\n",
    "        # Replace the current population by the offspring\n",
    "        population[:] = offspring\n",
    "\n",
    "        # Append the current generation statistics to the logbook\n",
    "        record = stats.compile(population) if stats else {}\n",
    "        logbook.record(gen=gen, nevals=len(invalid_ind), **record)\n",
    "        if verbose:\n",
    "            print(logbook.stream)\n",
    "\n",
    "    return population, logbook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def geneticAlgorithm_with_elitism(population_size, max_generations, gene_length, k):\n",
    "    \n",
    "    # Genetic Algorithm constants:\n",
    "    P_CROSSOVER = 0.5        # probability for crossover\n",
    "    P_MUTATION = 0.5         # probability for mutating an individual\n",
    "    HALL_OF_FAME_SIZE = 1    # Best individuals that pass to the other generation\n",
    "    \n",
    "    # set the random seed:\n",
    "    toolbox = base.Toolbox()\n",
    "\n",
    "    # As we are trying to minimize the RMSE score, that's why using -1.0. \n",
    "    # In case, when you want to maximize accuracy for instance, use 1.0\n",
    "    creator.create('FitnessMin', base.Fitness, weights = [-1.0])\n",
    "    creator.create('Individual', list , fitness = creator.FitnessMin)\n",
    "\n",
    "    # create the individual operator to fill up an Individual instance:\n",
    "    toolbox.register('binary', bernoulli.rvs, 0.5)\n",
    "    toolbox.register('individual', tools.initRepeat, creator.Individual, toolbox.binary, n = gene_length)\n",
    "\n",
    "    # create the population operator to generate a list of individuals:\n",
    "    toolbox.register('population', tools.initRepeat, list , toolbox.individual)\n",
    "\n",
    "    # genetic operators:\n",
    "    toolbox.register('evaluate', train_evaluate)\n",
    "    toolbox.register('select', tools.selTournament, tournsize = 2)\n",
    "    toolbox.register('mutate', tools.mutFlipBit, indpb = 0.11)\n",
    "    toolbox.register('mate', tools.cxUniform, indpb = 0.5)\n",
    "    \n",
    "    # create initial population (generation 0):\n",
    "    population = toolbox.population(n=population_size)\n",
    "\n",
    "    # prepare the statistics object:\n",
    "    stats = tools.Statistics(lambda ind: ind.fitness.values)\n",
    "    stats.register(\"min\", np.min)\n",
    "    stats.register(\"avg\", np.mean)\n",
    "    stats.register(\"max\", np.max)\n",
    "\n",
    "    # define the hall-of-fame object:\n",
    "    hof = tools.HallOfFame(HALL_OF_FAME_SIZE)\n",
    "\n",
    "    # Genetic Algorithm flow with elitism:\n",
    "    population, logbook = eaSimpleWithElitism(population, toolbox, cxpb=P_CROSSOVER, mutpb=P_MUTATION,\n",
    "                                              ngen=max_generations, stats=stats, halloffame=hof, verbose=True)\n",
    "\n",
    "    # print info for best solution found:\n",
    "    best = hof.items[0]\n",
    "    print(\"-- Best Individual = \", best)\n",
    "    print(\"-- Best Fitness = \", best.fitness.values[0])\n",
    "\n",
    "    # extract statistics:\n",
    "    minFitnessValues, meanFitnessValues, maxFitnessValues = logbook.select(\"min\", \"max\", \"avg\")\n",
    "\n",
    "    # plot statistics:\n",
    "    sns.set_style(\"whitegrid\")\n",
    "    plt.plot(minFitnessValues, color='blue', label=\"Min\")\n",
    "    plt.plot(meanFitnessValues, color='green', label=\"Mean\")\n",
    "    plt.plot(maxFitnessValues, color='red', label=\"Max\")\n",
    "    plt.xlabel('Generation'); plt.ylabel('Max / Min / Average Fitness')\n",
    "    plt.legend()\n",
    "    plt.title('Max, Min and Average fitness over Generations')\n",
    "    plt.show()\n",
    "    \n",
    "    best_population = tools.selBest(population,k = k)\n",
    "    return best_population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------------- Starting trial: 1 ---------------\n",
      "Deep layers: 3 , Number of neurons: 100 , Learning rate: 0.005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-16 10:58:25.247657: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-16 10:58:25.247912: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-12-16 10:58:25.247996: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory\n",
      "2022-12-16 10:58:25.248069: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory\n",
      "2022-12-16 10:58:25.248141: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcufft.so.10'; dlerror: libcufft.so.10: cannot open shared object file: No such file or directory\n",
      "2022-12-16 10:58:25.248212: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcurand.so.10'; dlerror: libcurand.so.10: cannot open shared object file: No such file or directory\n",
      "2022-12-16 10:58:25.248283: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory\n",
      "2022-12-16 10:58:25.248338: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory\n",
      "2022-12-16 10:58:25.248391: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2022-12-16 10:58:25.248402: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1934] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2022-12-16 10:58:25.249089: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1254 - mean_squared_error: 0.1254\n",
      "Loss: 0.12536080181598663 , Elapsed time: 143.38077855110168\n",
      "-------------------------------------------------\n",
      "\n",
      "\n",
      "--------------- Starting trial: 2 ---------------\n",
      "Deep layers: 2 , Number of neurons: 200 , Learning rate: 0.0001\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0510 - mean_squared_error: 0.0510\n",
      "Loss: 0.05098187178373337 , Elapsed time: 42.081318378448486\n",
      "-------------------------------------------------\n",
      "\n",
      "\n",
      "--------------- Starting trial: 3 ---------------\n",
      "Deep layers: 4 , Number of neurons: 200 , Learning rate: 0.005\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0556 - mean_squared_error: 0.0556\n",
      "Loss: 0.05561121553182602 , Elapsed time: 24.396983861923218\n",
      "-------------------------------------------------\n",
      "\n",
      "\n",
      "--------------- Starting trial: 4 ---------------\n",
      "Deep layers: 1 , Number of neurons: 100 , Learning rate: 0.0001\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0700 - mean_squared_error: 0.0700\n",
      "Loss: 0.06995031237602234 , Elapsed time: 51.4243860244751\n",
      "-------------------------------------------------\n",
      "\n",
      "\n",
      "--------------- Starting trial: 5 ---------------\n",
      "Deep layers: 2 , Number of neurons: 100 , Learning rate: 0.0001\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0374 - mean_squared_error: 0.0374\n",
      "Loss: 0.03737332299351692 , Elapsed time: 49.73900294303894\n",
      "-------------------------------------------------\n",
      "\n",
      "gen\tnevals\tmin      \tavg      \tmax     \n",
      "0  \t5     \t0.0373733\t0.0678555\t0.125361\n",
      "\n",
      "--------------- Starting trial: 6 ---------------\n",
      "Deep layers: 1 , Number of neurons: 100 , Learning rate: 0.005\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0378 - mean_squared_error: 0.0378\n",
      "Loss: 0.037782635539770126 , Elapsed time: 99.76213693618774\n",
      "-------------------------------------------------\n",
      "\n",
      "\n",
      "--------------- Starting trial: 7 ---------------\n",
      "Deep layers: 2 , Number of neurons: 150 , Learning rate: 0.0001\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0387 - mean_squared_error: 0.0387\n",
      "Loss: 0.038658689707517624 , Elapsed time: 34.49732708930969\n",
      "-------------------------------------------------\n",
      "\n",
      "1  \t2     \t0.0373733\t0.040434 \t0.0509819\n",
      "\n",
      "--------------- Starting trial: 8 ---------------\n",
      "Deep layers: 2 , Number of neurons: 100 , Learning rate: 0.0001\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0364 - mean_squared_error: 0.0364\n",
      "Loss: 0.036411307752132416 , Elapsed time: 55.573859453201294\n",
      "-------------------------------------------------\n",
      "\n",
      "\n",
      "--------------- Starting trial: 9 ---------------\n",
      "Deep layers: 1 , Number of neurons: 50 , Learning rate: 0.0001\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0846 - mean_squared_error: 0.0846\n",
      "Loss: 0.08463913202285767 , Elapsed time: 52.03933024406433\n",
      "-------------------------------------------------\n",
      "\n",
      "\n",
      "--------------- Starting trial: 10 ---------------\n",
      "Deep layers: 2 , Number of neurons: 200 , Learning rate: 0.0001\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0353 - mean_squared_error: 0.0353\n",
      "Loss: 0.0352751761674881 , Elapsed time: 83.08247494697571\n",
      "-------------------------------------------------\n",
      "\n",
      "\n",
      "--------------- Starting trial: 11 ---------------\n",
      "Deep layers: 1 , Number of neurons: 100 , Learning rate: 0.0001\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0819 - mean_squared_error: 0.0819\n",
      "Loss: 0.0818566158413887 , Elapsed time: 49.40391278266907\n",
      "-------------------------------------------------\n",
      "\n",
      "2  \t4     \t0.0352752\t0.0551111\t0.0846391\n",
      "\n",
      "--------------- Starting trial: 12 ---------------\n",
      "Deep layers: 2 , Number of neurons: 100 , Learning rate: 0.0001\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0391 - mean_squared_error: 0.0391\n",
      "Loss: 0.03906804323196411 , Elapsed time: 52.6911940574646\n",
      "-------------------------------------------------\n",
      "\n",
      "\n",
      "--------------- Starting trial: 13 ---------------\n",
      "Deep layers: 2 , Number of neurons: 100 , Learning rate: 0.0001\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0365 - mean_squared_error: 0.0365\n",
      "Loss: 0.036451615393161774 , Elapsed time: 49.618343353271484\n",
      "-------------------------------------------------\n",
      "\n",
      "\n",
      "--------------- Starting trial: 14 ---------------\n",
      "Deep layers: 2 , Number of neurons: 100 , Learning rate: 0.0001\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0365 - mean_squared_error: 0.0365\n",
      "Loss: 0.03647609055042267 , Elapsed time: 57.28697681427002\n",
      "-------------------------------------------------\n",
      "\n",
      "\n",
      "--------------- Starting trial: 15 ---------------\n",
      "Deep layers: 2 , Number of neurons: 100 , Learning rate: 0.0001\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0372 - mean_squared_error: 0.0372\n",
      "Loss: 0.037201449275016785 , Elapsed time: 83.10013175010681\n",
      "-------------------------------------------------\n",
      "\n",
      "3  \t4     \t0.0352752\t0.0368945\t0.039068 \n",
      "\n",
      "--------------- Starting trial: 16 ---------------\n",
      "Deep layers: 2 , Number of neurons: 100 , Learning rate: 0.0001\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0378 - mean_squared_error: 0.0378\n",
      "Loss: 0.037764180451631546 , Elapsed time: 55.708762407302856\n",
      "-------------------------------------------------\n",
      "\n",
      "\n",
      "--------------- Starting trial: 17 ---------------\n",
      "Deep layers: 2 , Number of neurons: 100 , Learning rate: 0.005\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1003 - mean_squared_error: 0.1003\n",
      "Loss: 0.10032720863819122 , Elapsed time: 143.06564450263977\n",
      "-------------------------------------------------\n",
      "\n",
      "\n",
      "--------------- Starting trial: 18 ---------------\n",
      "Deep layers: 2 , Number of neurons: 100 , Learning rate: 0.0001\n",
      "5/5 [==============================] - 1s 2ms/step - loss: 0.0364 - mean_squared_error: 0.0364\n",
      "Loss: 0.03635595738887787 , Elapsed time: 56.51395320892334\n",
      "-------------------------------------------------\n",
      "\n",
      "\n",
      "--------------- Starting trial: 19 ---------------\n",
      "Deep layers: 2 , Number of neurons: 100 , Learning rate: 0.0001\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0353 - mean_squared_error: 0.0353\n",
      "Loss: 0.03533744066953659 , Elapsed time: 54.93316650390625\n",
      "-------------------------------------------------\n",
      "\n",
      "4  \t4     \t0.0352752\t0.049012 \t0.100327 \n",
      "\n",
      "--------------- Starting trial: 20 ---------------\n",
      "Deep layers: 4 , Number of neurons: 100 , Learning rate: 0.0001\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0364 - mean_squared_error: 0.0364\n",
      "Loss: 0.0364200621843338 , Elapsed time: 21.733540773391724\n",
      "-------------------------------------------------\n",
      "\n",
      "\n",
      "--------------- Starting trial: 21 ---------------\n",
      "Deep layers: 2 , Number of neurons: 100 , Learning rate: 0.0001\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0356 - mean_squared_error: 0.0356\n",
      "Loss: 0.03561335429549217 , Elapsed time: 57.6849422454834\n",
      "-------------------------------------------------\n",
      "\n",
      "\n",
      "--------------- Starting trial: 22 ---------------\n",
      "Deep layers: 2 , Number of neurons: 100 , Learning rate: 0.0001\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0382 - mean_squared_error: 0.0382\n",
      "Loss: 0.03816944733262062 , Elapsed time: 53.81062388420105\n",
      "-------------------------------------------------\n",
      "\n",
      "5  \t3     \t0.0352752\t0.0361506\t0.0381694\n",
      "\n",
      "--------------- Starting trial: 23 ---------------\n",
      "Deep layers: 2 , Number of neurons: 200 , Learning rate: 0.0001\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0367 - mean_squared_error: 0.0367\n",
      "Loss: 0.03669651597738266 , Elapsed time: 62.527304887771606\n",
      "-------------------------------------------------\n",
      "\n",
      "\n",
      "--------------- Starting trial: 24 ---------------\n",
      "Deep layers: 2 , Number of neurons: 200 , Learning rate: 0.0001\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0351 - mean_squared_error: 0.0351\n",
      "Loss: 0.03508656844496727 , Elapsed time: 66.16962432861328\n",
      "-------------------------------------------------\n",
      "\n",
      "\n",
      "--------------- Starting trial: 25 ---------------\n",
      "Deep layers: 2 , Number of neurons: 150 , Learning rate: 0.0001\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0417 - mean_squared_error: 0.0417\n",
      "Loss: 0.04165039211511612 , Elapsed time: 63.80065941810608\n",
      "-------------------------------------------------\n",
      "\n",
      "\n",
      "--------------- Starting trial: 26 ---------------\n",
      "Deep layers: 1 , Number of neurons: 200 , Learning rate: 0.0001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 3ms/step - loss: 0.2004 - mean_squared_error: 0.2004\n",
      "Loss: 0.20041047036647797 , Elapsed time: 23.97352647781372\n",
      "-------------------------------------------------\n",
      "\n",
      "6  \t4     \t0.0350866\t0.0698238\t0.20041  \n",
      "\n",
      "--------------- Starting trial: 27 ---------------\n",
      "Deep layers: 2 , Number of neurons: 200 , Learning rate: 0.0001\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0369 - mean_squared_error: 0.0369\n",
      "Loss: 0.03686364367604256 , Elapsed time: 68.81199288368225\n",
      "-------------------------------------------------\n",
      "\n",
      "\n",
      "--------------- Starting trial: 28 ---------------\n",
      "Deep layers: 2 , Number of neurons: 150 , Learning rate: 0.0001\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0361 - mean_squared_error: 0.0361\n",
      "Loss: 0.036138977855443954 , Elapsed time: 61.36445999145508\n",
      "-------------------------------------------------\n",
      "\n",
      "7  \t2     \t0.0350866\t0.0356902\t0.0368636\n",
      "\n",
      "--------------- Starting trial: 29 ---------------\n",
      "Deep layers: 2 , Number of neurons: 200 , Learning rate: 0.0001\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0353 - mean_squared_error: 0.0353\n",
      "Loss: 0.035252705216407776 , Elapsed time: 62.758392572402954\n",
      "-------------------------------------------------\n",
      "\n",
      "\n",
      "--------------- Starting trial: 30 ---------------\n",
      "Deep layers: 2 , Number of neurons: 200 , Learning rate: 0.0001\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0308 - mean_squared_error: 0.0308\n",
      "Loss: 0.03081999532878399 , Elapsed time: 127.04470300674438\n",
      "-------------------------------------------------\n",
      "\n",
      "8  \t2     \t0.03082  \t0.0343419\t0.0352752\n",
      "\n",
      "--------------- Starting trial: 31 ---------------\n",
      "Deep layers: 2 , Number of neurons: 100 , Learning rate: 0.0001\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0457 - mean_squared_error: 0.0457\n",
      "Loss: 0.045671023428440094 , Elapsed time: 60.046005964279175\n",
      "-------------------------------------------------\n",
      "\n",
      "\n",
      "--------------- Starting trial: 32 ---------------\n",
      "Deep layers: 2 , Number of neurons: 200 , Learning rate: 0.0001\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0346 - mean_squared_error: 0.0346\n",
      "Loss: 0.03463594615459442 , Elapsed time: 83.42088437080383\n",
      "-------------------------------------------------\n",
      "\n",
      "\n",
      "--------------- Starting trial: 33 ---------------\n",
      "Deep layers: 2 , Number of neurons: 200 , Learning rate: 0.0001\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0313 - mean_squared_error: 0.0313\n",
      "Loss: 0.0313115194439888 , Elapsed time: 120.65438222885132\n",
      "-------------------------------------------------\n",
      "\n",
      "\n",
      "--------------- Starting trial: 34 ---------------\n",
      "Deep layers: 2 , Number of neurons: 200 , Learning rate: 0.005\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0428 - mean_squared_error: 0.0428\n",
      "Loss: 0.04280949756503105 , Elapsed time: 36.94733738899231\n",
      "-------------------------------------------------\n",
      "\n",
      "9  \t4     \t0.03082  \t0.0370496\t0.045671 \n",
      "\n",
      "--------------- Starting trial: 35 ---------------\n",
      "Deep layers: 2 , Number of neurons: 200 , Learning rate: 0.0001\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0317 - mean_squared_error: 0.0317\n",
      "Loss: 0.03170808032155037 , Elapsed time: 143.4573051929474\n",
      "-------------------------------------------------\n",
      "\n",
      "\n",
      "--------------- Starting trial: 36 ---------------\n",
      "Deep layers: 2 , Number of neurons: 200 , Learning rate: 0.0001\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0315 - mean_squared_error: 0.0315\n",
      "Loss: 0.03153352439403534 , Elapsed time: 125.74751567840576\n",
      "-------------------------------------------------\n",
      "\n",
      "\n",
      "--------------- Starting trial: 37 ---------------\n",
      "Deep layers: 1 , Number of neurons: 200 , Learning rate: 0.0001\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0430 - mean_squared_error: 0.0430\n",
      "Loss: 0.04298403859138489 , Elapsed time: 92.70825409889221\n",
      "-------------------------------------------------\n",
      "\n",
      "\n",
      "--------------- Starting trial: 38 ---------------\n",
      "Deep layers: 2 , Number of neurons: 200 , Learning rate: 0.0001\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0308 - mean_squared_error: 0.0308\n",
      "Loss: 0.03084302507340908 , Elapsed time: 123.30808758735657\n",
      "-------------------------------------------------\n",
      "\n",
      "10 \t4     \t0.03082  \t0.0335777\t0.042984 \n",
      "-- Best Individual =  [0, 1, 1, 1, 0, 0, 0]\n",
      "-- Best Fitness =  0.03081999532878399\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total elapsed time: 44.909447900454204 minutes\n"
     ]
    }
   ],
   "source": [
    "population_size = 5   # max of individuals per generation\n",
    "max_generations = 10  # number of generations\n",
    "gene_length = 7      # lenght of the gene, depends on how many hiperparameters are tested  \n",
    "k = 1;                 # num. of finalist individuals\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    t = time.time(); \n",
    "    datos = [];\n",
    "    ss = [i for i in range(1,population_size*(max_generations+1))]\n",
    "    best_population = geneticAlgorithm_with_elitism(population_size, max_generations, gene_length, k)\n",
    "    print(\"Total elapsed time:\", (time.time()-t)/60, \"minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k= 1 \n",
      "Deep layers: 1 , Number of neurons: 100\n",
      "Batch size 4 , Learning rate: 0.005\n"
     ]
    }
   ],
   "source": [
    "best_deep_layers   = []\n",
    "best_num_units     = []\n",
    "best_learning_rate = []\n",
    "best_batch_size    = []\n",
    "# best_activation_f  = []\n",
    "best_f_names       = []\n",
    "\n",
    "t = 0\n",
    "\n",
    "for bi in best_population:\n",
    "    deep_layers_bits   = BitArray(bi[0:1])    # (8)\n",
    "    num_units_bits     = BitArray(bi[1:2])    # (16)\n",
    "    learning_rate_bits = BitArray(bi[2:3])   # (8)\n",
    "    batch_size_bits    = BitArray(bi[3:4])  # (4)\n",
    "#     activation_f_bits  = BitArray(bi[12:13])  # (2)\n",
    "    t += 1 \n",
    "    \n",
    "    best_deep_layers.append(SC_DEEP[deep_layers_bits.uint])\n",
    "    best_num_units.append(SC_NUM_UNITS[num_units_bits.uint])\n",
    "    best_learning_rate.append(SC_LEARNING[learning_rate_bits.uint])\n",
    "    best_batch_size.append(SC_BATCH[batch_size_bits.uint])\n",
    "#     best_activation_f.append(SC_ACTIVATION[activation_f_bits.uint])\n",
    "#     best_f_names.append(f_names[activation_f_bits.uint])\n",
    "    print('k=',t,'\\nDeep layers:', best_deep_layers[-1], ', Number of neurons:', best_num_units[-1])\n",
    "    print('Batch size', best_batch_size[-1], ', Learning rate:', best_learning_rate[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Deep layers</th>\n",
       "      <th>Num units</th>\n",
       "      <th>Learning rate</th>\n",
       "      <th>Batch size</th>\n",
       "      <th>Loss</th>\n",
       "      <th>Score</th>\n",
       "      <th>Elapsed time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>200</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>2</td>\n",
       "      <td>0.030820</td>\n",
       "      <td>0.030820</td>\n",
       "      <td>127.044703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>200</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>2</td>\n",
       "      <td>0.030843</td>\n",
       "      <td>0.030843</td>\n",
       "      <td>123.308088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>200</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>2</td>\n",
       "      <td>0.031312</td>\n",
       "      <td>0.031312</td>\n",
       "      <td>120.654382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>200</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>2</td>\n",
       "      <td>0.031534</td>\n",
       "      <td>0.031534</td>\n",
       "      <td>125.747516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>200</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>2</td>\n",
       "      <td>0.031708</td>\n",
       "      <td>0.031708</td>\n",
       "      <td>143.457305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>200</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>4</td>\n",
       "      <td>0.034636</td>\n",
       "      <td>0.034636</td>\n",
       "      <td>83.420884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2</td>\n",
       "      <td>200</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>4</td>\n",
       "      <td>0.035087</td>\n",
       "      <td>0.035087</td>\n",
       "      <td>66.169624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2</td>\n",
       "      <td>200</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>4</td>\n",
       "      <td>0.035253</td>\n",
       "      <td>0.035253</td>\n",
       "      <td>62.758393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2</td>\n",
       "      <td>200</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>4</td>\n",
       "      <td>0.035275</td>\n",
       "      <td>0.035275</td>\n",
       "      <td>83.082475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>4</td>\n",
       "      <td>0.035337</td>\n",
       "      <td>0.035337</td>\n",
       "      <td>54.933167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>4</td>\n",
       "      <td>0.035613</td>\n",
       "      <td>0.035613</td>\n",
       "      <td>57.684942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2</td>\n",
       "      <td>150</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>4</td>\n",
       "      <td>0.036139</td>\n",
       "      <td>0.036139</td>\n",
       "      <td>61.364460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>4</td>\n",
       "      <td>0.036356</td>\n",
       "      <td>0.036356</td>\n",
       "      <td>56.513953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>4</td>\n",
       "      <td>0.036411</td>\n",
       "      <td>0.036411</td>\n",
       "      <td>55.573859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>4</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>16</td>\n",
       "      <td>0.036420</td>\n",
       "      <td>0.036420</td>\n",
       "      <td>21.733541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>4</td>\n",
       "      <td>0.036452</td>\n",
       "      <td>0.036452</td>\n",
       "      <td>49.618343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>4</td>\n",
       "      <td>0.036476</td>\n",
       "      <td>0.036476</td>\n",
       "      <td>57.286977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2</td>\n",
       "      <td>200</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>4</td>\n",
       "      <td>0.036697</td>\n",
       "      <td>0.036697</td>\n",
       "      <td>62.527305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2</td>\n",
       "      <td>200</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>4</td>\n",
       "      <td>0.036864</td>\n",
       "      <td>0.036864</td>\n",
       "      <td>68.811993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>4</td>\n",
       "      <td>0.037201</td>\n",
       "      <td>0.037201</td>\n",
       "      <td>83.100132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>4</td>\n",
       "      <td>0.037373</td>\n",
       "      <td>0.037373</td>\n",
       "      <td>49.739003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>4</td>\n",
       "      <td>0.037764</td>\n",
       "      <td>0.037764</td>\n",
       "      <td>55.708762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0050</td>\n",
       "      <td>2</td>\n",
       "      <td>0.037783</td>\n",
       "      <td>0.037783</td>\n",
       "      <td>99.762137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>4</td>\n",
       "      <td>0.038169</td>\n",
       "      <td>0.038169</td>\n",
       "      <td>53.810624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2</td>\n",
       "      <td>150</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>8</td>\n",
       "      <td>0.038659</td>\n",
       "      <td>0.038659</td>\n",
       "      <td>34.497327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>4</td>\n",
       "      <td>0.039068</td>\n",
       "      <td>0.039068</td>\n",
       "      <td>52.691194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2</td>\n",
       "      <td>150</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>4</td>\n",
       "      <td>0.041650</td>\n",
       "      <td>0.041650</td>\n",
       "      <td>63.800659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2</td>\n",
       "      <td>200</td>\n",
       "      <td>0.0050</td>\n",
       "      <td>8</td>\n",
       "      <td>0.042809</td>\n",
       "      <td>0.042809</td>\n",
       "      <td>36.947337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1</td>\n",
       "      <td>200</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>2</td>\n",
       "      <td>0.042984</td>\n",
       "      <td>0.042984</td>\n",
       "      <td>92.708254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>4</td>\n",
       "      <td>0.045671</td>\n",
       "      <td>0.045671</td>\n",
       "      <td>60.046006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>2</td>\n",
       "      <td>200</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>16</td>\n",
       "      <td>0.050982</td>\n",
       "      <td>0.050982</td>\n",
       "      <td>42.081318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>4</td>\n",
       "      <td>200</td>\n",
       "      <td>0.0050</td>\n",
       "      <td>16</td>\n",
       "      <td>0.055611</td>\n",
       "      <td>0.055611</td>\n",
       "      <td>24.396984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>4</td>\n",
       "      <td>0.069950</td>\n",
       "      <td>0.069950</td>\n",
       "      <td>51.424386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>4</td>\n",
       "      <td>0.081857</td>\n",
       "      <td>0.081857</td>\n",
       "      <td>49.403913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>4</td>\n",
       "      <td>0.084639</td>\n",
       "      <td>0.084639</td>\n",
       "      <td>52.039330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0050</td>\n",
       "      <td>2</td>\n",
       "      <td>0.100327</td>\n",
       "      <td>0.100327</td>\n",
       "      <td>143.065645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0050</td>\n",
       "      <td>2</td>\n",
       "      <td>0.125361</td>\n",
       "      <td>0.125361</td>\n",
       "      <td>143.380779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>1</td>\n",
       "      <td>200</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>16</td>\n",
       "      <td>0.200410</td>\n",
       "      <td>0.200410</td>\n",
       "      <td>23.973526</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Deep layers  Num units  Learning rate  Batch size      Loss     Score  \\\n",
       "0             2        200         0.0001           2  0.030820  0.030820   \n",
       "1             2        200         0.0001           2  0.030843  0.030843   \n",
       "2             2        200         0.0001           2  0.031312  0.031312   \n",
       "3             2        200         0.0001           2  0.031534  0.031534   \n",
       "4             2        200         0.0001           2  0.031708  0.031708   \n",
       "5             2        200         0.0001           4  0.034636  0.034636   \n",
       "6             2        200         0.0001           4  0.035087  0.035087   \n",
       "7             2        200         0.0001           4  0.035253  0.035253   \n",
       "8             2        200         0.0001           4  0.035275  0.035275   \n",
       "9             2        100         0.0001           4  0.035337  0.035337   \n",
       "10            2        100         0.0001           4  0.035613  0.035613   \n",
       "11            2        150         0.0001           4  0.036139  0.036139   \n",
       "12            2        100         0.0001           4  0.036356  0.036356   \n",
       "13            2        100         0.0001           4  0.036411  0.036411   \n",
       "14            4        100         0.0001          16  0.036420  0.036420   \n",
       "15            2        100         0.0001           4  0.036452  0.036452   \n",
       "16            2        100         0.0001           4  0.036476  0.036476   \n",
       "17            2        200         0.0001           4  0.036697  0.036697   \n",
       "18            2        200         0.0001           4  0.036864  0.036864   \n",
       "19            2        100         0.0001           4  0.037201  0.037201   \n",
       "20            2        100         0.0001           4  0.037373  0.037373   \n",
       "21            2        100         0.0001           4  0.037764  0.037764   \n",
       "22            1        100         0.0050           2  0.037783  0.037783   \n",
       "23            2        100         0.0001           4  0.038169  0.038169   \n",
       "24            2        150         0.0001           8  0.038659  0.038659   \n",
       "25            2        100         0.0001           4  0.039068  0.039068   \n",
       "26            2        150         0.0001           4  0.041650  0.041650   \n",
       "27            2        200         0.0050           8  0.042809  0.042809   \n",
       "28            1        200         0.0001           2  0.042984  0.042984   \n",
       "29            2        100         0.0001           4  0.045671  0.045671   \n",
       "30            2        200         0.0001          16  0.050982  0.050982   \n",
       "31            4        200         0.0050          16  0.055611  0.055611   \n",
       "32            1        100         0.0001           4  0.069950  0.069950   \n",
       "33            1        100         0.0001           4  0.081857  0.081857   \n",
       "34            1         50         0.0001           4  0.084639  0.084639   \n",
       "35            2        100         0.0050           2  0.100327  0.100327   \n",
       "36            3        100         0.0050           2  0.125361  0.125361   \n",
       "37            1        200         0.0001          16  0.200410  0.200410   \n",
       "\n",
       "    Elapsed time  \n",
       "0     127.044703  \n",
       "1     123.308088  \n",
       "2     120.654382  \n",
       "3     125.747516  \n",
       "4     143.457305  \n",
       "5      83.420884  \n",
       "6      66.169624  \n",
       "7      62.758393  \n",
       "8      83.082475  \n",
       "9      54.933167  \n",
       "10     57.684942  \n",
       "11     61.364460  \n",
       "12     56.513953  \n",
       "13     55.573859  \n",
       "14     21.733541  \n",
       "15     49.618343  \n",
       "16     57.286977  \n",
       "17     62.527305  \n",
       "18     68.811993  \n",
       "19     83.100132  \n",
       "20     49.739003  \n",
       "21     55.708762  \n",
       "22     99.762137  \n",
       "23     53.810624  \n",
       "24     34.497327  \n",
       "25     52.691194  \n",
       "26     63.800659  \n",
       "27     36.947337  \n",
       "28     92.708254  \n",
       "29     60.046006  \n",
       "30     42.081318  \n",
       "31     24.396984  \n",
       "32     51.424386  \n",
       "33     49.403913  \n",
       "34     52.039330  \n",
       "35    143.065645  \n",
       "36    143.380779  \n",
       "37     23.973526  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename = \"historial_genetic_jla1.txt\"\n",
    "df = pd.DataFrame(datos, columns = [\"Deep layers\", \"Num units\", \"Learning rate\", \"Batch size\", \"Loss\", \"Score\", \"Elapsed time\"])\n",
    "\n",
    "df.sort_values(by=[\"Loss\", \"Elapsed time\"], ascending=[True, True], ignore_index=True, inplace=True)\n",
    "\n",
    "df.to_csv(filename, header=True, index=False, sep='\\t', mode='w') # a=append, w=overwrite\n",
    "df.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time 44.904 minutes\n"
     ]
    }
   ],
   "source": [
    "total_time = float(np.sum(df[[\"Elapsed time\"]])/60)\n",
    "\n",
    "print(\"Elapsed time {:.3f} minutes\".format(total_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
