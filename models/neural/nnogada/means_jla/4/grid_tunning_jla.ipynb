{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load_ext tensorboard\n",
    "# Clear any logs from previous runs\n",
    "# !rm -rf ./logs/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-16 16:44:05.823211: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-12-16 16:44:06.001889: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-12-16 16:44:06.001927: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2022-12-16 16:44:07.126495: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2022-12-16 16:44:07.126643: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2022-12-16 16:44:07.126655: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time, os\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Input, Dense\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorboard.plugins.hparams import api as hp\n",
    "\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split as split\n",
    "\n",
    "import random\n",
    "from math import floor\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import optimizers\n",
    "from scipy.integrate import odeint\n",
    "import scipy\n",
    "import pandas as pd\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(740, 2)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = 'https://raw.githubusercontent.com/igomezv/nnogada/main/data/jla.csv'\n",
    "df=pd.read_csv(url)\n",
    "N = len(df.values)\n",
    "randomize = np.random.permutation(N)\n",
    "data = df.values[randomize]\n",
    "N = len(df.values)\n",
    "z = data[:,0] \n",
    "y = data[:,1:3] ### coge el resto de variables a predecir \n",
    "y[:,1] = y[:,1]**2+data[:,2]\n",
    "np.shape(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "scalerz = StandardScaler()\n",
    "scalerz.fit(z.reshape(-1,1))\n",
    "z = scalerz.transform(z.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((592, 1), (148, 1), (592, 2), (148, 2))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Modificar para incluir phanteon como test\n",
    "split = 0.8\n",
    "ntrain = int(split * len(z))\n",
    "indx = [ntrain]\n",
    "X_train, X_test = np.split(z, indx)\n",
    "Y_train, Y_test = np.split(y, indx)\n",
    "np.shape(X_train), np.shape(X_test), Y_train.shape, Y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss -> val_loss\n",
    "callbacks = [tf.keras.callbacks.EarlyStopping(monitor='val_loss', mode='min',\n",
    "                                   min_delta=0.0,\n",
    "                                   patience=200,\n",
    "                                   restore_best_weights=True, verbose=True)\n",
    "                                   ]\n",
    "\n",
    "n_cols = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "HP_BATCHSIZE = hp.HParam('batch_size', hp.Discrete([2, 4, 8, 16]))\n",
    "HP_LAYERS =    hp.HParam('layers', hp.Discrete([1, 2, 3, 4]))\n",
    "HP_NUM_UNITS = hp.HParam('num_units', hp.Discrete([50, 100, 150, 200]))\n",
    "HP_LEARNING  = hp.HParam('learning_rate', hp.Discrete([1e-4,1e-3]))\n",
    "# HP_NUM_UNITS3 = hp.HParam('num_units3', hp.Discrete([50, 100, 150, 200]))\n",
    "# HP_NUM_UNITS4 = hp.HParam('num_units4', hp.Discrete([2, 5, 10]))\n",
    "# HP_DROPOUT = hp.HParam('dropout', hp.RealInterval(0.0, 0.2))\n",
    "# HP_OPTIMIZER = hp.HParam('optimizer', hp.Discrete(['adam', 'sgd']))\n",
    "# HP_OPTIMIZER = hp.HParam('optimizer', hp.Discrete(['adam', 'Adadelta']))\n",
    "# HP_OPTIMIZER = hp.HParam('optimizer', hp.Discrete(['adam']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs=200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sess = tf.Session()\n",
    "# writer = tf.summary.FileWriter(\"/tmp/tfvgg\", sess.graph)\n",
    "# init = tf.initialize_all_variables()\n",
    "# sess.run(init)\n",
    "# with tf.summary.create_file_writer('logs/hparam_tuning').as_default():\n",
    "#     hp.hparams_config(\n",
    "#         hparams=[HP_NUM_UNITS1, HP_NUM_UNITS2, HP_NUM_UNITS3, HP_NUM_UNITS4,\n",
    "#                  HP_OPTIMIZER, HP_BATCHSIZE],\n",
    "#         metrics=[hp.Metric('loss', display_name=\"Loss\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-16 16:44:08.660772: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-16 16:44:08.661055: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-12-16 16:44:08.661131: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory\n",
      "2022-12-16 16:44:08.661196: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory\n",
      "2022-12-16 16:44:08.661259: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcufft.so.10'; dlerror: libcufft.so.10: cannot open shared object file: No such file or directory\n",
      "2022-12-16 16:44:08.661325: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcurand.so.10'; dlerror: libcurand.so.10: cannot open shared object file: No such file or directory\n",
      "2022-12-16 16:44:08.661394: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory\n",
      "2022-12-16 16:44:08.661457: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory\n",
      "2022-12-16 16:44:08.661533: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2022-12-16 16:44:08.661547: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1934] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2022-12-16 16:44:08.661804: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# METRIC_ACCURACY = 'accuracy'\n",
    "with tf.summary.create_file_writer('logs/hparam_tuning3').as_default():\n",
    "# with tf.summary.FileWriter('logs/hparam_tuning', sess.graph):\n",
    "#     init = tf.initialize_all_variables()\n",
    "#     sess.run(init)\n",
    "    hp.hparams_config(\n",
    "        hparams=[HP_LAYERS,\n",
    "                 HP_NUM_UNITS,\n",
    "                 HP_LEARNING, \n",
    "                 HP_BATCHSIZE],\n",
    "        metrics=[hp.Metric('loss', display_name=\"Loss\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_model(hparams):    \n",
    "    \n",
    "    # Train LSTM model and predict on validation set\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(Dense(int(X_train.shape[1])))\n",
    "#     model.add(Dense(hparams[HP_NUM_UNITS], input_shape=(int(X_train.shape[1]),)))\n",
    "    \n",
    "    for i in range(hparams[HP_LAYERS]):        \n",
    "        model.add(Dense(hparams[HP_NUM_UNITS], activation='relu'))\n",
    "    model.add(Dense(2, activation='linear'))\n",
    "     \n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=hparams[HP_LEARNING], beta_1=0.9, beta_2=0.999, epsilon=1e-3)\n",
    "    model.compile(\n",
    "            optimizer=optimizer,\n",
    "            loss='mse', \n",
    "            metrics=['mean_squared_error'])\n",
    "    \n",
    "    # Run with 1 epoch to speed things up for demo purposes\n",
    "\n",
    "    model.fit(X_train, Y_train, epochs=epochs, validation_data=(X_test, Y_test),\n",
    "              callbacks=callbacks, batch_size=hparams[HP_BATCHSIZE], shuffle=False, verbose=0)\n",
    "\n",
    "    _, loss = model.evaluate(X_test, Y_test)\n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(run_dir, hparams):\n",
    "    with tf.summary.create_file_writer(run_dir).as_default():\n",
    "        hp.hparams(hparams)  # record the values used in this trial\n",
    "        loss = train_test_model(hparams)\n",
    "        tf.summary.scalar(\"loss\", loss, step=1)\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Starting trial: run-0\n",
      "{'layers': 1, 'num_units': 50, 'learning_rate': 0.0001, 'batch_size': 2}\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0642 - mean_squared_error: 0.0642\n",
      "Loss: 0.06418228149414062 Tiempo transcurrido: 99.28778219223022\n",
      "\n",
      "--- Starting trial: run-1\n",
      "{'layers': 1, 'num_units': 50, 'learning_rate': 0.0001, 'batch_size': 4}\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.5545 - mean_squared_error: 0.5545\n",
      "Loss: 0.55450040102005 Tiempo transcurrido: 53.26859164237976\n",
      "\n",
      "--- Starting trial: run-2\n",
      "{'layers': 1, 'num_units': 50, 'learning_rate': 0.0001, 'batch_size': 8}\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2227 - mean_squared_error: 0.2227\n",
      "Loss: 0.22272852063179016 Tiempo transcurrido: 29.13958477973938\n",
      "\n",
      "--- Starting trial: run-3\n",
      "{'layers': 1, 'num_units': 50, 'learning_rate': 0.0001, 'batch_size': 16}\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 15.2891 - mean_squared_error: 15.2891\n",
      "Loss: 15.289128303527832 Tiempo transcurrido: 16.584038019180298\n",
      "\n",
      "--- Starting trial: run-4\n",
      "{'layers': 1, 'num_units': 50, 'learning_rate': 0.001, 'batch_size': 2}\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0366 - mean_squared_error: 0.0366\n",
      "Loss: 0.03661863133311272 Tiempo transcurrido: 93.10371375083923\n",
      "\n",
      "--- Starting trial: run-5\n",
      "{'layers': 1, 'num_units': 50, 'learning_rate': 0.001, 'batch_size': 4}\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0335 - mean_squared_error: 0.0335\n",
      "Loss: 0.03352074697613716 Tiempo transcurrido: 55.94889426231384\n",
      "\n",
      "--- Starting trial: run-6\n",
      "{'layers': 1, 'num_units': 50, 'learning_rate': 0.001, 'batch_size': 8}\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0365 - mean_squared_error: 0.0365\n",
      "Loss: 0.03647255152463913 Tiempo transcurrido: 35.655779123306274\n",
      "\n",
      "--- Starting trial: run-7\n",
      "{'layers': 1, 'num_units': 50, 'learning_rate': 0.001, 'batch_size': 16}\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0456 - mean_squared_error: 0.0456\n",
      "Loss: 0.045621108263731 Tiempo transcurrido: 19.766472339630127\n",
      "\n",
      "--- Starting trial: run-8\n",
      "{'layers': 1, 'num_units': 100, 'learning_rate': 0.0001, 'batch_size': 2}\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0570 - mean_squared_error: 0.0570\n",
      "Loss: 0.05703170225024223 Tiempo transcurrido: 101.28477430343628\n",
      "\n",
      "--- Starting trial: run-9\n",
      "{'layers': 1, 'num_units': 100, 'learning_rate': 0.0001, 'batch_size': 4}\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0708 - mean_squared_error: 0.0708\n",
      "Loss: 0.070825956761837 Tiempo transcurrido: 49.177035331726074\n",
      "\n",
      "--- Starting trial: run-10\n",
      "{'layers': 1, 'num_units': 100, 'learning_rate': 0.0001, 'batch_size': 8}\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1253 - mean_squared_error: 0.1253\n",
      "Loss: 0.12533193826675415 Tiempo transcurrido: 28.484145641326904\n",
      "\n",
      "--- Starting trial: run-11\n",
      "{'layers': 1, 'num_units': 100, 'learning_rate': 0.0001, 'batch_size': 16}\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.2468 - mean_squared_error: 1.2468\n",
      "Loss: 1.246774435043335 Tiempo transcurrido: 19.77068257331848\n",
      "\n",
      "--- Starting trial: run-12\n",
      "{'layers': 1, 'num_units': 100, 'learning_rate': 0.001, 'batch_size': 2}\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0314 - mean_squared_error: 0.0314\n",
      "Loss: 0.031431347131729126 Tiempo transcurrido: 98.06714248657227\n",
      "\n",
      "--- Starting trial: run-13\n",
      "{'layers': 1, 'num_units': 100, 'learning_rate': 0.001, 'batch_size': 4}\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0327 - mean_squared_error: 0.0327\n",
      "Loss: 0.03266273811459541 Tiempo transcurrido: 51.64467191696167\n",
      "\n",
      "--- Starting trial: run-14\n",
      "{'layers': 1, 'num_units': 100, 'learning_rate': 0.001, 'batch_size': 8}\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0382 - mean_squared_error: 0.0382\n",
      "Loss: 0.03815130889415741 Tiempo transcurrido: 31.585423231124878\n",
      "\n",
      "--- Starting trial: run-15\n",
      "{'layers': 1, 'num_units': 100, 'learning_rate': 0.001, 'batch_size': 16}\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0427 - mean_squared_error: 0.0427\n",
      "Loss: 0.0426618717610836 Tiempo transcurrido: 18.085516452789307\n",
      "\n",
      "--- Starting trial: run-16\n",
      "{'layers': 1, 'num_units': 150, 'learning_rate': 0.0001, 'batch_size': 2}\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0474 - mean_squared_error: 0.0474\n",
      "Loss: 0.04737868905067444 Tiempo transcurrido: 89.24283623695374\n",
      "\n",
      "--- Starting trial: run-17\n",
      "{'layers': 1, 'num_units': 150, 'learning_rate': 0.0001, 'batch_size': 4}\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1281 - mean_squared_error: 0.1281\n",
      "Loss: 0.12814292311668396 Tiempo transcurrido: 56.33350992202759\n",
      "\n",
      "--- Starting trial: run-18\n",
      "{'layers': 1, 'num_units': 150, 'learning_rate': 0.0001, 'batch_size': 8}\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0938 - mean_squared_error: 0.0938\n",
      "Loss: 0.09380624443292618 Tiempo transcurrido: 34.591979026794434\n",
      "\n",
      "--- Starting trial: run-19\n",
      "{'layers': 1, 'num_units': 150, 'learning_rate': 0.0001, 'batch_size': 16}\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.2621 - mean_squared_error: 0.2621\n",
      "Loss: 0.26211977005004883 Tiempo transcurrido: 21.326002836227417\n",
      "\n",
      "--- Starting trial: run-20\n",
      "{'layers': 1, 'num_units': 150, 'learning_rate': 0.001, 'batch_size': 2}\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0343 - mean_squared_error: 0.0343\n",
      "Loss: 0.03426571935415268 Tiempo transcurrido: 108.88051056861877\n",
      "\n",
      "--- Starting trial: run-21\n",
      "{'layers': 1, 'num_units': 150, 'learning_rate': 0.001, 'batch_size': 4}\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.0308 - mean_squared_error: 0.0308\n",
      "Loss: 0.030835602432489395 Tiempo transcurrido: 55.41991424560547\n",
      "\n",
      "--- Starting trial: run-22\n",
      "{'layers': 1, 'num_units': 150, 'learning_rate': 0.001, 'batch_size': 8}\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0374 - mean_squared_error: 0.0374\n",
      "Loss: 0.03739253804087639 Tiempo transcurrido: 32.94326829910278\n",
      "\n",
      "--- Starting trial: run-23\n",
      "{'layers': 1, 'num_units': 150, 'learning_rate': 0.001, 'batch_size': 16}\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0385 - mean_squared_error: 0.0385\n",
      "Loss: 0.03847450762987137 Tiempo transcurrido: 21.17122173309326\n",
      "\n",
      "--- Starting trial: run-24\n",
      "{'layers': 1, 'num_units': 200, 'learning_rate': 0.0001, 'batch_size': 2}\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0543 - mean_squared_error: 0.0543\n",
      "Loss: 0.0542566180229187 Tiempo transcurrido: 143.102392911911\n",
      "\n",
      "--- Starting trial: run-25\n",
      "{'layers': 1, 'num_units': 200, 'learning_rate': 0.0001, 'batch_size': 4}\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0518 - mean_squared_error: 0.0518\n",
      "Loss: 0.05178011953830719 Tiempo transcurrido: 49.19210362434387\n",
      "\n",
      "--- Starting trial: run-26\n",
      "{'layers': 1, 'num_units': 200, 'learning_rate': 0.0001, 'batch_size': 8}\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0898 - mean_squared_error: 0.0898\n",
      "Loss: 0.08984032273292542 Tiempo transcurrido: 34.856093883514404\n",
      "\n",
      "--- Starting trial: run-27\n",
      "{'layers': 1, 'num_units': 200, 'learning_rate': 0.0001, 'batch_size': 16}\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6323 - mean_squared_error: 0.6323\n",
      "Loss: 0.6323341131210327 Tiempo transcurrido: 22.334208250045776\n",
      "\n",
      "--- Starting trial: run-28\n",
      "{'layers': 1, 'num_units': 200, 'learning_rate': 0.001, 'batch_size': 2}\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0362 - mean_squared_error: 0.0362\n",
      "Loss: 0.03617218881845474 Tiempo transcurrido: 104.38814973831177\n",
      "\n",
      "--- Starting trial: run-29\n",
      "{'layers': 1, 'num_units': 200, 'learning_rate': 0.001, 'batch_size': 4}\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0302 - mean_squared_error: 0.0302\n",
      "Loss: 0.030221471562981606 Tiempo transcurrido: 83.07313060760498\n",
      "\n",
      "--- Starting trial: run-30\n",
      "{'layers': 1, 'num_units': 200, 'learning_rate': 0.001, 'batch_size': 8}\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0401 - mean_squared_error: 0.0401\n",
      "Loss: 0.04014778882265091 Tiempo transcurrido: 41.96849846839905\n",
      "\n",
      "--- Starting trial: run-31\n",
      "{'layers': 1, 'num_units': 200, 'learning_rate': 0.001, 'batch_size': 16}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0360 - mean_squared_error: 0.0360\n",
      "Loss: 0.03599366173148155 Tiempo transcurrido: 20.431771516799927\n",
      "\n",
      "--- Starting trial: run-32\n",
      "{'layers': 2, 'num_units': 50, 'learning_rate': 0.0001, 'batch_size': 2}\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0333 - mean_squared_error: 0.0333\n",
      "Loss: 0.033332034945487976 Tiempo transcurrido: 109.27167677879333\n",
      "\n",
      "--- Starting trial: run-33\n",
      "{'layers': 2, 'num_units': 50, 'learning_rate': 0.0001, 'batch_size': 4}\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0362 - mean_squared_error: 0.0362\n",
      "Loss: 0.03620372340083122 Tiempo transcurrido: 54.53160357475281\n",
      "\n",
      "--- Starting trial: run-34\n",
      "{'layers': 2, 'num_units': 50, 'learning_rate': 0.0001, 'batch_size': 8}\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0439 - mean_squared_error: 0.0439\n",
      "Loss: 0.04391714185476303 Tiempo transcurrido: 34.5291531085968\n",
      "\n",
      "--- Starting trial: run-35\n",
      "{'layers': 2, 'num_units': 50, 'learning_rate': 0.0001, 'batch_size': 16}\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1096 - mean_squared_error: 0.1096\n",
      "Loss: 0.1095815896987915 Tiempo transcurrido: 22.588392734527588\n",
      "\n",
      "--- Starting trial: run-36\n",
      "{'layers': 2, 'num_units': 50, 'learning_rate': 0.001, 'batch_size': 2}\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0417 - mean_squared_error: 0.0417\n",
      "Loss: 0.04174182936549187 Tiempo transcurrido: 116.00090217590332\n",
      "\n",
      "--- Starting trial: run-37\n",
      "{'layers': 2, 'num_units': 50, 'learning_rate': 0.001, 'batch_size': 4}\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0314 - mean_squared_error: 0.0314\n",
      "Loss: 0.03141997382044792 Tiempo transcurrido: 52.13177227973938\n",
      "\n",
      "--- Starting trial: run-38\n",
      "{'layers': 2, 'num_units': 50, 'learning_rate': 0.001, 'batch_size': 8}\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0307 - mean_squared_error: 0.0307\n",
      "Loss: 0.030727721750736237 Tiempo transcurrido: 33.20241332054138\n",
      "\n",
      "--- Starting trial: run-39\n",
      "{'layers': 2, 'num_units': 50, 'learning_rate': 0.001, 'batch_size': 16}\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0366 - mean_squared_error: 0.0366\n",
      "Loss: 0.036559782922267914 Tiempo transcurrido: 20.677273273468018\n",
      "\n",
      "--- Starting trial: run-40\n",
      "{'layers': 2, 'num_units': 100, 'learning_rate': 0.0001, 'batch_size': 2}\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0335 - mean_squared_error: 0.0335\n",
      "Loss: 0.03351353481411934 Tiempo transcurrido: 95.03355574607849\n",
      "\n",
      "--- Starting trial: run-41\n",
      "{'layers': 2, 'num_units': 100, 'learning_rate': 0.0001, 'batch_size': 4}\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0373 - mean_squared_error: 0.0373\n",
      "Loss: 0.037275560200214386 Tiempo transcurrido: 56.034457206726074\n",
      "\n",
      "--- Starting trial: run-42\n",
      "{'layers': 2, 'num_units': 100, 'learning_rate': 0.0001, 'batch_size': 8}\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0406 - mean_squared_error: 0.0406\n",
      "Loss: 0.040558796375989914 Tiempo transcurrido: 34.02515769004822\n",
      "\n",
      "--- Starting trial: run-43\n",
      "{'layers': 2, 'num_units': 100, 'learning_rate': 0.0001, 'batch_size': 16}\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0606 - mean_squared_error: 0.0606\n",
      "Loss: 0.060623954981565475 Tiempo transcurrido: 42.351656436920166\n",
      "\n",
      "--- Starting trial: run-44\n",
      "{'layers': 2, 'num_units': 100, 'learning_rate': 0.001, 'batch_size': 2}\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0564 - mean_squared_error: 0.0564\n",
      "Loss: 0.056412987411022186 Tiempo transcurrido: 93.44075131416321\n",
      "\n",
      "--- Starting trial: run-45\n",
      "{'layers': 2, 'num_units': 100, 'learning_rate': 0.001, 'batch_size': 4}\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0397 - mean_squared_error: 0.0397\n",
      "Loss: 0.03973115608096123 Tiempo transcurrido: 50.321051597595215\n",
      "\n",
      "--- Starting trial: run-46\n",
      "{'layers': 2, 'num_units': 100, 'learning_rate': 0.001, 'batch_size': 8}\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0419 - mean_squared_error: 0.0419\n",
      "Loss: 0.04185454174876213 Tiempo transcurrido: 30.574464321136475\n",
      "\n",
      "--- Starting trial: run-47\n",
      "{'layers': 2, 'num_units': 100, 'learning_rate': 0.001, 'batch_size': 16}\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0439 - mean_squared_error: 0.0439\n",
      "Loss: 0.04392893612384796 Tiempo transcurrido: 19.771043300628662\n",
      "\n",
      "--- Starting trial: run-48\n",
      "{'layers': 2, 'num_units': 150, 'learning_rate': 0.0001, 'batch_size': 2}\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0310 - mean_squared_error: 0.0310\n",
      "Loss: 0.03102296032011509 Tiempo transcurrido: 105.01470446586609\n",
      "\n",
      "--- Starting trial: run-49\n",
      "{'layers': 2, 'num_units': 150, 'learning_rate': 0.0001, 'batch_size': 4}\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0376 - mean_squared_error: 0.0376\n",
      "Loss: 0.03759662061929703 Tiempo transcurrido: 83.22834968566895\n",
      "\n",
      "--- Starting trial: run-50\n",
      "{'layers': 2, 'num_units': 150, 'learning_rate': 0.0001, 'batch_size': 8}\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0392 - mean_squared_error: 0.0392\n",
      "Loss: 0.03921234607696533 Tiempo transcurrido: 42.087783336639404\n",
      "\n",
      "--- Starting trial: run-51\n",
      "{'layers': 2, 'num_units': 150, 'learning_rate': 0.0001, 'batch_size': 16}\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0534 - mean_squared_error: 0.0534\n",
      "Loss: 0.0534326508641243 Tiempo transcurrido: 18.145130157470703\n",
      "\n",
      "--- Starting trial: run-52\n",
      "{'layers': 2, 'num_units': 150, 'learning_rate': 0.001, 'batch_size': 2}\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0727 - mean_squared_error: 0.0727\n",
      "Loss: 0.07273576408624649 Tiempo transcurrido: 143.2397232055664\n",
      "\n",
      "--- Starting trial: run-53\n",
      "{'layers': 2, 'num_units': 150, 'learning_rate': 0.001, 'batch_size': 4}\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0359 - mean_squared_error: 0.0359\n",
      "Loss: 0.03586876764893532 Tiempo transcurrido: 46.24025583267212\n",
      "\n",
      "--- Starting trial: run-54\n",
      "{'layers': 2, 'num_units': 150, 'learning_rate': 0.001, 'batch_size': 8}\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0340 - mean_squared_error: 0.0340\n",
      "Loss: 0.034021150320768356 Tiempo transcurrido: 28.058154582977295\n",
      "\n",
      "--- Starting trial: run-55\n",
      "{'layers': 2, 'num_units': 150, 'learning_rate': 0.001, 'batch_size': 16}\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0392 - mean_squared_error: 0.0392\n",
      "Loss: 0.0392238087952137 Tiempo transcurrido: 18.07571578025818\n",
      "\n",
      "--- Starting trial: run-56\n",
      "{'layers': 2, 'num_units': 200, 'learning_rate': 0.0001, 'batch_size': 2}\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0300 - mean_squared_error: 0.0300\n",
      "Loss: 0.029992951080203056 Tiempo transcurrido: 83.02109861373901\n",
      "\n",
      "--- Starting trial: run-57\n",
      "{'layers': 2, 'num_units': 200, 'learning_rate': 0.0001, 'batch_size': 4}\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0383 - mean_squared_error: 0.0383\n",
      "Loss: 0.0382574163377285 Tiempo transcurrido: 44.345258951187134\n",
      "\n",
      "--- Starting trial: run-58\n",
      "{'layers': 2, 'num_units': 200, 'learning_rate': 0.0001, 'batch_size': 8}\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0358 - mean_squared_error: 0.0358\n",
      "Loss: 0.035765390843153 Tiempo transcurrido: 26.77279305458069\n",
      "\n",
      "--- Starting trial: run-59\n",
      "{'layers': 2, 'num_units': 200, 'learning_rate': 0.0001, 'batch_size': 16}\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0528 - mean_squared_error: 0.0528\n",
      "Loss: 0.05280591920018196 Tiempo transcurrido: 17.406092405319214\n",
      "\n",
      "--- Starting trial: run-60\n",
      "{'layers': 2, 'num_units': 200, 'learning_rate': 0.001, 'batch_size': 2}\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0711 - mean_squared_error: 0.0711\n",
      "Loss: 0.07109232991933823 Tiempo transcurrido: 73.60529685020447\n",
      "\n",
      "--- Starting trial: run-61\n",
      "{'layers': 2, 'num_units': 200, 'learning_rate': 0.001, 'batch_size': 4}\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0477 - mean_squared_error: 0.0477\n",
      "Loss: 0.04769797623157501 Tiempo transcurrido: 35.49777913093567\n",
      "\n",
      "--- Starting trial: run-62\n",
      "{'layers': 2, 'num_units': 200, 'learning_rate': 0.001, 'batch_size': 8}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0320 - mean_squared_error: 0.0320\n",
      "Loss: 0.03196781873703003 Tiempo transcurrido: 20.089050769805908\n",
      "\n",
      "--- Starting trial: run-63\n",
      "{'layers': 2, 'num_units': 200, 'learning_rate': 0.001, 'batch_size': 16}\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0636 - mean_squared_error: 0.0636\n",
      "Loss: 0.06358816474676132 Tiempo transcurrido: 13.619547367095947\n",
      "\n",
      "--- Starting trial: run-64\n",
      "{'layers': 3, 'num_units': 50, 'learning_rate': 0.0001, 'batch_size': 2}\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0305 - mean_squared_error: 0.0305\n",
      "Loss: 0.030505811795592308 Tiempo transcurrido: 58.22625136375427\n",
      "\n",
      "--- Starting trial: run-65\n",
      "{'layers': 3, 'num_units': 50, 'learning_rate': 0.0001, 'batch_size': 4}\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0348 - mean_squared_error: 0.0348\n",
      "Loss: 0.03478826582431793 Tiempo transcurrido: 31.85734224319458\n",
      "\n",
      "--- Starting trial: run-66\n",
      "{'layers': 3, 'num_units': 50, 'learning_rate': 0.0001, 'batch_size': 8}\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0358 - mean_squared_error: 0.0358\n",
      "Loss: 0.035781677812337875 Tiempo transcurrido: 19.20120120048523\n",
      "\n",
      "--- Starting trial: run-67\n",
      "{'layers': 3, 'num_units': 50, 'learning_rate': 0.0001, 'batch_size': 16}\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0574 - mean_squared_error: 0.0574\n",
      "Loss: 0.057375308126211166 Tiempo transcurrido: 12.644456148147583\n",
      "\n",
      "--- Starting trial: run-68\n",
      "{'layers': 3, 'num_units': 50, 'learning_rate': 0.001, 'batch_size': 2}\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0570 - mean_squared_error: 0.0570\n",
      "Loss: 0.05704479664564133 Tiempo transcurrido: 57.98923921585083\n",
      "\n",
      "--- Starting trial: run-69\n",
      "{'layers': 3, 'num_units': 50, 'learning_rate': 0.001, 'batch_size': 4}\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0431 - mean_squared_error: 0.0431\n",
      "Loss: 0.04313139244914055 Tiempo transcurrido: 32.028804540634155\n",
      "\n",
      "--- Starting trial: run-70\n",
      "{'layers': 3, 'num_units': 50, 'learning_rate': 0.001, 'batch_size': 8}\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0361 - mean_squared_error: 0.0361\n",
      "Loss: 0.03607344999909401 Tiempo transcurrido: 19.699777603149414\n",
      "\n",
      "--- Starting trial: run-71\n",
      "{'layers': 3, 'num_units': 50, 'learning_rate': 0.001, 'batch_size': 16}\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0612 - mean_squared_error: 0.0612\n",
      "Loss: 0.06116584315896034 Tiempo transcurrido: 12.668020248413086\n",
      "\n",
      "--- Starting trial: run-72\n",
      "{'layers': 3, 'num_units': 100, 'learning_rate': 0.0001, 'batch_size': 2}\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0337 - mean_squared_error: 0.0337\n",
      "Loss: 0.03365284204483032 Tiempo transcurrido: 60.97711896896362\n",
      "\n",
      "--- Starting trial: run-73\n",
      "{'layers': 3, 'num_units': 100, 'learning_rate': 0.0001, 'batch_size': 4}\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0301 - mean_squared_error: 0.0301\n",
      "Loss: 0.030101627111434937 Tiempo transcurrido: 33.14344930648804\n",
      "\n",
      "--- Starting trial: run-74\n",
      "{'layers': 3, 'num_units': 100, 'learning_rate': 0.0001, 'batch_size': 8}\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0373 - mean_squared_error: 0.0373\n",
      "Loss: 0.037329770624637604 Tiempo transcurrido: 20.043059825897217\n",
      "\n",
      "--- Starting trial: run-75\n",
      "{'layers': 3, 'num_units': 100, 'learning_rate': 0.0001, 'batch_size': 16}\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0384 - mean_squared_error: 0.0384\n",
      "Loss: 0.03841407224535942 Tiempo transcurrido: 13.213167190551758\n",
      "\n",
      "--- Starting trial: run-76\n",
      "{'layers': 3, 'num_units': 100, 'learning_rate': 0.001, 'batch_size': 2}\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0647 - mean_squared_error: 0.0647\n",
      "Loss: 0.06468746811151505 Tiempo transcurrido: 61.07117223739624\n",
      "\n",
      "--- Starting trial: run-77\n",
      "{'layers': 3, 'num_units': 100, 'learning_rate': 0.001, 'batch_size': 4}\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0522 - mean_squared_error: 0.0522\n",
      "Loss: 0.052200570702552795 Tiempo transcurrido: 33.25625991821289\n",
      "\n",
      "--- Starting trial: run-78\n",
      "{'layers': 3, 'num_units': 100, 'learning_rate': 0.001, 'batch_size': 8}\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0419 - mean_squared_error: 0.0419\n",
      "Loss: 0.04193812236189842 Tiempo transcurrido: 20.085680723190308\n",
      "\n",
      "--- Starting trial: run-79\n",
      "{'layers': 3, 'num_units': 100, 'learning_rate': 0.001, 'batch_size': 16}\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0658 - mean_squared_error: 0.0658\n",
      "Loss: 0.0658065602183342 Tiempo transcurrido: 13.261324167251587\n",
      "\n",
      "--- Starting trial: run-80\n",
      "{'layers': 3, 'num_units': 150, 'learning_rate': 0.0001, 'batch_size': 2}\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0338 - mean_squared_error: 0.0338\n",
      "Loss: 0.03376638889312744 Tiempo transcurrido: 64.51280069351196\n",
      "\n",
      "--- Starting trial: run-81\n",
      "{'layers': 3, 'num_units': 150, 'learning_rate': 0.0001, 'batch_size': 4}\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0303 - mean_squared_error: 0.0303\n",
      "Loss: 0.03026486746966839 Tiempo transcurrido: 35.488423585891724\n",
      "\n",
      "--- Starting trial: run-82\n",
      "{'layers': 3, 'num_units': 150, 'learning_rate': 0.0001, 'batch_size': 8}\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0430 - mean_squared_error: 0.0430\n",
      "Loss: 0.042991168797016144 Tiempo transcurrido: 21.188307285308838\n",
      "\n",
      "--- Starting trial: run-83\n",
      "{'layers': 3, 'num_units': 150, 'learning_rate': 0.0001, 'batch_size': 16}\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0386 - mean_squared_error: 0.0386\n",
      "Loss: 0.03862646222114563 Tiempo transcurrido: 14.487042427062988\n",
      "\n",
      "--- Starting trial: run-84\n",
      "{'layers': 3, 'num_units': 150, 'learning_rate': 0.001, 'batch_size': 2}\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1313 - mean_squared_error: 0.1313\n",
      "Loss: 0.13134032487869263 Tiempo transcurrido: 64.3827269077301\n",
      "\n",
      "--- Starting trial: run-85\n",
      "{'layers': 3, 'num_units': 150, 'learning_rate': 0.001, 'batch_size': 4}\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0318 - mean_squared_error: 0.0318\n",
      "Loss: 0.03183690458536148 Tiempo transcurrido: 35.94893407821655\n",
      "\n",
      "--- Starting trial: run-86\n",
      "{'layers': 3, 'num_units': 150, 'learning_rate': 0.001, 'batch_size': 8}\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0462 - mean_squared_error: 0.0462\n",
      "Loss: 0.0461510494351387 Tiempo transcurrido: 21.830010890960693\n",
      "\n",
      "--- Starting trial: run-87\n",
      "{'layers': 3, 'num_units': 150, 'learning_rate': 0.001, 'batch_size': 16}\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1165 - mean_squared_error: 0.1165\n",
      "Loss: 0.11649899929761887 Tiempo transcurrido: 14.12990140914917\n",
      "\n",
      "--- Starting trial: run-88\n",
      "{'layers': 3, 'num_units': 200, 'learning_rate': 0.0001, 'batch_size': 2}\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0347 - mean_squared_error: 0.0347\n",
      "Loss: 0.03472797945141792 Tiempo transcurrido: 71.97556495666504\n",
      "\n",
      "--- Starting trial: run-89\n",
      "{'layers': 3, 'num_units': 200, 'learning_rate': 0.0001, 'batch_size': 4}\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0339 - mean_squared_error: 0.0339\n",
      "Loss: 0.033922433853149414 Tiempo transcurrido: 39.862967014312744\n",
      "\n",
      "--- Starting trial: run-90\n",
      "{'layers': 3, 'num_units': 200, 'learning_rate': 0.0001, 'batch_size': 8}\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0457 - mean_squared_error: 0.0457\n",
      "Loss: 0.04566146805882454 Tiempo transcurrido: 23.84842610359192\n",
      "\n",
      "--- Starting trial: run-91\n",
      "{'layers': 3, 'num_units': 200, 'learning_rate': 0.0001, 'batch_size': 16}\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0399 - mean_squared_error: 0.0399\n",
      "Loss: 0.039881281554698944 Tiempo transcurrido: 15.194508075714111\n",
      "\n",
      "--- Starting trial: run-92\n",
      "{'layers': 3, 'num_units': 200, 'learning_rate': 0.001, 'batch_size': 2}\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0723 - mean_squared_error: 0.0723\n",
      "Loss: 0.07228824496269226 Tiempo transcurrido: 71.26467251777649\n",
      "\n",
      "--- Starting trial: run-93\n",
      "{'layers': 3, 'num_units': 200, 'learning_rate': 0.001, 'batch_size': 4}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0321 - mean_squared_error: 0.0321\n",
      "Loss: 0.03206883743405342 Tiempo transcurrido: 37.22696495056152\n",
      "\n",
      "--- Starting trial: run-94\n",
      "{'layers': 3, 'num_units': 200, 'learning_rate': 0.001, 'batch_size': 8}\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0474 - mean_squared_error: 0.0474\n",
      "Loss: 0.047382909804582596 Tiempo transcurrido: 22.253122091293335\n",
      "\n",
      "--- Starting trial: run-95\n",
      "{'layers': 3, 'num_units': 200, 'learning_rate': 0.001, 'batch_size': 16}\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0366 - mean_squared_error: 0.0366\n",
      "Loss: 0.036567699164152145 Tiempo transcurrido: 14.295861721038818\n",
      "\n",
      "--- Starting trial: run-96\n",
      "{'layers': 4, 'num_units': 50, 'learning_rate': 0.0001, 'batch_size': 2}\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0396 - mean_squared_error: 0.0396\n",
      "Loss: 0.03963076323270798 Tiempo transcurrido: 60.9944429397583\n",
      "\n",
      "--- Starting trial: run-97\n",
      "{'layers': 4, 'num_units': 50, 'learning_rate': 0.0001, 'batch_size': 4}\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0321 - mean_squared_error: 0.0321\n",
      "Loss: 0.03212709724903107 Tiempo transcurrido: 33.000622510910034\n",
      "\n",
      "--- Starting trial: run-98\n",
      "{'layers': 4, 'num_units': 50, 'learning_rate': 0.0001, 'batch_size': 8}\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0408 - mean_squared_error: 0.0408\n",
      "Loss: 0.04079008847475052 Tiempo transcurrido: 19.995388507843018\n",
      "\n",
      "--- Starting trial: run-99\n",
      "{'layers': 4, 'num_units': 50, 'learning_rate': 0.0001, 'batch_size': 16}\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0416 - mean_squared_error: 0.0416\n",
      "Loss: 0.04160069674253464 Tiempo transcurrido: 13.265509128570557\n",
      "\n",
      "--- Starting trial: run-100\n",
      "{'layers': 4, 'num_units': 50, 'learning_rate': 0.001, 'batch_size': 2}\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0715 - mean_squared_error: 0.0715\n",
      "Loss: 0.07148803025484085 Tiempo transcurrido: 60.96269154548645\n",
      "\n",
      "--- Starting trial: run-101\n",
      "{'layers': 4, 'num_units': 50, 'learning_rate': 0.001, 'batch_size': 4}\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0428 - mean_squared_error: 0.0428\n",
      "Loss: 0.042772404849529266 Tiempo transcurrido: 33.664074420928955\n",
      "\n",
      "--- Starting trial: run-102\n",
      "{'layers': 4, 'num_units': 50, 'learning_rate': 0.001, 'batch_size': 8}\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0322 - mean_squared_error: 0.0322\n",
      "Loss: 0.03220198303461075 Tiempo transcurrido: 20.4672372341156\n",
      "\n",
      "--- Starting trial: run-103\n",
      "{'layers': 4, 'num_units': 50, 'learning_rate': 0.001, 'batch_size': 16}\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0542 - mean_squared_error: 0.0542\n",
      "Loss: 0.05419968441128731 Tiempo transcurrido: 13.68933367729187\n",
      "\n",
      "--- Starting trial: run-104\n",
      "{'layers': 4, 'num_units': 100, 'learning_rate': 0.0001, 'batch_size': 2}\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0372 - mean_squared_error: 0.0372\n",
      "Loss: 0.03715557977557182 Tiempo transcurrido: 64.73040986061096\n",
      "\n",
      "--- Starting trial: run-105\n",
      "{'layers': 4, 'num_units': 100, 'learning_rate': 0.0001, 'batch_size': 4}\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0342 - mean_squared_error: 0.0342\n",
      "Loss: 0.034171219915151596 Tiempo transcurrido: 35.40113401412964\n",
      "\n",
      "--- Starting trial: run-106\n",
      "{'layers': 4, 'num_units': 100, 'learning_rate': 0.0001, 'batch_size': 8}\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0444 - mean_squared_error: 0.0444\n",
      "Loss: 0.04435314983129501 Tiempo transcurrido: 21.659488201141357\n",
      "\n",
      "--- Starting trial: run-107\n",
      "{'layers': 4, 'num_units': 100, 'learning_rate': 0.0001, 'batch_size': 16}\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0376 - mean_squared_error: 0.0376\n",
      "Loss: 0.037647053599357605 Tiempo transcurrido: 13.879281520843506\n",
      "\n",
      "--- Starting trial: run-108\n",
      "{'layers': 4, 'num_units': 100, 'learning_rate': 0.001, 'batch_size': 2}\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1093 - mean_squared_error: 0.1093\n",
      "Loss: 0.10930716246366501 Tiempo transcurrido: 64.7452654838562\n",
      "\n",
      "--- Starting trial: run-109\n",
      "{'layers': 4, 'num_units': 100, 'learning_rate': 0.001, 'batch_size': 4}\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0377 - mean_squared_error: 0.0377\n",
      "Loss: 0.03770258277654648 Tiempo transcurrido: 36.58041763305664\n",
      "\n",
      "--- Starting trial: run-110\n",
      "{'layers': 4, 'num_units': 100, 'learning_rate': 0.001, 'batch_size': 8}\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0387 - mean_squared_error: 0.0387\n",
      "Loss: 0.03867122158408165 Tiempo transcurrido: 21.60365629196167\n",
      "\n",
      "--- Starting trial: run-111\n",
      "{'layers': 4, 'num_units': 100, 'learning_rate': 0.001, 'batch_size': 16}\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0324 - mean_squared_error: 0.0324\n",
      "Loss: 0.03242498263716698 Tiempo transcurrido: 14.04092001914978\n",
      "\n",
      "--- Starting trial: run-112\n",
      "{'layers': 4, 'num_units': 150, 'learning_rate': 0.0001, 'batch_size': 2}\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0325 - mean_squared_error: 0.0325\n",
      "Loss: 0.03253663703799248 Tiempo transcurrido: 70.05355024337769\n",
      "\n",
      "--- Starting trial: run-113\n",
      "{'layers': 4, 'num_units': 150, 'learning_rate': 0.0001, 'batch_size': 4}\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0329 - mean_squared_error: 0.0329\n",
      "Loss: 0.03294095769524574 Tiempo transcurrido: 38.304736614227295\n",
      "\n",
      "--- Starting trial: run-114\n",
      "{'layers': 4, 'num_units': 150, 'learning_rate': 0.0001, 'batch_size': 8}\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0331 - mean_squared_error: 0.0331\n",
      "Loss: 0.033133652061223984 Tiempo transcurrido: 23.171948671340942\n",
      "\n",
      "--- Starting trial: run-115\n",
      "{'layers': 4, 'num_units': 150, 'learning_rate': 0.0001, 'batch_size': 16}\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0366 - mean_squared_error: 0.0366\n",
      "Loss: 0.03658498451113701 Tiempo transcurrido: 15.666861772537231\n",
      "\n",
      "--- Starting trial: run-116\n",
      "{'layers': 4, 'num_units': 150, 'learning_rate': 0.001, 'batch_size': 2}\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0874 - mean_squared_error: 0.0874\n",
      "Loss: 0.08738493919372559 Tiempo transcurrido: 69.78553748130798\n",
      "\n",
      "--- Starting trial: run-117\n",
      "{'layers': 4, 'num_units': 150, 'learning_rate': 0.001, 'batch_size': 4}\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0326 - mean_squared_error: 0.0326\n",
      "Loss: 0.03259873390197754 Tiempo transcurrido: 39.35045838356018\n",
      "\n",
      "--- Starting trial: run-118\n",
      "{'layers': 4, 'num_units': 150, 'learning_rate': 0.001, 'batch_size': 8}\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0472 - mean_squared_error: 0.0472\n",
      "Loss: 0.04723941162228584 Tiempo transcurrido: 24.00154423713684\n",
      "\n",
      "--- Starting trial: run-119\n",
      "{'layers': 4, 'num_units': 150, 'learning_rate': 0.001, 'batch_size': 16}\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0604 - mean_squared_error: 0.0604\n",
      "Loss: 0.06039241701364517 Tiempo transcurrido: 15.32250452041626\n",
      "\n",
      "--- Starting trial: run-120\n",
      "{'layers': 4, 'num_units': 200, 'learning_rate': 0.0001, 'batch_size': 2}\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0355 - mean_squared_error: 0.0355\n",
      "Loss: 0.035457249730825424 Tiempo transcurrido: 82.11692261695862\n",
      "\n",
      "--- Starting trial: run-121\n",
      "{'layers': 4, 'num_units': 200, 'learning_rate': 0.0001, 'batch_size': 4}\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0334 - mean_squared_error: 0.0334\n",
      "Loss: 0.0334145613014698 Tiempo transcurrido: 45.583967208862305\n",
      "\n",
      "--- Starting trial: run-122\n",
      "{'layers': 4, 'num_units': 200, 'learning_rate': 0.0001, 'batch_size': 8}\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0322 - mean_squared_error: 0.0322\n",
      "Loss: 0.032232753932476044 Tiempo transcurrido: 27.011182069778442\n",
      "\n",
      "--- Starting trial: run-123\n",
      "{'layers': 4, 'num_units': 200, 'learning_rate': 0.0001, 'batch_size': 16}\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0341 - mean_squared_error: 0.0341\n",
      "Loss: 0.034096602350473404 Tiempo transcurrido: 17.128864765167236\n",
      "\n",
      "--- Starting trial: run-124\n",
      "{'layers': 4, 'num_units': 200, 'learning_rate': 0.001, 'batch_size': 2}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0661 - mean_squared_error: 0.0661\n",
      "Loss: 0.06605222076177597 Tiempo transcurrido: 82.40811944007874\n",
      "\n",
      "--- Starting trial: run-125\n",
      "{'layers': 4, 'num_units': 200, 'learning_rate': 0.001, 'batch_size': 4}\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0356 - mean_squared_error: 0.0356\n",
      "Loss: 0.03559416905045509 Tiempo transcurrido: 36.58378219604492\n",
      "\n",
      "--- Starting trial: run-126\n",
      "{'layers': 4, 'num_units': 200, 'learning_rate': 0.001, 'batch_size': 8}\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0347 - mean_squared_error: 0.0347\n",
      "Loss: 0.03468960523605347 Tiempo transcurrido: 21.500879049301147\n",
      "\n",
      "--- Starting trial: run-127\n",
      "{'layers': 4, 'num_units': 200, 'learning_rate': 0.001, 'batch_size': 16}\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0727 - mean_squared_error: 0.0727\n",
      "Loss: 0.07269438356161118 Tiempo transcurrido: 13.365513563156128\n",
      "128\n"
     ]
    }
   ],
   "source": [
    "session_num = 0\n",
    "datos = []\n",
    "\n",
    "for deep_layers in HP_LAYERS.domain.values:\n",
    "    for num_units in HP_NUM_UNITS.domain.values:\n",
    "        for learning_rate in HP_LEARNING.domain.values:\n",
    "            for batch_size in HP_BATCHSIZE.domain.values:\n",
    "                t = time.time()\n",
    "                hparams = {\n",
    "\n",
    "                    HP_LAYERS: deep_layers,\n",
    "                    HP_NUM_UNITS: num_units,\n",
    "                    HP_LEARNING: learning_rate,\n",
    "                    HP_BATCHSIZE: batch_size,\n",
    "                }\n",
    "                run_name = \"run-%d\" % session_num\n",
    "                print('\\n--- Starting trial: %s' % run_name)\n",
    "                print({h.name: hparams[h] for h in hparams})\n",
    "                score = run('logs/hparam_tuning3/' + run_name, hparams)\n",
    "                t = time.time()-t\n",
    "                session_num += 1\n",
    "                print(\"Loss:\", score, \"Tiempo transcurrido:\", t)\n",
    "            \n",
    "            datos.append([deep_layers, num_units, learning_rate, batch_size, score, t])\n",
    "\n",
    "print(session_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"historial_jla_tunning.txt\"\n",
    "df = pd.DataFrame(datos, columns = [\"Deep size\", \"Num units\", \"Learning rate\", \"Batch size\", \"MSE\", \"Tiempo de ejecucin\"])\n",
    "\n",
    "df.sort_values(by=[\"MSE\", \"Tiempo de ejecucin\"], ascending=[True, True], ignore_index=True, inplace=True)\n",
    "\n",
    "df.to_csv(filename, header=True, index=False, sep='\\t', mode='w') # a=append, w=overwrite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Deep size</th>\n",
       "      <th>Num units</th>\n",
       "      <th>Learning rate</th>\n",
       "      <th>Batch size</th>\n",
       "      <th>MSE</th>\n",
       "      <th>Tiempo de ejecucin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>16</td>\n",
       "      <td>0.032425</td>\n",
       "      <td>14.040920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>200</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>16</td>\n",
       "      <td>0.034097</td>\n",
       "      <td>17.128865</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Deep size  Num units  Learning rate  Batch size       MSE  \\\n",
       "0          4        100         0.0010          16  0.032425   \n",
       "1          4        200         0.0001          16  0.034097   \n",
       "\n",
       "   Tiempo de ejecucin  \n",
       "0            14.040920  \n",
       "1            17.128865  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time 9.306 minutes\n"
     ]
    }
   ],
   "source": [
    "total_time = float(np.sum(df[[\"Tiempo de ejecucin\"]])/60)\n",
    "\n",
    "print(\"Elapsed time {:.3f} minutes\".format(total_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     14.040920\n",
       "1     17.128865\n",
       "2     20.431772\n",
       "3     20.677273\n",
       "4     14.295862\n",
       "5     15.666862\n",
       "6     13.879282\n",
       "7     13.213167\n",
       "8     21.171222\n",
       "9     14.487042\n",
       "10    18.075716\n",
       "11    15.194508\n",
       "12    13.265509\n",
       "13    18.085516\n",
       "14    19.771043\n",
       "15    19.766472\n",
       "16    17.406092\n",
       "17    18.145130\n",
       "18    13.689334\n",
       "19    12.644456\n",
       "20    15.322505\n",
       "21    42.351656\n",
       "22    12.668020\n",
       "23    13.619547\n",
       "24    13.261324\n",
       "25    13.365514\n",
       "26    22.588393\n",
       "27    14.129901\n",
       "28    21.326003\n",
       "29    22.334208\n",
       "30    19.770683\n",
       "31    16.584038\n",
       "Name: Tiempo de ejecucin, dtype: float64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"Tiempo de ejecucin\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
