{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-18 17:43:35.191055: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-12-18 17:43:35.275500: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-12-18 17:43:35.275518: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2022-12-18 17:43:35.889146: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2022-12-18 17:43:35.889208: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2022-12-18 17:43:35.889216: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import time, os\n",
    "import random\n",
    "import seaborn as sns\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Input, Dense, LeakyReLU\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorboard.plugins.hparams import api as hp\n",
    "\n",
    "from tensorflow.keras import activations\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "import random\n",
    "from math import floor\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import optimizers\n",
    "from scipy.integrate import odeint\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split as split\n",
    "from scipy.stats import bernoulli\n",
    "\n",
    "# import deap\n",
    "from deap import base, creator, tools, algorithms\n",
    "\n",
    "from bitstring import BitArray\n",
    "\n",
    "# from elitism import eaSimpleWithElitism, main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "\n",
    "# tf.config.optimizer.set_jit(True)\n",
    "# scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "url = 'https://raw.githubusercontent.com/igomezv/nnogada/main/data/jla.csv'\n",
    "df=pd.read_csv(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = len(df.values)\n",
    "randomize = np.random.permutation(N)\n",
    "data = df.values[randomize]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(740, 2)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N = len(df.values)\n",
    "z = data[:,0] \n",
    "y = data[:,1:3] ### coge el resto de variables a predecir \n",
    "y[:,1] = y[:,1]**2+data[:,2]\n",
    "np.shape(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "scalerz = StandardScaler()\n",
    "scalerz.fit(z.reshape(-1,1))\n",
    "z = scalerz.transform(z.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((592, 1), (148, 1), (592, 2), (148, 2))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Modificar para incluir phanteon como test\n",
    "split = 0.8\n",
    "ntrain = int(split * len(z))\n",
    "indx = [ntrain]\n",
    "X_train, X_val = np.split(z, indx)\n",
    "Y_train, Y_val = np.split(y, indx)\n",
    "# X_train, X_test = np.split(z, indx)\n",
    "# Y_train, Y_test = np.split(y, indx)\n",
    "np.shape(X_train), np.shape(X_val), Y_train.shape, Y_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "SC_DEEP       = np.array([1,2,3,4])                           # Number of deep layers (8)\n",
    "SC_NUM_UNITS  = np.array([50,100,150,200]) # Number of fully conected neurons (16)\n",
    "SC_LEARNING   = np.array([1e-4,1e-3])   # Learning rates (8)\n",
    "SC_BATCH      = np.array([2, 4, 8, 16])                            # Batch sizes (4)\n",
    "# SC_ACTIVATION = [f1, f2, f3, f4]                                      # Activation function layers (2)\n",
    "\n",
    "my_callbacks = [tf.keras.callbacks.EarlyStopping(\n",
    "                               monitor='val_loss', mode='min',\n",
    "                               min_delta=0, \n",
    "                               patience=200,\n",
    "                               verbose=1,\n",
    "                            #    baseline=0,\n",
    "                               restore_best_weights=True)\n",
    "#                 keras.callbacks.TensorBoard(\n",
    "#                                log_dir='./logs'),\n",
    "#                 keras.callbacks.ReduceLROnPlateau(\n",
    "#                                monitor='val_loss', factor=0.5,\n",
    "#                                patience=6, min_lr=0,\n",
    "#                                verbose=1)\n",
    "               ] \n",
    "    \n",
    "epochs = 200\n",
    "# epochs = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_evaluate(ga_individual_solution):   \n",
    "    t = time.time()\n",
    "    t_total = 0\n",
    "    \n",
    "    # Decode GA solution to integer for window_size and num_units\n",
    "    deep_layers_bits   = BitArray(ga_individual_solution[0:2])     # (8)\n",
    "    num_units_bits     = BitArray(ga_individual_solution[2:4])     # (16)\n",
    "    learning_rate_bits = BitArray(ga_individual_solution[4:5])    # (8)\n",
    "    batch_size_bits    = BitArray(ga_individual_solution[5:7])   # (4)\n",
    "# #     activation_f_bits  = BitArray(ga_individual_solution[12:13])   # (2)   Solo se consideran las 2 primeras\n",
    "    \n",
    "    deep_layers   = SC_DEEP[deep_layers_bits.uint]\n",
    "    num_units     = SC_NUM_UNITS[num_units_bits.uint]\n",
    "    learning_rate = SC_LEARNING[learning_rate_bits.uint]\n",
    "    batch_size   = SC_BATCH[batch_size_bits.uint]\n",
    "#     activation_f  = SC_ACTIVATION[activation_f_bits.uint]\n",
    "\n",
    "    \n",
    "    print('\\n--------------- Starting trial:', population_size*(max_generations+1)-len(ss), \"---------------\")\n",
    "    print('Deep layers:',deep_layers,', Number of neurons:',num_units,\", Learning rate:\",learning_rate)\n",
    "#     print(\"-------------------------------------------------\")\n",
    "    \n",
    "    # Train model and predict on validation set\n",
    "    model = tf.keras.Sequential()\n",
    "#     model.add(Input(shape=(int(X_train.shape[1]),)))\n",
    "    model.add(Dense(int(X_train.shape[1])))\n",
    "    \n",
    "    for i in range(deep_layers):        \n",
    "        model.add(Dense(num_units, activation='relu'))\n",
    "#             model.add(keras.layers.Dropout(0.3))\n",
    "    model.add(Dense(2, activation='linear'))\n",
    "    \n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate, beta_1=0.9, beta_2=0.999, epsilon=1e-3)\n",
    "    model.compile(optimizer=optimizer, loss='mse', metrics=['mean_squared_error'])\n",
    "    model.fit(X_train, Y_train, epochs=epochs, validation_data=(X_val, Y_val),\n",
    "              callbacks=my_callbacks, batch_size=batch_size, shuffle=False, verbose=0)\n",
    "    \n",
    "    loss, score = model.evaluate(X_val, Y_val)    \n",
    "    t = time.time()-t\n",
    "    ss.pop(0)\n",
    "    print(\"Loss:\", score, \", Elapsed time:\", t)\n",
    "    print(\"-------------------------------------------------\\n\")\n",
    "#     print(loss, score)\n",
    "\n",
    "    datos.append([deep_layers, num_units, learning_rate, batch_size, loss, score, t])\n",
    "    \n",
    "    return loss,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deap import tools\n",
    "from deap import algorithms\n",
    "\n",
    "def eaSimpleWithElitism(population, toolbox, cxpb, mutpb, ngen, stats=None,\n",
    "             halloffame=None, verbose=__debug__):\n",
    "    \"\"\"This algorithm is similar to DEAP eaSimple() algorithm, with the modification that\n",
    "    halloffame is used to implement an elitism mechanism. The individuals contained in the\n",
    "    halloffame are directly injected into the next generation and are not subject to the\n",
    "    genetic operators of selection, crossover and mutation.\n",
    "    \"\"\"\n",
    "    logbook = tools.Logbook()\n",
    "    logbook.header = ['gen', 'nevals'] + (stats.fields if stats else [])\n",
    "\n",
    "    # Evaluate the individuals with an invalid fitness\n",
    "    invalid_ind = [ind for ind in population if not ind.fitness.valid]\n",
    "    fitnesses = toolbox.map(toolbox.evaluate, invalid_ind)\n",
    "    for ind, fit in zip(invalid_ind, fitnesses):\n",
    "        ind.fitness.values = fit\n",
    "\n",
    "    if halloffame is None:\n",
    "        raise ValueError(\"halloffame parameter must not be empty!\")\n",
    "\n",
    "    halloffame.update(population)\n",
    "    hof_size = len(halloffame.items) if halloffame.items else 0\n",
    "\n",
    "    record = stats.compile(population) if stats else {}\n",
    "    logbook.record(gen=0, nevals=len(invalid_ind), **record)\n",
    "    if verbose:\n",
    "        print(logbook.stream)\n",
    "\n",
    "    # Begin the generational process\n",
    "    for gen in range(1, ngen + 1):\n",
    "\n",
    "        # Select the next generation individuals\n",
    "        offspring = toolbox.select(population, len(population) - hof_size)\n",
    "\n",
    "        # Vary the pool of individuals\n",
    "        offspring = algorithms.varAnd(offspring, toolbox, cxpb, mutpb)\n",
    "\n",
    "        # Evaluate the individuals with an invalid fitness\n",
    "        invalid_ind = [ind for ind in offspring if not ind.fitness.valid]\n",
    "        fitnesses = toolbox.map(toolbox.evaluate, invalid_ind)\n",
    "        for ind, fit in zip(invalid_ind, fitnesses):\n",
    "            ind.fitness.values = fit\n",
    "\n",
    "        # add the best back to population:\n",
    "        offspring.extend(halloffame.items)\n",
    "\n",
    "        # Update the hall of fame with the generated individuals\n",
    "        halloffame.update(offspring)\n",
    "\n",
    "        # Replace the current population by the offspring\n",
    "        population[:] = offspring\n",
    "\n",
    "        # Append the current generation statistics to the logbook\n",
    "        record = stats.compile(population) if stats else {}\n",
    "        logbook.record(gen=gen, nevals=len(invalid_ind), **record)\n",
    "        if verbose:\n",
    "            print(logbook.stream)\n",
    "\n",
    "    return population, logbook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def geneticAlgorithm_with_elitism(population_size, max_generations, gene_length, k):\n",
    "    \n",
    "    # Genetic Algorithm constants:\n",
    "    P_CROSSOVER = 0.5        # probability for crossover\n",
    "    P_MUTATION = 0.2         # probability for mutating an individual\n",
    "    HALL_OF_FAME_SIZE = 1    # Best individuals that pass to the other generation\n",
    "    \n",
    "    # set the random seed:\n",
    "    toolbox = base.Toolbox()\n",
    "\n",
    "    # As we are trying to minimize the RMSE score, that's why using -1.0. \n",
    "    # In case, when you want to maximize accuracy for instance, use 1.0\n",
    "    creator.create('FitnessMin', base.Fitness, weights = [-1.0])\n",
    "    creator.create('Individual', list , fitness = creator.FitnessMin)\n",
    "\n",
    "    # create the individual operator to fill up an Individual instance:\n",
    "    toolbox.register('binary', bernoulli.rvs, 0.5)\n",
    "    toolbox.register('individual', tools.initRepeat, creator.Individual, toolbox.binary, n = gene_length)\n",
    "\n",
    "    # create the population operator to generate a list of individuals:\n",
    "    toolbox.register('population', tools.initRepeat, list , toolbox.individual)\n",
    "\n",
    "    # genetic operators:\n",
    "    toolbox.register('evaluate', train_evaluate)\n",
    "    toolbox.register('select', tools.selTournament, tournsize = 2)\n",
    "    toolbox.register('mutate', tools.mutFlipBit, indpb = 0.11)\n",
    "    toolbox.register('mate', tools.cxUniform, indpb = 0.5)\n",
    "    \n",
    "    # create initial population (generation 0):\n",
    "    population = toolbox.population(n=population_size)\n",
    "\n",
    "    # prepare the statistics object:\n",
    "    stats = tools.Statistics(lambda ind: ind.fitness.values)\n",
    "    stats.register(\"min\", np.min)\n",
    "    stats.register(\"avg\", np.mean)\n",
    "    stats.register(\"max\", np.max)\n",
    "\n",
    "    # define the hall-of-fame object:\n",
    "    hof = tools.HallOfFame(HALL_OF_FAME_SIZE)\n",
    "\n",
    "    # Genetic Algorithm flow with elitism:\n",
    "    population, logbook = eaSimpleWithElitism(population, toolbox, cxpb=P_CROSSOVER, mutpb=P_MUTATION,\n",
    "                                              ngen=max_generations, stats=stats, halloffame=hof, verbose=True)\n",
    "\n",
    "    # print info for best solution found:\n",
    "    best = hof.items[0]\n",
    "    print(\"-- Best Individual = \", best)\n",
    "    print(\"-- Best Fitness = \", best.fitness.values[0])\n",
    "\n",
    "    # extract statistics:\n",
    "    minFitnessValues, meanFitnessValues, maxFitnessValues = logbook.select(\"min\", \"max\", \"avg\")\n",
    "\n",
    "    # plot statistics:\n",
    "    sns.set_style(\"whitegrid\")\n",
    "    plt.plot(minFitnessValues, color='blue', label=\"Min\")\n",
    "    plt.plot(meanFitnessValues, color='green', label=\"Mean\")\n",
    "    plt.plot(maxFitnessValues, color='red', label=\"Max\")\n",
    "    plt.xlabel('Generation'); plt.ylabel('Max / Min / Average Fitness')\n",
    "    plt.legend()\n",
    "    plt.title('Max, Min and Average fitness over Generations')\n",
    "    plt.show()\n",
    "    \n",
    "    best_population = tools.selBest(population,k = k)\n",
    "    return best_population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------------- Starting trial: 1 ---------------\n",
      "Deep layers: 3 , Number of neurons: 100 , Learning rate: 0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-18 17:43:36.868465: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-18 17:43:36.868656: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-12-18 17:43:36.868711: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory\n",
      "2022-12-18 17:43:36.868756: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory\n",
      "2022-12-18 17:43:36.868800: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcufft.so.10'; dlerror: libcufft.so.10: cannot open shared object file: No such file or directory\n",
      "2022-12-18 17:43:36.868844: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcurand.so.10'; dlerror: libcurand.so.10: cannot open shared object file: No such file or directory\n",
      "2022-12-18 17:43:36.868887: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory\n",
      "2022-12-18 17:43:36.868931: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory\n",
      "2022-12-18 17:43:36.868974: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2022-12-18 17:43:36.868980: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1934] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2022-12-18 17:43:36.869160: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0693 - mean_squared_error: 0.0693\n",
      "Loss: 0.06926136463880539 , Elapsed time: 142.80675768852234\n",
      "-------------------------------------------------\n",
      "\n",
      "\n",
      "--------------- Starting trial: 2 ---------------\n",
      "Deep layers: 2 , Number of neurons: 200 , Learning rate: 0.0001\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0512 - mean_squared_error: 0.0512\n",
      "Loss: 0.05118468031287193 , Elapsed time: 42.053264141082764\n",
      "-------------------------------------------------\n",
      "\n",
      "\n",
      "--------------- Starting trial: 3 ---------------\n",
      "Deep layers: 4 , Number of neurons: 200 , Learning rate: 0.001\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0506 - mean_squared_error: 0.0506\n",
      "Loss: 0.0506153479218483 , Elapsed time: 42.87002372741699\n",
      "-------------------------------------------------\n",
      "\n",
      "\n",
      "--------------- Starting trial: 4 ---------------\n",
      "Deep layers: 1 , Number of neurons: 100 , Learning rate: 0.0001\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0750 - mean_squared_error: 0.0750\n",
      "Loss: 0.07504429668188095 , Elapsed time: 55.36690354347229\n",
      "-------------------------------------------------\n",
      "\n",
      "\n",
      "--------------- Starting trial: 5 ---------------\n",
      "Deep layers: 2 , Number of neurons: 100 , Learning rate: 0.0001\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0366 - mean_squared_error: 0.0366\n",
      "Loss: 0.0365702323615551 , Elapsed time: 57.59474277496338\n",
      "-------------------------------------------------\n",
      "\n",
      "gen\tnevals\tmin      \tavg      \tmax      \n",
      "0  \t5     \t0.0365702\t0.0565352\t0.0750443\n",
      "\n",
      "--------------- Starting trial: 6 ---------------\n",
      "Deep layers: 4 , Number of neurons: 200 , Learning rate: 0.001\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0735 - mean_squared_error: 0.0735\n",
      "Loss: 0.07349701970815659 , Elapsed time: 42.333192348480225\n",
      "-------------------------------------------------\n",
      "\n",
      "\n",
      "--------------- Starting trial: 7 ---------------\n",
      "Deep layers: 2 , Number of neurons: 200 , Learning rate: 0.0001\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0522 - mean_squared_error: 0.0522\n",
      "Loss: 0.05222676321864128 , Elapsed time: 23.82211947441101\n",
      "-------------------------------------------------\n",
      "\n",
      "1  \t2     \t0.0365702\t0.0564341\t0.073497 \n",
      "\n",
      "--------------- Starting trial: 8 ---------------\n",
      "Deep layers: 2 , Number of neurons: 200 , Learning rate: 0.0001\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0516 - mean_squared_error: 0.0516\n",
      "Loss: 0.05161595717072487 , Elapsed time: 25.63987135887146\n",
      "-------------------------------------------------\n",
      "\n",
      "\n",
      "--------------- Starting trial: 9 ---------------\n",
      "Deep layers: 4 , Number of neurons: 100 , Learning rate: 0.001\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0344 - mean_squared_error: 0.0344\n",
      "Loss: 0.03436867147684097 , Elapsed time: 75.63278818130493\n",
      "-------------------------------------------------\n",
      "\n",
      "\n",
      "--------------- Starting trial: 10 ---------------\n",
      "Deep layers: 2 , Number of neurons: 200 , Learning rate: 0.001\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0514 - mean_squared_error: 0.0514\n",
      "Loss: 0.051446978002786636 , Elapsed time: 30.500370264053345\n",
      "-------------------------------------------------\n",
      "\n",
      "2  \t3     \t0.0343687\t0.0421144\t0.051616 \n",
      "\n",
      "--------------- Starting trial: 11 ---------------\n",
      "Deep layers: 2 , Number of neurons: 100 , Learning rate: 0.0001\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0379 - mean_squared_error: 0.0379\n",
      "Loss: 0.03787599503993988 , Elapsed time: 62.81526017189026\n",
      "-------------------------------------------------\n",
      "\n",
      "\n",
      "--------------- Starting trial: 12 ---------------\n",
      "Deep layers: 2 , Number of neurons: 50 , Learning rate: 0.0001\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0444 - mean_squared_error: 0.0444\n",
      "Loss: 0.04435562342405319 , Elapsed time: 83.22939348220825\n",
      "-------------------------------------------------\n",
      "\n",
      "\n",
      "--------------- Starting trial: 13 ---------------\n",
      "Deep layers: 2 , Number of neurons: 100 , Learning rate: 0.0001\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0368 - mean_squared_error: 0.0368\n",
      "Loss: 0.0368073508143425 , Elapsed time: 70.0969729423523\n",
      "-------------------------------------------------\n",
      "\n",
      "3  \t3     \t0.0343687\t0.0379956\t0.0443556\n",
      "\n",
      "--------------- Starting trial: 14 ---------------\n",
      "Deep layers: 2 , Number of neurons: 100 , Learning rate: 0.0001\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0352 - mean_squared_error: 0.0352\n",
      "Loss: 0.03521609678864479 , Elapsed time: 67.1713616847992\n",
      "-------------------------------------------------\n",
      "\n",
      "\n",
      "--------------- Starting trial: 15 ---------------\n",
      "Deep layers: 2 , Number of neurons: 100 , Learning rate: 0.0001\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0379 - mean_squared_error: 0.0379\n",
      "Loss: 0.03791401907801628 , Elapsed time: 61.19633626937866\n",
      "-------------------------------------------------\n",
      "\n",
      "4  \t2     \t0.0343687\t0.0356875\t0.037914 \n",
      "\n",
      "--------------- Starting trial: 16 ---------------\n",
      "Deep layers: 2 , Number of neurons: 100 , Learning rate: 0.0001\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0360 - mean_squared_error: 0.0360\n",
      "Loss: 0.03600353002548218 , Elapsed time: 62.511285066604614\n",
      "-------------------------------------------------\n",
      "\n",
      "\n",
      "--------------- Starting trial: 17 ---------------\n",
      "Deep layers: 4 , Number of neurons: 100 , Learning rate: 0.001\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0375 - mean_squared_error: 0.0375\n",
      "Loss: 0.03746837377548218 , Elapsed time: 75.41279911994934\n",
      "-------------------------------------------------\n",
      "\n",
      "5  \t2     \t0.0343687\t0.0354851\t0.0374684\n",
      "\n",
      "--------------- Starting trial: 18 ---------------\n",
      "Deep layers: 4 , Number of neurons: 100 , Learning rate: 0.001\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0331 - mean_squared_error: 0.0331\n",
      "Loss: 0.03305092453956604 , Elapsed time: 77.3313717842102\n",
      "-------------------------------------------------\n",
      "\n",
      "\n",
      "--------------- Starting trial: 19 ---------------\n",
      "Deep layers: 4 , Number of neurons: 100 , Learning rate: 0.001\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0396 - mean_squared_error: 0.0396\n",
      "Loss: 0.039553917944431305 , Elapsed time: 83.98527359962463\n",
      "-------------------------------------------------\n",
      "\n",
      "\n",
      "--------------- Starting trial: 20 ---------------\n",
      "Deep layers: 4 , Number of neurons: 100 , Learning rate: 0.001\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0343 - mean_squared_error: 0.0343\n",
      "Loss: 0.0342765673995018 , Elapsed time: 27.839343309402466\n",
      "-------------------------------------------------\n",
      "\n",
      "6  \t3     \t0.0330509\t0.0351238\t0.0395539\n",
      "\n",
      "--------------- Starting trial: 21 ---------------\n",
      "Deep layers: 4 , Number of neurons: 100 , Learning rate: 0.001\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0383 - mean_squared_error: 0.0383\n",
      "Loss: 0.038328662514686584 , Elapsed time: 42.62064599990845\n",
      "-------------------------------------------------\n",
      "\n",
      "\n",
      "--------------- Starting trial: 22 ---------------\n",
      "Deep layers: 4 , Number of neurons: 100 , Learning rate: 0.001\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0317 - mean_squared_error: 0.0317\n",
      "Loss: 0.03167550265789032 , Elapsed time: 75.95975255966187\n",
      "-------------------------------------------------\n",
      "\n",
      "7  \t2     \t0.0316755\t0.0343216\t0.0383287\n",
      "\n",
      "--------------- Starting trial: 23 ---------------\n",
      "Deep layers: 4 , Number of neurons: 100 , Learning rate: 0.001\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0509 - mean_squared_error: 0.0509\n",
      "Loss: 0.050876688212156296 , Elapsed time: 42.870025634765625\n",
      "-------------------------------------------------\n",
      "\n",
      "8  \t1     \t0.0316755\t0.036311 \t0.0508767\n",
      "\n",
      "--------------- Starting trial: 24 ---------------\n",
      "Deep layers: 2 , Number of neurons: 100 , Learning rate: 0.0001\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0353 - mean_squared_error: 0.0353\n",
      "Loss: 0.03529946133494377 , Elapsed time: 70.09857940673828\n",
      "-------------------------------------------------\n",
      "\n",
      "\n",
      "--------------- Starting trial: 25 ---------------\n",
      "Deep layers: 4 , Number of neurons: 100 , Learning rate: 0.001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0357 - mean_squared_error: 0.0357\n",
      "Loss: 0.03570073843002319 , Elapsed time: 85.2973861694336\n",
      "-------------------------------------------------\n",
      "\n",
      "\n",
      "--------------- Starting trial: 26 ---------------\n",
      "Deep layers: 4 , Number of neurons: 100 , Learning rate: 0.001\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0308 - mean_squared_error: 0.0308\n",
      "Loss: 0.03083011321723461 , Elapsed time: 80.72365999221802\n",
      "-------------------------------------------------\n",
      "\n",
      "9  \t3     \t0.0308301\t0.0330363\t0.0357007\n",
      "\n",
      "--------------- Starting trial: 27 ---------------\n",
      "Deep layers: 4 , Number of neurons: 100 , Learning rate: 0.001\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0343 - mean_squared_error: 0.0343\n",
      "Loss: 0.03433465585112572 , Elapsed time: 144.330468416214\n",
      "-------------------------------------------------\n",
      "\n",
      "\n",
      "--------------- Starting trial: 28 ---------------\n",
      "Deep layers: 4 , Number of neurons: 200 , Learning rate: 0.001\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0488 - mean_squared_error: 0.0488\n",
      "Loss: 0.04875946789979935 , Elapsed time: 143.70973563194275\n",
      "-------------------------------------------------\n",
      "\n",
      "\n",
      "--------------- Starting trial: 29 ---------------\n",
      "Deep layers: 4 , Number of neurons: 100 , Learning rate: 0.001\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0328 - mean_squared_error: 0.0328\n",
      "Loss: 0.03280160203576088 , Elapsed time: 79.81712007522583\n",
      "-------------------------------------------------\n",
      "\n",
      "\n",
      "--------------- Starting trial: 30 ---------------\n",
      "Deep layers: 4 , Number of neurons: 100 , Learning rate: 0.001\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0335 - mean_squared_error: 0.0335\n",
      "Loss: 0.03346400707960129 , Elapsed time: 83.75982475280762\n",
      "-------------------------------------------------\n",
      "\n",
      "10 \t4     \t0.0316755\t0.036207 \t0.0487595\n",
      "-- Best Individual =  [1, 1, 0, 1, 1, 0, 1]\n",
      "-- Best Fitness =  0.03167550265789032\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total elapsed time: 34.327766394615175 minutes\n"
     ]
    }
   ],
   "source": [
    "population_size = 5   # max of individuals per generation\n",
    "max_generations = 10  # number of generations\n",
    "gene_length = 7      # lenght of the gene, depends on how many hiperparameters are tested  \n",
    "k = 1;                 # num. of finalist individuals\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    t = time.time(); \n",
    "    datos = [];\n",
    "    ss = [i for i in range(1,population_size*(max_generations+1))]\n",
    "    best_population = geneticAlgorithm_with_elitism(population_size, max_generations, gene_length, k)\n",
    "    print(\"Total elapsed time:\", (time.time()-t)/60, \"minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k= 1 \n",
      "Deep layers: 2 , Number of neurons: 100\n",
      "Batch size 4 , Learning rate: 0.0001\n"
     ]
    }
   ],
   "source": [
    "best_deep_layers   = []\n",
    "best_num_units     = []\n",
    "best_learning_rate = []\n",
    "best_batch_size    = []\n",
    "# best_activation_f  = []\n",
    "best_f_names       = []\n",
    "\n",
    "t = 0\n",
    "\n",
    "for bi in best_population:\n",
    "    deep_layers_bits   = BitArray(bi[0:1])    # (8)\n",
    "    num_units_bits     = BitArray(bi[1:2])    # (16)\n",
    "    learning_rate_bits = BitArray(bi[2:3])   # (8)\n",
    "    batch_size_bits    = BitArray(bi[3:4])  # (4)\n",
    "#     activation_f_bits  = BitArray(bi[12:13])  # (2)\n",
    "    t += 1 \n",
    "    \n",
    "    best_deep_layers.append(SC_DEEP[deep_layers_bits.uint])\n",
    "    best_num_units.append(SC_NUM_UNITS[num_units_bits.uint])\n",
    "    best_learning_rate.append(SC_LEARNING[learning_rate_bits.uint])\n",
    "    best_batch_size.append(SC_BATCH[batch_size_bits.uint])\n",
    "#     best_activation_f.append(SC_ACTIVATION[activation_f_bits.uint])\n",
    "#     best_f_names.append(f_names[activation_f_bits.uint])\n",
    "    print('k=',t,'\\nDeep layers:', best_deep_layers[-1], ', Number of neurons:', best_num_units[-1])\n",
    "    print('Batch size', best_batch_size[-1], ', Learning rate:', best_learning_rate[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Deep layers</th>\n",
       "      <th>Num units</th>\n",
       "      <th>Learning rate</th>\n",
       "      <th>Batch size</th>\n",
       "      <th>Loss</th>\n",
       "      <th>Score</th>\n",
       "      <th>Elapsed time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>4</td>\n",
       "      <td>0.030830</td>\n",
       "      <td>0.030830</td>\n",
       "      <td>80.723660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>4</td>\n",
       "      <td>0.031676</td>\n",
       "      <td>0.031676</td>\n",
       "      <td>75.959753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>4</td>\n",
       "      <td>0.032802</td>\n",
       "      <td>0.032802</td>\n",
       "      <td>79.817120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>4</td>\n",
       "      <td>0.033051</td>\n",
       "      <td>0.033051</td>\n",
       "      <td>77.331372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>4</td>\n",
       "      <td>0.033464</td>\n",
       "      <td>0.033464</td>\n",
       "      <td>83.759825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>16</td>\n",
       "      <td>0.034277</td>\n",
       "      <td>0.034277</td>\n",
       "      <td>27.839343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>4</td>\n",
       "      <td>0.034335</td>\n",
       "      <td>0.034335</td>\n",
       "      <td>144.330468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>4</td>\n",
       "      <td>0.034369</td>\n",
       "      <td>0.034369</td>\n",
       "      <td>75.632788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>4</td>\n",
       "      <td>0.035216</td>\n",
       "      <td>0.035216</td>\n",
       "      <td>67.171362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>4</td>\n",
       "      <td>0.035299</td>\n",
       "      <td>0.035299</td>\n",
       "      <td>70.098579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>4</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>4</td>\n",
       "      <td>0.035701</td>\n",
       "      <td>0.035701</td>\n",
       "      <td>85.297386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>4</td>\n",
       "      <td>0.036004</td>\n",
       "      <td>0.036004</td>\n",
       "      <td>62.511285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>4</td>\n",
       "      <td>0.036570</td>\n",
       "      <td>0.036570</td>\n",
       "      <td>57.594743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>4</td>\n",
       "      <td>0.036807</td>\n",
       "      <td>0.036807</td>\n",
       "      <td>70.096973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>4</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>4</td>\n",
       "      <td>0.037468</td>\n",
       "      <td>0.037468</td>\n",
       "      <td>75.412799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>4</td>\n",
       "      <td>0.037876</td>\n",
       "      <td>0.037876</td>\n",
       "      <td>62.815260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>4</td>\n",
       "      <td>0.037914</td>\n",
       "      <td>0.037914</td>\n",
       "      <td>61.196336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>4</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>16</td>\n",
       "      <td>0.038329</td>\n",
       "      <td>0.038329</td>\n",
       "      <td>42.620646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>4</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>4</td>\n",
       "      <td>0.039554</td>\n",
       "      <td>0.039554</td>\n",
       "      <td>83.985274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>4</td>\n",
       "      <td>0.044356</td>\n",
       "      <td>0.044356</td>\n",
       "      <td>83.229393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>4</td>\n",
       "      <td>200</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>4</td>\n",
       "      <td>0.048759</td>\n",
       "      <td>0.048759</td>\n",
       "      <td>143.709736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>4</td>\n",
       "      <td>200</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>16</td>\n",
       "      <td>0.050615</td>\n",
       "      <td>0.050615</td>\n",
       "      <td>42.870024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>4</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>8</td>\n",
       "      <td>0.050877</td>\n",
       "      <td>0.050877</td>\n",
       "      <td>42.870026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2</td>\n",
       "      <td>200</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>16</td>\n",
       "      <td>0.051185</td>\n",
       "      <td>0.051185</td>\n",
       "      <td>42.053264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2</td>\n",
       "      <td>200</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>16</td>\n",
       "      <td>0.051447</td>\n",
       "      <td>0.051447</td>\n",
       "      <td>30.500370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2</td>\n",
       "      <td>200</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>16</td>\n",
       "      <td>0.051616</td>\n",
       "      <td>0.051616</td>\n",
       "      <td>25.639871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2</td>\n",
       "      <td>200</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>16</td>\n",
       "      <td>0.052227</td>\n",
       "      <td>0.052227</td>\n",
       "      <td>23.822119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>2</td>\n",
       "      <td>0.069261</td>\n",
       "      <td>0.069261</td>\n",
       "      <td>142.806758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>4</td>\n",
       "      <td>200</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>16</td>\n",
       "      <td>0.073497</td>\n",
       "      <td>0.073497</td>\n",
       "      <td>42.333192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>4</td>\n",
       "      <td>0.075044</td>\n",
       "      <td>0.075044</td>\n",
       "      <td>55.366904</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Deep layers  Num units  Learning rate  Batch size      Loss     Score  \\\n",
       "0             4        100         0.0010           4  0.030830  0.030830   \n",
       "1             4        100         0.0010           4  0.031676  0.031676   \n",
       "2             4        100         0.0010           4  0.032802  0.032802   \n",
       "3             4        100         0.0010           4  0.033051  0.033051   \n",
       "4             4        100         0.0010           4  0.033464  0.033464   \n",
       "5             4        100         0.0010          16  0.034277  0.034277   \n",
       "6             4        100         0.0010           4  0.034335  0.034335   \n",
       "7             4        100         0.0010           4  0.034369  0.034369   \n",
       "8             2        100         0.0001           4  0.035216  0.035216   \n",
       "9             2        100         0.0001           4  0.035299  0.035299   \n",
       "10            4        100         0.0010           4  0.035701  0.035701   \n",
       "11            2        100         0.0001           4  0.036004  0.036004   \n",
       "12            2        100         0.0001           4  0.036570  0.036570   \n",
       "13            2        100         0.0001           4  0.036807  0.036807   \n",
       "14            4        100         0.0010           4  0.037468  0.037468   \n",
       "15            2        100         0.0001           4  0.037876  0.037876   \n",
       "16            2        100         0.0001           4  0.037914  0.037914   \n",
       "17            4        100         0.0010          16  0.038329  0.038329   \n",
       "18            4        100         0.0010           4  0.039554  0.039554   \n",
       "19            2         50         0.0001           4  0.044356  0.044356   \n",
       "20            4        200         0.0010           4  0.048759  0.048759   \n",
       "21            4        200         0.0010          16  0.050615  0.050615   \n",
       "22            4        100         0.0010           8  0.050877  0.050877   \n",
       "23            2        200         0.0001          16  0.051185  0.051185   \n",
       "24            2        200         0.0010          16  0.051447  0.051447   \n",
       "25            2        200         0.0001          16  0.051616  0.051616   \n",
       "26            2        200         0.0001          16  0.052227  0.052227   \n",
       "27            3        100         0.0010           2  0.069261  0.069261   \n",
       "28            4        200         0.0010          16  0.073497  0.073497   \n",
       "29            1        100         0.0001           4  0.075044  0.075044   \n",
       "\n",
       "    Elapsed time  \n",
       "0      80.723660  \n",
       "1      75.959753  \n",
       "2      79.817120  \n",
       "3      77.331372  \n",
       "4      83.759825  \n",
       "5      27.839343  \n",
       "6     144.330468  \n",
       "7      75.632788  \n",
       "8      67.171362  \n",
       "9      70.098579  \n",
       "10     85.297386  \n",
       "11     62.511285  \n",
       "12     57.594743  \n",
       "13     70.096973  \n",
       "14     75.412799  \n",
       "15     62.815260  \n",
       "16     61.196336  \n",
       "17     42.620646  \n",
       "18     83.985274  \n",
       "19     83.229393  \n",
       "20    143.709736  \n",
       "21     42.870024  \n",
       "22     42.870026  \n",
       "23     42.053264  \n",
       "24     30.500370  \n",
       "25     25.639871  \n",
       "26     23.822119  \n",
       "27    142.806758  \n",
       "28     42.333192  \n",
       "29     55.366904  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename = \"historial_genetic_jla2.txt\"\n",
    "df = pd.DataFrame(datos, columns = [\"Deep layers\", \"Num units\", \"Learning rate\", \"Batch size\", \"Loss\", \"Score\", \"Elapsed time\"])\n",
    "\n",
    "df.sort_values(by=[\"Loss\", \"Elapsed time\"], ascending=[True, True], ignore_index=True, inplace=True)\n",
    "\n",
    "df.to_csv(filename, header=True, index=False, sep='\\t', mode='w') # a=append, w=overwrite\n",
    "df.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time 34.323 minutes\n"
     ]
    }
   ],
   "source": [
    "total_time = float(np.sum(df[[\"Elapsed time\"]])/60)\n",
    "\n",
    "print(\"Elapsed time {:.3f} minutes\".format(total_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
