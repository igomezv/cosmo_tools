{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-19 22:02:51.917274: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-12-19 22:02:52.455438: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-12-19 22:02:52.455455: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2022-12-19 22:02:53.768373: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2022-12-19 22:02:53.768506: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2022-12-19 22:02:53.768516: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import time, os\n",
    "import random\n",
    "import seaborn as sns\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Input, Dense, LeakyReLU\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorboard.plugins.hparams import api as hp\n",
    "\n",
    "from tensorflow.keras import activations\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "import random\n",
    "from math import floor\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import optimizers\n",
    "from scipy.integrate import odeint\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split as split\n",
    "from scipy.stats import bernoulli\n",
    "\n",
    "# import deap\n",
    "from deap import base, creator, tools, algorithms\n",
    "\n",
    "from bitstring import BitArray\n",
    "\n",
    "# from elitism import eaSimpleWithElitism, main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "\n",
    "# tf.config.optimizer.set_jit(True)\n",
    "# scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "url = 'https://raw.githubusercontent.com/igomezv/nnogada/main/data/jla.csv'\n",
    "df=pd.read_csv(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = len(df.values)\n",
    "randomize = np.random.permutation(N)\n",
    "data = df.values[randomize]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(740, 2)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N = len(df.values)\n",
    "z = data[:,0] \n",
    "y = data[:,1:3] ### coge el resto de variables a predecir \n",
    "y[:,1] = y[:,1]**2+data[:,2]\n",
    "np.shape(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "scalerz = StandardScaler()\n",
    "scalerz.fit(z.reshape(-1,1))\n",
    "z = scalerz.transform(z.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((592, 1), (148, 1), (592, 2), (148, 2))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Modificar para incluir phanteon como test\n",
    "split = 0.8\n",
    "ntrain = int(split * len(z))\n",
    "indx = [ntrain]\n",
    "X_train, X_val = np.split(z, indx)\n",
    "Y_train, Y_val = np.split(y, indx)\n",
    "# X_train, X_test = np.split(z, indx)\n",
    "# Y_train, Y_test = np.split(y, indx)\n",
    "np.shape(X_train), np.shape(X_val), Y_train.shape, Y_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "SC_DEEP       = np.array([1,2,3,4])                           # Number of deep layers (8)\n",
    "SC_NUM_UNITS  = np.array([50,100,150,200]) # Number of fully conected neurons (16)\n",
    "SC_LEARNING   = np.array([1e-4,1e-3])   # Learning rates (8)\n",
    "SC_BATCH      = np.array([2, 4, 8, 16])                            # Batch sizes (4)\n",
    "# SC_ACTIVATION = [f1, f2, f3, f4]                                      # Activation function layers (2)\n",
    "\n",
    "my_callbacks = [tf.keras.callbacks.EarlyStopping(\n",
    "                               monitor='val_loss', mode='min',\n",
    "                               min_delta=0, \n",
    "                               patience=200,\n",
    "                               verbose=1,\n",
    "                            #    baseline=0,\n",
    "                               restore_best_weights=True)\n",
    "#                 keras.callbacks.TensorBoard(\n",
    "#                                log_dir='./logs'),\n",
    "#                 keras.callbacks.ReduceLROnPlateau(\n",
    "#                                monitor='val_loss', factor=0.5,\n",
    "#                                patience=6, min_lr=0,\n",
    "#                                verbose=1)\n",
    "               ] \n",
    "    \n",
    "epochs = 200\n",
    "# epochs = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_evaluate(ga_individual_solution):   \n",
    "    t = time.time()\n",
    "    t_total = 0\n",
    "    \n",
    "    # Decode GA solution to integer for window_size and num_units\n",
    "    deep_layers_bits   = BitArray(ga_individual_solution[0:2])     # (8)\n",
    "    num_units_bits     = BitArray(ga_individual_solution[2:4])     # (16)\n",
    "    learning_rate_bits = BitArray(ga_individual_solution[4:5])    # (8)\n",
    "    batch_size_bits    = BitArray(ga_individual_solution[5:7])   # (4)\n",
    "# #     activation_f_bits  = BitArray(ga_individual_solution[12:13])   # (2)   Solo se consideran las 2 primeras\n",
    "    \n",
    "    deep_layers   = SC_DEEP[deep_layers_bits.uint]\n",
    "    num_units     = SC_NUM_UNITS[num_units_bits.uint]\n",
    "    learning_rate = SC_LEARNING[learning_rate_bits.uint]\n",
    "    batch_size   = SC_BATCH[batch_size_bits.uint]\n",
    "#     activation_f  = SC_ACTIVATION[activation_f_bits.uint]\n",
    "\n",
    "    \n",
    "    print('\\n--------------- Starting trial:', population_size*(max_generations+1)-len(ss), \"---------------\")\n",
    "    print('Deep layers:',deep_layers,', Number of neurons:',num_units,\", Learning rate:\",learning_rate)\n",
    "#     print(\"-------------------------------------------------\")\n",
    "    \n",
    "    # Train model and predict on validation set\n",
    "    model = tf.keras.Sequential()\n",
    "#     model.add(Input(shape=(int(X_train.shape[1]),)))\n",
    "    model.add(Dense(int(X_train.shape[1])))\n",
    "    \n",
    "    for i in range(deep_layers):        \n",
    "        model.add(Dense(num_units, activation='relu'))\n",
    "#             model.add(keras.layers.Dropout(0.3))\n",
    "    model.add(Dense(2, activation='linear'))\n",
    "    \n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate, beta_1=0.9, beta_2=0.999, epsilon=1e-3)\n",
    "    model.compile(optimizer=optimizer, loss='mse', metrics=['mean_squared_error'])\n",
    "    model.fit(X_train, Y_train, epochs=epochs, validation_data=(X_val, Y_val),\n",
    "              callbacks=my_callbacks, batch_size=batch_size, shuffle=False, verbose=0)\n",
    "    \n",
    "    loss, score = model.evaluate(X_val, Y_val)    \n",
    "    t = time.time()-t\n",
    "    ss.pop(0)\n",
    "    print(\"Loss:\", score, \", Elapsed time:\", t)\n",
    "    print(\"-------------------------------------------------\\n\")\n",
    "#     print(loss, score)\n",
    "\n",
    "    datos.append([deep_layers, num_units, learning_rate, batch_size, loss, score, t])\n",
    "    \n",
    "    return loss,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deap import tools\n",
    "from deap import algorithms\n",
    "\n",
    "def eaSimpleWithElitism(population, toolbox, cxpb, mutpb, ngen, stats=None,\n",
    "             halloffame=None, verbose=__debug__):\n",
    "    \"\"\"This algorithm is similar to DEAP eaSimple() algorithm, with the modification that\n",
    "    halloffame is used to implement an elitism mechanism. The individuals contained in the\n",
    "    halloffame are directly injected into the next generation and are not subject to the\n",
    "    genetic operators of selection, crossover and mutation.\n",
    "    \"\"\"\n",
    "    logbook = tools.Logbook()\n",
    "    logbook.header = ['gen', 'nevals'] + (stats.fields if stats else [])\n",
    "\n",
    "    # Evaluate the individuals with an invalid fitness\n",
    "    invalid_ind = [ind for ind in population if not ind.fitness.valid]\n",
    "    fitnesses = toolbox.map(toolbox.evaluate, invalid_ind)\n",
    "    for ind, fit in zip(invalid_ind, fitnesses):\n",
    "        ind.fitness.values = fit\n",
    "\n",
    "    if halloffame is None:\n",
    "        raise ValueError(\"halloffame parameter must not be empty!\")\n",
    "\n",
    "    halloffame.update(population)\n",
    "    hof_size = len(halloffame.items) if halloffame.items else 0\n",
    "\n",
    "    record = stats.compile(population) if stats else {}\n",
    "    logbook.record(gen=0, nevals=len(invalid_ind), **record)\n",
    "    if verbose:\n",
    "        print(logbook.stream)\n",
    "\n",
    "    # Begin the generational process\n",
    "    for gen in range(1, ngen + 1):\n",
    "\n",
    "        # Select the next generation individuals\n",
    "        offspring = toolbox.select(population, len(population) - hof_size)\n",
    "\n",
    "        # Vary the pool of individuals\n",
    "        offspring = algorithms.varAnd(offspring, toolbox, cxpb, mutpb)\n",
    "\n",
    "        # Evaluate the individuals with an invalid fitness\n",
    "        invalid_ind = [ind for ind in offspring if not ind.fitness.valid]\n",
    "        fitnesses = toolbox.map(toolbox.evaluate, invalid_ind)\n",
    "        for ind, fit in zip(invalid_ind, fitnesses):\n",
    "            ind.fitness.values = fit\n",
    "\n",
    "        # add the best back to population:\n",
    "        offspring.extend(halloffame.items)\n",
    "\n",
    "        # Update the hall of fame with the generated individuals\n",
    "        halloffame.update(offspring)\n",
    "\n",
    "        # Replace the current population by the offspring\n",
    "        population[:] = offspring\n",
    "\n",
    "        # Append the current generation statistics to the logbook\n",
    "        record = stats.compile(population) if stats else {}\n",
    "        logbook.record(gen=gen, nevals=len(invalid_ind), **record)\n",
    "        if verbose:\n",
    "            print(logbook.stream)\n",
    "\n",
    "    return population, logbook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def geneticAlgorithm_with_elitism(population_size, max_generations, gene_length, k):\n",
    "    \n",
    "    # Genetic Algorithm constants:\n",
    "    P_CROSSOVER = 0.5        # probability for crossover\n",
    "    P_MUTATION = 0.5         # probability for mutating an individual\n",
    "    HALL_OF_FAME_SIZE = 1    # Best individuals that pass to the other generation\n",
    "    \n",
    "    # set the random seed:\n",
    "    toolbox = base.Toolbox()\n",
    "\n",
    "    # As we are trying to minimize the RMSE score, that's why using -1.0. \n",
    "    # In case, when you want to maximize accuracy for instance, use 1.0\n",
    "    creator.create('FitnessMin', base.Fitness, weights = [-1.0])\n",
    "    creator.create('Individual', list , fitness = creator.FitnessMin)\n",
    "\n",
    "    # create the individual operator to fill up an Individual instance:\n",
    "    toolbox.register('binary', bernoulli.rvs, 0.5)\n",
    "    toolbox.register('individual', tools.initRepeat, creator.Individual, toolbox.binary, n = gene_length)\n",
    "\n",
    "    # create the population operator to generate a list of individuals:\n",
    "    toolbox.register('population', tools.initRepeat, list , toolbox.individual)\n",
    "\n",
    "    # genetic operators:\n",
    "    toolbox.register('evaluate', train_evaluate)\n",
    "    toolbox.register('select', tools.selTournament, tournsize = 2)\n",
    "    toolbox.register('mutate', tools.mutFlipBit, indpb = 0.11)\n",
    "    toolbox.register('mate', tools.cxUniform, indpb = 0.5)\n",
    "    \n",
    "    # create initial population (generation 0):\n",
    "    population = toolbox.population(n=population_size)\n",
    "\n",
    "    # prepare the statistics object:\n",
    "    stats = tools.Statistics(lambda ind: ind.fitness.values)\n",
    "    stats.register(\"min\", np.min)\n",
    "    stats.register(\"avg\", np.mean)\n",
    "    stats.register(\"max\", np.max)\n",
    "\n",
    "    # define the hall-of-fame object:\n",
    "    hof = tools.HallOfFame(HALL_OF_FAME_SIZE)\n",
    "\n",
    "    # Genetic Algorithm flow with elitism:\n",
    "    population, logbook = eaSimpleWithElitism(population, toolbox, cxpb=P_CROSSOVER, mutpb=P_MUTATION,\n",
    "                                              ngen=max_generations, stats=stats, halloffame=hof, verbose=True)\n",
    "\n",
    "    # print info for best solution found:\n",
    "    best = hof.items[0]\n",
    "    print(\"-- Best Individual = \", best)\n",
    "    print(\"-- Best Fitness = \", best.fitness.values[0])\n",
    "\n",
    "    # extract statistics:\n",
    "    minFitnessValues, meanFitnessValues, maxFitnessValues = logbook.select(\"min\", \"max\", \"avg\")\n",
    "\n",
    "    # plot statistics:\n",
    "    sns.set_style(\"whitegrid\")\n",
    "    plt.plot(minFitnessValues, color='blue', label=\"Min\")\n",
    "    plt.plot(meanFitnessValues, color='green', label=\"Mean\")\n",
    "    plt.plot(maxFitnessValues, color='red', label=\"Max\")\n",
    "    plt.xlabel('Generation'); plt.ylabel('Max / Min / Average Fitness')\n",
    "    plt.legend()\n",
    "    plt.title('Max, Min and Average fitness over Generations')\n",
    "    plt.show()\n",
    "    \n",
    "    best_population = tools.selBest(population,k = k)\n",
    "    return best_population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------------- Starting trial: 1 ---------------\n",
      "Deep layers: 3 , Number of neurons: 100 , Learning rate: 0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-19 22:02:55.457120: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-19 22:02:55.457470: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-12-19 22:02:55.457595: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory\n",
      "2022-12-19 22:02:55.457688: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory\n",
      "2022-12-19 22:02:55.457778: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcufft.so.10'; dlerror: libcufft.so.10: cannot open shared object file: No such file or directory\n",
      "2022-12-19 22:02:55.457867: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcurand.so.10'; dlerror: libcurand.so.10: cannot open shared object file: No such file or directory\n",
      "2022-12-19 22:02:55.457954: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory\n",
      "2022-12-19 22:02:55.458041: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory\n",
      "2022-12-19 22:02:55.458130: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2022-12-19 22:02:55.458142: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1934] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2022-12-19 22:02:55.459403: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0797 - mean_squared_error: 0.0797\n",
      "Loss: 0.07966721057891846 , Elapsed time: 57.23694705963135\n",
      "-------------------------------------------------\n",
      "\n",
      "\n",
      "--------------- Starting trial: 2 ---------------\n",
      "Deep layers: 2 , Number of neurons: 200 , Learning rate: 0.0001\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0469 - mean_squared_error: 0.0469\n",
      "Loss: 0.04691782221198082 , Elapsed time: 11.403791666030884\n",
      "-------------------------------------------------\n",
      "\n",
      "\n",
      "--------------- Starting trial: 3 ---------------\n",
      "Deep layers: 4 , Number of neurons: 200 , Learning rate: 0.001\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0614 - mean_squared_error: 0.0614\n",
      "Loss: 0.06139012426137924 , Elapsed time: 13.780651092529297\n",
      "-------------------------------------------------\n",
      "\n",
      "\n",
      "--------------- Starting trial: 4 ---------------\n",
      "Deep layers: 1 , Number of neurons: 100 , Learning rate: 0.0001\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0711 - mean_squared_error: 0.0711\n",
      "Loss: 0.07113130390644073 , Elapsed time: 26.243995666503906\n",
      "-------------------------------------------------\n",
      "\n",
      "\n",
      "--------------- Starting trial: 5 ---------------\n",
      "Deep layers: 2 , Number of neurons: 100 , Learning rate: 0.0001\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0356 - mean_squared_error: 0.0356\n",
      "Loss: 0.035583995282649994 , Elapsed time: 30.185745239257812\n",
      "-------------------------------------------------\n",
      "\n",
      "gen\tnevals\tmin     \tavg      \tmax      \n",
      "0  \t5     \t0.035584\t0.0589381\t0.0796672\n",
      "\n",
      "--------------- Starting trial: 6 ---------------\n",
      "Deep layers: 2 , Number of neurons: 100 , Learning rate: 0.0001\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0679 - mean_squared_error: 0.0679\n",
      "Loss: 0.0678863450884819 , Elapsed time: 10.740662813186646\n",
      "-------------------------------------------------\n",
      "\n",
      "\n",
      "--------------- Starting trial: 7 ---------------\n",
      "Deep layers: 2 , Number of neurons: 150 , Learning rate: 0.001\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0394 - mean_squared_error: 0.0394\n",
      "Loss: 0.039440516382455826 , Elapsed time: 30.03522300720215\n",
      "-------------------------------------------------\n",
      "\n",
      "\n",
      "--------------- Starting trial: 8 ---------------\n",
      "Deep layers: 2 , Number of neurons: 100 , Learning rate: 0.0001\n",
      "5/5 [==============================] - 0s 992us/step - loss: 0.0338 - mean_squared_error: 0.0338\n",
      "Loss: 0.03379174694418907 , Elapsed time: 56.41043663024902\n",
      "-------------------------------------------------\n",
      "\n",
      "\n",
      "--------------- Starting trial: 9 ---------------\n",
      "Deep layers: 2 , Number of neurons: 100 , Learning rate: 0.0001\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0678 - mean_squared_error: 0.0678\n",
      "Loss: 0.06779073923826218 , Elapsed time: 11.142730951309204\n",
      "-------------------------------------------------\n",
      "\n",
      "1  \t4     \t0.0337917\t0.0488987\t0.0678863\n",
      "\n",
      "--------------- Starting trial: 10 ---------------\n",
      "Deep layers: 2 , Number of neurons: 100 , Learning rate: 0.0001\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0339 - mean_squared_error: 0.0339\n",
      "Loss: 0.03389126434922218 , Elapsed time: 55.46764373779297\n",
      "-------------------------------------------------\n",
      "\n",
      "\n",
      "--------------- Starting trial: 11 ---------------\n",
      "Deep layers: 2 , Number of neurons: 100 , Learning rate: 0.0001\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0357 - mean_squared_error: 0.0357\n",
      "Loss: 0.03573368862271309 , Elapsed time: 30.765026092529297\n",
      "-------------------------------------------------\n",
      "\n",
      "\n",
      "--------------- Starting trial: 12 ---------------\n",
      "Deep layers: 2 , Number of neurons: 100 , Learning rate: 0.0001\n",
      "5/5 [==============================] - 0s 983us/step - loss: 0.0379 - mean_squared_error: 0.0379\n",
      "Loss: 0.037855155766010284 , Elapsed time: 30.491633892059326\n",
      "-------------------------------------------------\n",
      "\n",
      "2  \t3     \t0.0337917\t0.0418125\t0.0677907\n",
      "\n",
      "--------------- Starting trial: 13 ---------------\n",
      "Deep layers: 4 , Number of neurons: 100 , Learning rate: 0.0001\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0368 - mean_squared_error: 0.0368\n",
      "Loss: 0.036759402602910995 , Elapsed time: 59.64087724685669\n",
      "-------------------------------------------------\n",
      "\n",
      "\n",
      "--------------- Starting trial: 14 ---------------\n",
      "Deep layers: 2 , Number of neurons: 100 , Learning rate: 0.0001\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0451 - mean_squared_error: 0.0451\n",
      "Loss: 0.04509509727358818 , Elapsed time: 17.54017972946167\n",
      "-------------------------------------------------\n",
      "\n",
      "\n",
      "--------------- Starting trial: 15 ---------------\n",
      "Deep layers: 2 , Number of neurons: 50 , Learning rate: 0.0001\n",
      "5/5 [==============================] - 0s 943us/step - loss: 0.0775 - mean_squared_error: 0.0775\n",
      "Loss: 0.07745148986577988 , Elapsed time: 10.670143842697144\n",
      "-------------------------------------------------\n",
      "\n",
      "\n",
      "--------------- Starting trial: 16 ---------------\n",
      "Deep layers: 2 , Number of neurons: 100 , Learning rate: 0.0001\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0350 - mean_squared_error: 0.0350\n",
      "Loss: 0.03503837808966637 , Elapsed time: 30.19563913345337\n",
      "-------------------------------------------------\n",
      "\n",
      "3  \t4     \t0.0337917\t0.0456272\t0.0774515\n",
      "\n",
      "--------------- Starting trial: 17 ---------------\n",
      "Deep layers: 2 , Number of neurons: 100 , Learning rate: 0.0001\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0381 - mean_squared_error: 0.0381\n",
      "Loss: 0.03813368082046509 , Elapsed time: 30.532360553741455\n",
      "-------------------------------------------------\n",
      "\n",
      "4  \t1     \t0.0337917\t0.0438907\t0.0774515\n",
      "\n",
      "--------------- Starting trial: 18 ---------------\n",
      "Deep layers: 2 , Number of neurons: 100 , Learning rate: 0.001\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0461 - mean_squared_error: 0.0461\n",
      "Loss: 0.04611832648515701 , Elapsed time: 30.27564549446106\n",
      "-------------------------------------------------\n",
      "\n",
      "\n",
      "--------------- Starting trial: 19 ---------------\n",
      "Deep layers: 1 , Number of neurons: 100 , Learning rate: 0.0001\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0680 - mean_squared_error: 0.0680\n",
      "Loss: 0.0680370107293129 , Elapsed time: 26.35692262649536\n",
      "-------------------------------------------------\n",
      "\n",
      "5  \t2     \t0.0337917\t0.0439745\t0.068037 \n",
      "\n",
      "--------------- Starting trial: 20 ---------------\n",
      "Deep layers: 1 , Number of neurons: 50 , Learning rate: 0.001\n",
      "5/5 [==============================] - 0s 974us/step - loss: 0.0305 - mean_squared_error: 0.0305\n",
      "Loss: 0.03046388179063797 , Elapsed time: 47.82299613952637\n",
      "-------------------------------------------------\n",
      "\n",
      "\n",
      "--------------- Starting trial: 21 ---------------\n",
      "Deep layers: 2 , Number of neurons: 100 , Learning rate: 0.0001\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0375 - mean_squared_error: 0.0375\n",
      "Loss: 0.03748549148440361 , Elapsed time: 30.36109733581543\n",
      "-------------------------------------------------\n",
      "\n",
      "\n",
      "--------------- Starting trial: 22 ---------------\n",
      "Deep layers: 2 , Number of neurons: 100 , Learning rate: 0.0001\n",
      "5/5 [==============================] - 0s 956us/step - loss: 0.0406 - mean_squared_error: 0.0406\n",
      "Loss: 0.040591441094875336 , Elapsed time: 17.69409465789795\n",
      "-------------------------------------------------\n",
      "\n",
      "6  \t3     \t0.0304639\t0.0352249\t0.0405914\n",
      "\n",
      "--------------- Starting trial: 23 ---------------\n",
      "Deep layers: 2 , Number of neurons: 100 , Learning rate: 0.001\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0548 - mean_squared_error: 0.0548\n",
      "Loss: 0.054815202951431274 , Elapsed time: 56.059462547302246\n",
      "-------------------------------------------------\n",
      "\n",
      "\n",
      "--------------- Starting trial: 24 ---------------\n",
      "Deep layers: 1 , Number of neurons: 50 , Learning rate: 0.0001\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0655 - mean_squared_error: 0.0655\n",
      "Loss: 0.06550310552120209 , Elapsed time: 47.59134078025818\n",
      "-------------------------------------------------\n",
      "\n",
      "\n",
      "--------------- Starting trial: 25 ---------------\n",
      "Deep layers: 1 , Number of neurons: 50 , Learning rate: 0.001\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0364 - mean_squared_error: 0.0364\n",
      "Loss: 0.0364212729036808 , Elapsed time: 47.23399329185486\n",
      "-------------------------------------------------\n",
      "\n",
      "\n",
      "--------------- Starting trial: 26 ---------------\n",
      "Deep layers: 1 , Number of neurons: 50 , Learning rate: 0.001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 956us/step - loss: 0.0308 - mean_squared_error: 0.0308\n",
      "Loss: 0.030809583142399788 , Elapsed time: 47.54917049407959\n",
      "-------------------------------------------------\n",
      "\n",
      "7  \t4     \t0.0304639\t0.0436026\t0.0655031\n",
      "\n",
      "--------------- Starting trial: 27 ---------------\n",
      "Deep layers: 2 , Number of neurons: 100 , Learning rate: 0.001\n",
      "5/5 [==============================] - 0s 976us/step - loss: 0.0641 - mean_squared_error: 0.0641\n",
      "Loss: 0.06407061964273453 , Elapsed time: 57.143001317977905\n",
      "-------------------------------------------------\n",
      "\n",
      "\n",
      "--------------- Starting trial: 28 ---------------\n",
      "Deep layers: 1 , Number of neurons: 50 , Learning rate: 0.001\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0376 - mean_squared_error: 0.0376\n",
      "Loss: 0.037641506642103195 , Elapsed time: 47.82774758338928\n",
      "-------------------------------------------------\n",
      "\n",
      "\n",
      "--------------- Starting trial: 29 ---------------\n",
      "Deep layers: 1 , Number of neurons: 100 , Learning rate: 0.001\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0313 - mean_squared_error: 0.0313\n",
      "Loss: 0.031281329691410065 , Elapsed time: 48.49930691719055\n",
      "-------------------------------------------------\n",
      "\n",
      "8  \t3     \t0.0304639\t0.0399757\t0.0640706\n",
      "\n",
      "--------------- Starting trial: 30 ---------------\n",
      "Deep layers: 3 , Number of neurons: 50 , Learning rate: 0.0001\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0317 - mean_squared_error: 0.0317\n",
      "Loss: 0.03168307617306709 , Elapsed time: 57.12601661682129\n",
      "-------------------------------------------------\n",
      "\n",
      "\n",
      "--------------- Starting trial: 31 ---------------\n",
      "Deep layers: 1 , Number of neurons: 50 , Learning rate: 0.001\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0306 - mean_squared_error: 0.0306\n",
      "Loss: 0.030649136751890182 , Elapsed time: 47.775699853897095\n",
      "-------------------------------------------------\n",
      "\n",
      "\n",
      "--------------- Starting trial: 32 ---------------\n",
      "Deep layers: 1 , Number of neurons: 50 , Learning rate: 0.001\n",
      "5/5 [==============================] - 0s 959us/step - loss: 0.0300 - mean_squared_error: 0.0300\n",
      "Loss: 0.029973894357681274 , Elapsed time: 48.13120365142822\n",
      "-------------------------------------------------\n",
      "\n",
      "9  \t3     \t0.0299739\t0.0318383\t0.0364213\n",
      "\n",
      "--------------- Starting trial: 33 ---------------\n",
      "Deep layers: 1 , Number of neurons: 50 , Learning rate: 0.001\n",
      "5/5 [==============================] - 0s 996us/step - loss: 0.0301 - mean_squared_error: 0.0301\n",
      "Loss: 0.030129242688417435 , Elapsed time: 47.85405731201172\n",
      "-------------------------------------------------\n",
      "\n",
      "\n",
      "--------------- Starting trial: 34 ---------------\n",
      "Deep layers: 1 , Number of neurons: 50 , Learning rate: 0.001\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0396 - mean_squared_error: 0.0396\n",
      "Loss: 0.03957736864686012 , Elapsed time: 47.86938214302063\n",
      "-------------------------------------------------\n",
      "\n",
      "\n",
      "--------------- Starting trial: 35 ---------------\n",
      "Deep layers: 1 , Number of neurons: 150 , Learning rate: 0.001\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0323 - mean_squared_error: 0.0323\n",
      "Loss: 0.03232819214463234 , Elapsed time: 49.66637921333313\n",
      "-------------------------------------------------\n",
      "\n",
      "\n",
      "--------------- Starting trial: 36 ---------------\n",
      "Deep layers: 1 , Number of neurons: 50 , Learning rate: 0.001\n",
      "5/5 [==============================] - 0s 958us/step - loss: 0.0373 - mean_squared_error: 0.0373\n",
      "Loss: 0.03725306689739227 , Elapsed time: 16.1569881439209\n",
      "-------------------------------------------------\n",
      "\n",
      "10 \t4     \t0.0301292\t0.0339504\t0.0395774\n",
      "-- Best Individual =  [0, 0, 0, 0, 1, 0, 0]\n",
      "-- Best Fitness =  0.03046388179063797\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total elapsed time: 22.194522325197855 minutes\n"
     ]
    }
   ],
   "source": [
    "population_size = 5   # max of individuals per generation\n",
    "max_generations = 10  # number of generations\n",
    "gene_length = 7      # lenght of the gene, depends on how many hiperparameters are tested  \n",
    "k = 1;                 # num. of finalist individuals\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    t = time.time(); \n",
    "    datos = [];\n",
    "    ss = [i for i in range(1,population_size*(max_generations+1))]\n",
    "    best_population = geneticAlgorithm_with_elitism(population_size, max_generations, gene_length, k)\n",
    "    print(\"Total elapsed time:\", (time.time()-t)/60, \"minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k= 1 \n",
      "Deep layers: 1 , Number of neurons: 50\n",
      "Batch size 2 , Learning rate: 0.0001\n"
     ]
    }
   ],
   "source": [
    "best_deep_layers   = []\n",
    "best_num_units     = []\n",
    "best_learning_rate = []\n",
    "best_batch_size    = []\n",
    "# best_activation_f  = []\n",
    "best_f_names       = []\n",
    "\n",
    "t = 0\n",
    "\n",
    "for bi in best_population:\n",
    "    deep_layers_bits   = BitArray(bi[0:1])    # (8)\n",
    "    num_units_bits     = BitArray(bi[1:2])    # (16)\n",
    "    learning_rate_bits = BitArray(bi[2:3])   # (8)\n",
    "    batch_size_bits    = BitArray(bi[3:4])  # (4)\n",
    "#     activation_f_bits  = BitArray(bi[12:13])  # (2)\n",
    "    t += 1 \n",
    "    \n",
    "    best_deep_layers.append(SC_DEEP[deep_layers_bits.uint])\n",
    "    best_num_units.append(SC_NUM_UNITS[num_units_bits.uint])\n",
    "    best_learning_rate.append(SC_LEARNING[learning_rate_bits.uint])\n",
    "    best_batch_size.append(SC_BATCH[batch_size_bits.uint])\n",
    "#     best_activation_f.append(SC_ACTIVATION[activation_f_bits.uint])\n",
    "#     best_f_names.append(f_names[activation_f_bits.uint])\n",
    "    print('k=',t,'\\nDeep layers:', best_deep_layers[-1], ', Number of neurons:', best_num_units[-1])\n",
    "    print('Batch size', best_batch_size[-1], ', Learning rate:', best_learning_rate[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Deep layers</th>\n",
       "      <th>Num units</th>\n",
       "      <th>Learning rate</th>\n",
       "      <th>Batch size</th>\n",
       "      <th>Loss</th>\n",
       "      <th>Score</th>\n",
       "      <th>Elapsed time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>2</td>\n",
       "      <td>0.029974</td>\n",
       "      <td>0.029974</td>\n",
       "      <td>48.131204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>2</td>\n",
       "      <td>0.030129</td>\n",
       "      <td>0.030129</td>\n",
       "      <td>47.854057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>2</td>\n",
       "      <td>0.030464</td>\n",
       "      <td>0.030464</td>\n",
       "      <td>47.822996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>2</td>\n",
       "      <td>0.030649</td>\n",
       "      <td>0.030649</td>\n",
       "      <td>47.775700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>2</td>\n",
       "      <td>0.030810</td>\n",
       "      <td>0.030810</td>\n",
       "      <td>47.549170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>2</td>\n",
       "      <td>0.031281</td>\n",
       "      <td>0.031281</td>\n",
       "      <td>48.499307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3</td>\n",
       "      <td>50</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>2</td>\n",
       "      <td>0.031683</td>\n",
       "      <td>0.031683</td>\n",
       "      <td>57.126017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>150</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>2</td>\n",
       "      <td>0.032328</td>\n",
       "      <td>0.032328</td>\n",
       "      <td>49.666379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>2</td>\n",
       "      <td>0.033792</td>\n",
       "      <td>0.033792</td>\n",
       "      <td>56.410437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>2</td>\n",
       "      <td>0.033891</td>\n",
       "      <td>0.033891</td>\n",
       "      <td>55.467644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>4</td>\n",
       "      <td>0.035038</td>\n",
       "      <td>0.035038</td>\n",
       "      <td>30.195639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>4</td>\n",
       "      <td>0.035584</td>\n",
       "      <td>0.035584</td>\n",
       "      <td>30.185745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>4</td>\n",
       "      <td>0.035734</td>\n",
       "      <td>0.035734</td>\n",
       "      <td>30.765026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>2</td>\n",
       "      <td>0.036421</td>\n",
       "      <td>0.036421</td>\n",
       "      <td>47.233993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>4</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>2</td>\n",
       "      <td>0.036759</td>\n",
       "      <td>0.036759</td>\n",
       "      <td>59.640877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>8</td>\n",
       "      <td>0.037253</td>\n",
       "      <td>0.037253</td>\n",
       "      <td>16.156988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>4</td>\n",
       "      <td>0.037485</td>\n",
       "      <td>0.037485</td>\n",
       "      <td>30.361097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>2</td>\n",
       "      <td>0.037642</td>\n",
       "      <td>0.037642</td>\n",
       "      <td>47.827748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>4</td>\n",
       "      <td>0.037855</td>\n",
       "      <td>0.037855</td>\n",
       "      <td>30.491634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>4</td>\n",
       "      <td>0.038134</td>\n",
       "      <td>0.038134</td>\n",
       "      <td>30.532361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2</td>\n",
       "      <td>150</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>4</td>\n",
       "      <td>0.039441</td>\n",
       "      <td>0.039441</td>\n",
       "      <td>30.035223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>2</td>\n",
       "      <td>0.039577</td>\n",
       "      <td>0.039577</td>\n",
       "      <td>47.869382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>8</td>\n",
       "      <td>0.040591</td>\n",
       "      <td>0.040591</td>\n",
       "      <td>17.694095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>8</td>\n",
       "      <td>0.045095</td>\n",
       "      <td>0.045095</td>\n",
       "      <td>17.540180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>4</td>\n",
       "      <td>0.046118</td>\n",
       "      <td>0.046118</td>\n",
       "      <td>30.275645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2</td>\n",
       "      <td>200</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>16</td>\n",
       "      <td>0.046918</td>\n",
       "      <td>0.046918</td>\n",
       "      <td>11.403792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>2</td>\n",
       "      <td>0.054815</td>\n",
       "      <td>0.054815</td>\n",
       "      <td>56.059463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>4</td>\n",
       "      <td>200</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>16</td>\n",
       "      <td>0.061390</td>\n",
       "      <td>0.061390</td>\n",
       "      <td>13.780651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>2</td>\n",
       "      <td>0.064071</td>\n",
       "      <td>0.064071</td>\n",
       "      <td>57.143001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>2</td>\n",
       "      <td>0.065503</td>\n",
       "      <td>0.065503</td>\n",
       "      <td>47.591341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>16</td>\n",
       "      <td>0.067791</td>\n",
       "      <td>0.067791</td>\n",
       "      <td>11.142731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>16</td>\n",
       "      <td>0.067886</td>\n",
       "      <td>0.067886</td>\n",
       "      <td>10.740663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>4</td>\n",
       "      <td>0.068037</td>\n",
       "      <td>0.068037</td>\n",
       "      <td>26.356923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>4</td>\n",
       "      <td>0.071131</td>\n",
       "      <td>0.071131</td>\n",
       "      <td>26.243996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>16</td>\n",
       "      <td>0.077451</td>\n",
       "      <td>0.077451</td>\n",
       "      <td>10.670144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>2</td>\n",
       "      <td>0.079667</td>\n",
       "      <td>0.079667</td>\n",
       "      <td>57.236947</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Deep layers  Num units  Learning rate  Batch size      Loss     Score  \\\n",
       "0             1         50         0.0010           2  0.029974  0.029974   \n",
       "1             1         50         0.0010           2  0.030129  0.030129   \n",
       "2             1         50         0.0010           2  0.030464  0.030464   \n",
       "3             1         50         0.0010           2  0.030649  0.030649   \n",
       "4             1         50         0.0010           2  0.030810  0.030810   \n",
       "5             1        100         0.0010           2  0.031281  0.031281   \n",
       "6             3         50         0.0001           2  0.031683  0.031683   \n",
       "7             1        150         0.0010           2  0.032328  0.032328   \n",
       "8             2        100         0.0001           2  0.033792  0.033792   \n",
       "9             2        100         0.0001           2  0.033891  0.033891   \n",
       "10            2        100         0.0001           4  0.035038  0.035038   \n",
       "11            2        100         0.0001           4  0.035584  0.035584   \n",
       "12            2        100         0.0001           4  0.035734  0.035734   \n",
       "13            1         50         0.0010           2  0.036421  0.036421   \n",
       "14            4        100         0.0001           2  0.036759  0.036759   \n",
       "15            1         50         0.0010           8  0.037253  0.037253   \n",
       "16            2        100         0.0001           4  0.037485  0.037485   \n",
       "17            1         50         0.0010           2  0.037642  0.037642   \n",
       "18            2        100         0.0001           4  0.037855  0.037855   \n",
       "19            2        100         0.0001           4  0.038134  0.038134   \n",
       "20            2        150         0.0010           4  0.039441  0.039441   \n",
       "21            1         50         0.0010           2  0.039577  0.039577   \n",
       "22            2        100         0.0001           8  0.040591  0.040591   \n",
       "23            2        100         0.0001           8  0.045095  0.045095   \n",
       "24            2        100         0.0010           4  0.046118  0.046118   \n",
       "25            2        200         0.0001          16  0.046918  0.046918   \n",
       "26            2        100         0.0010           2  0.054815  0.054815   \n",
       "27            4        200         0.0010          16  0.061390  0.061390   \n",
       "28            2        100         0.0010           2  0.064071  0.064071   \n",
       "29            1         50         0.0001           2  0.065503  0.065503   \n",
       "30            2        100         0.0001          16  0.067791  0.067791   \n",
       "31            2        100         0.0001          16  0.067886  0.067886   \n",
       "32            1        100         0.0001           4  0.068037  0.068037   \n",
       "33            1        100         0.0001           4  0.071131  0.071131   \n",
       "34            2         50         0.0001          16  0.077451  0.077451   \n",
       "35            3        100         0.0010           2  0.079667  0.079667   \n",
       "\n",
       "    Elapsed time  \n",
       "0      48.131204  \n",
       "1      47.854057  \n",
       "2      47.822996  \n",
       "3      47.775700  \n",
       "4      47.549170  \n",
       "5      48.499307  \n",
       "6      57.126017  \n",
       "7      49.666379  \n",
       "8      56.410437  \n",
       "9      55.467644  \n",
       "10     30.195639  \n",
       "11     30.185745  \n",
       "12     30.765026  \n",
       "13     47.233993  \n",
       "14     59.640877  \n",
       "15     16.156988  \n",
       "16     30.361097  \n",
       "17     47.827748  \n",
       "18     30.491634  \n",
       "19     30.532361  \n",
       "20     30.035223  \n",
       "21     47.869382  \n",
       "22     17.694095  \n",
       "23     17.540180  \n",
       "24     30.275645  \n",
       "25     11.403792  \n",
       "26     56.059463  \n",
       "27     13.780651  \n",
       "28     57.143001  \n",
       "29     47.591341  \n",
       "30     11.142731  \n",
       "31     10.740663  \n",
       "32     26.356923  \n",
       "33     26.243996  \n",
       "34     10.670144  \n",
       "35     57.236947  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename = \"historial_genetic_jla1.txt\"\n",
    "df = pd.DataFrame(datos, columns = [\"Deep layers\", \"Num units\", \"Learning rate\", \"Batch size\", \"Loss\", \"Score\", \"Elapsed time\"])\n",
    "\n",
    "df.sort_values(by=[\"Loss\"], ascending=[True], ignore_index=True, inplace=True)\n",
    "\n",
    "df.to_csv(filename, header=True, index=False, sep='\\t', mode='w') # a=append, w=overwrite\n",
    "df.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time 22.191 minutes\n"
     ]
    }
   ],
   "source": [
    "total_time = float(np.sum(df[[\"Elapsed time\"]])/60)\n",
    "\n",
    "print(\"Elapsed time {:.3f} minutes\".format(total_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
