{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-18 00:38:55.920936: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-12-18 00:38:56.120782: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-12-18 00:38:56.120843: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2022-12-18 00:38:57.393793: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2022-12-18 00:38:57.393961: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2022-12-18 00:38:57.393974: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import time, os\n",
    "import random\n",
    "import seaborn as sns\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Input, Dense, LeakyReLU\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorboard.plugins.hparams import api as hp\n",
    "\n",
    "from tensorflow.keras import activations\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "import random\n",
    "from math import floor\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import optimizers\n",
    "from scipy.integrate import odeint\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split as split\n",
    "from scipy.stats import bernoulli\n",
    "\n",
    "# import deap\n",
    "from deap import base, creator, tools, algorithms\n",
    "\n",
    "from bitstring import BitArray\n",
    "\n",
    "# from elitism import eaSimpleWithElitism, main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "\n",
    "# tf.config.optimizer.set_jit(True)\n",
    "# scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "url = 'https://raw.githubusercontent.com/igomezv/nnogada/main/data/jla.csv'\n",
    "df=pd.read_csv(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = len(df.values)\n",
    "randomize = np.random.permutation(N)\n",
    "data = df.values[randomize]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(740, 2)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N = len(df.values)\n",
    "z = data[:,0] \n",
    "y = data[:,1:3] ### coge el resto de variables a predecir \n",
    "y[:,1] = y[:,1]**2+data[:,2]\n",
    "np.shape(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "scalerz = StandardScaler()\n",
    "scalerz.fit(z.reshape(-1,1))\n",
    "z = scalerz.transform(z.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((592, 1), (148, 1), (592, 2), (148, 2))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Modificar para incluir phanteon como test\n",
    "split = 0.8\n",
    "ntrain = int(split * len(z))\n",
    "indx = [ntrain]\n",
    "X_train, X_val = np.split(z, indx)\n",
    "Y_train, Y_val = np.split(y, indx)\n",
    "# X_train, X_test = np.split(z, indx)\n",
    "# Y_train, Y_test = np.split(y, indx)\n",
    "np.shape(X_train), np.shape(X_val), Y_train.shape, Y_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "SC_DEEP       = np.array([1,2,3,4])                           # Number of deep layers (8)\n",
    "SC_NUM_UNITS  = np.array([50,100,150,200]) # Number of fully conected neurons (16)\n",
    "SC_LEARNING   = np.array([1e-4,1e-3])   # Learning rates (8)\n",
    "SC_BATCH      = np.array([2, 4, 8, 16])                            # Batch sizes (4)\n",
    "# SC_ACTIVATION = [f1, f2, f3, f4]                                      # Activation function layers (2)\n",
    "\n",
    "my_callbacks = [tf.keras.callbacks.EarlyStopping(\n",
    "                               monitor='val_loss', mode='min',\n",
    "                               min_delta=0, \n",
    "                               patience=200,\n",
    "                               verbose=1,\n",
    "                            #    baseline=0,\n",
    "                               restore_best_weights=True)\n",
    "#                 keras.callbacks.TensorBoard(\n",
    "#                                log_dir='./logs'),\n",
    "#                 keras.callbacks.ReduceLROnPlateau(\n",
    "#                                monitor='val_loss', factor=0.5,\n",
    "#                                patience=6, min_lr=0,\n",
    "#                                verbose=1)\n",
    "               ] \n",
    "    \n",
    "epochs = 200\n",
    "# epochs = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_evaluate(ga_individual_solution):   \n",
    "    t = time.time()\n",
    "    t_total = 0\n",
    "    \n",
    "    # Decode GA solution to integer for window_size and num_units\n",
    "    deep_layers_bits   = BitArray(ga_individual_solution[0:2])     # (8)\n",
    "    num_units_bits     = BitArray(ga_individual_solution[2:4])     # (16)\n",
    "    learning_rate_bits = BitArray(ga_individual_solution[4:5])    # (8)\n",
    "    batch_size_bits    = BitArray(ga_individual_solution[5:7])   # (4)\n",
    "# #     activation_f_bits  = BitArray(ga_individual_solution[12:13])   # (2)   Solo se consideran las 2 primeras\n",
    "    \n",
    "    deep_layers   = SC_DEEP[deep_layers_bits.uint]\n",
    "    num_units     = SC_NUM_UNITS[num_units_bits.uint]\n",
    "    learning_rate = SC_LEARNING[learning_rate_bits.uint]\n",
    "    batch_size   = SC_BATCH[batch_size_bits.uint]\n",
    "#     activation_f  = SC_ACTIVATION[activation_f_bits.uint]\n",
    "\n",
    "    \n",
    "    print('\\n--------------- Starting trial:', population_size*(max_generations+1)-len(ss), \"---------------\")\n",
    "    print('Deep layers:',deep_layers,', Number of neurons:',num_units,\", Learning rate:\",learning_rate)\n",
    "#     print(\"-------------------------------------------------\")\n",
    "    \n",
    "    # Train model and predict on validation set\n",
    "    model = tf.keras.Sequential()\n",
    "#     model.add(Input(shape=(int(X_train.shape[1]),)))\n",
    "    model.add(Dense(int(X_train.shape[1])))\n",
    "    \n",
    "    for i in range(deep_layers):        \n",
    "        model.add(Dense(num_units, activation='relu'))\n",
    "#             model.add(keras.layers.Dropout(0.3))\n",
    "    model.add(Dense(2, activation='linear'))\n",
    "    \n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate, beta_1=0.9, beta_2=0.999, epsilon=1e-3)\n",
    "    model.compile(optimizer=optimizer, loss='mse', metrics=['mean_squared_error'])\n",
    "    model.fit(X_train, Y_train, epochs=epochs, validation_data=(X_val, Y_val),\n",
    "              callbacks=my_callbacks, batch_size=batch_size, shuffle=False, verbose=0)\n",
    "    \n",
    "    loss, score = model.evaluate(X_val, Y_val)    \n",
    "    t = time.time()-t\n",
    "    ss.pop(0)\n",
    "    print(\"Loss:\", score, \", Elapsed time:\", t)\n",
    "    print(\"-------------------------------------------------\\n\")\n",
    "#     print(loss, score)\n",
    "\n",
    "    datos.append([deep_layers, num_units, learning_rate, batch_size, loss, score, t])\n",
    "    \n",
    "    return loss,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deap import tools\n",
    "from deap import algorithms\n",
    "\n",
    "def eaSimpleWithElitism(population, toolbox, cxpb, mutpb, ngen, stats=None,\n",
    "             halloffame=None, verbose=__debug__):\n",
    "    \"\"\"This algorithm is similar to DEAP eaSimple() algorithm, with the modification that\n",
    "    halloffame is used to implement an elitism mechanism. The individuals contained in the\n",
    "    halloffame are directly injected into the next generation and are not subject to the\n",
    "    genetic operators of selection, crossover and mutation.\n",
    "    \"\"\"\n",
    "    logbook = tools.Logbook()\n",
    "    logbook.header = ['gen', 'nevals'] + (stats.fields if stats else [])\n",
    "\n",
    "    # Evaluate the individuals with an invalid fitness\n",
    "    invalid_ind = [ind for ind in population if not ind.fitness.valid]\n",
    "    fitnesses = toolbox.map(toolbox.evaluate, invalid_ind)\n",
    "    for ind, fit in zip(invalid_ind, fitnesses):\n",
    "        ind.fitness.values = fit\n",
    "\n",
    "    if halloffame is None:\n",
    "        raise ValueError(\"halloffame parameter must not be empty!\")\n",
    "\n",
    "    halloffame.update(population)\n",
    "    hof_size = len(halloffame.items) if halloffame.items else 0\n",
    "\n",
    "    record = stats.compile(population) if stats else {}\n",
    "    logbook.record(gen=0, nevals=len(invalid_ind), **record)\n",
    "    if verbose:\n",
    "        print(logbook.stream)\n",
    "\n",
    "    # Begin the generational process\n",
    "    for gen in range(1, ngen + 1):\n",
    "\n",
    "        # Select the next generation individuals\n",
    "        offspring = toolbox.select(population, len(population) - hof_size)\n",
    "\n",
    "        # Vary the pool of individuals\n",
    "        offspring = algorithms.varAnd(offspring, toolbox, cxpb, mutpb)\n",
    "\n",
    "        # Evaluate the individuals with an invalid fitness\n",
    "        invalid_ind = [ind for ind in offspring if not ind.fitness.valid]\n",
    "        fitnesses = toolbox.map(toolbox.evaluate, invalid_ind)\n",
    "        for ind, fit in zip(invalid_ind, fitnesses):\n",
    "            ind.fitness.values = fit\n",
    "\n",
    "        # add the best back to population:\n",
    "        offspring.extend(halloffame.items)\n",
    "\n",
    "        # Update the hall of fame with the generated individuals\n",
    "        halloffame.update(offspring)\n",
    "\n",
    "        # Replace the current population by the offspring\n",
    "        population[:] = offspring\n",
    "\n",
    "        # Append the current generation statistics to the logbook\n",
    "        record = stats.compile(population) if stats else {}\n",
    "        logbook.record(gen=gen, nevals=len(invalid_ind), **record)\n",
    "        if verbose:\n",
    "            print(logbook.stream)\n",
    "\n",
    "    return population, logbook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def geneticAlgorithm_with_elitism(population_size, max_generations, gene_length, k):\n",
    "    \n",
    "    # Genetic Algorithm constants:\n",
    "    P_CROSSOVER = 0.5        # probability for crossover\n",
    "    P_MUTATION = 0.2         # probability for mutating an individual\n",
    "    HALL_OF_FAME_SIZE = 1    # Best individuals that pass to the other generation\n",
    "    \n",
    "    # set the random seed:\n",
    "    toolbox = base.Toolbox()\n",
    "\n",
    "    # As we are trying to minimize the RMSE score, that's why using -1.0. \n",
    "    # In case, when you want to maximize accuracy for instance, use 1.0\n",
    "    creator.create('FitnessMin', base.Fitness, weights = [-1.0])\n",
    "    creator.create('Individual', list , fitness = creator.FitnessMin)\n",
    "\n",
    "    # create the individual operator to fill up an Individual instance:\n",
    "    toolbox.register('binary', bernoulli.rvs, 0.5)\n",
    "    toolbox.register('individual', tools.initRepeat, creator.Individual, toolbox.binary, n = gene_length)\n",
    "\n",
    "    # create the population operator to generate a list of individuals:\n",
    "    toolbox.register('population', tools.initRepeat, list , toolbox.individual)\n",
    "\n",
    "    # genetic operators:\n",
    "    toolbox.register('evaluate', train_evaluate)\n",
    "    toolbox.register('select', tools.selTournament, tournsize = 2)\n",
    "    toolbox.register('mutate', tools.mutFlipBit, indpb = 0.11)\n",
    "    toolbox.register('mate', tools.cxUniform, indpb = 0.5)\n",
    "    \n",
    "    # create initial population (generation 0):\n",
    "    population = toolbox.population(n=population_size)\n",
    "\n",
    "    # prepare the statistics object:\n",
    "    stats = tools.Statistics(lambda ind: ind.fitness.values)\n",
    "    stats.register(\"min\", np.min)\n",
    "    stats.register(\"avg\", np.mean)\n",
    "    stats.register(\"max\", np.max)\n",
    "\n",
    "    # define the hall-of-fame object:\n",
    "    hof = tools.HallOfFame(HALL_OF_FAME_SIZE)\n",
    "\n",
    "    # Genetic Algorithm flow with elitism:\n",
    "    population, logbook = eaSimpleWithElitism(population, toolbox, cxpb=P_CROSSOVER, mutpb=P_MUTATION,\n",
    "                                              ngen=max_generations, stats=stats, halloffame=hof, verbose=True)\n",
    "\n",
    "    # print info for best solution found:\n",
    "    best = hof.items[0]\n",
    "    print(\"-- Best Individual = \", best)\n",
    "    print(\"-- Best Fitness = \", best.fitness.values[0])\n",
    "\n",
    "    # extract statistics:\n",
    "    minFitnessValues, meanFitnessValues, maxFitnessValues = logbook.select(\"min\", \"max\", \"avg\")\n",
    "\n",
    "    # plot statistics:\n",
    "    sns.set_style(\"whitegrid\")\n",
    "    plt.plot(minFitnessValues, color='blue', label=\"Min\")\n",
    "    plt.plot(meanFitnessValues, color='green', label=\"Mean\")\n",
    "    plt.plot(maxFitnessValues, color='red', label=\"Max\")\n",
    "    plt.xlabel('Generation'); plt.ylabel('Max / Min / Average Fitness')\n",
    "    plt.legend()\n",
    "    plt.title('Max, Min and Average fitness over Generations')\n",
    "    plt.show()\n",
    "    \n",
    "    best_population = tools.selBest(population,k = k)\n",
    "    return best_population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------------- Starting trial: 1 ---------------\n",
      "Deep layers: 3 , Number of neurons: 100 , Learning rate: 0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-18 00:38:58.787828: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-18 00:38:58.788207: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-12-18 00:38:58.788308: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory\n",
      "2022-12-18 00:38:58.788379: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory\n",
      "2022-12-18 00:38:58.788450: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcufft.so.10'; dlerror: libcufft.so.10: cannot open shared object file: No such file or directory\n",
      "2022-12-18 00:38:58.788520: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcurand.so.10'; dlerror: libcurand.so.10: cannot open shared object file: No such file or directory\n",
      "2022-12-18 00:38:58.788588: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory\n",
      "2022-12-18 00:38:58.788675: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory\n",
      "2022-12-18 00:38:58.788744: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2022-12-18 00:38:58.788759: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1934] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2022-12-18 00:38:58.789771: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0833 - mean_squared_error: 0.0833\n",
      "Loss: 0.08327122777700424 , Elapsed time: 203.80449151992798\n",
      "-------------------------------------------------\n",
      "\n",
      "\n",
      "--------------- Starting trial: 2 ---------------\n",
      "Deep layers: 2 , Number of neurons: 200 , Learning rate: 0.0001\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.0506 - mean_squared_error: 0.0506\n",
      "Loss: 0.050635408610105515 , Elapsed time: 41.46568489074707\n",
      "-------------------------------------------------\n",
      "\n",
      "\n",
      "--------------- Starting trial: 3 ---------------\n",
      "Deep layers: 4 , Number of neurons: 200 , Learning rate: 0.001\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0417 - mean_squared_error: 0.0417\n",
      "Loss: 0.041745446622371674 , Elapsed time: 83.92974758148193\n",
      "-------------------------------------------------\n",
      "\n",
      "\n",
      "--------------- Starting trial: 4 ---------------\n",
      "Deep layers: 1 , Number of neurons: 100 , Learning rate: 0.0001\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0620 - mean_squared_error: 0.0620\n",
      "Loss: 0.06201022490859032 , Elapsed time: 83.05897855758667\n",
      "-------------------------------------------------\n",
      "\n",
      "\n",
      "--------------- Starting trial: 5 ---------------\n",
      "Deep layers: 2 , Number of neurons: 100 , Learning rate: 0.0001\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0365 - mean_squared_error: 0.0365\n",
      "Loss: 0.03653709962964058 , Elapsed time: 81.94148755073547\n",
      "-------------------------------------------------\n",
      "\n",
      "gen\tnevals\tmin      \tavg      \tmax      \n",
      "0  \t5     \t0.0365371\t0.0548399\t0.0832712\n",
      "\n",
      "--------------- Starting trial: 6 ---------------\n",
      "Deep layers: 2 , Number of neurons: 100 , Learning rate: 0.0001\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0366 - mean_squared_error: 0.0366\n",
      "Loss: 0.036588676273822784 , Elapsed time: 88.52880215644836\n",
      "-------------------------------------------------\n",
      "\n",
      "\n",
      "--------------- Starting trial: 7 ---------------\n",
      "Deep layers: 2 , Number of neurons: 100 , Learning rate: 0.0001\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0385 - mean_squared_error: 0.0385\n",
      "Loss: 0.03849620372056961 , Elapsed time: 143.31467151641846\n",
      "-------------------------------------------------\n",
      "\n",
      "\n",
      "--------------- Starting trial: 8 ---------------\n",
      "Deep layers: 4 , Number of neurons: 100 , Learning rate: 0.001\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0370 - mean_squared_error: 0.0370\n",
      "Loss: 0.03695811703801155 , Elapsed time: 42.6951539516449\n",
      "-------------------------------------------------\n",
      "\n",
      "\n",
      "--------------- Starting trial: 9 ---------------\n",
      "Deep layers: 3 , Number of neurons: 200 , Learning rate: 0.001\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1003 - mean_squared_error: 0.1003\n",
      "Loss: 0.10025513172149658 , Elapsed time: 240.4452452659607\n",
      "-------------------------------------------------\n",
      "\n",
      "1  \t4     \t0.0365371\t0.049767 \t0.100255 \n",
      "\n",
      "--------------- Starting trial: 10 ---------------\n",
      "Deep layers: 2 , Number of neurons: 100 , Learning rate: 0.0001\n",
      "5/5 [==============================] - 1s 4ms/step - loss: 0.0369 - mean_squared_error: 0.0369\n",
      "Loss: 0.03693435341119766 , Elapsed time: 84.03907203674316\n",
      "-------------------------------------------------\n",
      "\n",
      "2  \t1     \t0.0365371\t0.0494444\t0.100255 \n",
      "\n",
      "--------------- Starting trial: 11 ---------------\n",
      "Deep layers: 2 , Number of neurons: 100 , Learning rate: 0.001\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0535 - mean_squared_error: 0.0535\n",
      "Loss: 0.053479794412851334 , Elapsed time: 164.62798047065735\n",
      "-------------------------------------------------\n",
      "\n",
      "\n",
      "--------------- Starting trial: 12 ---------------\n",
      "Deep layers: 3 , Number of neurons: 200 , Learning rate: 0.0001\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0336 - mean_squared_error: 0.0336\n",
      "Loss: 0.03355177119374275 , Elapsed time: 143.69788789749146\n",
      "-------------------------------------------------\n",
      "\n",
      "3  \t2     \t0.0335518\t0.0393286\t0.0534798\n",
      "\n",
      "--------------- Starting trial: 13 ---------------\n",
      "Deep layers: 3 , Number of neurons: 100 , Learning rate: 0.0001\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0332 - mean_squared_error: 0.0332\n",
      "Loss: 0.0331827774643898 , Elapsed time: 98.29569983482361\n",
      "-------------------------------------------------\n",
      "\n",
      "\n",
      "--------------- Starting trial: 14 ---------------\n",
      "Deep layers: 2 , Number of neurons: 200 , Learning rate: 0.0001\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0359 - mean_squared_error: 0.0359\n",
      "Loss: 0.03590302914381027 , Elapsed time: 143.55107045173645\n",
      "-------------------------------------------------\n",
      "\n",
      "\n",
      "--------------- Starting trial: 15 ---------------\n",
      "Deep layers: 3 , Number of neurons: 100 , Learning rate: 0.0001\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0322 - mean_squared_error: 0.0322\n",
      "Loss: 0.03224568068981171 , Elapsed time: 143.7938368320465\n",
      "-------------------------------------------------\n",
      "\n",
      "\n",
      "--------------- Starting trial: 16 ---------------\n",
      "Deep layers: 2 , Number of neurons: 200 , Learning rate: 0.0001\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0355 - mean_squared_error: 0.0355\n",
      "Loss: 0.035484712570905685 , Elapsed time: 143.57014989852905\n",
      "-------------------------------------------------\n",
      "\n",
      "4  \t4     \t0.0322457\t0.0340736\t0.035903 \n",
      "\n",
      "--------------- Starting trial: 17 ---------------\n",
      "Deep layers: 4 , Number of neurons: 50 , Learning rate: 0.001\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0525 - mean_squared_error: 0.0525\n",
      "Loss: 0.052527666091918945 , Elapsed time: 144.14592170715332\n",
      "-------------------------------------------------\n",
      "\n",
      "\n",
      "--------------- Starting trial: 18 ---------------\n",
      "Deep layers: 3 , Number of neurons: 100 , Learning rate: 0.0001\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0319 - mean_squared_error: 0.0319\n",
      "Loss: 0.03189831227064133 , Elapsed time: 145.3899290561676\n",
      "-------------------------------------------------\n",
      "\n",
      "\n",
      "--------------- Starting trial: 19 ---------------\n",
      "Deep layers: 4 , Number of neurons: 200 , Learning rate: 0.0001\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0345 - mean_squared_error: 0.0345\n",
      "Loss: 0.03447838872671127 , Elapsed time: 158.47885394096375\n",
      "-------------------------------------------------\n",
      "\n",
      "\n",
      "--------------- Starting trial: 20 ---------------\n",
      "Deep layers: 1 , Number of neurons: 100 , Learning rate: 0.0001\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0870 - mean_squared_error: 0.0870\n",
      "Loss: 0.08701436221599579 , Elapsed time: 143.59561443328857\n",
      "-------------------------------------------------\n",
      "\n",
      "5  \t4     \t0.0318983\t0.0478203\t0.0870144\n",
      "\n",
      "--------------- Starting trial: 21 ---------------\n",
      "Deep layers: 3 , Number of neurons: 100 , Learning rate: 0.0001\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0319 - mean_squared_error: 0.0319\n",
      "Loss: 0.031893692910671234 , Elapsed time: 143.83611917495728\n",
      "-------------------------------------------------\n",
      "\n",
      "\n",
      "--------------- Starting trial: 22 ---------------\n",
      "Deep layers: 3 , Number of neurons: 100 , Learning rate: 0.0001\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0315 - mean_squared_error: 0.0315\n",
      "Loss: 0.031504690647125244 , Elapsed time: 143.6886851787567\n",
      "-------------------------------------------------\n",
      "\n",
      "6  \t2     \t0.0315047\t0.0331076\t0.0344784\n",
      "\n",
      "--------------- Starting trial: 23 ---------------\n",
      "Deep layers: 3 , Number of neurons: 200 , Learning rate: 0.0001\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0335 - mean_squared_error: 0.0335\n",
      "Loss: 0.033472705632448196 , Elapsed time: 131.90234541893005\n",
      "-------------------------------------------------\n",
      "\n",
      "\n",
      "--------------- Starting trial: 24 ---------------\n",
      "Deep layers: 4 , Number of neurons: 100 , Learning rate: 0.001\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0346 - mean_squared_error: 0.0346\n",
      "Loss: 0.034570276737213135 , Elapsed time: 108.21348977088928\n",
      "-------------------------------------------------\n",
      "\n",
      "7  \t2     \t0.0315047\t0.032847 \t0.0345703\n",
      "\n",
      "--------------- Starting trial: 25 ---------------\n",
      "Deep layers: 3 , Number of neurons: 100 , Learning rate: 0.0001\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0327 - mean_squared_error: 0.0327\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.032700467854738235 , Elapsed time: 96.96986150741577\n",
      "-------------------------------------------------\n",
      "\n",
      "\n",
      "--------------- Starting trial: 26 ---------------\n",
      "Deep layers: 3 , Number of neurons: 100 , Learning rate: 0.0001\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0323 - mean_squared_error: 0.0323\n",
      "Loss: 0.032348986715078354 , Elapsed time: 144.09460377693176\n",
      "-------------------------------------------------\n",
      "\n",
      "\n",
      "--------------- Starting trial: 27 ---------------\n",
      "Deep layers: 3 , Number of neurons: 200 , Learning rate: 0.0001\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0378 - mean_squared_error: 0.0378\n",
      "Loss: 0.037791669368743896 , Elapsed time: 34.01786661148071\n",
      "-------------------------------------------------\n",
      "\n",
      "8  \t3     \t0.0315047\t0.0335057\t0.0377917\n",
      "\n",
      "--------------- Starting trial: 28 ---------------\n",
      "Deep layers: 4 , Number of neurons: 50 , Learning rate: 0.0001\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0340 - mean_squared_error: 0.0340\n",
      "Loss: 0.03404177352786064 , Elapsed time: 203.9195957183838\n",
      "-------------------------------------------------\n",
      "\n",
      "\n",
      "--------------- Starting trial: 29 ---------------\n",
      "Deep layers: 3 , Number of neurons: 100 , Learning rate: 0.0001\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0306 - mean_squared_error: 0.0306\n",
      "Loss: 0.03061508573591709 , Elapsed time: 83.62490439414978\n",
      "-------------------------------------------------\n",
      "\n",
      "9  \t2     \t0.0306151\t0.0336664\t0.0377917\n",
      "\n",
      "--------------- Starting trial: 30 ---------------\n",
      "Deep layers: 3 , Number of neurons: 100 , Learning rate: 0.0001\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0332 - mean_squared_error: 0.0332\n",
      "Loss: 0.033157847821712494 , Elapsed time: 75.54553818702698\n",
      "-------------------------------------------------\n",
      "\n",
      "\n",
      "--------------- Starting trial: 31 ---------------\n",
      "Deep layers: 3 , Number of neurons: 100 , Learning rate: 0.0001\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0321 - mean_squared_error: 0.0321\n",
      "Loss: 0.03206902742385864 , Elapsed time: 74.25961899757385\n",
      "-------------------------------------------------\n",
      "\n",
      "10 \t2     \t0.0306151\t0.031928 \t0.0331828\n",
      "-- Best Individual =  [1, 0, 0, 1, 0, 0, 1]\n",
      "-- Best Fitness =  0.0331827774643898\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEWCAYAAAB8LwAVAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAABnbUlEQVR4nO3dd1hT1xsH8G8ChD0E2USsioATMICASkURFVEUF1atWqvWgVat1baOurCt2latttbWUUfdUMWNVawLFBAHblGGBCsoO4Tk/P64P1KQQAJkAefzPHkgybn3vpeEvLlnsgghBBRFURT1Dra6A6AoiqI0E00QFEVRlFQ0QVAURVFS0QRBURRFSUUTBEVRFCUVTRAURVGUVDRBNFFZWVlwd3eHSCRSdygICAjAlStX1B2GSu3duxe+vr5wd3dHXl4e3N3dkZ6eru6wKCWYPHkyjh49qu4wlIImiDoKCAhAp06dkJubW+XxIUOGwNnZGRkZGUo9/pEjR+Ds7IzIyMgqj587dw7Ozs5YuHAhAMDOzg5JSUnQ0tJSajyKsnHjRjg7OyMlJUXdoTSYUCjEmjVr8PvvvyMpKQktWrRAUlISuFwuAGDhwoX4/vvv1Ryl5rh9+zamTp0KT09P8Hg8DBw4EN9//z3evn2r7tCq2bhxI+bPn1/lsW3btmHo0KFqiki5aIKoB3t7e8TExEjuP3jwAKWlpSo7fqtWrXDixAmUl5dLHouKikLr1q1VFoMiEUIQHR0NMzMzpX0TU+WV1OvXryEQCNCuXTuVHbMxqPx+rZCYmIjx48fDw8MDJ0+exI0bN7Bt2zZoaWnh/v37ao+vuaMJoh6GDBmCqKgoyf2oqCiEhoZWKXPhwgWEhobCw8MD/v7+2Lhxo+S5EydOoE+fPigsLAQAXLx4EX5+ftWuSmrSsmVLtG/fHv/88w8A4M2bN0hKSkJAQICkTEZGBpydnSVv+nHjxuGHH37A6NGj4e7ujkmTJtV4vLdv32Lq1Kno3r07PD09MXXqVGRnZ0uel7WvqKgo9O7dG97e3tiyZYvM87lx4wZycnLwxRdf4MSJEygrKwMAfPTRR9i9e3eVsoMHD8aZM2cAAE+ePMHEiRPh5eWFoKAgnDhxQlJu4cKFWLp0KT7++GO4ubnh+vXrtb4m78b9008/VakaE4vF2Lp1K/r27Qtvb2/Mnj0bb968qXYuz549Q//+/QEAnp6eGD9+PADA2dkZz58/x/79+3Hs2DH89ttvcHd3x7Rp0wAwV6a//fYbQkJC0K1bN8yZMwcCgUCy37///htDhgwBj8fD6NGjq3x4bt26FT179oS7uzuCgoJw9epVAEBKSgqGDRsGDw8P+Pr6VrvqrOzAgQMIDAyEl5cXpk2bBj6fDwBYsmQJvvnmmyplP/nkE2zfvh0AwOfzMWvWLHTv3h0BAQHYtWuXpNzGjRsRERGB+fPnw8PDQ2ry/+677zBs2DBMnToVLVu2BMBc/UZERMDb21tS7tChQxgwYAA8PT3x0UcfITMzU/Kcs7Mz9u3bh379+sHT0xNff/01Kk8QIWvbPXv2oF+/fujXrx8AYOXKlfD394eHhweGDRuGGzduAADi4uLwyy+/4OTJk3B3d8fgwYMBMP8PBw8eBMC8TzZv3ozevXvDx8cHCxYsQEFBAYD//iePHj2K999/v9r/R11eL5UhVJ307t2bXL58mfTr1488fvyYlJeXk169epGMjAzSvn17kp6eTggh5Nq1a+T+/ftEJBKR1NRU4uPjQ86ePSvZz9y5c8nnn39OcnNziZ+fHzl//rxcxz98+DAZPXo0+euvv8js2bMJIYTs3r2bLF68mKxfv558/vnnhBBC0tPTSfv27YlQKCSEEDJ27FjSp08f8vTpU1JSUkLGjh1LvvvuO6nHyM3NJadOnSLFxcWkoKCAzJo1i3zyySeS52vb16NHj4ibmxuJj48nAoGArF69mri6upLLly/XeE6LFi0iERERpKysjHh5eZHTp08TQgg5evQoGTVqlKTco0ePSLdu3YhAICBFRUWkV69e5NChQ0QoFJI7d+4QLy8v8vDhQ0IIIZ9//jnx8PAgN27cICKRiJSWltb6mlTEnZCQQAQCAVmzZg3p0KGDJO7t27eTESNGkJcvXxKBQEAWL15MPv30U6nn8+7fnhBC2rdvT9LS0iSxrV+/vso2vXv3JmFhYSQ7O5vk5eWR/v37k7179xJCCLlz5w7p3r07SU5OJuXl5eTIkSOkd+/eRCAQkCdPnpBevXqR7OxsybGfP39OCCFk5MiR5OjRo4QQQgoLC0lSUpLUeK9cuUK8vLzInTt3iEAgIMuXLydjxowhhBASHx9PevXqRcRiMSGEkDdv3pDOnTuT7OxsIhKJyNChQ8nGjRuJQCAgL168IAEBASQuLo4QQsiGDRtIhw4dyNmzZ4lIJCIlJSVVjltUVERcXFzItWvXpMZV4ezZs6Rv377k8ePHRCgUkp9++qnK+6J9+/ZkypQp5O3btyQzM5N4e3uTixcvyr3thAkTSF5eniS+qKgokpubS4RCIfntt9+Ir68vKS0tlZzTvHnzqsQ3duxYcuDAAUIIIQcPHiR9+/YlL168IIWFhWTGjBlk/vz5ktemffv25MsvvyQlJSUkNTWVdOzYkTx+/LhOr5cq0SuIeqq4irh8+TLatGkDa2vrKs97e3vD2dkZbDYbLi4uCA4ORnx8vOT5pUuX4tq1axg/fjwCAgLQu3fvOh0/MDAQ8fHxKCgoQHR0NIYMGSJzm2HDhuG9996Dnp4e+vfvj9TUVKnlWrRogaCgIOjr68PIyAiffPIJEhIS5NrXqVOn8P7778PT0xMcDgezZ88Gm13z26ykpASnTp1CSEgIdHR0EBQUJPmm2bdvX9y/f1/yje/YsWMIDAwEh8PBhQsXYG9vj7CwMGhra6Njx44ICgrC6dOnJfvu06cPunXrBjabDV1d3Vpfk1OnTqF3797g8XjgcDiIiIgAi8WS7Gv//v349NNPYWNjAw6Hg5kzZ+L06dMKrZYYN24crK2tYWZmht69e0v+pgcOHMCoUaPQtWtXaGlpYejQodDR0UFycjK0tLRQVlaGJ0+eQCgUwsHBAa1atQIAaGtr48WLF8jNzYWhoSHc3NykHvfYsWMICwtDx44dweFwMHfuXCQnJyMjIwM8Hg8sFkvyLfr06dNwc3ODtbU1bt++jdzcXMycORMcDgdcLhcjR46sciXn5uaGvn37gs1mQ09Pr8px8/PzIRaLJVcOAPDtt9+Cx+PBzc0NmzdvBgD8+eefmDJlCtq2bQttbW1MmzYNqampVa4EPv74Y5iYmMDOzg7e3t6SKyx5tp0yZQrMzMwk8Q0ZMgQtWrSAtrY2Jk2ahLKyMjx79kyu1/DYsWOYMGECuFwuDA0NMXfu3GrVwTNnzoSenh5cXFzg4uIiiVXe10uVtNUdQGM1ZMgQjB07FhkZGVI/nG/duoW1a9fi0aNHEAqFKCsrk1Q9AICJiQn69++P7du3Y8OGDXU+vp6eHvz9/bF582bk5eWhW7duiIuLq3UbS0tLye/6+vooLi6WWq6kpASRkZG4dOmSpKGwqKgIIpFI0uhd075ycnJgY2Mjec7AwABmZmY1xnT27Floa2ujV69eAICQkBBMnDgRubm5MDc3h7+/P2JiYjBlyhTExMRgxYoVAIDMzEykpKSAx+NJ9iUSiSSX/QBga2tb5Vi1vSbvxq2vr18l7qysLMyYMaNKsmOz2Xj9+nW1Lwf19e7fNCcnR3LsqKioKtVtQqEQOTk58PLywhdffIGNGzfi8ePH6NGjBxYuXAhra2usWrUKGzZswIABA+Dg4ICZM2dK/SKSk5ODjh07Su4bGhrCzMwMfD4fDg4OGDhwII4fPw5PT08cO3ZM8jfOzMxETk5Otdeg8v3Kf9N3mZiYgM1m49WrV2jbti0AYMGCBViwYAHmz58vaTfKysrC6tWrq1R1EULA5/Nhb28v9W9XVFQk97bvvk9+//13HDx4EDk5OWCxWCgsLEReXl6N51FZTk6OZL8A015ZXl6O169fSx6rnBAr/+/I+3qpEk0Q9WRvbw8HBwdcvHgRq1atqvb8vHnzMHbsWGzbtg26urpYtWpVlTdZamoqDh8+jEGDBmHlypX47bff6hxDaGgoPvzwQ8ycObNB5/Ku33//Hc+ePcOBAwdgaWmJ1NRUhIaGVqnXrYmVlRWePHkiuV9SUiK1rr5CVFQUiouLJf8IhBAIhUIcP34c48ePx6BBg7Bp0yZ4enqitLRUUi9ta2sLT09PSV24PGp7TaysrKp8SywtLa0St42NDVavXo1u3brJfbyaVL4ykYetrS2mTZuGTz75ROrzISEhCAkJQWFhIZYsWYK1a9fiu+++Q+vWrbF+/XqIxWKcOXMGERERuH79OgwMDKpsb2VlVeUbdXFxMd68eSNJfIMGDcKkSZMwZcoUpKSk4KeffpLE5eDgIGkTquu5GhgYoGvXrjh79iy6d+8u8/wrJ395ybNt5Rhv3LiBX3/9FTt27ICTkxPYbDY8PT0l731Zr927f8usrCxoa2vDwsKiSjueNPK+XqpEq5gaYNWqVdi5c6fUF7CoqAimpqbQ1dVFSkoKjh8/LnlOIBDgs88+w6efforIyEjk5ORgz549kufHjRtXrQFVGi8vL2zfvh1jx45VzAlVil1XVxcmJiZ48+YNNm3aJPe2QUFBuHDhAm7cuIGysjJs2LABYrFYalk+n4+rV6/i559/RlRUFKKiohAdHY2PP/5Y0gnA398fWVlZ2LBhAwYOHCj5Bv/+++8jLS0NUVFREAqFEAqFSElJqZKcpJ1XTa9JUFAQzp8/j8TEREnclRNieHg4fvjhB8k/f25uLs6dOyf336UyCwuLOnWHHjFiBP7880/cunULhBAUFxfjwoULKCwsxNOnT3H16lWUlZWBw+FAV1dXcpUXHR2N3NxcsNlsmJiYAIDUbs8hISE4cuQIUlNTUVZWhvXr16NLly5wcHAAAHTo0AHm5ub46quv0KNHD8m+unTpAiMjI2zduhWlpaUQiUR4+PBhnboqz58/H4cPH8bWrVsl37Kzs7Or/H1Gjx6NrVu34tGjRwCAgoICnDx5Uq7913XboqIiaGlpwdzcHOXl5di0aZOkMwnAvHaZmZk1vqcHDRqEnTt3Ij09HUVFRfj+++8xYMAAaGvL/i4u7+ulSjRBNECrVq3QuXNnqc8tXboUGzZsgLu7O3766ScMGDBA8ty6detgbW2NMWPGgMPh4LvvvsOPP/6ItLQ0AMDLly/h4eEh8/gsFgs+Pj61VuHUx4cffgiBQIDu3btj1KhR6Nmzp9zbOjk5YcmSJZg/fz569uwJExOTGqsZoqOj4erqih49esDS0lJyGzduHB48eICHDx+Cw+EgMDAQV65cwaBBgyTbGhkZ4bfffsOJEyfQs2dP9OjRA2vXrpX0gJKmttfEyckJixcvxty5c9GzZ08YGhrC3NwcHA4HACRtRZMmTYK7uztGjhxZ7zEbw4cPx+PHj8Hj8TB9+nSZ5Tt37owVK1Zg+fLl8PT0RL9+/XDkyBEAQFlZGdatWwdvb2/06NEDubm5+PTTTwEAly5dQnBwMNzd3bFq1Sp8//330NXVrbZ/Hx8fzJ49G7NmzUKPHj2Qnp5ebZxGcHBwtddAS0sLW7Zswf3799GnTx90794dX331VZUPVFl4PB527tyJhIQEBAUFgcfjYfLkyfD29pZ88QkMDMTkyZMxd+5ceHh4YNCgQTKrUyvUddsePXqgV69eCAoKQkBAAHR1datUQVVUSXp7e0sd+xAWFobBgwdj7Nix6NOnDzgcDhYvXixXrPK+XqrEIvLUG1Aqk52djdmzZ2P//v3qDqVZKyoqgqenJ06fPi0Z4EZRzQ1NEBT1f+fPn4ePjw8IIVizZg1SUlJw9OjROrcZUFRTQauYKOr/YmNj0bNnT/Ts2RPPnz/H+vXraXKgmjV6BUFRFEVJRa8gKIqiKKma1DiI5OTkerf6CwQCtfcYUDV6zk1fcztfgJ5zfbatadR2k0oQurq6cHV1rde2qamp9d62saLn3PQ1t/MF6DnXZ9ua0ComiqIoSiqaICiKoiipaIKgKIqipGpSbRAURVGyCIVCZGRkqHQVSGUTCoW1tiUAzAzQDg4O0NHRkXu/NEFQFNWsZGRkwNjYGK1bt24yAyFLSkqgr69f4/OEELx+/RoZGRl477335N4vrWKiKKpZKS0thYWFRZNJDvJgsViwsLCo81WTUhNEXFwcgoKCEBgYiK1bt1Z7/smTJxg1ahQ6depUbT0EWdtSFEXVV3NKDhXqc85Kq2ISiURYvnw5tm/fDmtrawwfPhwBAQFo166dpIyZmRm+/PJLxMbG1nnbpuD5m+fYkbwDIiJS+bF12DrobaLe1aooitJsSksQKSkpcHR0lEyVHBwcjNjY2Cof8hYWFrCwsMDFixfrvG1jVy4uR+j+UCRnJ4MF1X+bISCY0XEGerj3UPmxKaq5c3Z2xuDBg/Hdd98BAMrLy9GjRw907doVv/zyC2JjY/HkyRNMmTJFrXEqLUHw+fwqC8VYW1vLvcBKfbcVCAQyW/JrUlpaWu9t6+P3+78jOTsZP/j+gH4O/VR23ApDTw/FzZybKj1nTaDq11ndmtv5ArLPWSgUoqSkRIURVaevr48HDx4gLy8Penp6+Oeff2BpaQmRSISSkhL4+vrC19dX7jgJIXKVlae3U2VKSxDSJomVtw6svts2lqk2nuU9w09HfsJg58GI6BuhlvrQgKcB2JW8C+2d20OLrd5lDVWpuU3D0NzOF5B9zqmpqbX2+FEFFouF999/H9evX0f//v1x9uxZhISE4ObNm9DX18eRI0dw584dLFmyBAsXLoSRkRHu3LmDV69e4bPPPpOsbFdBVi+mCjo6OtX+NrUlDKUlCBsbmyqLdPP5fFhZWSl9W01HCMEnMZ9Ai62FTQM2qa2xzJfriy03tuBOzh10temqlhgoSt127QJ+/12x+5w0CRg/Xna5gQMHYvPmzejduzcePHiAsLAw3Lx5U2rZnJwc7N27F0+fPsUnn3xSLUEoi9J6MXXu3BlpaWlIT09HWVkZYmJiEBAQoPRtNd2fd/7E6SensSpgFbim6lvK0o/rBwC4nH5ZbTFQVHPm4uKCjIwMHD9+HP7+/rWW7du3L9hsNtq1a4d///1XRREq8QpCW1sbS5YsweTJkyESiRAWFgYnJyfs27cPABAeHo5Xr14hLCwMhYWFYLPZ2LlzJ06cOAEjIyOp2zZ2uSW5mH1qNjztPDHDc4ZaY2lt1hqWepa4kn4F0z2nqzUWilKX8ePl+7avLAEBAfj222+xa9cuvHnzpsZyHA5HdUFVotSR1P7+/tUyY3h4uOR3S0tLxMXFyb1tY7fg7ALkluTi7Lizaq/3Z7FYcG/pTq8gKEqNhg8fDmNjYzg7O+P69evqDqcaOpJaRS6kXcBvSb9hns88janzd7dwR9qbNGQVZKk7FIpqlmxsbPDhhx+qO4wa0bmYVKC0vBRTj0/Fe2bvYen7S9UdjoR7S3cAwJX0KxjeYbiao6Go5iMpKanaY97e3vD29gYADBs2DMOGDQMArFmzRua2ykKvIFQg8lIkHr5+iJ8H/QwDHQN1hyPhYuYCPW09XH5Bq5koiqqOJgglu/fqHiL/icQHnT9Av7aqHxBXG44WB172XrQdgqIoqWiCUCIxEWPKsSkw1jXG+qD16g5HKj+uH5Kyk1AsLFZ3KBRFaRiaIJRoW+I2XE6/jLWBa2FlqJkD/Xy5vigXlyMhM0HdoVAUpWFoglCSlwUvseDsArzf+n1McJug7nBq5Mv1BUAHzFEUVR1NEEoy5/QclJaX4pdBv2j03PPm+uZwbemKK+lX1B0KRVEahiYIJTj+8DgO3D2Ar3p9hfYW7dUdjky+XF9cSb8CMRGrOxSKahacnZ3x2WefSe6Xl5eje/fumDp1qhqjqo4mCAUrLCvEjBMz0MGyAxb4LVB3OHLx4/ohrzQP9/+9r+5QKKpZMDAwwKNHjyRLgF6+fBnW1tZqjqo6miAUbMnfS/Di7Qv8GvIrOFrqmT+lrvxaMRP30WomilKdXr164cKFCwCAmJgYBAcHS54rLi7GokWLEBYWhtDQUJw7dw4AkJGRgTFjxmDo0KEYOnQoEhMTAQAJCQkYN24cIiIi0L9/f8ybN0/qsgl1RUdSK9DNrJv48fqPmNZtmqTxtzFwMndCS4OWuJx+GZM9Jqs7HIpSmV23duH3JMXO9z3JfRLGd5U9A2Bt033//PPP6N69OyIjI5Gfn48RI0bA19cXFhYW2L59O3R1dZGWloa5c+fiyJEjAIB79+4hJiYGVlZWCA8Px82bN8Hj8Rp0LjRBKEi5uBwfH/sY1obWiOwbqe5w6oTFYsGX60tHVFOUCtU23fc///yD8+fP4/f/L1YhEAjw8uVLWFlZYfny5bh//z7YbDbS0tIk23Tp0kWyEqeLiwsyMzNpgtAUP177EUnZSTg04hDM9MzUHU6d+XH98NeDv/Cq6BUsDS3VHQ5FqcT4ruPl+ravLLVN971hwwa0adOmymMbN25Ey5YtER0dDbFYjC5dukieqzwluJaWFkQiUYPjo20QCpD2Jg1LLixBSPsQDHMdpu5w6qViASHaDkFRqjN8+HBMnz4dzs7OVR7v0aMHdu/eLWlHuHfvHgCgoKAAlpaWYLPZiI6OVkgSqA1NEA1UsYQom8XGTwN/0ugxD7XpZtcNHC0OHTBHUSpU03Tf06dPR3l5OQYPHoxBgwbhxx9/BACMGTMGR48exciRI5GWlgYDA+VO/kmrmBpo/939OPX4FH4I+kGtS4g2lJ62HrrZdqNXEBSlArKm+9bT08Py5curlWndujWOHTsmuT9v3jwAgKenJ3r16iV5fMmSJQqJk15BNEDFEqI8Ox5mes1UdzgN5sf1w42sGxCUC9QdCkVRGoAmiAb4/OzneF38Gr+G/Kr2JUQVwZfrC4FIgJsvb6o7FIqiNIBSE0RcXByCgoIQGBiIrVu3VnueEIKVK1ciMDAQISEhuHv3ruS5nTt3YtCgQQgODsaOHTuUGWa9xD2Pw7akbZjrMxduNm7qDkchKsZu0GomiqIAJSYIkUiE5cuXY9u2bYiJicHx48fx+PHjKmXi4uKQlpaGM2fOYMWKFVi2bBkA4OHDhzh48CAOHjyI6OhoXLhwoUp/X3UTlAsw5dgUZglRf81ZQrShrI2s0c68HW2opigKgBITREpKChwdHcHlcsHhcBAcHIzY2NgqZWJjYxEaGgoWiwU3Nzfk5+cjJycHT548QdeuXaGvrw9tbW14enri7Nmzygq1ziL/icSD1w+wJXgLDDmG6g5HoSoGzClimD5FUY2b0nox8fl8yag+ALC2tkZKSkqtZWxsbMDn89G+fXv88MMPyMvLg56eHuLi4tCpUyeZxxQIBEhNTa1XvKWlpXJt+yT/CVZdWoXgVsFoJWxV7+NpAmnn3Ea7DV4Vv8LphNNwNHZUU2TKI+/r3FQ0t/MFZJ+zUChESUmJCiNSPkKIXOckFArr9H5QWoKQ9g303TECNZVp27YtJk+ejEmTJsHAwADOzs7Q0pLdCKyrqwtXV9d6xZuamipzWzERY+qOqTDmGOP3kb9r7Cpx8pJ2zsMthmPZzWXgc/jo79pfTZEpjzyvc1PS3M4XkH3Oqamp0NfXV2FE1Tk7O2Pw4MH47rvvADDTfffo0QNdu3bFL7/8Uuf9lZSUyHVOOjo61f42tSUMpVUx2djYIDs7W3Kfz+fDysqq1jLZ2dmSMiNGjMDRo0exZ88emJmZwdFR/d9mf0v8DZdeXMK6fusafXKoiaulK8z0zGg7BEUpUZOc7lssFqOwsFCusp07d0ZaWhrS09NRVlaGmJgYBAQEVCkTEBCAqKgoEEKQnJwMY2NjSYJ4/fo1ACArKwtnzpzBoEGD6hKqwmUXZmPBOc1fQrSh2Cw2fBx8aIKgKCWrbbrvlJQUjB49GqGhoRg9ejSePn0KANi+fTsWLVoEAHjw4AEGDRqk1OoymVVM8+bNw9dffw02m41hw4ahsLAQEyZMwOTJtU8Lra2tjSVLlmDy5MkQiUQICwuDk5MT9u3bBwAIDw+Hv78/Ll68iMDAQOjr62P16tWS7WfNmoU3b95AW1sbS5cuhampaQNPtWHmnJqDEmGJxi8hqgh+XD+cfHwSeSV5aKHfQt3hUJTy7NoF/K7Y6b4xaRIwvmHTfbdp0wa7d++GtrY2rly5gu+//x4bN27Ehx9+iHHjxuHs2bPYsmULvv76a+jr6ystSchMEI8fP4aRkRH++usv+Pv7Y/78+Rg2bJjMBAEA/v7+1aaxDQ8Pl/zOYrGwdKn0bqJ79+6VuX9VOfHoBPbf3Y8VvVc0iiVEG6piPMTVjKsY6DRQzdFQVNNU23TfBQUF+Pzzz/H8+XOwWCwIhUIAAJvNxpo1azB48GCMGjUK3bp1U2qMMhNEeXk5hEIhzp07h7Fjx0JHR6fJf4OurLCsENNjpjeqJUQbysveC1osLVx+cZkmCKppGz9erm/7ylLTdN8//vgjvL298dNPPyEjIwPjK8VYMUlfTk6O0uOT2QYxatQoBAQEoKSkBJ6ensjMzISRkZHSA9MUS/9eiudvn2ProK2NZgnRhjLkGMLd1h1XMuiIaopSppqm+y4oKJA0Wh89erTK46tWrcLu3bvx5s0bnDp1SqnxyUwQ48ePx6VLl/Drr7+CxWLB3t4eu3btUmpQmuJm1k38cP0HTO02VbJuc3Ph6+CL6xnXIRQJ1R1Kozfv9Dws+Vsxs2tSTUtN031PnjwZ69evx+jRo6us+bB69WqMGTMG7733HlatWoV169ZJOvQoBZFhx44dpKCggIjFYrJo0SISGhpKLl26JGsztbh3757CthWKhMTjFw9is9aG5JXkNTAyzVTb32v/nf0Ey0DiM+JVGJHyNeQ9Uh9isZiYrTEjrb5vpdLjVlD1+WoCWefcFP8mxcXFcpWTdu61/T1kXkEcPnwYRkZG+Oeff5Cbm4vIyEisW7dOeRlLQ2y4vgGJLxOxccDGRrmEaEPRifsU43HuY7wpfYMXb18gp0j5dcYUpUgyEwT5/2jnixcvIiwsDC4uLk1+np60N2lY/PdiDGo/CGGuYeoORy0cTBzQyrQVHQ/RQPGZ8ZLfb2bRadSpxkVmgujUqRMmTZqEuLg49OjRA4WFhWCzm+4yEoQQTI+ZDhZYjXoJUUXw4/rhcjqduK8hErISoKetBxZYuJF1Q93hUP/XHN/T9Tlnmd1cV61ahdTUVHC5XOjr6yMvL6/KgLam5sDdAzj5+CR+CPoBrUxbqTsctfLj+mHfnX148fYFHM3UP9VJYxSfGQ9PO0+8Kn6FhKwEdYdDgVnO8/Xr17CwsGg2XwAJIXj9+jX09PTqtJ3MBMFisfD48WP8/fffmDlzJkpKSlBWVlbvQDVZXklek1pCtKEqem5dTr9ME0Q9CEVCJGUnYTpvOnKKcxD7NFb2RpTSOTg4ICMjA69evVJ3KAojFAqho6NTaxk9PT04ODjUab8yE8SyZcvAZrNx7do1zJw5E4aGhpg1axYOHz5cpwM1Bp+f+xz/Fv+Lkx+cbBJLiDZUJ6tOMOIY4fKLyxjTeYy6w2l07uTcQWl5KbzsvcAv4mN3ym5kFWTBzthO3aE1azo6OnjvvffUHYZCKWvWXpmNCSkpKVi6dCl0dXUBAKamppJh303JjVc38Gvir5jrMxfutu7qDkcjaLO10d2hOx0wV08VDdRe9l7g2fEAgLZDUI2KzAShra0NkUgkqavLzc1tco3UgnIBlt1YhtZmrZvUEqKK4Mf1Qwo/BQWCAnWH0ujEZ8bDQt8Crc1aw83GDWwWGwmZtB2CajxkftKPGzcOM2bMwOvXr/H9998jPDwcU6dOVUVsKrPmnzV4WvC0SS4h2lC+XF+IiRjXMq6pO5RGJz4rHl72XmCxWDDQMUBHy4648ZJeQVCNh8w2iMGDB6Njx464du0aCCHYvHkz2rZtq4rYVObgvYMY7DgY/ds1vRXUGqq7Q3ewWWxcSb+CwLaB6g6n0SgsK8S9V/eqjKPxtPPEXw//AiGk2fSeoRo3uZYcbd26NYyMjCRzgmRlZcHOruk0tF2aeAlZz7LUHYZGMtE1QWerznTAXB0lvkyEmIjhZe8leYxnx8Pvyb/TbsNUoyEzQfzxxx/YtGkTWrZsWaXt4dixY0oNTJVa6LdANitbdsFmypfri90puyESi2jvLjlVNFB72nlKHqtoqE7ISqAJgmoUZCaIXbt24dSpU2jRgq4s1lz5cf2w5cYW3Mm5g642XdUdTqOQkJWA1matYWloKXmsi3UX6LB1cCPrBoZ3GK7G6ChKPjIbqW1sbGBsbKyKWCgNVXnAHCWf+Mz4KtVLAKCrrYsu1l1oV1eq0ZB5BcHlcjFu3Di8//774HD+WzBn4sSJSg2M0hyOpo6wNbLF5fTLmO45Xd3haLycohykvUnDDM8Z1Z7j2fHw550/aUM11SjIvIKws7ODn58fhEIhioqKJDeq+WCxWPBr5Uen/pZTxViHd68gACZBvBW8xePcx6oOi6LqTOYVRNu2bTFgwIAqj508eVKuncfFxWHVqlUQi8UYMWIEpkyZUuV5QghWrVqFixcvQk9PD2vWrEHHjh0BADt27MDBgwfBYrHQvn17REZGSkZzU6rnx/XDoXuH6FQRckjISgCbxYaHrUe15yqPqHaycFJ1aBRVJzKvILZu3SrXY+8SiURYvnw5tm3bhpiYGBw/fhyPH1f91hQXF4e0tDScOXMGK1aswLJlywAAfD4fu3btwuHDh3H8+HGIRCLExMTIeUqUMlQsIHT5BW2HkCU+Mx4dLDvAiFN97faOlh2hp61H2yGoRqHGK4iLFy8iLi4OfD4fK1eulDxeWFgILS3ZXR1TUlLg6OgILpcLAAgODkZsbCzatWsnKRMbG4vQ0FCwWCy4ubkhPz8fOTnMqlsikQilpaXQ1tZGaWkprKys6n2SVMO527hDX1sfV9KvYETHEeoOR2MRQhCfGY8hzkOkPq+jpQM3Gzc6oppqFGpMENbW1ujUqRPOnz8vqfYBAENDQyxatEjmjvl8PmxsbKrsLyUlpdYyNjY24PP56Ny5MyZNmoTevXtDV1cXfn5+6NGjh8xjCgQCpKamyiwnTWlpab23bazqes6dWnRC7KNYpDo23r+Tsl/njMIMvC55Da4Wt8bjtNFrg6NpR3Hn7h2ljyuh7+vmQVnnXGOCcHFxgYuLC0JCQqCtLdeA6yqkrV70bq+Nmsq8ffsWsbGxiI2NhbGxMWbPno3o6GgMGSL9W1kFXV3dek95q6zpcjVZXc+5b1ZffHflOzi2c4SBjoESI1MeZb/OKXeYL0FDug2Bq6304/QT9MPex3vBtmLD1VK57zn6vm4eGnLOtSWWGtsgZs+eDQAYOnQoQkJCqt1ksbGxQXb2f6OT+Xx+tWqid8tkZ2fDysoKV65cgYODA8zNzaGjo4N+/fohKSlJ5jEp5fLj+qFcXF5lnWWqqvjMeOhp66GTVacay3jaM6OraTsEpelqvDRYuHAhAODnn3+u1447d+6MtLQ0pKenw9raGjExMVi3bl2VMgEBAdi9ezeCg4Nx69YtGBsbw8rKCnZ2drh16xZKSkqgp6eHq1evolOnmv/hKNXw4foAAK6kX8H7rd9XbzAaKj4rHu427tDRqnl1L2cLZxjqGOJG1g2M7zpehdFRVN3UmCCmT5+Oo0ePwt7eHitWrMDixYvrtmNtbSxZsgSTJ0+GSCRCWFgYnJycsG/fPgBAeHg4/P39cfHiRQQGBkJfX1+y1nXXrl0RFBSEoUOHQltbG66urhg1alQDTpNSBHN9c7i2dKUjqmtQLi5H4stEfOzxca3ltNha8LD1oGtUUxqvxgRRuX0gMTGxXjv39/eHv79/lcfCw8Mlv7NYLCxdKn2BnoiICERERNTruJTy+HH9cCj1EMREDDaraS0c1VD3Xt1DsbC4ygR9NeHZ8bDlxhYIRcJarzYoSp1q/A+n0wBQ0vi18sOb0je4/+99dYeicSovMSqLp50nSstLce/VPWWHRVH1VuMVxNOnTyWN0S9evKjWMN2Upvum5Fd5wFwHyw5qjkazJGQmwEzPDO3M28ksW3lENZ0hl9JUNSaIEydOqDIOqpFwMneCpYElLqdfxsfdaq9rb27is+Lhaecp19V3W/O2MNU1RUJWAj7y+EgF0VFU3dWYIOzt7VUZB9VIsFgs+HJ96cR97ygWFuM2/zYW9lgoV3k2i41udt1oV1dKo9FWRqrO/Lh+eJT7CDlFOeoORWMkZydDRERytT9U8LTzRAo/BYJygRIjo6j6owmCqrOKdgh6FfEfaUuMysKz40EoFuJ2zm1lhUVRDSJXgigtLcXTp0+VHQvVSHSz6waOFocmiEriM+PhYOIAW2NbubeRrFGdScdDUJpJZoI4f/48hgwZgsmTJwNg5u2YNm2a0gOjNJeeth54djw6YK4SaUuMyuJo6ggLfQvaDkFpLJkJYtOmTTh06BBMTEwAAK6ursjMzFR6YJRm83XwxY2sGygtL1V3KGqXW5KLJ3lP4GVXtwTBYrHgae9Jp/6mNJbMBKGlpQVjY2NVxEI1In6t/FAmKkPiy/qNsm9KKqqIKibhqwueLQ93c+6iWFis6LAoqsFkJggnJyccO3YMIpEIaWlpWLFiBdzd3VURG6XB6Apz/4nPjAcLLHSz7VbnbXl2PIiICMnZyYoPjKIaSGaCWLx4MR4/fgwOh4O5c+fCyMgIX375pSpiozSYlaEV2pm3o+0QYNagdmnpAlM90zpvW3lENUVpGpkrAenr6+PTTz/Fp59+qop4qEbEj+uHE49OgBDSbOfuqlhitH+7/vXa3t7EHrZGtjRBUBpJZoKQ1mPJ2NgYnTp1wujRo6Grq6uUwCjN58f1w85bO/E49zGcLJzUHY5apOeng1/Er9P4h3fx7Hg0QVAaSWYVk4ODAwwNDTFy5EiMHDkSRkZGaNmyJdLS0vDVV1+pIkZKQ0naIZpxNVNdZnCtCc+Oh/v/3keBoEBRYVGUQsi8gkhNTcWePXsk9wMCAvDBBx9gz549CA4OVmpwlGZztXSFmZ4ZrqRfwQS3CeoORy0SMhPA0eKgi3WXeu+DZ8cDAUHiy0T4t/aXvQFFqYjMK4jc3FxkZWVJ7mdlZSEvLw8AoKNDFzppztgsNny5vs37CiIrHl2tu0JXu/5VrbShmtJUMq8gFi5ciDFjxoDL5QIAMjIysHTpUhQXFyM0NFTZ8VEaztfBFycenUBuSS7M9c3VHY5KicQi3Mi6gQ+7ftig/VgZWqGVaSs6YI7SODIThL+/P86cOYOnT5+CEII2bdpIGqYnTJig7PgoDefXyg8AcC3jGgY6DVRzNKr14PUDFJYVNqj9oQLPjkfnZKI0jlyT9aWlpeHp06d48OABTp48iaioKLl2HhcXh6CgIAQGBmLr1q3VnieEYOXKlQgMDERISAju3r0LgFnNbsiQIZKbh4cHduzYIfdJUarjZe8FLZZWsxwwV58ZXGvCs+XhSd4T5JXkNXhfFKUoMq8gNm3ahOvXr+PJkyfw9/dHXFwcunXrJrN6SSQSYfny5di+fTusra0xfPhwBAQEoF27/5ZjjIuLQ1paGs6cOYNbt25h2bJlOHjwINq0aYPo6GjJfnr16oXAwMCGnSmlFAY6BnC3dW+W7RDxmfEw5hjDuaVzg/dVMU3HzZc30bdN3wbvj6IUQeYVxOnTp7Fz5060bNkSkZGRiI6ORllZmcwdp6SkwNHREVwuFxwOB8HBwYiNja1SJjY2FqGhoWCxWHBzc0N+fj5ycqouQnP16lVwuVy6wp0G8+P6IT4zHkKRUN2hqFR8Zjw87T3BZjV8WZWKaTpoQzWlSWReQejq6oLNZkNbWxuFhYWwsLBAenq6zB3z+XzY2NhI7ltbWyMlJaXWMjY2NuDz+bCyspI8FhMTg0GDBsl1MgKBAKmpqXKVfVdpaWm9t22sFHXOjmxHlJSX4Oi1o+hs3lkBkSmPos5ZIBLgFv8WJrSfoLD3DdeIi/P3z2OIxRCF7A+g7+vmQlnnLDNBdOrUCfn5+RgxYgSGDRsGAwMDdOkiu883IaTaY+9OxyCrTFlZGc6fP4958+bJPB7AJDNXV1e5yr4rNTW13ts2Voo6ZxN7E8y9OhdZWlkY6TpSAZEpj6LO+XrGdZSLyzGgywCFvW987/riasZVhb4P6fu6eWjIOdeWWGpNEIQQTJ06FSYmJggPD0fPnj1RWFgIFxcXmQe1sbFBdna25P67VwbSymRnZ1cpExcXh44dO6Jly5Yyj0epj72JPRxNHXEl/QrmdJ+j7nBUQhEjqN/laeeJ/Xf3I6coB1aGVrI3oCglq7XylMViYcaMGZL7Dg4OciUHAOjcuTPS0tKQnp6OsrIyxMTEICAgoEqZgIAAREVFgRCC5ORkGBsbV6teoqO1Gwe/Vn64nH5Z6lVhU5SQlQBbI1vYGyuubaxiwNzNrJsK2ydFNYTM1rWuXbtWazuQh7a2NpYsWYLJkydj4MCBGDBgAJycnLBv3z7s27cPADPGgsvlIjAwEIsXL8bSpUsl25eUlODKlSvo169fnY9NqZ6vgy+yCrLw/O1zdYeiEhUN1Iqcxdbd1h0ssJCQRcdDUJpBZhvE9evX8eeff8Le3h76+vqSx48dOyZz5/7+/vD3rzq3THh4uOR3FotVJSlUpq+vj+vXr8s8BqUZKgbMXX5xGa3NWqs3GCV7U/oGD14/wLgu4xS6XxNdEzi3dKY9mSiNITNB/Prrr6qIg2rkOlt1hjHHGFfSr+CDLh+oOxylqvgAV2T7QwVPO0+ce3pO4fulqPqQWcVkb2+Ply9f4tq1a5KrCLFYrIrYqEZEi62F7g7dm8WAuYopMSraDBSJZ8fDy8KXyCrIkl2YopRMZoLYtGkTtm3bJpkqQygU4rPPPlN6YFTj48v1xe2c28gX5Ks7FKWKz4qHk7kTWui3UPi+K5IOnZeJ0gQyE8TZs2exZcsWSfuDtbU1ioqKlB4Y1fj4cf0gJmJcz2jabUfxmfFKqV4CADcbN2ixtGg7BKURZCYIHR0dsFgsSW+N4uJipQdFNU7eDt5gs9hNupopMz8TWQVZSksQBjoG6GjVkU79TWkEmQliwIABWLJkCfLz83HgwAFMnDgRI0dq9mhZSj1MdE3Q2apzk04QFV1QFTGDa014tswa1c1lTAmluWQmiI8++ghBQUHo168fnj17hoiICIwbp9jufVTT4cf1w7WMaxCJReoORSniM+OhzdaGm42b0o7Bs+Ph3+J/m82YEkpzyezmumPHDvTv3x9+fn6qiIdq5Pxa+WHzjc24nXNbqR+i6hKfGY8u1l2gr6Mvu3A9VV6CtKmPKaE0m8wriMLCQnz00UcYM2YM9uzZg3///VcVcVGNlC/XFwCa5AJCYiLGjawbSq1eAoAu1l2gw9ahDdWU2slMEDNnzkRMTAyWLFmCnJwcjB07li41StXI0dQRdsZ2uJJxRd2hKNyj14/wVvBWaQ3UFXS1ddHFugtNEJTayb3SiYWFBVq2bAkzMzO8fv1amTFRjRiLxYIf169JXkEoYwbXmvDsmIZqMaGDUin1kZkg9u7di3HjxmHChAnIy8vDypUr5ZqHiWq+fLm+eP72OTLzM9UdikIlZCXAUMcQri2Vv9YAz46Ht4K3eJL7ROnHoqiayEwQWVlZ+OKLLxATE4OIiAhwuVycPHlSFbFRjZQfl+nQcCW9aVUzxWfGo5tdN2ixtZR+rIp2DlrNRKmTzAQxf/58tG/fHhcvXsSCBQvQu3dvmiCoWrnZuEFfW79JjYcoE5UhKTsJXnbKr14CgA6WHaCnrUcTBKVWtXZzTUhIwLFjx3Dx4kV06dIFiYmJiI2NrTLtN0W9S0dLB172Xk0qQaTwU1AmKlNJ+wPA/A3dbNzo2hCUWtV4BdGrVy+sW7cOHh4eiImJwcaNG6Grq0uTAyUXP64fkl4moaisaczbVTF5nqe9cru4Vsaz5SHxZWKTHXRIab4aE0S/fv3A5/Nx8uRJ/P333yguLlbo6llU0+bXyg8iImoy34Djs+JhaWAJR1NHlR3T094TRcIiPHj9QGXHpKjKakwQX331Fc6fP48JEybg+vXrCAoKQm5uLk6cOEFnc6Vk6u7QHUDTGTBXMYOrKr8kVR5RTVHqUGsjNYvFgo+PD1auXInz589j3bp1iI2NRUBAgKrioxopc31zdLDs0CQGzBUICpD6KlXpI6jf5WzhDEMdQ7o2BKU2cg+U09HRQUBAANatW4eLFy/KtU1cXByCgoIQGBgoWXCoMkIIVq5cicDAQISEhODu3buS5/Lz8xEREYH+/ftjwIABSEpKkjdUSkP4cf1wJf1Kox/sdfPlTRAQlTVQV9Bia8HD1oNO/U2pjdwJojI9PT2ZZUQiEZYvX45t27YhJiYGx48fx+PHj6uUiYuLQ1paGs6cOYMVK1Zg2bJlkudWrVqFnj174tSpU4iOjkbbtm3rEyqlRr5cX7wpfYPUV6nqDqVBKkZQq7KBuoKnnSeSs5MhFAlVfmyKqleCkEdKSgocHR3B5XLB4XAQHByM2NjYKmViY2MRGhoKFosFNzc35OfnIycnB4WFhUhISMDw4cMBABwOByYmJsoKlVKSpjJgLj4zHm1atEFLg5YqPzbPjofS8lLce3VP5cemqBoTxC+//IJ79+r/puTz+bCxsZHct7a2Bp/Pr7WMjY0N+Hw+0tPTYW5ujkWLFiE0NBRffvklXcmuEWpn3g6WBpaNfjxEQlaCytsfKkjWqG4ivcGoxqXGgXIODg7YtWsX7t+/DxcXF/Tq1Qt+fn4wNTWVa8fSVsN6twdITWXKy8tx7949LF68GF27dsXKlSuxdetWzJkzp9ZjCgQCpKbWrzqjtLS03ts2Vqo4585mnfH3k7815m9b13N+VfIKL96+wOjWo9VyDmIihrGOMc7ePQs//bqvyULf182Dss65xgQRHByM4OBgAMC9e/dw6dIlzJw5E2KxGD4+PujVqxe6dOlS445tbGyQnZ0tuc/n82FlZVVrmezsbFhZWYHFYsHGxgZdu3YFAPTv319qI/e7dHV14epav4nUUlNT671tY6WKc+6f2x8Lzi2ARSsLWBlayd5Ayep6zo8fMO1mIR4hcG2lnveH1w0vPCl5Uq/Xir6vm4eGnHNtiUWuNogOHTpg6tSp+OOPP/DLL7/AyckJBw8erHWbzp07Iy0tDenp6SgrK0NMTEy17rEBAQGIiooCIQTJyckwNjaGlZUVLC0tYWNjg6dPnwIArl69ShupGym/Vo27HSIhKwFsFhvuNu5qi4Fnx0MKPwWCcoHaYqCaJ5lLjr7LyMgIQUFBCAoKqn3H2tpYsmQJJk+eDJFIhLCwMDg5OWHfvn0AgPDwcPj7++PixYsIDAyEvr4+Vq9eLdl+8eLFmD9/PoRCIbhcLiIjI+saKqUButl2A0eLg8svLiPUJVTd4dRZfGY8Oll1giHHUG0x8Ox4EIqFSOGnqKUnFdV81TlB1IW/vz/8/f2rPBYeHi75ncViYenSpVK3dXV1xZEjR5QZHqUCutq64NnxGmVDNSEE8ZnxCHMNU2sclUdU0wRBqZLSurlSVAU/rh9uvryJ0vJSdYdSJ0/yniCvNE/tH8qOpo5oadCSTrlBqZxcCYLP5yMxMREJCQmSG0XJy4/rhzJRGW5m3VR3KHVSMcWFqkdQv4vFYjFLkNIR1ZSKyaxi+u6773Dy5Em0bdsWWlr/raTl6UkvdSn5+HB9AACX0y9LGq0bg/jMeOhr66OjZUd1hwKeLQ+RTyJRLCyGgY6BusOhmgmZCeLcuXM4deoUOByOKuKhmiArQys4mTs1up5M8Vnx8LD1gI6WjrpDAc+OBxERITk7Gb5cX3WHQzUTMquYuFwuhEI6DwzVMH6tmIn7pA2O1ERCkRBJL5PUNoL6XRXtILQdglIlmVcQ+vr6CA0NhY+PT5WriK+++kqpgVFNi6+DL3Yk78Cj3Edob9Fe3eHIdPfVXZSUl6i9/aGCnbEdbI1saYKgVEpmgggICKDrP1ANVnnAXGNIEBUzuGpKggCYaiY6JxOlSjITxNChQ1URB9XEubR0QQu9Frj84jImuE1QdzgyxWfGw1zfHG1atFF3KBI8Ox6OPzyOfEE+THTp7MaU8tWYIGbPno0ff/wRISEhUp8/duyY0oJSuT/+gPGrV0D79kClnlqU4rBZbPhwfRrNgLmKGVw1aR12TztPEBAkvUyCf2t/2RtQVAPVmCC+/PJLAMDPP/+ssmDUZt8+OJw8CWzeDCxYAHz4IaCrq+6omhw/rh9OPDqB3JJcmOubqzucGhWVFeFOzh0McR6i7lCq6GbXDQDTUE0TBKUKNfZiqph51d7eXuqtSTl+HBk//gi0aAFMnQq89x6wbh1QUKDuyJqUigWErqZfVXMktUt8mQgxEWtU+wPAdBduZdqKtkNQKlPjFYS7u3uVy2tCCFgsluRnYmKiSgJUCTYbBYGBwKxZQGwsEBkJzJ8PrFrFPBYRAVhYqDvKRs/T3hPabG1cTr+M4PbB6g6nRhUfwJrSxbUynh2P9mSiVKbGBOHj44N///0XgYGBCA4Ohp2dnSrjUg8WC+jbl7nFxzOJYvlyYO1aYMoUYN48wMFB3VE2WgY6BnC3cUfc8zh1h1Kr+Mx4tDJtBWsja3WHUo2nnSeOpB5BXkkeWui3UHc4VBNXYxXT5s2b8dtvv8Hc3ByLFy/G2LFjsWfPHrx580aF4amRlxdw9Chw9y4wfDiwcSPQpg3w0UfAw4fqjq7RCnMNw+X0yzj9+LS6Q6lRfGa8xlUvVaiY2fXmy8Y1rxXVONU6ktrY2BhhYWH49ddfMXr0aGzYsAFHjx5VVWyaoUMHYOdO4PFj5ipi717AxQUYMQJoStVsKjKn+xw4mTth5smZGjm767/F/+LZm2caWb0EMOtrAP9NJEhRylRrgkhMTMSKFSswdOhQJCYm4qeffsLEiRNVFZtmad0a2LQJSEsDFi4EzpwBunUDgoKAixeBRjKFhLrpautic/BmPM59jG8vf6vucKrRlBlca9JCvwXatmhLZ3alVKLGBBEQEICvv/4a1tbWWLFiBcLCwqCvr4+7d+/i7t27qoxRs1hbA6tXAy9eMG0UycnA++8Dfn7AsWOAWKzuCDVe3zZ9MbrTaKy+tBpPcp+oO5wq4jPjwQJL8k1dE3nae9KGakolamykrujKeunSJfzzzz9VJlljsVjYtWuX8qPTZKamzJXE7NnA9u3Ad98BgwcDnToxj48aBWgrdcG+Rm1dv3WIeRiDmSdn4sSYExozIC0+Kx6ulq4w1jVWdyg14tny8OedP5FTlAMrQyt1h0M1YTV+gv3xxx+qjKPx0tcHpk8HPv4Y2L8fWLMGGDsWWLwY+OwzYOJEQE9P3VFqHDtjO6zovQJzTs/BkdQjCOug3mU9AaYrd0JmgkZ3wQWqLkE60GmgmqOhmjK65Kii6OgwiSElBYiOBqysmMTRujXwzTdAfr66I9Q4M7xmoKt1V8w+NRsFAvUPSnz+9jleFb+Cl51mtj9U8LD1AAssWs1EKZ1SE0RcXByCgoIQGBiIrVu3VnueEIKVK1ciMDAQISEhVdo2AgICEBISgiFDhmDYsGHKDFOx2GymqunqVeD8eaBLF6bKqVUr4KuvgFev1B2hxtBma2NL8BZkFmRi+cXl6g5HI2dwlcZY1xguLV1ogqCUrsYEUV5e3qAdi0QiLF++HNu2bUNMTAyOHz+Ox48fVykTFxeHtLQ0nDlzBitWrMCyZcuqPL9z505ER0fjyJEjDYpFLVgsoHdvprdTQgIz+G71asDRkRmZ/eKFuiPUCD5cH3zs8TG+v/Y97uTcUWssCZkJ4Ghx0Nm6s1rjkAcdUU2pQo0JYuTIkZg+fTr27duHjIyMOu84JSUFjo6O4HK54HA4CA4ORmxsbJUysbGxCA0NBYvFgpubG/Lz85GTk1P3s9B0PB5w6BBw7x4wejSwZQvQti0wYQJw+TKQmgo8fQpkZQG5uUBxMSASqTtqlYnsEwkzPTN8EvOJWleci8+Kh7uNOzhamr+8Ls+Oh5eFL5GZn6nuUKgmrMZG6iNHjiAzMxNxcXFYvXo1+Hw+unXrhl69esHLy0vmGtV8Ph82NjaS+9bW1khJSam1jI2NDfh8vmSiwI8++ggsFgujRo3CqFGjZJ6MQCBAamqqzHLSlJaW1nvbOvnsM2iPHQuLHTtgtn8/2Dt31liUaGtDzOGAcDggurrMTw4HYl1d6fd1dEB0dZn772wneazivqEhBJ07q+ac5TCn4xwsvrEYkScjMfQ95a1BUtPrXC4uR0JGAoa9N0xj/ia1aVnWEgBwNP4o+tj3qbGcyt7XGoSes+LU2g/T3t4e4eHhCA8Ph1AoxI0bN3Dp0iX88MMPMDc3l9quUEHaN8F3uzLWVmbfvn2wtrbG69evMXHiRLRp0waenrWPbtXV1YWrq2utZWqSmppa723rzNUVCAgA1q9nriBKSgCBACgtZW7//51VWgqtyo9Xek7ye0kJkJcndXuUldUahoW3NwzPngWM1d+l8wuXL3CSfxLf3/0e03pPU9p04DW9zrf5t1EiKkFQpyDVvQ8awFHoCK2/tcBn82uNV6Xvaw1Bz7nu29ZE7o76Ojo68PHxgY+PDwDm239tbGxskJ2dLblf+cqgpjLZ2dmSMtbWzERpFhYWCAwMREpKiswE0ei0bAkMUeKaA2IxkyykJY9r12AwYwYQGAicOAGYq3d9BjaLjS3BW+Dxiwe+iP0CPw9S7TokFTO4anoDdQUDHQN0tOpIR1RTSlXvXkwVH+A16dy5M9LS0pCeno6ysjLExMRUW9s6ICAAUVFRIIQgOTkZxsbGsLKyQnFxMQoLCwEAxcXFuHz5MpycnOobavPFZjPjNMzMABsbpsutszPQtSswdSoyfvgBSEpiRoJXStTq0sW6CyK8I7D15lZcz7iu0mPHZ8bDVNcUThaN533Gs+UhITNBre02VNOmtG6u2traWLJkCSZPnoyBAwdiwIABcHJywr59+7Bv3z4AgL+/P7hcLgIDA7F48WIsXboUAPD69WuMGTMGgwcPxogRI+Dv749evXopK9Rmq7BPHyAmBnjyBOjVSyN6Vn39/tewNbbFJzGfQCRWXUN9fGY8PO09wWY1nqFBPDseXpe8xvO3z9UdCtVEyaxiEggE0H1n+c3c3FyYy1El4e/vD3//qksjhoeHS35nsViSpFAZl8vFX3/9JXP/lAL07QucOwcMHAj06MH83r692sIx1jXGD0E/YOShkdicsBmzvGcp/ZglwhLczrmNz3w/U84BfvsNMDAAKr33FcHTnqlyvZF1A63NWit03xQFyHEFMXz4cCQnJ0vunz59usqHPNUE+PgAf//NtE307AncuqXWcIZ3GI5+bfvhq7+/wsuCl0o/XnJ2MsrF5cppfzh6FJg8GRg3DrhyRaG77mzVGTpsHToeglIamQli7dq1WLFiBb755hvMmzcPBw4cwM5aumZSjZSbG3DpEsDhMG0S166pLRQWi4VNAzahtLwU88/OV/rxlDaC+uFD4MMPmXEwrVoxVxAKXHBLV1sXXay70DWqKaWRmSCcnZ3xySef4M8//8T169exZMmSKmMXqCbE2Rn45x+md1XfvsxUIWriZOGEhX4Lsff2Xpx/ptw44rPiYWdsBztjBS6rW1QEDBvGJNzDh4F9+5iBkB9/rNC1Q3h2PNzMugkxodPMU4onM0F88cUX2LlzJ/766y9ERkZi2rRp2LNnjypio9TB0ZG5knjvPaZd4tgxtYWysMdCtG3RFtNjpqNMVPuYjoZIyExQ7NUDIUwiSE0F/vyTuXrw9gZWrmRG1P/6q8IO5WnnibeCtxq3rgbVNMhMEO3bt8euXbvA5XLRs2dPHDhwoHkvGNQc2Ngwq+R16QIMHcoss6oG+jr62DhgIx68foB1V9Yp5Ri5Jbl4lPtIsTO4btzIXDGsWMFciVX47DPm/uzZzFrnClB56m+KUjSZCWLChAlVRkAbGxtj9erVSg2K0gDm5kBsLNOzaexYoJZR88o0wGkAwlzDsCJuBZ7lPVP4/is+WCt6BDXY5cvAvHnMjL4LF1Z9js0Gdu1iRq6PHs2Mgm+gDpYdoKetR9shKKWQmSDS0tIQERGBgQMHok+fPpIb1QwYGwMnTzJVTVOnAmvXqiWM74O+B5vFxuxTsxW+74o1qCu+iTdIdjYwYgQzIHHnTiYhvMvWlkkSd+4A8xveAK+jpQM3Gzd6BUEphcwEsWjRIoSHh0NLSwu7du1CaGgohihzeghKs+jrA0eOACNHMlUkixcrtJFVHlxTLpa9vwzHHh7DXw8UOz4mPisezhbOMNMza9iOhEJmmdk3b5hGabNa9te/P3OVsXkz0w22gXi2PCS+TFTpwEKqeZCZIAQCgWT+JXt7e8yaNQvX1NgFklIDDodph/joI6ahdc4cZp4nFZrtPRudrDoh4mQEisqKFLJPQgiuZ1xXTAP1okVAXBxTFdeli+zyq1cD3boxf9P09AYd2tPeE0XCIjx4/aBB+6God8lMEBwOB2KxGI6Ojti9ezfOnj2L169fqyI2SpNoaTG9bz79FNiwgflga+CiUnWho6WDLcFb8Pztc6y6tEoh+8zIzwC/iA9Puwa2Pxw8CKxbB8ycybTXyIPDYRqyhULggw8a9LesqB6rqC6jKEWRq5trSUkJvvrqK9y9exfR0dH45ptvVBEbpWlYLOaDcNkyYMcOZuCXjCnFFalHqx6Y4DYBa6+sReqrhs99r5AZXFNTgYkTmdHo6+rY08rJialmunSJuTKrJ2cLZxjqGNJ2CErhZM7F1OX/l8uGhoaIjIxUekCUhmOxgKVLmQbsefOAwkKmzt3AQCWH/7bvt4i+H43pJ6bj/Pjz1dYYqYv4zHjosHXQ1aZr/XZQUMAMhjM0BA4cYK4K6mrcOODsWaZLbEAAM2liHWmxteBh60Gn/qYUrsYEMW3atFo3/Pln1c7XT2mYuXMBExNgyhSm0fX4cea+klkaWiKyTySmxUzD3tt78UGXD+q9r/jMeHSx7gI9bb26b0wIMGkS8OgRM8Ghg0O948BPPwFXrzJVTcnJgIVFnXfhaeeJzTc2QygSQkdLp/6xUFQlNSaI5ORk2NraIjg4GF27dqVzzlPVTZ7MXEmMHct8+z11ipmmQ8k+7vYxfk/+HfPOzENw++B69UASEzFuZN3A2C5ythm8a/16ZlT0t98yc1c1hLExM+Lax4f5mx45wlyp1QHPjofS8lLcfXUXbjZuDYuHov6vxjaIy5cv49NPP8WjR4+watUqXL58GS1atICXlxe8vBrHqluUCowaBURFMf36/f2Z+YaUrGL1uVfFr7D4/OJ67ePBvw9QUFZQv/aHixeBzz9nqpcUMJYBANOjac0a5m+5ZUudN6cjqillqDFBaGlpoVevXvjmm29w4MABODo6Yty4cfjjjz9UGR/VGAQHMwPqXrxgpgt/pvgRz+/ysPXADM8Z2HxjM25m3azz9hUzuNa5B1NmJjMmpF07YPv2On/Tr9WcOUx13dy5wO3bddq0rXlbmOqa0gRBKVStvZjKyspw5swZzJ8/H3v27MG4cePQr18/VcVGNSa9ezNTc+TlMdNz1LIQuqKs6L0ClgaW9Vp9Lj4zHkYcI7i0dJF/o7IyJjkUFTHVQIpuc2GzmRHYZmbMlVlxsfybstjg2fFogqAUqsYE8fnnn2P06NG4e/cuZs6cicOHD2PGjBky16KmmjEvL6b6RSRieuMkJir1cKZ6plgftB4JWQn4NbFuM6QmZCWAZ8eDFltL/o3mz2cW/fntN6BDhzpGKycrK+CPP5gE++mnddqUZ8dDCj8FgnKBcmKjmp0aE0R0dDSePXuGXbt2YfTo0fDw8ICHhwfc3d3h4eGhyhipxqRzZ6Zfv4EBc1Xxzz9KPVx4p3D0bt0bi2IXIacoR65tBOUCJGcn120G1717mVlaP/2U+XavTIGBTBvH1q3MIDw58ex4EIqFSOGnKDE4qjmpMUHcv38fSUlJSEpKQmJiouRWcV8ecXFxCAoKQmBgILZKmQ2UEIKVK1ciMDAQISEh1aYRF4lECA0NxdSpU+t4WpRaOTkxicHGBujXDzh9WmmHYrFY2By8GUVlRVhwdoFc29zi34JQLJR/Btfbt5n1HXr0AFQ1SHTFCuaK7OOPgbQ0uTahDdWUoskcSV1fIpEIy5cvx7Zt2xATE4Pjx4/j8ePHVcrExcUhLS0NZ86cwYoVK7Bs2bIqz+/atQtt27ZVVoiUMnG5zNxE7dsDISFMnb2SuLR0wWe+n2HnrZ2Iex4ns3zFlBRy9WB6+5bprWRiwgyG01HRGAMdHWYqDkKAMWPkmorD0dQRLQ1a0gRBKYzSEkRKSgocHR3B5XLB4XAQHByM2NjYKmViY2MRGhoKFosFNzc35OfnIyeHqSbIzs7GhQsXMHz4cGWFSCmbtTXw999MF84RI5hprpXky15fwtHUEdNjpkMoEtZaNj4rHtaG1uCacGvfqVjMrCmdlsZU9djaKi5gebRpA/z8MzOI7p0vT9KwWCzw7Hh0bQhKYWROtVFffD6/ytrV1tbWSElJqbWMjY0N+Hw+rKyssHr1anz22WcoKpJ/5k6BQIDUevaeKS0trfe2jZWqzpm1cSO4s2bB8MMPkf3oEfLGjFHKcRZ0XoAZ/8zAor8W4SOXj6SWKS0txT9P/4GriSvu379f6/4sfv0VVtHRyF64EHkWFirpmVWNmxtshw6F6erVeNGuHYq9vWst3lqnNc68OoPE24nQ19an7+tmQlnnrLQEIW3k9bvz5tRU5u+//4a5uTk6deqE69evy31MXV1duLq61j1YAKmpqfXetrFS6Tn//TcwahRsVq6ETXk58OWXgJGRQg/h6uqK069OY0vqFswOmA2uafUrhPhb8Xha8BQTuk2o/dzPnQN+/JGJefVq2ChyvENd/fEH0K0bHL/8Erh1q9bR6v1Z/fFz6s8oNSuFB9eDvq+biYacc22JRWlVTDY2NsjOzpbcr7gyqK1MdnY2rKyskJiYiPPnzyMgIABz587FtWvXMF9RI1Yp9dDTY6am+PBDZsRw69bAqlVMHb8C/dj/RxBCMOf0HKnP381jOkLU2v6Qns7MVOviAmzbptjBcPVhaMhMxfHvv8zMsbVMe1PR8E7bIShFUFqC6Ny5M9LS0pCeno6ysjLExMQgICCgSpmAgABERUWBEILk5GQYGxvDysoK8+bNQ1xcHM6fP4/169eje/fuWKum5S4pBdLRYaYJv3YN6N4d+OorJlEsW8YMsFOA1matsbjXYhxJPYITj05Ue/52LjNCucYeTAIBMHw48/PIEYVf5dSbmxvw3XfMpIgbN9ZYzM7YDrZGtrQdglIIpSUIbW1tLFmyBJMnT8bAgQMxYMAAODk5Yd++fdi3bx8AwN/fH1wuF4GBgVi8eDGWLl2qrHAoTeLtzXzQ3bjBTHT39deAoyNT7fTvvw3e/TzfeXBp6YJZJ2ehRFhS5bnbubfRtkVbmOubS994zhwgPp5JZM7ODY5FoWbNAgYNYpZ+TUqqsRgdUU0pitLaIAAmAfj7+1d5LDw8XPI7i8WSmRS8vb3hLaNhjmqkunVj1mROSWEWzImMZOr9p09n1pqo56h9jhYHmwduRsCuAET+E4nlvZdLnruTewe92/aWvuHOnUyvoQULmK6tmobFYuZ/6toVGD0auHlT6hUOz46H4w+PI1+Qr4Yg1atYWIy7uXdRlKWYZWnrggUWOll1gq62rsqPrSxKTRAUJZcuXZgxBvfuMe0S69YBmzYBU6cy35bt7Oq8y97v9cYHnT/AN5e/wdguY9Heoj2yCrKQXZItvf0hORmYNo0Z/b1KMUuaKkXLlsDu3UCfPkBEBPD779WKeNp5goAg6WUSrGAlZSdNS0Z+Bo4/PI5jD4/h/LPzKC0vVVssVoZWmNptKqbxpsHOuO7vW01DEwSlOTp0APbsYVasW72aqWvfsoVZI+Hzz5nBd3Wwtt9aHHt4DDNOzMCZsWckA+SqzeCal8dcMVhYMIPTtDX836J3b+CLL5hEFhjINKhX0s2uGwBmvqngFsHqiFCpxESMxJeJOPbgGI49PIakbKa67T2z9zDFYwraardFG8c2Ko+rqKwIu2/vxsq4lYj8JxIjOoxAhHcEvO29G7TyoVqRJuTevXtq2bax0vhzfvKEkMmTCdHRYW5TphDy9GmddrHx+kaCZSD77+wnX5z7gmh9rUWKyor+KyASETJwILP/K1cUfAJKJBQS4utLiLEx83d6R6vvW5FRB0dp/mssp6KyIvLX/b/Ix399TGzX2hIsA2F/zSZ+v/mRNZfWkLs5d4lYLCaEqP99/ej1IzLn5BxiEmlCsAzEc6sn+ePWH6RUWKq0Yyrrs49FSNNZKq6+fYF//BE4e/YtTE1NlRCVZmKzATs7Pj780BqururvyVmrFy+YOZC2bWNmih0/nvkG3a6dzE1FYhG8tnnhZcFLOJo54k3hG6TOrtTve8UKYMkSZtnP6dOVeBJK8Pw50x7h7MzMfVVpGpCwA2G4lX0LxwKPNdoxAZn5mTj+8DiOPzqOc0/PobS8FMYcYwS1C0JI+xAMdBqIlgbVx4RoyjiIAkEB/kj5Axuub8CD1w9gbWiNabxpmMabBhsjG9k7qIOGjoOoaVuaIAB89BFw7lwZOPVZdL6REgiY7v4As5xyUBCzVk2fPkCLFuqNrUaZmUxXz19+YdZmCA9nej7JeM3jM+PRfVt3EBCMaDMCB8YdYJ44dQoYOJBZC3rXLg3PkjU4dIiZxuTzz5nxJf+35p81WBS7CFdDr6J71+5qDFB+hBCm6ughU3WU+JKZFPQ9s/cQ0j4EIc4h6OXYCxyt2v9PNSVBVBATMc4+OYsN8Rtw4tEJ6LB1MLLjSER4R9RvRUMplJUgaBWTArZtrM6de0i2biUkLIwQU1NCAELYbEJ8fAj5+mtCrl0jpLxc3VFK8fIlIfPnE2JgQAiLRcjIkYSkpNS6ybRj0wiWgSw/vpx54OlTQlq0IKRLF0KKimrdVuNNmcK8eGfOSB46++QswTKQbee3qTEw2YrLismxB8fIlL+mELt1dgTLQFjLWMT3N18SeSmS3OHfkVQdyUuT/5cf/vuQRJyIIMarjQmWgXj/6k32pOwhgnJBg/arrM8+miAUsG1jVfmchUJC/vmHkMWLCfH0ZD53AULMzZnP399/JyQjQ43BSpOTQ8iiRYQYGTHBDh1KSGKi1KJ5JXlk7qm55ErSFUJKSgjx8GCy4qNHqo1ZGYqKCOnQgRBra0L4fEIIIbnFuQTLQOYcnqPm4KrLys8iW29sJSF7Q4j+Sn2CZSBGq41I2P4wsiNpB8kpzGnQ/hvD//Lb0rdkw7UNxGmDE8EyENu1tuTrC1+T7ILseu2PJgg50ARRN7Wd86tXhOzbR8iECYTY2DCfvwAhnToRMm8eIWfPMp+zGuH1a0KWLPnvMmjQIEKuX5da9N69e4R89BFT7q+/VBunMqWkEKKnR0j//kzDOyGk7Y9tSeCvgWoOjBCxWExuZt0ky/5eRnhbeQTLQLAMpPUPrcmsE7PImcdnFNqA25j+l0ViETnx8ATpv7s/wTIQzgoOGXdkHEnITKjTfmiCkANNEHUj7zmLxYTcukXIt98SEhBACIfDfL7q6xMyYAAhP/5IyP37TDm1yssjZMUKpuoIICQoiLksqiRr+XLmuS+/VE+MyrR5M3Nu69YRQggZfWg0sf3WVmmHE4vFRCQWEaFISATlAlJcVkwKBYUkvzSfvC5+TY4/OE6mHptK7NfZS6qOfLb5kNVxq8lt/u06Vx3Jq7H+L99/dZ/MjJlJjFYbESwD8dnmQ/68/ScpKy+TuS3txSQHpTXUNFH1PeeiIuDCBaaN9/Rp4NEj5nFHx/8auwMCALV1CisoADZvBtauZabuCAhgeioZGkLs6wv2++8DJ08CWnVYj7oxIAQIC2OmMbl6FesEFzD/7Hx0te4KMRFXuYmIqPpj4uqP1VaWQPZHhxHHCEFtgzCo/SAMdBoIK0PlD9xr7P/Lb0vfYkfyDmyM34gneU9gZ2yH6bzpmNJtCiwNLaVuQ3sxyYEmiLpR1Dk/e8YkilOngPPnmc9nLS3Ax4dJFkFBgIcH07VWpYqKmB5P334L8PmAri6E5ubQSUmpdcrsRi03l+n6qqeHF+ej8PGZudA31Aebxa5y02JrVX0MNTxeUZ5Vw+O1lO9o1RH+jv4qn3qiqfwvi4kYJx+dxIb4DTjz5Ax0tXQR3jkcEV4RcLd1r1KWJgg50ARRN8o4Z6GQWQCt4uqiYvnyli2ZQb/9+zNLO3O5qlu9EyUlzBiKP//Eszlz8N6IESo6sJpcusRMgvjBB0hdtKh5va/FYtxPSoJLu3bMMq3v3kSiuj1el21EIuaN7erK3BR4CZ36KhWb4jdh562dKBIWoUerHojwikCoSyh0tHRogpAHTRB1o4pzzskBzp5lEsaZM8x9oGKgHlMt1bo18/Pdm76+4uNpNq/z118Dy5Yhc80a2H/+ubqjkV95ObNGyNu3wJs3/93kvf/2ba3rZaiUnR0zfYyra9WfltKrieTxpvQNtidtx8b4jXj25hkcTBwwnTcd7xu/Dx83n3rtkyYIJW/bWKn6nMViZkG0pCRmEHBaGvPz+XMgI4P5bKjMyqp60qicTOrzBa3ZvM7l5UBAAMjVq2DZ2gIczn83Xd3a78tTRp5tSkvr/gFfWCj73ExMADOz/26mplXu84uLYW1vz8yppa3N1HdW/F75Ju3xhpRlsZg38717zPK0lX9WXjrZwkJ64rC3l3uwpkgswolHJ7AhfgPOPT0HT0tPxE+Pl/vtUVlt/xMaPisZ1ZSw2YC7O3N7l0gEZGVVTxzPnwO3bzPtrqXvTNJpaio9cVTcLC0b5+BohdDWBvbvR+6iRbBgs5mR55VvAgHzs7Cw6v13ny8rq565G0JLq/oHu7NztQ/5Gu8bG8vsXJCbmgprdX0JaNeOuQ0e/N9jhDDfgN5NHIcOMW1GFYyN/6ueqpw4Wreuds5abC2EODOjy1NfpeLRk0dKOR2aICiNoKXFVN9yuUwbxbsIYaqnKieOimSSlgZcvAjkv7P8gb5+1YTB5QLFxS3g6MisgKqvz/x893dpzzXKDk+2tsj5/HNYNPTDUiyunmBkJRWBgPnjvfshb2jY/LI2i/Xfmzso6L/HCQFevaqeOM6cYdYmqaCryyx/+27iaNcO4HDgaukKNHydLalogqAaBRaLWT/I2hrwqmH6mjdvqiaOyokkMZH5XwTqN0matnbNyaO2xFL5d319wMCg6s/aHlNZI74sbPZ/J0IpDovF1KNaWTGdCip784ZJFpUTx7VrzNrkFbS0ACcnwNUVJn5+Muckqw+aIKgmo+KLateu0p8vLQWSkh7A0dEZpaVM56bS0v9ule/X9bm3b5metNKeEwrrdz5aWvIlkpoe09cHcnNNcfNmff+ijROfb4LMTOZz19KS6UGnMclWXmZmTD9xn3canouKgAcPqrVxGIrFzCqMCkYTBNVsMDUe4vosUNcgItF/yaK4uOpPWY/V9HxBAVPlJq1cVY1/VbO6s6/2iJnZfwmj4lbT/ZYtmTZ2jWRoyAwq8vCo8vDL1FSYKeFwNEFQlJJpaTH/14aGyj8WIf8lo5IS4Pbtx2gnx7oZTUlq6hOYmrZFTg5TrVhxq7j/+DEzVufVK6Z5RRpT06oJRFZy0diE0kBKTRBxcXFYtWoVxGIxRowYgSlTplR5nhCCVatW4eLFi9DT08OaNWvQsWNHCAQCfPDBBygrK4NIJEJQUBAiIiKUGSpFNQks1n/VSwCQny+UZ12lJkUoLJOrOl4sZlabrZw83k0mr14BT58y1f///stcDUpjaqreROHpaYUdOxS/X6UlCJFIhOXLl2P79u2wtrbG8OHDERAQUOXbTFxcHNLS0nDmzBncunULy5Ytw8GDB8HhcLBz504YGhpCKBRizJgx6NWrF9zc3JQVLkVRzQybzQxJsLBgOgnJIhYzbcc1JZR//61/e1NDcbnKObDSEkRKSgocHR3B/f9C88HBwYiNja2SIGJjYxEaGgoWiwU3Nzfk5+cjJycHVlZWMPz/9Xh5eTnKy8sb76LfFEU1CWw2YG7O3Jyd1R1NVampeahvD73aKC1B8Pl82Nj8F7C1tTVSUlJqLWNjYwM+nw8rKyuIRCIMGzYML168wJgxY9C1pq4plQgEAqSmpsosJ01paWm9t22s6Dk3fc3tfAF6zoqktAQhbQaPd68CaiujpaWF6Oho5OfnY8aMGXj48CHat29f6zF1dXXpVBt1QM+56Wtu5wvQc67PtjVR2gTMNjY2yM7OltyvuDKorUx2dna1MiYmJvD29salS5eUFSpFURQlhdISROfOnZGWlob09HSUlZUhJiYGAQEBVcoEBAQgKioKhBAkJyfD2NgYVlZWyM3NRf7/500oLS3FlStX0KZNG2WFSlEURUmhtCombW1tLFmyBJMnT4ZIJEJYWBicnJywb98+AEB4eDj8/f1x8eJFBAYGQl9fH6tXrwYA5OTkYOHChRCJRCCEoH///ujdu7eyQqUoiqKkUOo4CH9/f/j7+1d5LDw8XPI7i8XC0qVLq23n4uKCqKgoZYZGURRFyaDqRSApiqKoRoImCIqiKEqqJrWiXHJyMnR1VbtAOkVRVGMmEAhqnKWiSSUIiqIoSnFoFRNFURQlFU0QFEVRlFQ0QVAURVFS0QRBURRFSUUTBEVRFCUVTRAURVGUVM0+QcTFxSEoKAiBgYHYunWrusNRupcvX2LcuHEYMGAAgoODsXPnTnWHpDIikQihoaGYOnWqukNRifz8fERERKB///4YMGAAkpKS1B2S0u3YsQPBwcEYNGgQ5s6dC4FAoO6QFG7RokXw8fHBoEGDJI+9efMGEydORL9+/TBx4kS8fftWIcdq1gmiYlnUbdu2ISYmBsePH8fjx4/VHZZSaWlpYeHChTh58iT279+PvXv3NvlzrrBr1y60bdtW3WGozKpVq9CzZ0+cOnUK0dHRTf7c+Xw+du3ahcOHD+P48eMQiUSIiYlRd1gKN2zYMGzbtq3KY1u3boWPjw/OnDkDHx8fhX3ZbdYJovKyqBwOR7IsalNmZWWFjh07AgCMjIzQpk0b8Pl8NUelfNnZ2bhw4QKGDx+u7lBUorCwEAkJCZLz5XA4MDExUXNUyicSiVBaWory8nKUlpZWW1+mKfD09ISpqWmVxyqWbwaA0NBQnDt3TiHHatYJQtqyqM3hw7JCRkYGUlNT5VrOtbFbvXo1PvvsM7DZzeMtn56eDnNzcyxatAihoaH48ssvUVxcrO6wlMra2hqTJk1C79690aNHDxgZGaFHjx7qDkslXr9+LUmGFWvqKELz+G+pgTzLojZVRUVFiIiIwBdffAEjIyN1h6NUf//9N8zNzdGpUyd1h6Iy5eXluHfvHsLDwxEVFQV9ff0m38b29u1bxMbGIjY2FpcuXUJJSQmio6PVHVaj1qwThDzLojZFQqEQERERCAkJQb9+/dQdjtIlJibi/PnzCAgIwNy5c3Ht2jXMnz9f3WEplY2NDWxsbCRXh/3798e9e/fUHJVyXblyBQ4ODjA3N4eOjg769evXLBrmAcDCwgI5OTkAmAXXzM3NFbLfZp0g5FkWtakhhODLL79EmzZtMHHiRHWHoxLz5s1DXFwczp8/j/Xr16N79+5Yu3atusNSKktLS9jY2ODp06cAgKtXrzb5Rmo7OzvcunULJSUlIIQ0i3OuULF8MwBERUWhT58+CtmvUleU03Q1LYvalN28eRPR0dFo3749hgwZAgCYO3dutZX/qMZv8eLFmD9/PoRCIbhcLiIjI9UdklJ17doVQUFBGDp0KLS1teHq6opRo0apOyyFmzt3LuLj45GXl4devXph1qxZmDJlCubMmYNDhw7B1tYWP/74o0KORaf7piiKoqRq1lVMFEVRVM1ogqAoiqKkogmCoiiKkoomCIqiKEoqmiAoiqIoqZp1N1eK+vfffxEZGYnk5GSYmppCR0cHkydPRmBgoMpjuX79OnR0dODh4QEA2LdvH/T19SVz7FCUqtEEQTVbhBDMmDEDoaGhWLduHQAgMzMT58+fV9oxy8vLoa0t/d8uPj4eBgYGkgQRHh6utDgoSh50HATVbF29ehU//fQTdu/eXe05kUiEtWvXIj4+HmVlZfjggw8wevRoXL9+HZs2bUKLFi3w8OFDdOzYEWvXrgWLxcKdO3ewZs0aFBcXo0WLFoiMjISVlRXGjRsHd3d3JCYmIiAgAK1bt8aWLVsgFAphZmaGtWvXorS0FKNGjQKbzYa5uTkWL16Mq1evwsDAAB999BFSU1OxdOlSlJSUoFWrVli9ejVMTU0xbtw4dOnSBdevX0dBQQFWrVoFHo+nhr8m1RTRNgiq2Xr06BE6dOgg9blDhw7B2NgYhw8fxuHDh3HgwAGkp6cDAO7du4cvvvgCJ06cQEZGBm7evAmhUIiVK1diw4YNOHLkCMLCwvD9999L9pefn4/du3dj0qRJ6NatGw4cOICoqCgEBwdj27ZtcHBwwOjRozFhwgRER0dX+5BfsGAB5s+fj2PHjqF9+/bYtGmT5DmRSIRDhw7hiy++qPI4RTUUrWKiqP/7+uuvcfPmTejo6MDe3h4PHjzA6dOnAQAFBQV4/vw5dHR00KVLF8k08S4uLsjMzISJiQkePnwomd9KLBbD0tJSsu+BAwdKfs/Ozsann36KV69eoaysDA4ODrXGVVBQgIKCAnh5eQEAhg4ditmzZ0uer2gv6dixIzIzMxXwl6AoBk0QVLPl5OSEM2fOSO4vXboUubm5GD58OOzs7PDVV1+hZ8+eVba5fv06OByO5L6WlhZEIhEIIXBycsL+/fulHktfX1/y+8qVKzFhwgT06dNHUmXVEBXxsNlsiESiBu2LoiqjVUxUs9W9e3cIBALs3btX8lhpaSkAoEePHti3bx+EQiEA4NmzZ7UuuPPee+8hNzdXMr20UCjEo0ePpJYtKCiAtbU1AEhm4AQAQ0NDFBUVVStvbGwMExMT3LhxAwAQHR0NT0/POpwpRdUPvYKgmi0Wi4WffvoJkZGR2LZtG8zNzaGvr4/58+ejf//+yMzMxLBhw0AIQYsWLbB58+Ya98XhcLBhwwasXLkSBQUFEIlE+PDDD6XODjxz5kzMnj0b1tbW6Nq1KzIyMgAAvXv3RkREBGJjY7F48eIq23zzzTeSRurmMDMrpRloLyaKoihKKlrFRFEURUlFEwRFURQlFU0QFEVRlFQ0QVAURVFS0QRBURRFSUUTBEVRFCUVTRAURVGUVP8DH8tvI5jFKgsAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total elapsed time: 62.71206338802973 minutes\n"
     ]
    }
   ],
   "source": [
    "population_size = 5   # max of individuals per generation\n",
    "max_generations = 10  # number of generations\n",
    "gene_length = 7      # lenght of the gene, depends on how many hiperparameters are tested  \n",
    "k = 1;                 # num. of finalist individuals\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    t = time.time(); \n",
    "    datos = [];\n",
    "    ss = [i for i in range(1,population_size*(max_generations+1))]\n",
    "    best_population = geneticAlgorithm_with_elitism(population_size, max_generations, gene_length, k)\n",
    "    print(\"Total elapsed time:\", (time.time()-t)/60, \"minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k= 1 \n",
      "Deep layers: 2 , Number of neurons: 50\n",
      "Batch size 4 , Learning rate: 0.0001\n"
     ]
    }
   ],
   "source": [
    "best_deep_layers   = []\n",
    "best_num_units     = []\n",
    "best_learning_rate = []\n",
    "best_batch_size    = []\n",
    "# best_activation_f  = []\n",
    "best_f_names       = []\n",
    "\n",
    "t = 0\n",
    "\n",
    "for bi in best_population:\n",
    "    deep_layers_bits   = BitArray(bi[0:1])    # (8)\n",
    "    num_units_bits     = BitArray(bi[1:2])    # (16)\n",
    "    learning_rate_bits = BitArray(bi[2:3])   # (8)\n",
    "    batch_size_bits    = BitArray(bi[3:4])  # (4)\n",
    "#     activation_f_bits  = BitArray(bi[12:13])  # (2)\n",
    "    t += 1 \n",
    "    \n",
    "    best_deep_layers.append(SC_DEEP[deep_layers_bits.uint])\n",
    "    best_num_units.append(SC_NUM_UNITS[num_units_bits.uint])\n",
    "    best_learning_rate.append(SC_LEARNING[learning_rate_bits.uint])\n",
    "    best_batch_size.append(SC_BATCH[batch_size_bits.uint])\n",
    "#     best_activation_f.append(SC_ACTIVATION[activation_f_bits.uint])\n",
    "#     best_f_names.append(f_names[activation_f_bits.uint])\n",
    "    print('k=',t,'\\nDeep layers:', best_deep_layers[-1], ', Number of neurons:', best_num_units[-1])\n",
    "    print('Batch size', best_batch_size[-1], ', Learning rate:', best_learning_rate[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Deep layers</th>\n",
       "      <th>Num units</th>\n",
       "      <th>Learning rate</th>\n",
       "      <th>Batch size</th>\n",
       "      <th>Loss</th>\n",
       "      <th>Score</th>\n",
       "      <th>Elapsed time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>4</td>\n",
       "      <td>0.030615</td>\n",
       "      <td>0.030615</td>\n",
       "      <td>83.624904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>4</td>\n",
       "      <td>0.031505</td>\n",
       "      <td>0.031505</td>\n",
       "      <td>143.688685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>4</td>\n",
       "      <td>0.031894</td>\n",
       "      <td>0.031894</td>\n",
       "      <td>143.836119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>4</td>\n",
       "      <td>0.031898</td>\n",
       "      <td>0.031898</td>\n",
       "      <td>145.389929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>4</td>\n",
       "      <td>0.032069</td>\n",
       "      <td>0.032069</td>\n",
       "      <td>74.259619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>4</td>\n",
       "      <td>0.032246</td>\n",
       "      <td>0.032246</td>\n",
       "      <td>143.793837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>4</td>\n",
       "      <td>0.032349</td>\n",
       "      <td>0.032349</td>\n",
       "      <td>144.094604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>4</td>\n",
       "      <td>0.032700</td>\n",
       "      <td>0.032700</td>\n",
       "      <td>96.969862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>4</td>\n",
       "      <td>0.033158</td>\n",
       "      <td>0.033158</td>\n",
       "      <td>75.545538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>4</td>\n",
       "      <td>0.033183</td>\n",
       "      <td>0.033183</td>\n",
       "      <td>98.295700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>3</td>\n",
       "      <td>200</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>4</td>\n",
       "      <td>0.033473</td>\n",
       "      <td>0.033473</td>\n",
       "      <td>131.902345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>3</td>\n",
       "      <td>200</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>4</td>\n",
       "      <td>0.033552</td>\n",
       "      <td>0.033552</td>\n",
       "      <td>143.697888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>4</td>\n",
       "      <td>50</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>2</td>\n",
       "      <td>0.034042</td>\n",
       "      <td>0.034042</td>\n",
       "      <td>203.919596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>4</td>\n",
       "      <td>200</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>4</td>\n",
       "      <td>0.034478</td>\n",
       "      <td>0.034478</td>\n",
       "      <td>158.478854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>4</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>4</td>\n",
       "      <td>0.034570</td>\n",
       "      <td>0.034570</td>\n",
       "      <td>108.213490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2</td>\n",
       "      <td>200</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>4</td>\n",
       "      <td>0.035485</td>\n",
       "      <td>0.035485</td>\n",
       "      <td>143.570150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2</td>\n",
       "      <td>200</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>4</td>\n",
       "      <td>0.035903</td>\n",
       "      <td>0.035903</td>\n",
       "      <td>143.551070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>4</td>\n",
       "      <td>0.036537</td>\n",
       "      <td>0.036537</td>\n",
       "      <td>81.941488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>4</td>\n",
       "      <td>0.036589</td>\n",
       "      <td>0.036589</td>\n",
       "      <td>88.528802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>4</td>\n",
       "      <td>0.036934</td>\n",
       "      <td>0.036934</td>\n",
       "      <td>84.039072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>4</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>16</td>\n",
       "      <td>0.036958</td>\n",
       "      <td>0.036958</td>\n",
       "      <td>42.695154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>3</td>\n",
       "      <td>200</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>16</td>\n",
       "      <td>0.037792</td>\n",
       "      <td>0.037792</td>\n",
       "      <td>34.017867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>4</td>\n",
       "      <td>0.038496</td>\n",
       "      <td>0.038496</td>\n",
       "      <td>143.314672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>4</td>\n",
       "      <td>200</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>16</td>\n",
       "      <td>0.041745</td>\n",
       "      <td>0.041745</td>\n",
       "      <td>83.929748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2</td>\n",
       "      <td>200</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>16</td>\n",
       "      <td>0.050635</td>\n",
       "      <td>0.050635</td>\n",
       "      <td>41.465685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>4</td>\n",
       "      <td>50</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>4</td>\n",
       "      <td>0.052528</td>\n",
       "      <td>0.052528</td>\n",
       "      <td>144.145922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>2</td>\n",
       "      <td>0.053480</td>\n",
       "      <td>0.053480</td>\n",
       "      <td>164.627980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>4</td>\n",
       "      <td>0.062010</td>\n",
       "      <td>0.062010</td>\n",
       "      <td>83.058979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>2</td>\n",
       "      <td>0.083271</td>\n",
       "      <td>0.083271</td>\n",
       "      <td>203.804492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>4</td>\n",
       "      <td>0.087014</td>\n",
       "      <td>0.087014</td>\n",
       "      <td>143.595614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>3</td>\n",
       "      <td>200</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>2</td>\n",
       "      <td>0.100255</td>\n",
       "      <td>0.100255</td>\n",
       "      <td>240.445245</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Deep layers  Num units  Learning rate  Batch size      Loss     Score  \\\n",
       "0             3        100         0.0001           4  0.030615  0.030615   \n",
       "1             3        100         0.0001           4  0.031505  0.031505   \n",
       "2             3        100         0.0001           4  0.031894  0.031894   \n",
       "3             3        100         0.0001           4  0.031898  0.031898   \n",
       "4             3        100         0.0001           4  0.032069  0.032069   \n",
       "5             3        100         0.0001           4  0.032246  0.032246   \n",
       "6             3        100         0.0001           4  0.032349  0.032349   \n",
       "7             3        100         0.0001           4  0.032700  0.032700   \n",
       "8             3        100         0.0001           4  0.033158  0.033158   \n",
       "9             3        100         0.0001           4  0.033183  0.033183   \n",
       "10            3        200         0.0001           4  0.033473  0.033473   \n",
       "11            3        200         0.0001           4  0.033552  0.033552   \n",
       "12            4         50         0.0001           2  0.034042  0.034042   \n",
       "13            4        200         0.0001           4  0.034478  0.034478   \n",
       "14            4        100         0.0010           4  0.034570  0.034570   \n",
       "15            2        200         0.0001           4  0.035485  0.035485   \n",
       "16            2        200         0.0001           4  0.035903  0.035903   \n",
       "17            2        100         0.0001           4  0.036537  0.036537   \n",
       "18            2        100         0.0001           4  0.036589  0.036589   \n",
       "19            2        100         0.0001           4  0.036934  0.036934   \n",
       "20            4        100         0.0010          16  0.036958  0.036958   \n",
       "21            3        200         0.0001          16  0.037792  0.037792   \n",
       "22            2        100         0.0001           4  0.038496  0.038496   \n",
       "23            4        200         0.0010          16  0.041745  0.041745   \n",
       "24            2        200         0.0001          16  0.050635  0.050635   \n",
       "25            4         50         0.0010           4  0.052528  0.052528   \n",
       "26            2        100         0.0010           2  0.053480  0.053480   \n",
       "27            1        100         0.0001           4  0.062010  0.062010   \n",
       "28            3        100         0.0010           2  0.083271  0.083271   \n",
       "29            1        100         0.0001           4  0.087014  0.087014   \n",
       "30            3        200         0.0010           2  0.100255  0.100255   \n",
       "\n",
       "    Elapsed time  \n",
       "0      83.624904  \n",
       "1     143.688685  \n",
       "2     143.836119  \n",
       "3     145.389929  \n",
       "4      74.259619  \n",
       "5     143.793837  \n",
       "6     144.094604  \n",
       "7      96.969862  \n",
       "8      75.545538  \n",
       "9      98.295700  \n",
       "10    131.902345  \n",
       "11    143.697888  \n",
       "12    203.919596  \n",
       "13    158.478854  \n",
       "14    108.213490  \n",
       "15    143.570150  \n",
       "16    143.551070  \n",
       "17     81.941488  \n",
       "18     88.528802  \n",
       "19     84.039072  \n",
       "20     42.695154  \n",
       "21     34.017867  \n",
       "22    143.314672  \n",
       "23     83.929748  \n",
       "24     41.465685  \n",
       "25    144.145922  \n",
       "26    164.627980  \n",
       "27     83.058979  \n",
       "28    203.804492  \n",
       "29    143.595614  \n",
       "30    240.445245  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename = \"historial_genetic_jla2.txt\"\n",
    "df = pd.DataFrame(datos, columns = [\"Deep layers\", \"Num units\", \"Learning rate\", \"Batch size\", \"Loss\", \"Score\", \"Elapsed time\"])\n",
    "\n",
    "df.sort_values(by=[\"Loss\", \"Elapsed time\"], ascending=[True, True], ignore_index=True, inplace=True)\n",
    "\n",
    "df.to_csv(filename, header=True, index=False, sep='\\t', mode='w') # a=append, w=overwrite\n",
    "df.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time 62.707 minutes\n"
     ]
    }
   ],
   "source": [
    "total_time = float(np.sum(df[[\"Elapsed time\"]])/60)\n",
    "\n",
    "print(\"Elapsed time {:.3f} minutes\".format(total_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
