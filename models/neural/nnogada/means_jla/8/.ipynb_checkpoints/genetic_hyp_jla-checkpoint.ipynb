{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-16 20:40:53.843058: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-12-16 20:40:54.004868: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-12-16 20:40:54.004905: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2022-12-16 20:40:55.165416: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2022-12-16 20:40:55.165546: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2022-12-16 20:40:55.165558: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import time, os\n",
    "import random\n",
    "import seaborn as sns\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Input, Dense, LeakyReLU\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorboard.plugins.hparams import api as hp\n",
    "\n",
    "from tensorflow.keras import activations\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "import random\n",
    "from math import floor\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import optimizers\n",
    "from scipy.integrate import odeint\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split as split\n",
    "from scipy.stats import bernoulli\n",
    "\n",
    "# import deap\n",
    "from deap import base, creator, tools, algorithms\n",
    "\n",
    "from bitstring import BitArray\n",
    "\n",
    "# from elitism import eaSimpleWithElitism, main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "\n",
    "# tf.config.optimizer.set_jit(True)\n",
    "# scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "url = 'https://raw.githubusercontent.com/igomezv/nnogada/main/data/jla.csv'\n",
    "df=pd.read_csv(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = len(df.values)\n",
    "randomize = np.random.permutation(N)\n",
    "data = df.values[randomize]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(740, 2)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N = len(df.values)\n",
    "z = data[:,0] \n",
    "y = data[:,1:3] ### coge el resto de variables a predecir \n",
    "y[:,1] = y[:,1]**2+data[:,2]\n",
    "np.shape(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "scalerz = StandardScaler()\n",
    "scalerz.fit(z.reshape(-1,1))\n",
    "z = scalerz.transform(z.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((592, 1), (148, 1), (592, 2), (148, 2))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Modificar para incluir phanteon como test\n",
    "split = 0.8\n",
    "ntrain = int(split * len(z))\n",
    "indx = [ntrain]\n",
    "X_train, X_val = np.split(z, indx)\n",
    "Y_train, Y_val = np.split(y, indx)\n",
    "# X_train, X_test = np.split(z, indx)\n",
    "# Y_train, Y_test = np.split(y, indx)\n",
    "np.shape(X_train), np.shape(X_val), Y_train.shape, Y_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "SC_DEEP       = np.array([1,2,3,4])                           # Number of deep layers (8)\n",
    "SC_NUM_UNITS  = np.array([50,100,150,200]) # Number of fully conected neurons (16)\n",
    "SC_LEARNING   = np.array([1e-4,5e-3])   # Learning rates (8)\n",
    "SC_BATCH      = np.array([2, 4, 8, 16])                            # Batch sizes (4)\n",
    "# SC_ACTIVATION = [f1, f2, f3, f4]                                      # Activation function layers (2)\n",
    "\n",
    "my_callbacks = [tf.keras.callbacks.EarlyStopping(\n",
    "                               monitor='val_loss', mode='min',\n",
    "                               min_delta=0, \n",
    "                               patience=200,\n",
    "                               verbose=1,\n",
    "                            #    baseline=0,\n",
    "                               restore_best_weights=True)\n",
    "#                 keras.callbacks.TensorBoard(\n",
    "#                                log_dir='./logs'),\n",
    "#                 keras.callbacks.ReduceLROnPlateau(\n",
    "#                                monitor='val_loss', factor=0.5,\n",
    "#                                patience=6, min_lr=0,\n",
    "#                                verbose=1)\n",
    "               ] \n",
    "    \n",
    "epochs = 200\n",
    "# epochs = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_evaluate(ga_individual_solution):   \n",
    "    t = time.time()\n",
    "    t_total = 0\n",
    "    \n",
    "    # Decode GA solution to integer for window_size and num_units\n",
    "    deep_layers_bits   = BitArray(ga_individual_solution[0:2])     # (8)\n",
    "    num_units_bits     = BitArray(ga_individual_solution[2:4])     # (16)\n",
    "    learning_rate_bits = BitArray(ga_individual_solution[4:5])    # (8)\n",
    "    batch_size_bits    = BitArray(ga_individual_solution[5:7])   # (4)\n",
    "# #     activation_f_bits  = BitArray(ga_individual_solution[12:13])   # (2)   Solo se consideran las 2 primeras\n",
    "    \n",
    "    deep_layers   = SC_DEEP[deep_layers_bits.uint]\n",
    "    num_units     = SC_NUM_UNITS[num_units_bits.uint]\n",
    "    learning_rate = SC_LEARNING[learning_rate_bits.uint]\n",
    "    batch_size   = SC_BATCH[batch_size_bits.uint]\n",
    "#     activation_f  = SC_ACTIVATION[activation_f_bits.uint]\n",
    "\n",
    "    \n",
    "    print('\\n--------------- Starting trial:', population_size*(max_generations+1)-len(ss), \"---------------\")\n",
    "    print('Deep layers:',deep_layers,', Number of neurons:',num_units,\", Learning rate:\",learning_rate)\n",
    "#     print(\"-------------------------------------------------\")\n",
    "    \n",
    "    # Train model and predict on validation set\n",
    "    model = tf.keras.Sequential()\n",
    "#     model.add(Input(shape=(int(X_train.shape[1]),)))\n",
    "    model.add(Dense(int(X_train.shape[1])))\n",
    "    \n",
    "    for i in range(deep_layers):        \n",
    "        model.add(Dense(num_units, activation='relu'))\n",
    "#             model.add(keras.layers.Dropout(0.3))\n",
    "    model.add(Dense(2, activation='linear'))\n",
    "    \n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate, beta_1=0.9, beta_2=0.999, epsilon=1e-3)\n",
    "    model.compile(optimizer=optimizer, loss='mse', metrics=['mean_squared_error'])\n",
    "    model.fit(X_train, Y_train, epochs=epochs, validation_data=(X_val, Y_val),\n",
    "              callbacks=my_callbacks, batch_size=batch_size, shuffle=False, verbose=0)\n",
    "    \n",
    "    loss, score = model.evaluate(X_val, Y_val)    \n",
    "    t = time.time()-t\n",
    "    ss.pop(0)\n",
    "    print(\"Loss:\", score, \", Elapsed time:\", t)\n",
    "    print(\"-------------------------------------------------\\n\")\n",
    "#     print(loss, score)\n",
    "\n",
    "    datos.append([deep_layers, num_units, learning_rate, batch_size, loss, score, t])\n",
    "    \n",
    "    return loss,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deap import tools\n",
    "from deap import algorithms\n",
    "\n",
    "def eaSimpleWithElitism(population, toolbox, cxpb, mutpb, ngen, stats=None,\n",
    "             halloffame=None, verbose=__debug__):\n",
    "    \"\"\"This algorithm is similar to DEAP eaSimple() algorithm, with the modification that\n",
    "    halloffame is used to implement an elitism mechanism. The individuals contained in the\n",
    "    halloffame are directly injected into the next generation and are not subject to the\n",
    "    genetic operators of selection, crossover and mutation.\n",
    "    \"\"\"\n",
    "    logbook = tools.Logbook()\n",
    "    logbook.header = ['gen', 'nevals'] + (stats.fields if stats else [])\n",
    "\n",
    "    # Evaluate the individuals with an invalid fitness\n",
    "    invalid_ind = [ind for ind in population if not ind.fitness.valid]\n",
    "    fitnesses = toolbox.map(toolbox.evaluate, invalid_ind)\n",
    "    for ind, fit in zip(invalid_ind, fitnesses):\n",
    "        ind.fitness.values = fit\n",
    "\n",
    "    if halloffame is None:\n",
    "        raise ValueError(\"halloffame parameter must not be empty!\")\n",
    "\n",
    "    halloffame.update(population)\n",
    "    hof_size = len(halloffame.items) if halloffame.items else 0\n",
    "\n",
    "    record = stats.compile(population) if stats else {}\n",
    "    logbook.record(gen=0, nevals=len(invalid_ind), **record)\n",
    "    if verbose:\n",
    "        print(logbook.stream)\n",
    "\n",
    "    # Begin the generational process\n",
    "    for gen in range(1, ngen + 1):\n",
    "\n",
    "        # Select the next generation individuals\n",
    "        offspring = toolbox.select(population, len(population) - hof_size)\n",
    "\n",
    "        # Vary the pool of individuals\n",
    "        offspring = algorithms.varAnd(offspring, toolbox, cxpb, mutpb)\n",
    "\n",
    "        # Evaluate the individuals with an invalid fitness\n",
    "        invalid_ind = [ind for ind in offspring if not ind.fitness.valid]\n",
    "        fitnesses = toolbox.map(toolbox.evaluate, invalid_ind)\n",
    "        for ind, fit in zip(invalid_ind, fitnesses):\n",
    "            ind.fitness.values = fit\n",
    "\n",
    "        # add the best back to population:\n",
    "        offspring.extend(halloffame.items)\n",
    "\n",
    "        # Update the hall of fame with the generated individuals\n",
    "        halloffame.update(offspring)\n",
    "\n",
    "        # Replace the current population by the offspring\n",
    "        population[:] = offspring\n",
    "\n",
    "        # Append the current generation statistics to the logbook\n",
    "        record = stats.compile(population) if stats else {}\n",
    "        logbook.record(gen=gen, nevals=len(invalid_ind), **record)\n",
    "        if verbose:\n",
    "            print(logbook.stream)\n",
    "\n",
    "    return population, logbook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def geneticAlgorithm_with_elitism(population_size, max_generations, gene_length, k):\n",
    "    \n",
    "    # Genetic Algorithm constants:\n",
    "    P_CROSSOVER = 0.5        # probability for crossover\n",
    "    P_MUTATION = 0.5         # probability for mutating an individual\n",
    "    HALL_OF_FAME_SIZE = 1    # Best individuals that pass to the other generation\n",
    "    \n",
    "    # set the random seed:\n",
    "    toolbox = base.Toolbox()\n",
    "\n",
    "    # As we are trying to minimize the RMSE score, that's why using -1.0. \n",
    "    # In case, when you want to maximize accuracy for instance, use 1.0\n",
    "    creator.create('FitnessMin', base.Fitness, weights = [-1.0])\n",
    "    creator.create('Individual', list , fitness = creator.FitnessMin)\n",
    "\n",
    "    # create the individual operator to fill up an Individual instance:\n",
    "    toolbox.register('binary', bernoulli.rvs, 0.5)\n",
    "    toolbox.register('individual', tools.initRepeat, creator.Individual, toolbox.binary, n = gene_length)\n",
    "\n",
    "    # create the population operator to generate a list of individuals:\n",
    "    toolbox.register('population', tools.initRepeat, list , toolbox.individual)\n",
    "\n",
    "    # genetic operators:\n",
    "    toolbox.register('evaluate', train_evaluate)\n",
    "    toolbox.register('select', tools.selTournament, tournsize = 2)\n",
    "    toolbox.register('mutate', tools.mutFlipBit, indpb = 0.11)\n",
    "    toolbox.register('mate', tools.cxUniform, indpb = 0.5)\n",
    "    \n",
    "    # create initial population (generation 0):\n",
    "    population = toolbox.population(n=population_size)\n",
    "\n",
    "    # prepare the statistics object:\n",
    "    stats = tools.Statistics(lambda ind: ind.fitness.values)\n",
    "    stats.register(\"min\", np.min)\n",
    "    stats.register(\"avg\", np.mean)\n",
    "    stats.register(\"max\", np.max)\n",
    "\n",
    "    # define the hall-of-fame object:\n",
    "    hof = tools.HallOfFame(HALL_OF_FAME_SIZE)\n",
    "\n",
    "    # Genetic Algorithm flow with elitism:\n",
    "    population, logbook = eaSimpleWithElitism(population, toolbox, cxpb=P_CROSSOVER, mutpb=P_MUTATION,\n",
    "                                              ngen=max_generations, stats=stats, halloffame=hof, verbose=True)\n",
    "\n",
    "    # print info for best solution found:\n",
    "    best = hof.items[0]\n",
    "    print(\"-- Best Individual = \", best)\n",
    "    print(\"-- Best Fitness = \", best.fitness.values[0])\n",
    "\n",
    "    # extract statistics:\n",
    "    minFitnessValues, meanFitnessValues, maxFitnessValues = logbook.select(\"min\", \"max\", \"avg\")\n",
    "\n",
    "    # plot statistics:\n",
    "    sns.set_style(\"whitegrid\")\n",
    "    plt.plot(minFitnessValues, color='blue', label=\"Min\")\n",
    "    plt.plot(meanFitnessValues, color='green', label=\"Mean\")\n",
    "    plt.plot(maxFitnessValues, color='red', label=\"Max\")\n",
    "    plt.xlabel('Generation'); plt.ylabel('Max / Min / Average Fitness')\n",
    "    plt.legend()\n",
    "    plt.title('Max, Min and Average fitness over Generations')\n",
    "    plt.show()\n",
    "    \n",
    "    best_population = tools.selBest(population,k = k)\n",
    "    return best_population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------------- Starting trial: 1 ---------------\n",
      "Deep layers: 3 , Number of neurons: 100 , Learning rate: 0.005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-16 20:40:56.476504: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-16 20:40:56.476833: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-12-16 20:40:56.476926: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory\n",
      "2022-12-16 20:40:56.477003: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory\n",
      "2022-12-16 20:40:56.477075: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcufft.so.10'; dlerror: libcufft.so.10: cannot open shared object file: No such file or directory\n",
      "2022-12-16 20:40:56.477147: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcurand.so.10'; dlerror: libcurand.so.10: cannot open shared object file: No such file or directory\n",
      "2022-12-16 20:40:56.477217: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory\n",
      "2022-12-16 20:40:56.477287: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory\n",
      "2022-12-16 20:40:56.477358: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2022-12-16 20:40:56.477371: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1934] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2022-12-16 20:40:56.478243: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1171 - mean_squared_error: 0.1171\n",
      "Loss: 0.11713431030511856 , Elapsed time: 157.97067666053772\n",
      "-------------------------------------------------\n",
      "\n",
      "\n",
      "--------------- Starting trial: 2 ---------------\n",
      "Deep layers: 2 , Number of neurons: 200 , Learning rate: 0.0001\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0487 - mean_squared_error: 0.0487\n",
      "Loss: 0.04872516542673111 , Elapsed time: 26.06775999069214\n",
      "-------------------------------------------------\n",
      "\n",
      "\n",
      "--------------- Starting trial: 3 ---------------\n",
      "Deep layers: 4 , Number of neurons: 200 , Learning rate: 0.005\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0471 - mean_squared_error: 0.0471\n",
      "Loss: 0.04712760075926781 , Elapsed time: 38.20367383956909\n",
      "-------------------------------------------------\n",
      "\n",
      "\n",
      "--------------- Starting trial: 4 ---------------\n",
      "Deep layers: 1 , Number of neurons: 100 , Learning rate: 0.0001\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0739 - mean_squared_error: 0.0739\n",
      "Loss: 0.07392831891775131 , Elapsed time: 83.03227877616882\n",
      "-------------------------------------------------\n",
      "\n",
      "\n",
      "--------------- Starting trial: 5 ---------------\n",
      "Deep layers: 2 , Number of neurons: 100 , Learning rate: 0.0001\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0385 - mean_squared_error: 0.0385\n",
      "Loss: 0.03853312134742737 , Elapsed time: 83.17290186882019\n",
      "-------------------------------------------------\n",
      "\n",
      "gen\tnevals\tmin      \tavg      \tmax     \n",
      "0  \t5     \t0.0385331\t0.0650897\t0.117134\n",
      "\n",
      "--------------- Starting trial: 6 ---------------\n",
      "Deep layers: 2 , Number of neurons: 100 , Learning rate: 0.0001\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0368 - mean_squared_error: 0.0368\n",
      "Loss: 0.03677813336253166 , Elapsed time: 88.80115032196045\n",
      "-------------------------------------------------\n",
      "\n",
      "\n",
      "--------------- Starting trial: 7 ---------------\n",
      "Deep layers: 1 , Number of neurons: 100 , Learning rate: 0.005\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0497 - mean_squared_error: 0.0497\n",
      "Loss: 0.049677763134241104 , Elapsed time: 83.03127074241638\n",
      "-------------------------------------------------\n",
      "\n",
      "\n",
      "--------------- Starting trial: 8 ---------------\n",
      "Deep layers: 1 , Number of neurons: 100 , Learning rate: 0.0001\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0715 - mean_squared_error: 0.0715\n",
      "Loss: 0.07149871438741684 , Elapsed time: 66.14546990394592\n",
      "-------------------------------------------------\n",
      "\n",
      "\n",
      "--------------- Starting trial: 9 ---------------\n",
      "Deep layers: 2 , Number of neurons: 100 , Learning rate: 0.0001\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0359 - mean_squared_error: 0.0359\n",
      "Loss: 0.035898443311452866 , Elapsed time: 83.21392512321472\n",
      "-------------------------------------------------\n",
      "\n",
      "1  \t4     \t0.0358984\t0.0464772\t0.0714987\n",
      "\n",
      "--------------- Starting trial: 10 ---------------\n",
      "Deep layers: 2 , Number of neurons: 100 , Learning rate: 0.005\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0352 - mean_squared_error: 0.0352\n",
      "Loss: 0.03519608452916145 , Elapsed time: 74.67976903915405\n",
      "-------------------------------------------------\n",
      "\n",
      "\n",
      "--------------- Starting trial: 11 ---------------\n",
      "Deep layers: 2 , Number of neurons: 100 , Learning rate: 0.0001\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0338 - mean_squared_error: 0.0338\n",
      "Loss: 0.03383804112672806 , Elapsed time: 143.84657049179077\n",
      "-------------------------------------------------\n",
      "\n",
      "\n",
      "--------------- Starting trial: 12 ---------------\n",
      "Deep layers: 2 , Number of neurons: 100 , Learning rate: 0.0001\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0324 - mean_squared_error: 0.0324\n",
      "Loss: 0.032387688755989075 , Elapsed time: 140.01054906845093\n",
      "-------------------------------------------------\n",
      "\n",
      "2  \t3     \t0.0323877\t0.0351707\t0.0385331\n",
      "\n",
      "--------------- Starting trial: 13 ---------------\n",
      "Deep layers: 2 , Number of neurons: 100 , Learning rate: 0.0001\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0393 - mean_squared_error: 0.0393\n",
      "Loss: 0.039250705391168594 , Elapsed time: 84.56164240837097\n",
      "-------------------------------------------------\n",
      "\n",
      "\n",
      "--------------- Starting trial: 14 ---------------\n",
      "Deep layers: 2 , Number of neurons: 50 , Learning rate: 0.005\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0565 - mean_squared_error: 0.0565\n",
      "Loss: 0.05646711587905884 , Elapsed time: 83.32285594940186\n",
      "-------------------------------------------------\n",
      "\n",
      "\n",
      "--------------- Starting trial: 15 ---------------\n",
      "Deep layers: 1 , Number of neurons: 100 , Learning rate: 0.0001\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0762 - mean_squared_error: 0.0762\n",
      "Loss: 0.07624811679124832 , Elapsed time: 83.04010772705078\n",
      "-------------------------------------------------\n",
      "\n",
      "3  \t3     \t0.0323877\t0.0485773\t0.0762481\n",
      "\n",
      "--------------- Starting trial: 16 ---------------\n",
      "Deep layers: 1 , Number of neurons: 100 , Learning rate: 0.0001\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.2670 - mean_squared_error: 0.2670\n",
      "Loss: 0.26701727509498596 , Elapsed time: 67.59564638137817\n",
      "-------------------------------------------------\n",
      "\n",
      "\n",
      "--------------- Starting trial: 17 ---------------\n",
      "Deep layers: 2 , Number of neurons: 100 , Learning rate: 0.0001\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0361 - mean_squared_error: 0.0361\n",
      "Loss: 0.036067984998226166 , Elapsed time: 83.32764601707458\n",
      "-------------------------------------------------\n",
      "\n",
      "\n",
      "--------------- Starting trial: 18 ---------------\n",
      "Deep layers: 2 , Number of neurons: 100 , Learning rate: 0.0001\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0312 - mean_squared_error: 0.0312\n",
      "Loss: 0.031228082254529 , Elapsed time: 143.34351086616516\n",
      "-------------------------------------------------\n",
      "\n",
      "\n",
      "--------------- Starting trial: 19 ---------------\n",
      "Deep layers: 2 , Number of neurons: 100 , Learning rate: 0.0001\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0429 - mean_squared_error: 0.0429\n",
      "Loss: 0.04292174428701401 , Elapsed time: 144.22354221343994\n",
      "-------------------------------------------------\n",
      "\n",
      "4  \t4     \t0.0312281\t0.0819246\t0.267017 \n",
      "\n",
      "--------------- Starting trial: 20 ---------------\n",
      "Deep layers: 1 , Number of neurons: 200 , Learning rate: 0.0001\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0437 - mean_squared_error: 0.0437\n",
      "Loss: 0.04367363825440407 , Elapsed time: 139.2972753047943\n",
      "-------------------------------------------------\n",
      "\n",
      "\n",
      "--------------- Starting trial: 21 ---------------\n",
      "Deep layers: 2 , Number of neurons: 100 , Learning rate: 0.0001\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0363 - mean_squared_error: 0.0363\n",
      "Loss: 0.0363144688308239 , Elapsed time: 155.44690918922424\n",
      "-------------------------------------------------\n",
      "\n",
      "5  \t2     \t0.0312281\t0.0359344\t0.0436736\n",
      "\n",
      "--------------- Starting trial: 22 ---------------\n",
      "Deep layers: 2 , Number of neurons: 100 , Learning rate: 0.0001\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0338 - mean_squared_error: 0.0338\n",
      "Loss: 0.03375324606895447 , Elapsed time: 146.53898000717163\n",
      "-------------------------------------------------\n",
      "\n",
      "\n",
      "--------------- Starting trial: 23 ---------------\n",
      "Deep layers: 2 , Number of neurons: 200 , Learning rate: 0.0001\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0306 - mean_squared_error: 0.0306\n",
      "Loss: 0.030603695660829544 , Elapsed time: 203.68999886512756\n",
      "-------------------------------------------------\n",
      "\n",
      "\n",
      "--------------- Starting trial: 24 ---------------\n",
      "Deep layers: 2 , Number of neurons: 100 , Learning rate: 0.0001\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0321 - mean_squared_error: 0.0321\n",
      "Loss: 0.032105717808008194 , Elapsed time: 158.763685464859\n",
      "-------------------------------------------------\n",
      "\n",
      "\n",
      "--------------- Starting trial: 25 ---------------\n",
      "Deep layers: 2 , Number of neurons: 100 , Learning rate: 0.0001\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0326 - mean_squared_error: 0.0326\n",
      "Loss: 0.03259583190083504 , Elapsed time: 203.4131600856781\n",
      "-------------------------------------------------\n",
      "\n",
      "6  \t4     \t0.0306037\t0.0322892\t0.0337532\n",
      "\n",
      "--------------- Starting trial: 26 ---------------\n",
      "Deep layers: 2 , Number of neurons: 200 , Learning rate: 0.005\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0920 - mean_squared_error: 0.0920\n",
      "Loss: 0.09198781102895737 , Elapsed time: 203.35576009750366\n",
      "-------------------------------------------------\n",
      "\n",
      "\n",
      "--------------- Starting trial: 27 ---------------\n",
      "Deep layers: 2 , Number of neurons: 200 , Learning rate: 0.005\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1006 - mean_squared_error: 0.1006\n",
      "Loss: 0.10062847286462784 , Elapsed time: 204.3575520515442\n",
      "-------------------------------------------------\n",
      "\n",
      "\n",
      "--------------- Starting trial: 28 ---------------\n",
      "Deep layers: 3 , Number of neurons: 200 , Learning rate: 0.0001\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0342 - mean_squared_error: 0.0342\n",
      "Loss: 0.03424103930592537 , Elapsed time: 203.841148853302\n",
      "-------------------------------------------------\n",
      "\n",
      "\n",
      "--------------- Starting trial: 29 ---------------\n",
      "Deep layers: 2 , Number of neurons: 200 , Learning rate: 0.0001\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0302 - mean_squared_error: 0.0302\n",
      "Loss: 0.030192896723747253 , Elapsed time: 140.54719996452332\n",
      "-------------------------------------------------\n",
      "\n",
      "7  \t4     \t0.0301929\t0.0575308\t0.100628 \n",
      "\n",
      "--------------- Starting trial: 30 ---------------\n",
      "Deep layers: 2 , Number of neurons: 200 , Learning rate: 0.0001\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0327 - mean_squared_error: 0.0327\n",
      "Loss: 0.03271058574318886 , Elapsed time: 143.5376718044281\n",
      "-------------------------------------------------\n",
      "\n",
      "\n",
      "--------------- Starting trial: 31 ---------------\n",
      "Deep layers: 1 , Number of neurons: 200 , Learning rate: 0.0001\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1723 - mean_squared_error: 0.1723\n",
      "Loss: 0.17225489020347595 , Elapsed time: 42.06563091278076\n",
      "-------------------------------------------------\n",
      "\n",
      "\n",
      "--------------- Starting trial: 32 ---------------\n",
      "Deep layers: 1 , Number of neurons: 200 , Learning rate: 0.0001\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0445 - mean_squared_error: 0.0445\n",
      "Loss: 0.04449906200170517 , Elapsed time: 99.90975522994995\n",
      "-------------------------------------------------\n",
      "\n",
      "8  \t3     \t0.0306037\t0.0628619\t0.172255 \n",
      "\n",
      "--------------- Starting trial: 33 ---------------\n",
      "Deep layers: 2 , Number of neurons: 200 , Learning rate: 0.0001\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0316 - mean_squared_error: 0.0316\n",
      "Loss: 0.031602516770362854 , Elapsed time: 148.79492855072021\n",
      "-------------------------------------------------\n",
      "\n",
      "\n",
      "--------------- Starting trial: 34 ---------------\n",
      "Deep layers: 3 , Number of neurons: 200 , Learning rate: 0.0001\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0338 - mean_squared_error: 0.0338\n",
      "Loss: 0.03384411334991455 , Elapsed time: 161.48542094230652\n",
      "-------------------------------------------------\n",
      "\n",
      "\n",
      "--------------- Starting trial: 35 ---------------\n",
      "Deep layers: 3 , Number of neurons: 200 , Learning rate: 0.0001\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0459 - mean_squared_error: 0.0459\n",
      "Loss: 0.04594296216964722 , Elapsed time: 51.996567726135254\n",
      "-------------------------------------------------\n",
      "\n",
      "\n",
      "--------------- Starting trial: 36 ---------------\n",
      "Deep layers: 1 , Number of neurons: 200 , Learning rate: 0.0001\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0590 - mean_squared_error: 0.0590\n",
      "Loss: 0.05897032842040062 , Elapsed time: 59.524105072021484\n",
      "-------------------------------------------------\n",
      "\n",
      "9  \t4     \t0.0306037\t0.0401927\t0.0589703\n",
      "\n",
      "--------------- Starting trial: 37 ---------------\n",
      "Deep layers: 3 , Number of neurons: 200 , Learning rate: 0.0001\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0354 - mean_squared_error: 0.0354\n",
      "Loss: 0.03537868335843086 , Elapsed time: 163.50107789039612\n",
      "-------------------------------------------------\n",
      "\n",
      "\n",
      "--------------- Starting trial: 38 ---------------\n",
      "Deep layers: 3 , Number of neurons: 200 , Learning rate: 0.0001\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0360 - mean_squared_error: 0.0360\n",
      "Loss: 0.03604763373732567 , Elapsed time: 144.6208791732788\n",
      "-------------------------------------------------\n",
      "\n",
      "10 \t2     \t0.0306037\t0.0326475\t0.0360476\n",
      "-- Best Individual =  [0, 1, 1, 1, 0, 0, 0]\n",
      "-- Best Fitness =  0.030603695660829544\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total elapsed time: 75.54255432287852 minutes\n"
     ]
    }
   ],
   "source": [
    "population_size = 5   # max of individuals per generation\n",
    "max_generations = 10  # number of generations\n",
    "gene_length = 7      # lenght of the gene, depends on how many hiperparameters are tested  \n",
    "k = 1;                 # num. of finalist individuals\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    t = time.time(); \n",
    "    datos = [];\n",
    "    ss = [i for i in range(1,population_size*(max_generations+1))]\n",
    "    best_population = geneticAlgorithm_with_elitism(population_size, max_generations, gene_length, k)\n",
    "    print(\"Total elapsed time:\", (time.time()-t)/60, \"minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k= 1 \n",
      "Deep layers: 1 , Number of neurons: 100\n",
      "Batch size 4 , Learning rate: 0.005\n"
     ]
    }
   ],
   "source": [
    "best_deep_layers   = []\n",
    "best_num_units     = []\n",
    "best_learning_rate = []\n",
    "best_batch_size    = []\n",
    "# best_activation_f  = []\n",
    "best_f_names       = []\n",
    "\n",
    "t = 0\n",
    "\n",
    "for bi in best_population:\n",
    "    deep_layers_bits   = BitArray(bi[0:1])    # (8)\n",
    "    num_units_bits     = BitArray(bi[1:2])    # (16)\n",
    "    learning_rate_bits = BitArray(bi[2:3])   # (8)\n",
    "    batch_size_bits    = BitArray(bi[3:4])  # (4)\n",
    "#     activation_f_bits  = BitArray(bi[12:13])  # (2)\n",
    "    t += 1 \n",
    "    \n",
    "    best_deep_layers.append(SC_DEEP[deep_layers_bits.uint])\n",
    "    best_num_units.append(SC_NUM_UNITS[num_units_bits.uint])\n",
    "    best_learning_rate.append(SC_LEARNING[learning_rate_bits.uint])\n",
    "    best_batch_size.append(SC_BATCH[batch_size_bits.uint])\n",
    "#     best_activation_f.append(SC_ACTIVATION[activation_f_bits.uint])\n",
    "#     best_f_names.append(f_names[activation_f_bits.uint])\n",
    "    print('k=',t,'\\nDeep layers:', best_deep_layers[-1], ', Number of neurons:', best_num_units[-1])\n",
    "    print('Batch size', best_batch_size[-1], ', Learning rate:', best_learning_rate[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Deep layers</th>\n",
       "      <th>Num units</th>\n",
       "      <th>Learning rate</th>\n",
       "      <th>Batch size</th>\n",
       "      <th>Loss</th>\n",
       "      <th>Score</th>\n",
       "      <th>Elapsed time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>200</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>2</td>\n",
       "      <td>0.030193</td>\n",
       "      <td>0.030193</td>\n",
       "      <td>140.547200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>200</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>2</td>\n",
       "      <td>0.030604</td>\n",
       "      <td>0.030604</td>\n",
       "      <td>203.689999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>2</td>\n",
       "      <td>0.031228</td>\n",
       "      <td>0.031228</td>\n",
       "      <td>143.343511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>200</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>2</td>\n",
       "      <td>0.031603</td>\n",
       "      <td>0.031603</td>\n",
       "      <td>148.794929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>2</td>\n",
       "      <td>0.032106</td>\n",
       "      <td>0.032106</td>\n",
       "      <td>158.763685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>2</td>\n",
       "      <td>0.032388</td>\n",
       "      <td>0.032388</td>\n",
       "      <td>140.010549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>2</td>\n",
       "      <td>0.032596</td>\n",
       "      <td>0.032596</td>\n",
       "      <td>203.413160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2</td>\n",
       "      <td>200</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>2</td>\n",
       "      <td>0.032711</td>\n",
       "      <td>0.032711</td>\n",
       "      <td>143.537672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>2</td>\n",
       "      <td>0.033753</td>\n",
       "      <td>0.033753</td>\n",
       "      <td>146.538980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>4</td>\n",
       "      <td>0.033838</td>\n",
       "      <td>0.033838</td>\n",
       "      <td>143.846570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>3</td>\n",
       "      <td>200</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>2</td>\n",
       "      <td>0.033844</td>\n",
       "      <td>0.033844</td>\n",
       "      <td>161.485421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>3</td>\n",
       "      <td>200</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>2</td>\n",
       "      <td>0.034241</td>\n",
       "      <td>0.034241</td>\n",
       "      <td>203.841149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0050</td>\n",
       "      <td>4</td>\n",
       "      <td>0.035196</td>\n",
       "      <td>0.035196</td>\n",
       "      <td>74.679769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>3</td>\n",
       "      <td>200</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>2</td>\n",
       "      <td>0.035379</td>\n",
       "      <td>0.035379</td>\n",
       "      <td>163.501078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>4</td>\n",
       "      <td>0.035898</td>\n",
       "      <td>0.035898</td>\n",
       "      <td>83.213925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>3</td>\n",
       "      <td>200</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>2</td>\n",
       "      <td>0.036048</td>\n",
       "      <td>0.036048</td>\n",
       "      <td>144.620879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>4</td>\n",
       "      <td>0.036068</td>\n",
       "      <td>0.036068</td>\n",
       "      <td>83.327646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>2</td>\n",
       "      <td>0.036314</td>\n",
       "      <td>0.036314</td>\n",
       "      <td>155.446909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>4</td>\n",
       "      <td>0.036778</td>\n",
       "      <td>0.036778</td>\n",
       "      <td>88.801150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>4</td>\n",
       "      <td>0.038533</td>\n",
       "      <td>0.038533</td>\n",
       "      <td>83.172902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>4</td>\n",
       "      <td>0.039251</td>\n",
       "      <td>0.039251</td>\n",
       "      <td>84.561642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>4</td>\n",
       "      <td>0.042922</td>\n",
       "      <td>0.042922</td>\n",
       "      <td>144.223542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1</td>\n",
       "      <td>200</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>2</td>\n",
       "      <td>0.043674</td>\n",
       "      <td>0.043674</td>\n",
       "      <td>139.297275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1</td>\n",
       "      <td>200</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>2</td>\n",
       "      <td>0.044499</td>\n",
       "      <td>0.044499</td>\n",
       "      <td>99.909755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>3</td>\n",
       "      <td>200</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>8</td>\n",
       "      <td>0.045943</td>\n",
       "      <td>0.045943</td>\n",
       "      <td>51.996568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>4</td>\n",
       "      <td>200</td>\n",
       "      <td>0.0050</td>\n",
       "      <td>16</td>\n",
       "      <td>0.047128</td>\n",
       "      <td>0.047128</td>\n",
       "      <td>38.203674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2</td>\n",
       "      <td>200</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>16</td>\n",
       "      <td>0.048725</td>\n",
       "      <td>0.048725</td>\n",
       "      <td>26.067760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0050</td>\n",
       "      <td>4</td>\n",
       "      <td>0.049678</td>\n",
       "      <td>0.049678</td>\n",
       "      <td>83.031271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>0.0050</td>\n",
       "      <td>4</td>\n",
       "      <td>0.056467</td>\n",
       "      <td>0.056467</td>\n",
       "      <td>83.322856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1</td>\n",
       "      <td>200</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>4</td>\n",
       "      <td>0.058970</td>\n",
       "      <td>0.058970</td>\n",
       "      <td>59.524105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>4</td>\n",
       "      <td>0.071499</td>\n",
       "      <td>0.071499</td>\n",
       "      <td>66.145470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>4</td>\n",
       "      <td>0.073928</td>\n",
       "      <td>0.073928</td>\n",
       "      <td>83.032279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>4</td>\n",
       "      <td>0.076248</td>\n",
       "      <td>0.076248</td>\n",
       "      <td>83.040108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>2</td>\n",
       "      <td>200</td>\n",
       "      <td>0.0050</td>\n",
       "      <td>2</td>\n",
       "      <td>0.091988</td>\n",
       "      <td>0.091988</td>\n",
       "      <td>203.355760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>2</td>\n",
       "      <td>200</td>\n",
       "      <td>0.0050</td>\n",
       "      <td>2</td>\n",
       "      <td>0.100628</td>\n",
       "      <td>0.100628</td>\n",
       "      <td>204.357552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0050</td>\n",
       "      <td>2</td>\n",
       "      <td>0.117134</td>\n",
       "      <td>0.117134</td>\n",
       "      <td>157.970677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>1</td>\n",
       "      <td>200</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>16</td>\n",
       "      <td>0.172255</td>\n",
       "      <td>0.172255</td>\n",
       "      <td>42.065631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>4</td>\n",
       "      <td>0.267017</td>\n",
       "      <td>0.267017</td>\n",
       "      <td>67.595646</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Deep layers  Num units  Learning rate  Batch size      Loss     Score  \\\n",
       "0             2        200         0.0001           2  0.030193  0.030193   \n",
       "1             2        200         0.0001           2  0.030604  0.030604   \n",
       "2             2        100         0.0001           2  0.031228  0.031228   \n",
       "3             2        200         0.0001           2  0.031603  0.031603   \n",
       "4             2        100         0.0001           2  0.032106  0.032106   \n",
       "5             2        100         0.0001           2  0.032388  0.032388   \n",
       "6             2        100         0.0001           2  0.032596  0.032596   \n",
       "7             2        200         0.0001           2  0.032711  0.032711   \n",
       "8             2        100         0.0001           2  0.033753  0.033753   \n",
       "9             2        100         0.0001           4  0.033838  0.033838   \n",
       "10            3        200         0.0001           2  0.033844  0.033844   \n",
       "11            3        200         0.0001           2  0.034241  0.034241   \n",
       "12            2        100         0.0050           4  0.035196  0.035196   \n",
       "13            3        200         0.0001           2  0.035379  0.035379   \n",
       "14            2        100         0.0001           4  0.035898  0.035898   \n",
       "15            3        200         0.0001           2  0.036048  0.036048   \n",
       "16            2        100         0.0001           4  0.036068  0.036068   \n",
       "17            2        100         0.0001           2  0.036314  0.036314   \n",
       "18            2        100         0.0001           4  0.036778  0.036778   \n",
       "19            2        100         0.0001           4  0.038533  0.038533   \n",
       "20            2        100         0.0001           4  0.039251  0.039251   \n",
       "21            2        100         0.0001           4  0.042922  0.042922   \n",
       "22            1        200         0.0001           2  0.043674  0.043674   \n",
       "23            1        200         0.0001           2  0.044499  0.044499   \n",
       "24            3        200         0.0001           8  0.045943  0.045943   \n",
       "25            4        200         0.0050          16  0.047128  0.047128   \n",
       "26            2        200         0.0001          16  0.048725  0.048725   \n",
       "27            1        100         0.0050           4  0.049678  0.049678   \n",
       "28            2         50         0.0050           4  0.056467  0.056467   \n",
       "29            1        200         0.0001           4  0.058970  0.058970   \n",
       "30            1        100         0.0001           4  0.071499  0.071499   \n",
       "31            1        100         0.0001           4  0.073928  0.073928   \n",
       "32            1        100         0.0001           4  0.076248  0.076248   \n",
       "33            2        200         0.0050           2  0.091988  0.091988   \n",
       "34            2        200         0.0050           2  0.100628  0.100628   \n",
       "35            3        100         0.0050           2  0.117134  0.117134   \n",
       "36            1        200         0.0001          16  0.172255  0.172255   \n",
       "37            1        100         0.0001           4  0.267017  0.267017   \n",
       "\n",
       "    Elapsed time  \n",
       "0     140.547200  \n",
       "1     203.689999  \n",
       "2     143.343511  \n",
       "3     148.794929  \n",
       "4     158.763685  \n",
       "5     140.010549  \n",
       "6     203.413160  \n",
       "7     143.537672  \n",
       "8     146.538980  \n",
       "9     143.846570  \n",
       "10    161.485421  \n",
       "11    203.841149  \n",
       "12     74.679769  \n",
       "13    163.501078  \n",
       "14     83.213925  \n",
       "15    144.620879  \n",
       "16     83.327646  \n",
       "17    155.446909  \n",
       "18     88.801150  \n",
       "19     83.172902  \n",
       "20     84.561642  \n",
       "21    144.223542  \n",
       "22    139.297275  \n",
       "23     99.909755  \n",
       "24     51.996568  \n",
       "25     38.203674  \n",
       "26     26.067760  \n",
       "27     83.031271  \n",
       "28     83.322856  \n",
       "29     59.524105  \n",
       "30     66.145470  \n",
       "31     83.032279  \n",
       "32     83.040108  \n",
       "33    203.355760  \n",
       "34    204.357552  \n",
       "35    157.970677  \n",
       "36     42.065631  \n",
       "37     67.595646  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename = \"historial_genetic_jla1.txt\"\n",
    "df = pd.DataFrame(datos, columns = [\"Deep layers\", \"Num units\", \"Learning rate\", \"Batch size\", \"Loss\", \"Score\", \"Elapsed time\"])\n",
    "\n",
    "df.sort_values(by=[\"Loss\", \"Elapsed time\"], ascending=[True, True], ignore_index=True, inplace=True)\n",
    "\n",
    "df.to_csv(filename, header=True, index=False, sep='\\t', mode='w') # a=append, w=overwrite\n",
    "df.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time 75.538 minutes\n"
     ]
    }
   ],
   "source": [
    "total_time = float(np.sum(df[[\"Elapsed time\"]])/60)\n",
    "\n",
    "print(\"Elapsed time {:.3f} minutes\".format(total_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
