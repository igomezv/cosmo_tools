{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-18 19:23:18.752062: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-12-18 19:23:18.886145: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-12-18 19:23:18.886164: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2022-12-18 19:23:19.882803: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2022-12-18 19:23:19.882937: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2022-12-18 19:23:19.882961: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import time, os\n",
    "import random\n",
    "import seaborn as sns\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Input, Dense, LeakyReLU\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorboard.plugins.hparams import api as hp\n",
    "\n",
    "from tensorflow.keras import activations\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "import random\n",
    "from math import floor\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import optimizers\n",
    "from scipy.integrate import odeint\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split as split\n",
    "from scipy.stats import bernoulli\n",
    "\n",
    "# import deap\n",
    "from deap import base, creator, tools, algorithms\n",
    "\n",
    "from bitstring import BitArray\n",
    "\n",
    "# from elitism import eaSimpleWithElitism, main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "\n",
    "# tf.config.optimizer.set_jit(True)\n",
    "# scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "url = 'https://raw.githubusercontent.com/igomezv/nnogada/main/data/jla.csv'\n",
    "df=pd.read_csv(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = len(df.values)\n",
    "randomize = np.random.permutation(N)\n",
    "data = df.values[randomize]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(740, 2)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N = len(df.values)\n",
    "z = data[:,0] \n",
    "y = data[:,1:3] ### coge el resto de variables a predecir \n",
    "y[:,1] = y[:,1]**2+data[:,2]\n",
    "np.shape(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "scalerz = StandardScaler()\n",
    "scalerz.fit(z.reshape(-1,1))\n",
    "z = scalerz.transform(z.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((592, 1), (148, 1), (592, 2), (148, 2))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Modificar para incluir phanteon como test\n",
    "split = 0.8\n",
    "ntrain = int(split * len(z))\n",
    "indx = [ntrain]\n",
    "X_train, X_val = np.split(z, indx)\n",
    "Y_train, Y_val = np.split(y, indx)\n",
    "# X_train, X_test = np.split(z, indx)\n",
    "# Y_train, Y_test = np.split(y, indx)\n",
    "np.shape(X_train), np.shape(X_val), Y_train.shape, Y_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "SC_DEEP       = np.array([1,2,3,4])                           # Number of deep layers (8)\n",
    "SC_NUM_UNITS  = np.array([50,100,150,200]) # Number of fully conected neurons (16)\n",
    "SC_LEARNING   = np.array([1e-4,1e-3])   # Learning rates (8)\n",
    "SC_BATCH      = np.array([2, 4, 8, 16])                            # Batch sizes (4)\n",
    "# SC_ACTIVATION = [f1, f2, f3, f4]                                      # Activation function layers (2)\n",
    "\n",
    "my_callbacks = [tf.keras.callbacks.EarlyStopping(\n",
    "                               monitor='val_loss', mode='min',\n",
    "                               min_delta=0, \n",
    "                               patience=200,\n",
    "                               verbose=1,\n",
    "                            #    baseline=0,\n",
    "                               restore_best_weights=True)\n",
    "#                 keras.callbacks.TensorBoard(\n",
    "#                                log_dir='./logs'),\n",
    "#                 keras.callbacks.ReduceLROnPlateau(\n",
    "#                                monitor='val_loss', factor=0.5,\n",
    "#                                patience=6, min_lr=0,\n",
    "#                                verbose=1)\n",
    "               ] \n",
    "    \n",
    "epochs = 200\n",
    "# epochs = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_evaluate(ga_individual_solution):   \n",
    "    t = time.time()\n",
    "    t_total = 0\n",
    "    \n",
    "    # Decode GA solution to integer for window_size and num_units\n",
    "    deep_layers_bits   = BitArray(ga_individual_solution[0:2])     # (8)\n",
    "    num_units_bits     = BitArray(ga_individual_solution[2:4])     # (16)\n",
    "    learning_rate_bits = BitArray(ga_individual_solution[4:5])    # (8)\n",
    "    batch_size_bits    = BitArray(ga_individual_solution[5:7])   # (4)\n",
    "# #     activation_f_bits  = BitArray(ga_individual_solution[12:13])   # (2)   Solo se consideran las 2 primeras\n",
    "    \n",
    "    deep_layers   = SC_DEEP[deep_layers_bits.uint]\n",
    "    num_units     = SC_NUM_UNITS[num_units_bits.uint]\n",
    "    learning_rate = SC_LEARNING[learning_rate_bits.uint]\n",
    "    batch_size   = SC_BATCH[batch_size_bits.uint]\n",
    "#     activation_f  = SC_ACTIVATION[activation_f_bits.uint]\n",
    "\n",
    "    \n",
    "    print('\\n--------------- Starting trial:', population_size*(max_generations+1)-len(ss), \"---------------\")\n",
    "    print('Deep layers:',deep_layers,', Number of neurons:',num_units,\", Learning rate:\",learning_rate)\n",
    "#     print(\"-------------------------------------------------\")\n",
    "    \n",
    "    # Train model and predict on validation set\n",
    "    model = tf.keras.Sequential()\n",
    "#     model.add(Input(shape=(int(X_train.shape[1]),)))\n",
    "    model.add(Dense(int(X_train.shape[1])))\n",
    "    \n",
    "    for i in range(deep_layers):        \n",
    "        model.add(Dense(num_units, activation='relu'))\n",
    "#             model.add(keras.layers.Dropout(0.3))\n",
    "    model.add(Dense(2, activation='linear'))\n",
    "    \n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate, beta_1=0.9, beta_2=0.999, epsilon=1e-3)\n",
    "    model.compile(optimizer=optimizer, loss='mse', metrics=['mean_squared_error'])\n",
    "    model.fit(X_train, Y_train, epochs=epochs, validation_data=(X_val, Y_val),\n",
    "              callbacks=my_callbacks, batch_size=batch_size, shuffle=False, verbose=0)\n",
    "    \n",
    "    loss, score = model.evaluate(X_val, Y_val)    \n",
    "    t = time.time()-t\n",
    "    ss.pop(0)\n",
    "    print(\"Loss:\", score, \", Elapsed time:\", t)\n",
    "    print(\"-------------------------------------------------\\n\")\n",
    "#     print(loss, score)\n",
    "\n",
    "    datos.append([deep_layers, num_units, learning_rate, batch_size, loss, score, t])\n",
    "    \n",
    "    return loss,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deap import tools\n",
    "from deap import algorithms\n",
    "\n",
    "def eaSimpleWithElitism(population, toolbox, cxpb, mutpb, ngen, stats=None,\n",
    "             halloffame=None, verbose=__debug__):\n",
    "    \"\"\"This algorithm is similar to DEAP eaSimple() algorithm, with the modification that\n",
    "    halloffame is used to implement an elitism mechanism. The individuals contained in the\n",
    "    halloffame are directly injected into the next generation and are not subject to the\n",
    "    genetic operators of selection, crossover and mutation.\n",
    "    \"\"\"\n",
    "    logbook = tools.Logbook()\n",
    "    logbook.header = ['gen', 'nevals'] + (stats.fields if stats else [])\n",
    "\n",
    "    # Evaluate the individuals with an invalid fitness\n",
    "    invalid_ind = [ind for ind in population if not ind.fitness.valid]\n",
    "    fitnesses = toolbox.map(toolbox.evaluate, invalid_ind)\n",
    "    for ind, fit in zip(invalid_ind, fitnesses):\n",
    "        ind.fitness.values = fit\n",
    "\n",
    "    if halloffame is None:\n",
    "        raise ValueError(\"halloffame parameter must not be empty!\")\n",
    "\n",
    "    halloffame.update(population)\n",
    "    hof_size = len(halloffame.items) if halloffame.items else 0\n",
    "\n",
    "    record = stats.compile(population) if stats else {}\n",
    "    logbook.record(gen=0, nevals=len(invalid_ind), **record)\n",
    "    if verbose:\n",
    "        print(logbook.stream)\n",
    "\n",
    "    # Begin the generational process\n",
    "    for gen in range(1, ngen + 1):\n",
    "\n",
    "        # Select the next generation individuals\n",
    "        offspring = toolbox.select(population, len(population) - hof_size)\n",
    "\n",
    "        # Vary the pool of individuals\n",
    "        offspring = algorithms.varAnd(offspring, toolbox, cxpb, mutpb)\n",
    "\n",
    "        # Evaluate the individuals with an invalid fitness\n",
    "        invalid_ind = [ind for ind in offspring if not ind.fitness.valid]\n",
    "        fitnesses = toolbox.map(toolbox.evaluate, invalid_ind)\n",
    "        for ind, fit in zip(invalid_ind, fitnesses):\n",
    "            ind.fitness.values = fit\n",
    "\n",
    "        # add the best back to population:\n",
    "        offspring.extend(halloffame.items)\n",
    "\n",
    "        # Update the hall of fame with the generated individuals\n",
    "        halloffame.update(offspring)\n",
    "\n",
    "        # Replace the current population by the offspring\n",
    "        population[:] = offspring\n",
    "\n",
    "        # Append the current generation statistics to the logbook\n",
    "        record = stats.compile(population) if stats else {}\n",
    "        logbook.record(gen=gen, nevals=len(invalid_ind), **record)\n",
    "        if verbose:\n",
    "            print(logbook.stream)\n",
    "\n",
    "    return population, logbook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def geneticAlgorithm_with_elitism(population_size, max_generations, gene_length, k):\n",
    "    \n",
    "    # Genetic Algorithm constants:\n",
    "    P_CROSSOVER = 0.5        # probability for crossover\n",
    "    P_MUTATION = 0.2         # probability for mutating an individual\n",
    "    HALL_OF_FAME_SIZE = 1    # Best individuals that pass to the other generation\n",
    "    \n",
    "    # set the random seed:\n",
    "    toolbox = base.Toolbox()\n",
    "\n",
    "    # As we are trying to minimize the RMSE score, that's why using -1.0. \n",
    "    # In case, when you want to maximize accuracy for instance, use 1.0\n",
    "    creator.create('FitnessMin', base.Fitness, weights = [-1.0])\n",
    "    creator.create('Individual', list , fitness = creator.FitnessMin)\n",
    "\n",
    "    # create the individual operator to fill up an Individual instance:\n",
    "    toolbox.register('binary', bernoulli.rvs, 0.5)\n",
    "    toolbox.register('individual', tools.initRepeat, creator.Individual, toolbox.binary, n = gene_length)\n",
    "\n",
    "    # create the population operator to generate a list of individuals:\n",
    "    toolbox.register('population', tools.initRepeat, list , toolbox.individual)\n",
    "\n",
    "    # genetic operators:\n",
    "    toolbox.register('evaluate', train_evaluate)\n",
    "    toolbox.register('select', tools.selTournament, tournsize = 2)\n",
    "    toolbox.register('mutate', tools.mutFlipBit, indpb = 0.11)\n",
    "    toolbox.register('mate', tools.cxUniform, indpb = 0.5)\n",
    "    \n",
    "    # create initial population (generation 0):\n",
    "    population = toolbox.population(n=population_size)\n",
    "\n",
    "    # prepare the statistics object:\n",
    "    stats = tools.Statistics(lambda ind: ind.fitness.values)\n",
    "    stats.register(\"min\", np.min)\n",
    "    stats.register(\"avg\", np.mean)\n",
    "    stats.register(\"max\", np.max)\n",
    "\n",
    "    # define the hall-of-fame object:\n",
    "    hof = tools.HallOfFame(HALL_OF_FAME_SIZE)\n",
    "\n",
    "    # Genetic Algorithm flow with elitism:\n",
    "    population, logbook = eaSimpleWithElitism(population, toolbox, cxpb=P_CROSSOVER, mutpb=P_MUTATION,\n",
    "                                              ngen=max_generations, stats=stats, halloffame=hof, verbose=True)\n",
    "\n",
    "    # print info for best solution found:\n",
    "    best = hof.items[0]\n",
    "    print(\"-- Best Individual = \", best)\n",
    "    print(\"-- Best Fitness = \", best.fitness.values[0])\n",
    "\n",
    "    # extract statistics:\n",
    "    minFitnessValues, meanFitnessValues, maxFitnessValues = logbook.select(\"min\", \"max\", \"avg\")\n",
    "\n",
    "    # plot statistics:\n",
    "    sns.set_style(\"whitegrid\")\n",
    "    plt.plot(minFitnessValues, color='blue', label=\"Min\")\n",
    "    plt.plot(meanFitnessValues, color='green', label=\"Mean\")\n",
    "    plt.plot(maxFitnessValues, color='red', label=\"Max\")\n",
    "    plt.xlabel('Generation'); plt.ylabel('Max / Min / Average Fitness')\n",
    "    plt.legend()\n",
    "    plt.title('Max, Min and Average fitness over Generations')\n",
    "    plt.show()\n",
    "    \n",
    "    best_population = tools.selBest(population,k = k)\n",
    "    return best_population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------------- Starting trial: 1 ---------------\n",
      "Deep layers: 3 , Number of neurons: 100 , Learning rate: 0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-18 19:23:21.036300: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-18 19:23:21.036621: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-12-18 19:23:21.036684: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory\n",
      "2022-12-18 19:23:21.036751: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory\n",
      "2022-12-18 19:23:21.036819: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcufft.so.10'; dlerror: libcufft.so.10: cannot open shared object file: No such file or directory\n",
      "2022-12-18 19:23:21.036880: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcurand.so.10'; dlerror: libcurand.so.10: cannot open shared object file: No such file or directory\n",
      "2022-12-18 19:23:21.036933: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory\n",
      "2022-12-18 19:23:21.036985: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory\n",
      "2022-12-18 19:23:21.037036: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2022-12-18 19:23:21.037046: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1934] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2022-12-18 19:23:21.037261: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0816 - mean_squared_error: 0.0816\n",
      "Loss: 0.08157148212194443 , Elapsed time: 128.32738161087036\n",
      "-------------------------------------------------\n",
      "\n",
      "\n",
      "--------------- Starting trial: 2 ---------------\n",
      "Deep layers: 2 , Number of neurons: 200 , Learning rate: 0.0001\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0506 - mean_squared_error: 0.0506\n",
      "Loss: 0.05061854049563408 , Elapsed time: 27.467384338378906\n",
      "-------------------------------------------------\n",
      "\n",
      "\n",
      "--------------- Starting trial: 3 ---------------\n",
      "Deep layers: 4 , Number of neurons: 200 , Learning rate: 0.001\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0784 - mean_squared_error: 0.0784\n",
      "Loss: 0.07838669419288635 , Elapsed time: 42.191662549972534\n",
      "-------------------------------------------------\n",
      "\n",
      "\n",
      "--------------- Starting trial: 4 ---------------\n",
      "Deep layers: 1 , Number of neurons: 100 , Learning rate: 0.0001\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0678 - mean_squared_error: 0.0678\n",
      "Loss: 0.06779778003692627 , Elapsed time: 60.25505781173706\n",
      "-------------------------------------------------\n",
      "\n",
      "\n",
      "--------------- Starting trial: 5 ---------------\n",
      "Deep layers: 2 , Number of neurons: 100 , Learning rate: 0.0001\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0366 - mean_squared_error: 0.0366\n",
      "Loss: 0.036633096635341644 , Elapsed time: 58.08927822113037\n",
      "-------------------------------------------------\n",
      "\n",
      "gen\tnevals\tmin      \tavg      \tmax      \n",
      "0  \t5     \t0.0366331\t0.0630015\t0.0815715\n",
      "1  \t0     \t0.0366331\t0.050578 \t0.0783867\n",
      "\n",
      "--------------- Starting trial: 6 ---------------\n",
      "Deep layers: 2 , Number of neurons: 100 , Learning rate: 0.001\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0495 - mean_squared_error: 0.0495\n",
      "Loss: 0.04952579736709595 , Elapsed time: 67.02236008644104\n",
      "-------------------------------------------------\n",
      "\n",
      "\n",
      "--------------- Starting trial: 7 ---------------\n",
      "Deep layers: 2 , Number of neurons: 100 , Learning rate: 0.0001\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0382 - mean_squared_error: 0.0382\n",
      "Loss: 0.038244836032390594 , Elapsed time: 77.07084274291992\n",
      "-------------------------------------------------\n",
      "\n",
      "\n",
      "--------------- Starting trial: 8 ---------------\n",
      "Deep layers: 2 , Number of neurons: 50 , Learning rate: 0.0001\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0366 - mean_squared_error: 0.0366\n",
      "Loss: 0.03658811375498772 , Elapsed time: 66.70726919174194\n",
      "-------------------------------------------------\n",
      "\n",
      "2  \t3     \t0.0365881\t0.0423221\t0.0506185\n",
      "\n",
      "--------------- Starting trial: 9 ---------------\n",
      "Deep layers: 2 , Number of neurons: 50 , Learning rate: 0.0001\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0355 - mean_squared_error: 0.0355\n",
      "Loss: 0.03554011881351471 , Elapsed time: 143.15559697151184\n",
      "-------------------------------------------------\n",
      "\n",
      "\n",
      "--------------- Starting trial: 10 ---------------\n",
      "Deep layers: 2 , Number of neurons: 200 , Learning rate: 0.0001\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0360 - mean_squared_error: 0.0360\n",
      "Loss: 0.03604220971465111 , Elapsed time: 78.86362886428833\n",
      "-------------------------------------------------\n",
      "\n",
      "\n",
      "--------------- Starting trial: 11 ---------------\n",
      "Deep layers: 2 , Number of neurons: 50 , Learning rate: 0.0001\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0660 - mean_squared_error: 0.0660\n",
      "Loss: 0.0660213828086853 , Elapsed time: 80.35647821426392\n",
      "-------------------------------------------------\n",
      "\n",
      "\n",
      "--------------- Starting trial: 12 ---------------\n",
      "Deep layers: 2 , Number of neurons: 100 , Learning rate: 0.0001\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0397 - mean_squared_error: 0.0397\n",
      "Loss: 0.039726413786411285 , Elapsed time: 83.6841287612915\n",
      "-------------------------------------------------\n",
      "\n",
      "3  \t4     \t0.0355401\t0.0427836\t0.0660214\n",
      "\n",
      "--------------- Starting trial: 13 ---------------\n",
      "Deep layers: 2 , Number of neurons: 50 , Learning rate: 0.0001\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0439 - mean_squared_error: 0.0439\n",
      "Loss: 0.04392421990633011 , Elapsed time: 83.41939735412598\n",
      "-------------------------------------------------\n",
      "\n",
      "\n",
      "--------------- Starting trial: 14 ---------------\n",
      "Deep layers: 4 , Number of neurons: 50 , Learning rate: 0.0001\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0321 - mean_squared_error: 0.0321\n",
      "Loss: 0.03206174448132515 , Elapsed time: 83.8795714378357\n",
      "-------------------------------------------------\n",
      "\n",
      "\n",
      "--------------- Starting trial: 15 ---------------\n",
      "Deep layers: 2 , Number of neurons: 200 , Learning rate: 0.0001\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0366 - mean_squared_error: 0.0366\n",
      "Loss: 0.03660917654633522 , Elapsed time: 79.83170223236084\n",
      "-------------------------------------------------\n",
      "\n",
      "\n",
      "--------------- Starting trial: 16 ---------------\n",
      "Deep layers: 2 , Number of neurons: 200 , Learning rate: 0.0001\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0359 - mean_squared_error: 0.0359\n",
      "Loss: 0.03589552640914917 , Elapsed time: 89.36112546920776\n",
      "-------------------------------------------------\n",
      "\n",
      "4  \t4     \t0.0320617\t0.0368062\t0.0439242\n",
      "\n",
      "--------------- Starting trial: 17 ---------------\n",
      "Deep layers: 2 , Number of neurons: 150 , Learning rate: 0.0001\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0394 - mean_squared_error: 0.0394\n",
      "Loss: 0.039375290274620056 , Elapsed time: 74.0304868221283\n",
      "-------------------------------------------------\n",
      "\n",
      "\n",
      "--------------- Starting trial: 18 ---------------\n",
      "Deep layers: 2 , Number of neurons: 100 , Learning rate: 0.0001\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0434 - mean_squared_error: 0.0434\n",
      "Loss: 0.04336587339639664 , Elapsed time: 42.05470848083496\n",
      "-------------------------------------------------\n",
      "\n",
      "\n",
      "--------------- Starting trial: 19 ---------------\n",
      "Deep layers: 2 , Number of neurons: 150 , Learning rate: 0.0001\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0372 - mean_squared_error: 0.0372\n",
      "Loss: 0.037237972021102905 , Elapsed time: 76.15791368484497\n",
      "-------------------------------------------------\n",
      "\n",
      "\n",
      "--------------- Starting trial: 20 ---------------\n",
      "Deep layers: 2 , Number of neurons: 100 , Learning rate: 0.0001\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0337 - mean_squared_error: 0.0337\n",
      "Loss: 0.03367933630943298 , Elapsed time: 119.01869416236877\n",
      "-------------------------------------------------\n",
      "\n",
      "5  \t4     \t0.0320617\t0.037144 \t0.0433659\n",
      "\n",
      "--------------- Starting trial: 21 ---------------\n",
      "Deep layers: 2 , Number of neurons: 150 , Learning rate: 0.0001\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0375 - mean_squared_error: 0.0375\n",
      "Loss: 0.03746534511446953 , Elapsed time: 65.78820061683655\n",
      "-------------------------------------------------\n",
      "\n",
      "\n",
      "--------------- Starting trial: 22 ---------------\n",
      "Deep layers: 2 , Number of neurons: 100 , Learning rate: 0.0001\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0323 - mean_squared_error: 0.0323\n",
      "Loss: 0.032266274094581604 , Elapsed time: 114.36692905426025\n",
      "-------------------------------------------------\n",
      "\n",
      "\n",
      "--------------- Starting trial: 23 ---------------\n",
      "Deep layers: 2 , Number of neurons: 150 , Learning rate: 0.0001\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0352 - mean_squared_error: 0.0352\n",
      "Loss: 0.03518151119351387 , Elapsed time: 57.47051382064819\n",
      "-------------------------------------------------\n",
      "\n",
      "\n",
      "--------------- Starting trial: 24 ---------------\n",
      "Deep layers: 2 , Number of neurons: 150 , Learning rate: 0.0001\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0374 - mean_squared_error: 0.0374\n",
      "Loss: 0.037420883774757385 , Elapsed time: 56.39615559577942\n",
      "-------------------------------------------------\n",
      "\n",
      "6  \t4     \t0.0320617\t0.0348792\t0.0374653\n",
      "7  \t0     \t0.0320617\t0.0337664\t0.0374653\n",
      "\n",
      "--------------- Starting trial: 25 ---------------\n",
      "Deep layers: 4 , Number of neurons: 50 , Learning rate: 0.0001\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0313 - mean_squared_error: 0.0313\n",
      "Loss: 0.03128302842378616 , Elapsed time: 60.24954319000244\n",
      "-------------------------------------------------\n",
      "\n",
      "\n",
      "--------------- Starting trial: 26 ---------------\n",
      "Deep layers: 3 , Number of neurons: 50 , Learning rate: 0.0001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0464 - mean_squared_error: 0.0464\n",
      "Loss: 0.046374764293432236 , Elapsed time: 57.89943242073059\n",
      "-------------------------------------------------\n",
      "\n",
      "8  \t2     \t0.031283 \t0.0347686\t0.0463748\n",
      "\n",
      "--------------- Starting trial: 27 ---------------\n",
      "Deep layers: 3 , Number of neurons: 50 , Learning rate: 0.0001\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0349 - mean_squared_error: 0.0349\n",
      "Loss: 0.03488193452358246 , Elapsed time: 60.333733797073364\n",
      "-------------------------------------------------\n",
      "\n",
      "\n",
      "--------------- Starting trial: 28 ---------------\n",
      "Deep layers: 4 , Number of neurons: 50 , Learning rate: 0.0001\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0337 - mean_squared_error: 0.0337\n",
      "Loss: 0.03369656205177307 , Elapsed time: 84.14976119995117\n",
      "-------------------------------------------------\n",
      "\n",
      "9  \t2     \t0.031283 \t0.032797 \t0.0348819\n",
      "10 \t0     \t0.031283 \t0.03247  \t0.0348819\n",
      "-- Best Individual =  [1, 1, 0, 0, 0, 0, 1]\n",
      "-- Best Fitness =  0.03206174448132515\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total elapsed time: 35.29770476818085 minutes\n"
     ]
    }
   ],
   "source": [
    "population_size = 5   # max of individuals per generation\n",
    "max_generations = 10  # number of generations\n",
    "gene_length = 7      # lenght of the gene, depends on how many hiperparameters are tested  \n",
    "k = 1;                 # num. of finalist individuals\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    t = time.time(); \n",
    "    datos = [];\n",
    "    ss = [i for i in range(1,population_size*(max_generations+1))]\n",
    "    best_population = geneticAlgorithm_with_elitism(population_size, max_generations, gene_length, k)\n",
    "    print(\"Total elapsed time:\", (time.time()-t)/60, \"minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k= 1 \n",
      "Deep layers: 2 , Number of neurons: 100\n",
      "Batch size 2 , Learning rate: 0.0001\n"
     ]
    }
   ],
   "source": [
    "best_deep_layers   = []\n",
    "best_num_units     = []\n",
    "best_learning_rate = []\n",
    "best_batch_size    = []\n",
    "# best_activation_f  = []\n",
    "best_f_names       = []\n",
    "\n",
    "t = 0\n",
    "\n",
    "for bi in best_population:\n",
    "    deep_layers_bits   = BitArray(bi[0:1])    # (8)\n",
    "    num_units_bits     = BitArray(bi[1:2])    # (16)\n",
    "    learning_rate_bits = BitArray(bi[2:3])   # (8)\n",
    "    batch_size_bits    = BitArray(bi[3:4])  # (4)\n",
    "#     activation_f_bits  = BitArray(bi[12:13])  # (2)\n",
    "    t += 1 \n",
    "    \n",
    "    best_deep_layers.append(SC_DEEP[deep_layers_bits.uint])\n",
    "    best_num_units.append(SC_NUM_UNITS[num_units_bits.uint])\n",
    "    best_learning_rate.append(SC_LEARNING[learning_rate_bits.uint])\n",
    "    best_batch_size.append(SC_BATCH[batch_size_bits.uint])\n",
    "#     best_activation_f.append(SC_ACTIVATION[activation_f_bits.uint])\n",
    "#     best_f_names.append(f_names[activation_f_bits.uint])\n",
    "    print('k=',t,'\\nDeep layers:', best_deep_layers[-1], ', Number of neurons:', best_num_units[-1])\n",
    "    print('Batch size', best_batch_size[-1], ', Learning rate:', best_learning_rate[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Deep layers</th>\n",
       "      <th>Num units</th>\n",
       "      <th>Learning rate</th>\n",
       "      <th>Batch size</th>\n",
       "      <th>Loss</th>\n",
       "      <th>Score</th>\n",
       "      <th>Elapsed time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>50</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>4</td>\n",
       "      <td>0.031283</td>\n",
       "      <td>0.031283</td>\n",
       "      <td>60.249543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>50</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>4</td>\n",
       "      <td>0.032062</td>\n",
       "      <td>0.032062</td>\n",
       "      <td>83.879571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>2</td>\n",
       "      <td>0.032266</td>\n",
       "      <td>0.032266</td>\n",
       "      <td>114.366929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>2</td>\n",
       "      <td>0.033679</td>\n",
       "      <td>0.033679</td>\n",
       "      <td>119.018694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>50</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>4</td>\n",
       "      <td>0.033697</td>\n",
       "      <td>0.033697</td>\n",
       "      <td>84.149761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3</td>\n",
       "      <td>50</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>4</td>\n",
       "      <td>0.034882</td>\n",
       "      <td>0.034882</td>\n",
       "      <td>60.333734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2</td>\n",
       "      <td>150</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>4</td>\n",
       "      <td>0.035182</td>\n",
       "      <td>0.035182</td>\n",
       "      <td>57.470514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>2</td>\n",
       "      <td>0.035540</td>\n",
       "      <td>0.035540</td>\n",
       "      <td>143.155597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2</td>\n",
       "      <td>200</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>4</td>\n",
       "      <td>0.035896</td>\n",
       "      <td>0.035896</td>\n",
       "      <td>89.361125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2</td>\n",
       "      <td>200</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>4</td>\n",
       "      <td>0.036042</td>\n",
       "      <td>0.036042</td>\n",
       "      <td>78.863629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>4</td>\n",
       "      <td>0.036588</td>\n",
       "      <td>0.036588</td>\n",
       "      <td>66.707269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2</td>\n",
       "      <td>200</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>4</td>\n",
       "      <td>0.036609</td>\n",
       "      <td>0.036609</td>\n",
       "      <td>79.831702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>4</td>\n",
       "      <td>0.036633</td>\n",
       "      <td>0.036633</td>\n",
       "      <td>58.089278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2</td>\n",
       "      <td>150</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>4</td>\n",
       "      <td>0.037238</td>\n",
       "      <td>0.037238</td>\n",
       "      <td>76.157914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2</td>\n",
       "      <td>150</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>4</td>\n",
       "      <td>0.037421</td>\n",
       "      <td>0.037421</td>\n",
       "      <td>56.396156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2</td>\n",
       "      <td>150</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>4</td>\n",
       "      <td>0.037465</td>\n",
       "      <td>0.037465</td>\n",
       "      <td>65.788201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>4</td>\n",
       "      <td>0.038245</td>\n",
       "      <td>0.038245</td>\n",
       "      <td>77.070843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2</td>\n",
       "      <td>150</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>4</td>\n",
       "      <td>0.039375</td>\n",
       "      <td>0.039375</td>\n",
       "      <td>74.030487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>4</td>\n",
       "      <td>0.039726</td>\n",
       "      <td>0.039726</td>\n",
       "      <td>83.684129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>8</td>\n",
       "      <td>0.043366</td>\n",
       "      <td>0.043366</td>\n",
       "      <td>42.054708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>4</td>\n",
       "      <td>0.043924</td>\n",
       "      <td>0.043924</td>\n",
       "      <td>83.419397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>3</td>\n",
       "      <td>50</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>4</td>\n",
       "      <td>0.046375</td>\n",
       "      <td>0.046375</td>\n",
       "      <td>57.899432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>4</td>\n",
       "      <td>0.049526</td>\n",
       "      <td>0.049526</td>\n",
       "      <td>67.022360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2</td>\n",
       "      <td>200</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>16</td>\n",
       "      <td>0.050619</td>\n",
       "      <td>0.050619</td>\n",
       "      <td>27.467384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>4</td>\n",
       "      <td>0.066021</td>\n",
       "      <td>0.066021</td>\n",
       "      <td>80.356478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>4</td>\n",
       "      <td>0.067798</td>\n",
       "      <td>0.067798</td>\n",
       "      <td>60.255058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>4</td>\n",
       "      <td>200</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>16</td>\n",
       "      <td>0.078387</td>\n",
       "      <td>0.078387</td>\n",
       "      <td>42.191663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>2</td>\n",
       "      <td>0.081571</td>\n",
       "      <td>0.081571</td>\n",
       "      <td>128.327382</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Deep layers  Num units  Learning rate  Batch size      Loss     Score  \\\n",
       "0             4         50         0.0001           4  0.031283  0.031283   \n",
       "1             4         50         0.0001           4  0.032062  0.032062   \n",
       "2             2        100         0.0001           2  0.032266  0.032266   \n",
       "3             2        100         0.0001           2  0.033679  0.033679   \n",
       "4             4         50         0.0001           4  0.033697  0.033697   \n",
       "5             3         50         0.0001           4  0.034882  0.034882   \n",
       "6             2        150         0.0001           4  0.035182  0.035182   \n",
       "7             2         50         0.0001           2  0.035540  0.035540   \n",
       "8             2        200         0.0001           4  0.035896  0.035896   \n",
       "9             2        200         0.0001           4  0.036042  0.036042   \n",
       "10            2         50         0.0001           4  0.036588  0.036588   \n",
       "11            2        200         0.0001           4  0.036609  0.036609   \n",
       "12            2        100         0.0001           4  0.036633  0.036633   \n",
       "13            2        150         0.0001           4  0.037238  0.037238   \n",
       "14            2        150         0.0001           4  0.037421  0.037421   \n",
       "15            2        150         0.0001           4  0.037465  0.037465   \n",
       "16            2        100         0.0001           4  0.038245  0.038245   \n",
       "17            2        150         0.0001           4  0.039375  0.039375   \n",
       "18            2        100         0.0001           4  0.039726  0.039726   \n",
       "19            2        100         0.0001           8  0.043366  0.043366   \n",
       "20            2         50         0.0001           4  0.043924  0.043924   \n",
       "21            3         50         0.0001           4  0.046375  0.046375   \n",
       "22            2        100         0.0010           4  0.049526  0.049526   \n",
       "23            2        200         0.0001          16  0.050619  0.050619   \n",
       "24            2         50         0.0001           4  0.066021  0.066021   \n",
       "25            1        100         0.0001           4  0.067798  0.067798   \n",
       "26            4        200         0.0010          16  0.078387  0.078387   \n",
       "27            3        100         0.0010           2  0.081571  0.081571   \n",
       "\n",
       "    Elapsed time  \n",
       "0      60.249543  \n",
       "1      83.879571  \n",
       "2     114.366929  \n",
       "3     119.018694  \n",
       "4      84.149761  \n",
       "5      60.333734  \n",
       "6      57.470514  \n",
       "7     143.155597  \n",
       "8      89.361125  \n",
       "9      78.863629  \n",
       "10     66.707269  \n",
       "11     79.831702  \n",
       "12     58.089278  \n",
       "13     76.157914  \n",
       "14     56.396156  \n",
       "15     65.788201  \n",
       "16     77.070843  \n",
       "17     74.030487  \n",
       "18     83.684129  \n",
       "19     42.054708  \n",
       "20     83.419397  \n",
       "21     57.899432  \n",
       "22     67.022360  \n",
       "23     27.467384  \n",
       "24     80.356478  \n",
       "25     60.255058  \n",
       "26     42.191663  \n",
       "27    128.327382  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename = \"historial_genetic_jla2.txt\"\n",
    "df = pd.DataFrame(datos, columns = [\"Deep layers\", \"Num units\", \"Learning rate\", \"Batch size\", \"Loss\", \"Score\", \"Elapsed time\"])\n",
    "\n",
    "df.sort_values(by=[\"Loss\", \"Elapsed time\"], ascending=[True, True], ignore_index=True, inplace=True)\n",
    "\n",
    "df.to_csv(filename, header=True, index=False, sep='\\t', mode='w') # a=append, w=overwrite\n",
    "df.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time 35.293 minutes\n"
     ]
    }
   ],
   "source": [
    "total_time = float(np.sum(df[[\"Elapsed time\"]])/60)\n",
    "\n",
    "print(\"Elapsed time {:.3f} minutes\".format(total_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
