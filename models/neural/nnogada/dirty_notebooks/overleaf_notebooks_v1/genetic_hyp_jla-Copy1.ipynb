{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import time, os\n",
    "import random\n",
    "import seaborn as sns\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Input, Dense, LeakyReLU\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorboard.plugins.hparams import api as hp\n",
    "\n",
    "from tensorflow.keras import activations\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "import random\n",
    "from math import floor\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import optimizers\n",
    "from scipy.integrate import odeint\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split as split\n",
    "from scipy.stats import bernoulli\n",
    "\n",
    "# import deap\n",
    "from deap import base, creator, tools, algorithms\n",
    "\n",
    "from bitstring import BitArray\n",
    "\n",
    "# from elitism import eaSimpleWithElitism, main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "\n",
    "# tf.config.optimizer.set_jit(True)\n",
    "# scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "url = 'https://raw.githubusercontent.com/igomezv/nnogada/main/data/jla.csv'\n",
    "df=pd.read_csv(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = len(df.values)\n",
    "randomize = np.random.permutation(N)\n",
    "data = df.values[randomize]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(740, 2)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N = len(df.values)\n",
    "z = data[:,0] \n",
    "y = data[:,1:3] ### coge el resto de variables a predecir \n",
    "y[:,1] = y[:,1]**2+data[:,2]\n",
    "np.shape(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "scalerz = StandardScaler()\n",
    "scalerz.fit(z.reshape(-1,1))\n",
    "z = scalerz.transform(z.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((592, 1), (148, 1), (592, 2), (148, 2))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Modificar para incluir phanteon como test\n",
    "split = 0.8\n",
    "ntrain = int(split * len(z))\n",
    "indx = [ntrain]\n",
    "X_train, X_val = np.split(z, indx)\n",
    "Y_train, Y_val = np.split(y, indx)\n",
    "# X_train, X_test = np.split(z, indx)\n",
    "# Y_train, Y_test = np.split(y, indx)\n",
    "np.shape(X_train), np.shape(X_val), Y_train.shape, Y_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "SC_DEEP       = np.array([1,2,3,4])                           # Number of deep layers (8)\n",
    "SC_NUM_UNITS  = np.array([50,100,150,200]) # Number of fully conected neurons (16)\n",
    "SC_LEARNING   = np.array([1e-4,5e-3])   # Learning rates (8)\n",
    "SC_BATCH      = np.array([2, 4, 8, 16])                            # Batch sizes (4)\n",
    "# SC_ACTIVATION = [f1, f2, f3, f4]                                      # Activation function layers (2)\n",
    "\n",
    "my_callbacks = [tf.keras.callbacks.EarlyStopping(\n",
    "                               monitor='val_loss', mode='min',\n",
    "                               min_delta=0, \n",
    "                               patience=200,\n",
    "                               verbose=1,\n",
    "                            #    baseline=0,\n",
    "                               restore_best_weights=True)\n",
    "#                 keras.callbacks.TensorBoard(\n",
    "#                                log_dir='./logs'),\n",
    "#                 keras.callbacks.ReduceLROnPlateau(\n",
    "#                                monitor='val_loss', factor=0.5,\n",
    "#                                patience=6, min_lr=0,\n",
    "#                                verbose=1)\n",
    "               ] \n",
    "    \n",
    "epochs = 200\n",
    "# epochs = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_evaluate(ga_individual_solution):   \n",
    "    t = time.time()\n",
    "    t_total = 0\n",
    "    \n",
    "    # Decode GA solution to integer for window_size and num_units\n",
    "    deep_layers_bits   = BitArray(ga_individual_solution[0:2])     # (8)\n",
    "    num_units_bits     = BitArray(ga_individual_solution[2:4])     # (16)\n",
    "    learning_rate_bits = BitArray(ga_individual_solution[4:5])    # (8)\n",
    "    batch_size_bits    = BitArray(ga_individual_solution[5:7])   # (4)\n",
    "# #     activation_f_bits  = BitArray(ga_individual_solution[12:13])   # (2)   Solo se consideran las 2 primeras\n",
    "    \n",
    "    deep_layers   = SC_DEEP[deep_layers_bits.uint]\n",
    "    num_units     = SC_NUM_UNITS[num_units_bits.uint]\n",
    "    learning_rate = SC_LEARNING[learning_rate_bits.uint]\n",
    "    batch_size   = SC_BATCH[batch_size_bits.uint]\n",
    "#     activation_f  = SC_ACTIVATION[activation_f_bits.uint]\n",
    "\n",
    "    \n",
    "    print('\\n--------------- Starting trial:', population_size*(max_generations+1)-len(ss), \"---------------\")\n",
    "    print('Deep layers:',deep_layers,', Number of neurons:',num_units,\", Learning rate:\",learning_rate)\n",
    "#     print(\"-------------------------------------------------\")\n",
    "    \n",
    "    # Train model and predict on validation set\n",
    "    model = tf.keras.Sequential()\n",
    "#     model.add(Input(shape=(int(X_train.shape[1]),)))\n",
    "    model.add(Dense(int(X_train.shape[1])))\n",
    "    \n",
    "    for i in range(deep_layers):        \n",
    "        model.add(Dense(num_units, activation='relu'))\n",
    "#             model.add(keras.layers.Dropout(0.3))\n",
    "    model.add(Dense(2, activation='linear'))\n",
    "    \n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate, beta_1=0.9, beta_2=0.999, epsilon=1e-3)\n",
    "    model.compile(optimizer=optimizer, loss='mse', metrics=['mean_squared_error'])\n",
    "    model.fit(X_train, Y_train, epochs=epochs, validation_data=(X_val, Y_val),\n",
    "              callbacks=my_callbacks, batch_size=batch_size, shuffle=False, verbose=0)\n",
    "    \n",
    "    loss, score = model.evaluate(X_val, Y_val)    \n",
    "    t = time.time()-t\n",
    "    ss.pop(0)\n",
    "    print(\"Loss:\", score, \", Elapsed time:\", t)\n",
    "    print(\"-------------------------------------------------\\n\")\n",
    "#     print(loss, score)\n",
    "\n",
    "    datos.append([deep_layers, num_units, learning_rate, batch_size, loss, score, t])\n",
    "    \n",
    "    return loss,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deap import tools\n",
    "from deap import algorithms\n",
    "\n",
    "def eaSimpleWithElitism(population, toolbox, cxpb, mutpb, ngen, stats=None,\n",
    "             halloffame=None, verbose=__debug__):\n",
    "    \"\"\"This algorithm is similar to DEAP eaSimple() algorithm, with the modification that\n",
    "    halloffame is used to implement an elitism mechanism. The individuals contained in the\n",
    "    halloffame are directly injected into the next generation and are not subject to the\n",
    "    genetic operators of selection, crossover and mutation.\n",
    "    \"\"\"\n",
    "    logbook = tools.Logbook()\n",
    "    logbook.header = ['gen', 'nevals'] + (stats.fields if stats else [])\n",
    "\n",
    "    # Evaluate the individuals with an invalid fitness\n",
    "    invalid_ind = [ind for ind in population if not ind.fitness.valid]\n",
    "    fitnesses = toolbox.map(toolbox.evaluate, invalid_ind)\n",
    "    for ind, fit in zip(invalid_ind, fitnesses):\n",
    "        ind.fitness.values = fit\n",
    "\n",
    "    if halloffame is None:\n",
    "        raise ValueError(\"halloffame parameter must not be empty!\")\n",
    "\n",
    "    halloffame.update(population)\n",
    "    hof_size = len(halloffame.items) if halloffame.items else 0\n",
    "\n",
    "    record = stats.compile(population) if stats else {}\n",
    "    logbook.record(gen=0, nevals=len(invalid_ind), **record)\n",
    "    if verbose:\n",
    "        print(logbook.stream)\n",
    "\n",
    "    # Begin the generational process\n",
    "    for gen in range(1, ngen + 1):\n",
    "\n",
    "        # Select the next generation individuals\n",
    "        offspring = toolbox.select(population, len(population) - hof_size)\n",
    "\n",
    "        # Vary the pool of individuals\n",
    "        offspring = algorithms.varAnd(offspring, toolbox, cxpb, mutpb)\n",
    "\n",
    "        # Evaluate the individuals with an invalid fitness\n",
    "        invalid_ind = [ind for ind in offspring if not ind.fitness.valid]\n",
    "        fitnesses = toolbox.map(toolbox.evaluate, invalid_ind)\n",
    "        for ind, fit in zip(invalid_ind, fitnesses):\n",
    "            ind.fitness.values = fit\n",
    "\n",
    "        # add the best back to population:\n",
    "        offspring.extend(halloffame.items)\n",
    "\n",
    "        # Update the hall of fame with the generated individuals\n",
    "        halloffame.update(offspring)\n",
    "\n",
    "        # Replace the current population by the offspring\n",
    "        population[:] = offspring\n",
    "\n",
    "        # Append the current generation statistics to the logbook\n",
    "        record = stats.compile(population) if stats else {}\n",
    "        logbook.record(gen=gen, nevals=len(invalid_ind), **record)\n",
    "        if verbose:\n",
    "            print(logbook.stream)\n",
    "\n",
    "    return population, logbook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def geneticAlgorithm_with_elitism(population_size, max_generations, gene_length, k):\n",
    "    \n",
    "    # Genetic Algorithm constants:\n",
    "    P_CROSSOVER = 0.5        # probability for crossover\n",
    "    P_MUTATION = 0.5         # probability for mutating an individual\n",
    "    HALL_OF_FAME_SIZE = 1    # Best individuals that pass to the other generation\n",
    "    \n",
    "    # set the random seed:\n",
    "    toolbox = base.Toolbox()\n",
    "\n",
    "    # As we are trying to minimize the RMSE score, that's why using -1.0. \n",
    "    # In case, when you want to maximize accuracy for instance, use 1.0\n",
    "    creator.create('FitnessMin', base.Fitness, weights = [-1.0])\n",
    "    creator.create('Individual', list , fitness = creator.FitnessMin)\n",
    "\n",
    "    # create the individual operator to fill up an Individual instance:\n",
    "    toolbox.register('binary', bernoulli.rvs, 0.5)\n",
    "    toolbox.register('individual', tools.initRepeat, creator.Individual, toolbox.binary, n = gene_length)\n",
    "\n",
    "    # create the population operator to generate a list of individuals:\n",
    "    toolbox.register('population', tools.initRepeat, list , toolbox.individual)\n",
    "\n",
    "    # genetic operators:\n",
    "    toolbox.register('evaluate', train_evaluate)\n",
    "    toolbox.register('select', tools.selTournament, tournsize = 2)\n",
    "    toolbox.register('mutate', tools.mutFlipBit, indpb = 0.11)\n",
    "    toolbox.register('mate', tools.cxUniform, indpb = 0.5)\n",
    "    \n",
    "    # create initial population (generation 0):\n",
    "    population = toolbox.population(n=population_size)\n",
    "\n",
    "    # prepare the statistics object:\n",
    "    stats = tools.Statistics(lambda ind: ind.fitness.values)\n",
    "    stats.register(\"min\", np.min)\n",
    "    stats.register(\"avg\", np.mean)\n",
    "    stats.register(\"max\", np.max)\n",
    "\n",
    "    # define the hall-of-fame object:\n",
    "    hof = tools.HallOfFame(HALL_OF_FAME_SIZE)\n",
    "\n",
    "    # Genetic Algorithm flow with elitism:\n",
    "    population, logbook = eaSimpleWithElitism(population, toolbox, cxpb=P_CROSSOVER, mutpb=P_MUTATION,\n",
    "                                              ngen=max_generations, stats=stats, halloffame=hof, verbose=True)\n",
    "\n",
    "    # print info for best solution found:\n",
    "    best = hof.items[0]\n",
    "    print(\"-- Best Individual = \", best)\n",
    "    print(\"-- Best Fitness = \", best.fitness.values[0])\n",
    "\n",
    "    # extract statistics:\n",
    "    minFitnessValues, meanFitnessValues, maxFitnessValues = logbook.select(\"min\", \"max\", \"avg\")\n",
    "\n",
    "    # plot statistics:\n",
    "    sns.set_style(\"whitegrid\")\n",
    "    plt.plot(minFitnessValues, color='blue', label=\"Min\")\n",
    "    plt.plot(meanFitnessValues, color='green', label=\"Mean\")\n",
    "    plt.plot(maxFitnessValues, color='red', label=\"Max\")\n",
    "    plt.xlabel('Generation'); plt.ylabel('Max / Min / Average Fitness')\n",
    "    plt.legend()\n",
    "    plt.title('Max, Min and Average fitness over Generations')\n",
    "    plt.show()\n",
    "    \n",
    "    best_population = tools.selBest(population,k = k)\n",
    "    return best_population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------------- Starting trial: 1 ---------------\n",
      "Deep layers: 3 , Number of neurons: 100 , Learning rate: 0.005\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1251 - mean_squared_error: 0.1251\n",
      "Loss: 0.125118687748909 , Elapsed time: 125.48352646827698\n",
      "-------------------------------------------------\n",
      "\n",
      "\n",
      "--------------- Starting trial: 2 ---------------\n",
      "Deep layers: 2 , Number of neurons: 200 , Learning rate: 0.0001\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0502 - mean_squared_error: 0.0502\n",
      "Loss: 0.05023360624909401 , Elapsed time: 28.26795220375061\n",
      "-------------------------------------------------\n",
      "\n",
      "\n",
      "--------------- Starting trial: 3 ---------------\n",
      "Deep layers: 4 , Number of neurons: 200 , Learning rate: 0.005\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0575 - mean_squared_error: 0.0575\n",
      "Loss: 0.057511769235134125 , Elapsed time: 36.673715353012085\n",
      "-------------------------------------------------\n",
      "\n",
      "\n",
      "--------------- Starting trial: 4 ---------------\n",
      "Deep layers: 1 , Number of neurons: 100 , Learning rate: 0.0001\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0787 - mean_squared_error: 0.0787\n",
      "Loss: 0.07872594892978668 , Elapsed time: 83.08224177360535\n",
      "-------------------------------------------------\n",
      "\n",
      "\n",
      "--------------- Starting trial: 5 ---------------\n",
      "Deep layers: 2 , Number of neurons: 100 , Learning rate: 0.0001\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0391 - mean_squared_error: 0.0391\n",
      "Loss: 0.03913464769721031 , Elapsed time: 61.63377118110657\n",
      "-------------------------------------------------\n",
      "\n",
      "gen\tnevals\tmin      \tavg      \tmax     \n",
      "0  \t5     \t0.0391346\t0.0701449\t0.125119\n",
      "\n",
      "--------------- Starting trial: 6 ---------------\n",
      "Deep layers: 2 , Number of neurons: 100 , Learning rate: 0.0001\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0758 - mean_squared_error: 0.0758\n",
      "Loss: 0.07584161311388016 , Elapsed time: 22.281200408935547\n",
      "-------------------------------------------------\n",
      "\n",
      "\n",
      "--------------- Starting trial: 7 ---------------\n",
      "Deep layers: 2 , Number of neurons: 200 , Learning rate: 0.0001\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0361 - mean_squared_error: 0.0361\n",
      "Loss: 0.036094002425670624 , Elapsed time: 74.87210154533386\n",
      "-------------------------------------------------\n",
      "\n",
      "1  \t2     \t0.036094 \t0.0537862\t0.0787259\n",
      "\n",
      "--------------- Starting trial: 8 ---------------\n",
      "Deep layers: 2 , Number of neurons: 100 , Learning rate: 0.0001\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0312 - mean_squared_error: 0.0312\n",
      "Loss: 0.031183259561657906 , Elapsed time: 120.10931420326233\n",
      "-------------------------------------------------\n",
      "\n",
      "\n",
      "--------------- Starting trial: 9 ---------------\n",
      "Deep layers: 2 , Number of neurons: 200 , Learning rate: 0.0001\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0349 - mean_squared_error: 0.0349\n",
      "Loss: 0.03486151248216629 , Elapsed time: 72.81657695770264\n",
      "-------------------------------------------------\n",
      "\n",
      "\n",
      "--------------- Starting trial: 10 ---------------\n",
      "Deep layers: 2 , Number of neurons: 100 , Learning rate: 0.005\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0507 - mean_squared_error: 0.0507\n",
      "Loss: 0.05074645206332207 , Elapsed time: 70.96409320831299\n",
      "-------------------------------------------------\n",
      "\n",
      "2  \t3     \t0.0311833\t0.0377958\t0.0507465\n",
      "\n",
      "--------------- Starting trial: 11 ---------------\n",
      "Deep layers: 2 , Number of neurons: 100 , Learning rate: 0.0001\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0322 - mean_squared_error: 0.0322\n",
      "Loss: 0.03219306468963623 , Elapsed time: 142.974303483963\n",
      "-------------------------------------------------\n",
      "\n",
      "\n",
      "--------------- Starting trial: 12 ---------------\n",
      "Deep layers: 2 , Number of neurons: 100 , Learning rate: 0.005\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1062 - mean_squared_error: 0.1062\n",
      "Loss: 0.10621622949838638 , Elapsed time: 140.81331372261047\n",
      "-------------------------------------------------\n",
      "\n",
      "\n",
      "--------------- Starting trial: 13 ---------------\n",
      "Deep layers: 2 , Number of neurons: 200 , Learning rate: 0.0001\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0367 - mean_squared_error: 0.0367\n",
      "Loss: 0.03669574484229088 , Elapsed time: 81.15813970565796\n",
      "-------------------------------------------------\n",
      "\n",
      "\n",
      "--------------- Starting trial: 14 ---------------\n",
      "Deep layers: 2 , Number of neurons: 200 , Learning rate: 0.0001\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0356 - mean_squared_error: 0.0356\n",
      "Loss: 0.03561653196811676 , Elapsed time: 72.2315628528595\n",
      "-------------------------------------------------\n",
      "\n",
      "3  \t4     \t0.0311833\t0.048381 \t0.106216 \n",
      "\n",
      "--------------- Starting trial: 15 ---------------\n",
      "Deep layers: 1 , Number of neurons: 100 , Learning rate: 0.0001\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0728 - mean_squared_error: 0.0728\n",
      "Loss: 0.07284629344940186 , Elapsed time: 114.02387952804565\n",
      "-------------------------------------------------\n",
      "\n",
      "\n",
      "--------------- Starting trial: 16 ---------------\n",
      "Deep layers: 2 , Number of neurons: 100 , Learning rate: 0.0001\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0315 - mean_squared_error: 0.0315\n",
      "Loss: 0.03150143474340439 , Elapsed time: 129.70582580566406\n",
      "-------------------------------------------------\n",
      "\n",
      "\n",
      "--------------- Starting trial: 17 ---------------\n",
      "Deep layers: 2 , Number of neurons: 50 , Learning rate: 0.0001\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0326 - mean_squared_error: 0.0326\n",
      "Loss: 0.032641682773828506 , Elapsed time: 129.93729186058044\n",
      "-------------------------------------------------\n",
      "\n",
      "\n",
      "--------------- Starting trial: 18 ---------------\n",
      "Deep layers: 2 , Number of neurons: 200 , Learning rate: 0.0001\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0321 - mean_squared_error: 0.0321\n",
      "Loss: 0.03205772489309311 , Elapsed time: 138.97734832763672\n",
      "-------------------------------------------------\n",
      "\n",
      "4  \t4     \t0.0311833\t0.0400461\t0.0728463\n",
      "\n",
      "--------------- Starting trial: 19 ---------------\n",
      "Deep layers: 4 , Number of neurons: 100 , Learning rate: 0.0001\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0335 - mean_squared_error: 0.0335\n",
      "Loss: 0.033510785549879074 , Elapsed time: 83.80155086517334\n",
      "-------------------------------------------------\n",
      "\n",
      "\n",
      "--------------- Starting trial: 20 ---------------\n",
      "Deep layers: 2 , Number of neurons: 50 , Learning rate: 0.0001\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0343 - mean_squared_error: 0.0343\n",
      "Loss: 0.03430704027414322 , Elapsed time: 134.1083574295044\n",
      "-------------------------------------------------\n",
      "\n",
      "\n",
      "--------------- Starting trial: 21 ---------------\n",
      "Deep layers: 2 , Number of neurons: 100 , Learning rate: 0.0001\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0319 - mean_squared_error: 0.0319\n",
      "Loss: 0.03187647834420204 , Elapsed time: 134.5523076057434\n",
      "-------------------------------------------------\n",
      "\n",
      "\n",
      "--------------- Starting trial: 22 ---------------\n",
      "Deep layers: 4 , Number of neurons: 100 , Learning rate: 0.0001\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0348 - mean_squared_error: 0.0348\n",
      "Loss: 0.03484150022268295 , Elapsed time: 179.84532260894775\n",
      "-------------------------------------------------\n",
      "\n",
      "5  \t4     \t0.0311833\t0.0331438\t0.0348415\n",
      "\n",
      "--------------- Starting trial: 23 ---------------\n",
      "Deep layers: 2 , Number of neurons: 100 , Learning rate: 0.0001\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0315 - mean_squared_error: 0.0315\n",
      "Loss: 0.03154098615050316 , Elapsed time: 156.26851677894592\n",
      "-------------------------------------------------\n",
      "\n",
      "\n",
      "--------------- Starting trial: 24 ---------------\n",
      "Deep layers: 2 , Number of neurons: 100 , Learning rate: 0.0001\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0310 - mean_squared_error: 0.0310\n",
      "Loss: 0.03101317584514618 , Elapsed time: 139.6541965007782\n",
      "-------------------------------------------------\n",
      "\n",
      "\n",
      "--------------- Starting trial: 25 ---------------\n",
      "Deep layers: 2 , Number of neurons: 100 , Learning rate: 0.0001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0356 - mean_squared_error: 0.0356\n",
      "Loss: 0.03557182848453522 , Elapsed time: 50.895254373550415\n",
      "-------------------------------------------------\n",
      "\n",
      "6  \t3     \t0.0310132\t0.0327233\t0.0355718\n",
      "\n",
      "--------------- Starting trial: 26 ---------------\n",
      "Deep layers: 2 , Number of neurons: 200 , Learning rate: 0.0001\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0311 - mean_squared_error: 0.0311\n",
      "Loss: 0.031090401113033295 , Elapsed time: 149.11923027038574\n",
      "-------------------------------------------------\n",
      "\n",
      "\n",
      "--------------- Starting trial: 27 ---------------\n",
      "Deep layers: 2 , Number of neurons: 100 , Learning rate: 0.0001\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0308 - mean_squared_error: 0.0308\n",
      "Loss: 0.030824899673461914 , Elapsed time: 121.24732995033264\n",
      "-------------------------------------------------\n",
      "\n",
      "\n",
      "--------------- Starting trial: 28 ---------------\n",
      "Deep layers: 2 , Number of neurons: 100 , Learning rate: 0.0001\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0317 - mean_squared_error: 0.0317\n",
      "Loss: 0.03166439011693001 , Elapsed time: 106.61882162094116\n",
      "-------------------------------------------------\n",
      "\n",
      "\n",
      "--------------- Starting trial: 29 ---------------\n",
      "Deep layers: 2 , Number of neurons: 100 , Learning rate: 0.0001\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0321 - mean_squared_error: 0.0321\n",
      "Loss: 0.03207399696111679 , Elapsed time: 118.84712481498718\n",
      "-------------------------------------------------\n",
      "\n",
      "7  \t4     \t0.0308249\t0.0313674\t0.032074 \n",
      "\n",
      "--------------- Starting trial: 30 ---------------\n",
      "Deep layers: 2 , Number of neurons: 100 , Learning rate: 0.0001\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0374 - mean_squared_error: 0.0374\n",
      "Loss: 0.03742682561278343 , Elapsed time: 89.42177510261536\n",
      "-------------------------------------------------\n",
      "\n",
      "\n",
      "--------------- Starting trial: 31 ---------------\n",
      "Deep layers: 2 , Number of neurons: 100 , Learning rate: 0.0001\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0326 - mean_squared_error: 0.0326\n",
      "Loss: 0.032601065933704376 , Elapsed time: 148.1261796951294\n",
      "-------------------------------------------------\n",
      "\n",
      "\n",
      "--------------- Starting trial: 32 ---------------\n",
      "Deep layers: 4 , Number of neurons: 150 , Learning rate: 0.0001\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0340 - mean_squared_error: 0.0340\n",
      "Loss: 0.03396027535200119 , Elapsed time: 184.7097692489624\n",
      "-------------------------------------------------\n",
      "\n",
      "\n",
      "--------------- Starting trial: 33 ---------------\n",
      "Deep layers: 1 , Number of neurons: 100 , Learning rate: 0.0001\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0564 - mean_squared_error: 0.0564\n",
      "Loss: 0.05644965171813965 , Elapsed time: 130.55510830879211\n",
      "-------------------------------------------------\n",
      "\n",
      "8  \t4     \t0.0308249\t0.0382525\t0.0564497\n",
      "\n",
      "--------------- Starting trial: 34 ---------------\n",
      "Deep layers: 2 , Number of neurons: 100 , Learning rate: 0.0001\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0322 - mean_squared_error: 0.0322\n",
      "Loss: 0.032231077551841736 , Elapsed time: 130.23206782341003\n",
      "-------------------------------------------------\n",
      "\n",
      "\n",
      "--------------- Starting trial: 35 ---------------\n",
      "Deep layers: 2 , Number of neurons: 100 , Learning rate: 0.0001\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0372 - mean_squared_error: 0.0372\n",
      "Loss: 0.037229858338832855 , Elapsed time: 145.6050009727478\n",
      "-------------------------------------------------\n",
      "\n",
      "\n",
      "--------------- Starting trial: 36 ---------------\n",
      "Deep layers: 2 , Number of neurons: 50 , Learning rate: 0.005\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0975 - mean_squared_error: 0.0975\n",
      "Loss: 0.09748995304107666 , Elapsed time: 125.70613026618958\n",
      "-------------------------------------------------\n",
      "\n",
      "9  \t3     \t0.0308249\t0.0463472\t0.09749  \n",
      "\n",
      "--------------- Starting trial: 37 ---------------\n",
      "Deep layers: 1 , Number of neurons: 150 , Learning rate: 0.0001\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0472 - mean_squared_error: 0.0472\n",
      "Loss: 0.04718438535928726 , Elapsed time: 203.02558732032776\n",
      "-------------------------------------------------\n",
      "\n",
      "\n",
      "--------------- Starting trial: 38 ---------------\n",
      "Deep layers: 2 , Number of neurons: 200 , Learning rate: 0.0001\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0309 - mean_squared_error: 0.0309\n",
      "Loss: 0.03085889108479023 , Elapsed time: 194.77766633033752\n",
      "-------------------------------------------------\n",
      "\n",
      "10 \t2     \t0.0308249\t0.0341036\t0.0471844\n",
      "-- Best Individual =  [0, 1, 0, 1, 0, 0, 0]\n",
      "-- Best Fitness =  0.030824899673461914\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total elapsed time: 72.89556902647018 minutes\n"
     ]
    }
   ],
   "source": [
    "population_size = 5   # max of individuals per generation\n",
    "max_generations = 10  # number of generations\n",
    "gene_length = 7      # lenght of the gene, depends on how many hiperparameters are tested  \n",
    "k = 1;                 # num. of finalist individuals\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    t = time.time(); \n",
    "    datos = [];\n",
    "    ss = [i for i in range(1,population_size*(max_generations+1))]\n",
    "    best_population = geneticAlgorithm_with_elitism(population_size, max_generations, gene_length, k)\n",
    "    print(\"Total elapsed time:\", (time.time()-t)/60, \"minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k= 1 \n",
      "Deep layers: 1 , Number of neurons: 100\n",
      "Batch size 4 , Learning rate: 0.0001\n"
     ]
    }
   ],
   "source": [
    "best_deep_layers   = []\n",
    "best_num_units     = []\n",
    "best_learning_rate = []\n",
    "best_batch_size    = []\n",
    "# best_activation_f  = []\n",
    "best_f_names       = []\n",
    "\n",
    "t = 0\n",
    "\n",
    "for bi in best_population:\n",
    "    deep_layers_bits   = BitArray(bi[0:1])    # (8)\n",
    "    num_units_bits     = BitArray(bi[1:2])    # (16)\n",
    "    learning_rate_bits = BitArray(bi[2:3])   # (8)\n",
    "    batch_size_bits    = BitArray(bi[3:4])  # (4)\n",
    "#     activation_f_bits  = BitArray(bi[12:13])  # (2)\n",
    "    t += 1 \n",
    "    \n",
    "    best_deep_layers.append(SC_DEEP[deep_layers_bits.uint])\n",
    "    best_num_units.append(SC_NUM_UNITS[num_units_bits.uint])\n",
    "    best_learning_rate.append(SC_LEARNING[learning_rate_bits.uint])\n",
    "    best_batch_size.append(SC_BATCH[batch_size_bits.uint])\n",
    "#     best_activation_f.append(SC_ACTIVATION[activation_f_bits.uint])\n",
    "#     best_f_names.append(f_names[activation_f_bits.uint])\n",
    "    print('k=',t,'\\nDeep layers:', best_deep_layers[-1], ', Number of neurons:', best_num_units[-1])\n",
    "    print('Batch size', best_batch_size[-1], ', Learning rate:', best_learning_rate[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Deep layers</th>\n",
       "      <th>Num units</th>\n",
       "      <th>Learning rate</th>\n",
       "      <th>Batch size</th>\n",
       "      <th>Loss</th>\n",
       "      <th>Score</th>\n",
       "      <th>Elapsed time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>2</td>\n",
       "      <td>0.030825</td>\n",
       "      <td>0.030825</td>\n",
       "      <td>121.247330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>200</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>2</td>\n",
       "      <td>0.030859</td>\n",
       "      <td>0.030859</td>\n",
       "      <td>194.777666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>2</td>\n",
       "      <td>0.031013</td>\n",
       "      <td>0.031013</td>\n",
       "      <td>139.654197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>200</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>2</td>\n",
       "      <td>0.031090</td>\n",
       "      <td>0.031090</td>\n",
       "      <td>149.119230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>2</td>\n",
       "      <td>0.031183</td>\n",
       "      <td>0.031183</td>\n",
       "      <td>120.109314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>2</td>\n",
       "      <td>0.031501</td>\n",
       "      <td>0.031501</td>\n",
       "      <td>129.705826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>2</td>\n",
       "      <td>0.031541</td>\n",
       "      <td>0.031541</td>\n",
       "      <td>156.268517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>2</td>\n",
       "      <td>0.031664</td>\n",
       "      <td>0.031664</td>\n",
       "      <td>106.618822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>2</td>\n",
       "      <td>0.031876</td>\n",
       "      <td>0.031876</td>\n",
       "      <td>134.552308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2</td>\n",
       "      <td>200</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>2</td>\n",
       "      <td>0.032058</td>\n",
       "      <td>0.032058</td>\n",
       "      <td>138.977348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>2</td>\n",
       "      <td>0.032074</td>\n",
       "      <td>0.032074</td>\n",
       "      <td>118.847125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>2</td>\n",
       "      <td>0.032193</td>\n",
       "      <td>0.032193</td>\n",
       "      <td>142.974303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>2</td>\n",
       "      <td>0.032231</td>\n",
       "      <td>0.032231</td>\n",
       "      <td>130.232068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>2</td>\n",
       "      <td>0.032601</td>\n",
       "      <td>0.032601</td>\n",
       "      <td>148.126180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>2</td>\n",
       "      <td>0.032642</td>\n",
       "      <td>0.032642</td>\n",
       "      <td>129.937292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>4</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>4</td>\n",
       "      <td>0.033511</td>\n",
       "      <td>0.033511</td>\n",
       "      <td>83.801551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>4</td>\n",
       "      <td>150</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>2</td>\n",
       "      <td>0.033960</td>\n",
       "      <td>0.033960</td>\n",
       "      <td>184.709769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>2</td>\n",
       "      <td>0.034307</td>\n",
       "      <td>0.034307</td>\n",
       "      <td>134.108357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>4</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>2</td>\n",
       "      <td>0.034842</td>\n",
       "      <td>0.034842</td>\n",
       "      <td>179.845323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2</td>\n",
       "      <td>200</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>4</td>\n",
       "      <td>0.034862</td>\n",
       "      <td>0.034862</td>\n",
       "      <td>72.816577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>4</td>\n",
       "      <td>0.035572</td>\n",
       "      <td>0.035572</td>\n",
       "      <td>50.895254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2</td>\n",
       "      <td>200</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>4</td>\n",
       "      <td>0.035617</td>\n",
       "      <td>0.035617</td>\n",
       "      <td>72.231563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2</td>\n",
       "      <td>200</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>4</td>\n",
       "      <td>0.036094</td>\n",
       "      <td>0.036094</td>\n",
       "      <td>74.872102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2</td>\n",
       "      <td>200</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>4</td>\n",
       "      <td>0.036696</td>\n",
       "      <td>0.036696</td>\n",
       "      <td>81.158140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>2</td>\n",
       "      <td>0.037230</td>\n",
       "      <td>0.037230</td>\n",
       "      <td>145.605001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>4</td>\n",
       "      <td>0.037427</td>\n",
       "      <td>0.037427</td>\n",
       "      <td>89.421775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>4</td>\n",
       "      <td>0.039135</td>\n",
       "      <td>0.039135</td>\n",
       "      <td>61.633771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1</td>\n",
       "      <td>150</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>2</td>\n",
       "      <td>0.047184</td>\n",
       "      <td>0.047184</td>\n",
       "      <td>203.025587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2</td>\n",
       "      <td>200</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>16</td>\n",
       "      <td>0.050234</td>\n",
       "      <td>0.050234</td>\n",
       "      <td>28.267952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0050</td>\n",
       "      <td>4</td>\n",
       "      <td>0.050746</td>\n",
       "      <td>0.050746</td>\n",
       "      <td>70.964093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>2</td>\n",
       "      <td>0.056450</td>\n",
       "      <td>0.056450</td>\n",
       "      <td>130.555108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>4</td>\n",
       "      <td>200</td>\n",
       "      <td>0.0050</td>\n",
       "      <td>16</td>\n",
       "      <td>0.057512</td>\n",
       "      <td>0.057512</td>\n",
       "      <td>36.673715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>2</td>\n",
       "      <td>0.072846</td>\n",
       "      <td>0.072846</td>\n",
       "      <td>114.023880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>16</td>\n",
       "      <td>0.075842</td>\n",
       "      <td>0.075842</td>\n",
       "      <td>22.281200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>4</td>\n",
       "      <td>0.078726</td>\n",
       "      <td>0.078726</td>\n",
       "      <td>83.082242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>0.0050</td>\n",
       "      <td>2</td>\n",
       "      <td>0.097490</td>\n",
       "      <td>0.097490</td>\n",
       "      <td>125.706130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0050</td>\n",
       "      <td>2</td>\n",
       "      <td>0.106216</td>\n",
       "      <td>0.106216</td>\n",
       "      <td>140.813314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0050</td>\n",
       "      <td>2</td>\n",
       "      <td>0.125119</td>\n",
       "      <td>0.125119</td>\n",
       "      <td>125.483526</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Deep layers  Num units  Learning rate  Batch size      Loss     Score  \\\n",
       "0             2        100         0.0001           2  0.030825  0.030825   \n",
       "1             2        200         0.0001           2  0.030859  0.030859   \n",
       "2             2        100         0.0001           2  0.031013  0.031013   \n",
       "3             2        200         0.0001           2  0.031090  0.031090   \n",
       "4             2        100         0.0001           2  0.031183  0.031183   \n",
       "5             2        100         0.0001           2  0.031501  0.031501   \n",
       "6             2        100         0.0001           2  0.031541  0.031541   \n",
       "7             2        100         0.0001           2  0.031664  0.031664   \n",
       "8             2        100         0.0001           2  0.031876  0.031876   \n",
       "9             2        200         0.0001           2  0.032058  0.032058   \n",
       "10            2        100         0.0001           2  0.032074  0.032074   \n",
       "11            2        100         0.0001           2  0.032193  0.032193   \n",
       "12            2        100         0.0001           2  0.032231  0.032231   \n",
       "13            2        100         0.0001           2  0.032601  0.032601   \n",
       "14            2         50         0.0001           2  0.032642  0.032642   \n",
       "15            4        100         0.0001           4  0.033511  0.033511   \n",
       "16            4        150         0.0001           2  0.033960  0.033960   \n",
       "17            2         50         0.0001           2  0.034307  0.034307   \n",
       "18            4        100         0.0001           2  0.034842  0.034842   \n",
       "19            2        200         0.0001           4  0.034862  0.034862   \n",
       "20            2        100         0.0001           4  0.035572  0.035572   \n",
       "21            2        200         0.0001           4  0.035617  0.035617   \n",
       "22            2        200         0.0001           4  0.036094  0.036094   \n",
       "23            2        200         0.0001           4  0.036696  0.036696   \n",
       "24            2        100         0.0001           2  0.037230  0.037230   \n",
       "25            2        100         0.0001           4  0.037427  0.037427   \n",
       "26            2        100         0.0001           4  0.039135  0.039135   \n",
       "27            1        150         0.0001           2  0.047184  0.047184   \n",
       "28            2        200         0.0001          16  0.050234  0.050234   \n",
       "29            2        100         0.0050           4  0.050746  0.050746   \n",
       "30            1        100         0.0001           2  0.056450  0.056450   \n",
       "31            4        200         0.0050          16  0.057512  0.057512   \n",
       "32            1        100         0.0001           2  0.072846  0.072846   \n",
       "33            2        100         0.0001          16  0.075842  0.075842   \n",
       "34            1        100         0.0001           4  0.078726  0.078726   \n",
       "35            2         50         0.0050           2  0.097490  0.097490   \n",
       "36            2        100         0.0050           2  0.106216  0.106216   \n",
       "37            3        100         0.0050           2  0.125119  0.125119   \n",
       "\n",
       "    Elapsed time  \n",
       "0     121.247330  \n",
       "1     194.777666  \n",
       "2     139.654197  \n",
       "3     149.119230  \n",
       "4     120.109314  \n",
       "5     129.705826  \n",
       "6     156.268517  \n",
       "7     106.618822  \n",
       "8     134.552308  \n",
       "9     138.977348  \n",
       "10    118.847125  \n",
       "11    142.974303  \n",
       "12    130.232068  \n",
       "13    148.126180  \n",
       "14    129.937292  \n",
       "15     83.801551  \n",
       "16    184.709769  \n",
       "17    134.108357  \n",
       "18    179.845323  \n",
       "19     72.816577  \n",
       "20     50.895254  \n",
       "21     72.231563  \n",
       "22     74.872102  \n",
       "23     81.158140  \n",
       "24    145.605001  \n",
       "25     89.421775  \n",
       "26     61.633771  \n",
       "27    203.025587  \n",
       "28     28.267952  \n",
       "29     70.964093  \n",
       "30    130.555108  \n",
       "31     36.673715  \n",
       "32    114.023880  \n",
       "33     22.281200  \n",
       "34     83.082242  \n",
       "35    125.706130  \n",
       "36    140.813314  \n",
       "37    125.483526  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename = \"historial_genetic_jla1.txt\"\n",
    "df = pd.DataFrame(datos, columns = [\"Deep layers\", \"Num units\", \"Learning rate\", \"Batch size\", \"Loss\", \"Score\", \"Elapsed time\"])\n",
    "\n",
    "df.sort_values(by=[\"Loss\", \"Elapsed time\"], ascending=[True, True], ignore_index=True, inplace=True)\n",
    "\n",
    "df.to_csv(filename, header=True, index=False, sep='\\t', mode='w') # a=append, w=overwrite\n",
    "df.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time 72.885 minutes\n"
     ]
    }
   ],
   "source": [
    "total_time = float(np.sum(df[[\"Elapsed time\"]])/60)\n",
    "\n",
    "print(\"Elapsed time {:.3f} minutes\".format(total_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
