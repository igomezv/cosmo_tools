{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import time, os\n",
    "import random\n",
    "import seaborn as sns\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Input, Dense, LeakyReLU\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorboard.plugins.hparams import api as hp\n",
    "\n",
    "from tensorflow.keras import activations\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split as split\n",
    "from scipy.stats import bernoulli\n",
    "\n",
    "# import deap\n",
    "from deap import base, creator, tools, algorithms\n",
    "\n",
    "from bitstring import BitArray\n",
    "\n",
    "# from elitism import eaSimpleWithElitism, main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "\n",
    "# tf.config.optimizer.set_jit(True)\n",
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alpha</th>\n",
       "      <th>delta</th>\n",
       "      <th>u</th>\n",
       "      <th>g</th>\n",
       "      <th>r</th>\n",
       "      <th>i</th>\n",
       "      <th>z</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>135.689107</td>\n",
       "      <td>32.494632</td>\n",
       "      <td>23.87882</td>\n",
       "      <td>22.27530</td>\n",
       "      <td>20.39501</td>\n",
       "      <td>19.16573</td>\n",
       "      <td>18.79371</td>\n",
       "      <td>GALAXY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>144.826101</td>\n",
       "      <td>31.274185</td>\n",
       "      <td>24.77759</td>\n",
       "      <td>22.83188</td>\n",
       "      <td>22.58444</td>\n",
       "      <td>21.16812</td>\n",
       "      <td>21.61427</td>\n",
       "      <td>GALAXY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>142.188790</td>\n",
       "      <td>35.582444</td>\n",
       "      <td>25.26307</td>\n",
       "      <td>22.66389</td>\n",
       "      <td>20.60976</td>\n",
       "      <td>19.34857</td>\n",
       "      <td>18.94827</td>\n",
       "      <td>GALAXY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>338.741038</td>\n",
       "      <td>-0.402828</td>\n",
       "      <td>22.13682</td>\n",
       "      <td>23.77656</td>\n",
       "      <td>21.61162</td>\n",
       "      <td>20.50454</td>\n",
       "      <td>19.25010</td>\n",
       "      <td>GALAXY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>345.282593</td>\n",
       "      <td>21.183866</td>\n",
       "      <td>19.43718</td>\n",
       "      <td>17.58028</td>\n",
       "      <td>16.49747</td>\n",
       "      <td>15.97711</td>\n",
       "      <td>15.54461</td>\n",
       "      <td>GALAXY</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        alpha      delta         u         g         r         i         z  \\\n",
       "0  135.689107  32.494632  23.87882  22.27530  20.39501  19.16573  18.79371   \n",
       "1  144.826101  31.274185  24.77759  22.83188  22.58444  21.16812  21.61427   \n",
       "2  142.188790  35.582444  25.26307  22.66389  20.60976  19.34857  18.94827   \n",
       "3  338.741038  -0.402828  22.13682  23.77656  21.61162  20.50454  19.25010   \n",
       "4  345.282593  21.183866  19.43718  17.58028  16.49747  15.97711  15.54461   \n",
       "\n",
       "    class  \n",
       "0  GALAXY  \n",
       "1  GALAXY  \n",
       "2  GALAXY  \n",
       "3  GALAXY  \n",
       "4  GALAXY  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = \"https://raw.githubusercontent.com/igomezv/nnogada/main/data/star_classification.csv\"\n",
    "data = pd.read_csv(url)\n",
    "cols = ['alpha','delta','u','g','r','i','z','class']\n",
    "data = data[cols]\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        alpha      delta         u         g         r         i         z  \\\n",
      "0  135.689107  32.494632  23.87882  22.27530  20.39501  19.16573  18.79371   \n",
      "1  144.826101  31.274185  24.77759  22.83188  22.58444  21.16812  21.61427   \n",
      "2  142.188790  35.582444  25.26307  22.66389  20.60976  19.34857  18.94827   \n",
      "3  338.741038  -0.402828  22.13682  23.77656  21.61162  20.50454  19.25010   \n",
      "4  345.282593  21.183866  19.43718  17.58028  16.49747  15.97711  15.54461   \n",
      "\n",
      "   class  \n",
      "0      0  \n",
      "1      0  \n",
      "2      0  \n",
      "3      0  \n",
      "4      0  \n"
     ]
    }
   ],
   "source": [
    "data[\"class\"]=[0 if i == \"GALAXY\" else 1 if i == \"STAR\" else 2 for i in data[\"class\"]]\n",
    "print(data.head())\n",
    "data = data.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Activation function layers\n",
    "\n",
    "# f1 = lambda x: Dense(x, activation='relu')      #ReLU\n",
    "# f2 = lambda x: Dense(x, activation='elu')       #ELU\n",
    "# f3 = lambda x: keras.layers.LeakyReLU(0.3)      #LReLU\n",
    "# f4 = lambda x: Dense(x, kernel_initializer='lecun_normal', activation='selu')   #SELU\n",
    "\n",
    "# f_names = [\"ReLU\", \"ELU\", \"LReLU\", \"SELU\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "SC_DEEP       = np.array([1, 2,3, 4])                           # Number of deep layers (8)\n",
    "SC_NUM_UNITS  = np.array([150, 200, 100, 50]) # Number of fully conected neurons (16)\n",
    "SC_LEARNING   = np.array([1e-5,1e-4,1e-3, 0.01])   # Learning rates (8)\n",
    "# SC_BATCH      = np.array([64,128,256,512])                            # Batch sizes (4)\n",
    "# SC_ACTIVATION = [f1, f2, f3, f4]                                      # Activation function layers (2)\n",
    "\n",
    "my_callbacks = [tf.keras.callbacks.EarlyStopping(\n",
    "                               monitor='val_loss', mode='min',\n",
    "                               min_delta=0, \n",
    "                               patience=50,\n",
    "                               verbose=1,\n",
    "                            #    baseline=0,\n",
    "                               restore_best_weights=1)\n",
    "#                 keras.callbacks.TensorBoard(\n",
    "#                                log_dir='./logs'),\n",
    "#                 keras.callbacks.ReduceLROnPlateau(\n",
    "#                                monitor='val_loss', factor=0.5,\n",
    "#                                patience=6, min_lr=0,\n",
    "#                                verbose=1)\n",
    "               ] \n",
    "    \n",
    "epochs = 50\n",
    "# epochs = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divide data into X and Y and implement hot_ones in Y\n",
    "def prepare_dataset(data):\n",
    "    X, Y = np.empty((0)), np.empty((0))\n",
    "    X = data[:,0:7]\n",
    "    Y = data[:,7]\n",
    "    Y = to_categorical(Y, num_classes=3)\n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dataset into train, validation and test sets\n",
    "X,Y = prepare_dataset(data)\n",
    "\n",
    "# Defines ratios, w.r.t. whole dataset.\n",
    "ratio_train = 0.8\n",
    "ratio_val = 0.1\n",
    "ratio_test = 0.1\n",
    "\n",
    "# Produces test split.\n",
    "x_, X_test, y_, Y_test = split(X, Y, test_size = ratio_test, random_state=0)\n",
    "\n",
    "# Adjusts val ratio, w.r.t. remaining dataset.\n",
    "ratio_remaining = 1 - ratio_test\n",
    "ratio_val_adjusted = ratio_val / ratio_remaining\n",
    "\n",
    "# Produces train and val splits.\n",
    "X_train, X_val, Y_train, Y_val = split(x_, y_, test_size=ratio_val_adjusted, random_state=0)\n",
    "\n",
    "# Normalize and scale the input sets.\n",
    "scaler.fit(X)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test  = scaler.transform(X_test)\n",
    "X_val   = scaler.transform(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_evaluate(ga_individual_solution):   \n",
    "    t = time.time()\n",
    "    t_total = 0\n",
    "    \n",
    "    # Decode GA solution to integer for window_size and num_units\n",
    "    deep_layers_bits   = BitArray(ga_individual_solution[0:2])     # (8)\n",
    "    num_units_bits     = BitArray(ga_individual_solution[2:4])     # (16)\n",
    "    learning_rate_bits = BitArray(ga_individual_solution[4:6])    # (8)\n",
    "# #     batch_size_bits    = BitArray(ga_individual_solution[10:12])   # (4)\n",
    "# #     activation_f_bits  = BitArray(ga_individual_solution[12:13])   # (2)   Solo se consideran las 2 primeras\n",
    "    \n",
    "    deep_layers   = SC_DEEP[deep_layers_bits.uint]\n",
    "    num_units     = SC_NUM_UNITS[num_units_bits.uint]\n",
    "    learning_rate = SC_LEARNING[learning_rate_bits.uint]\n",
    "#     batch_size   = SC_BATCH[batch_size_bits.uint]\n",
    "#     activation_f  = SC_ACTIVATION[activation_f_bits.uint]\n",
    "\n",
    "    \n",
    "    print('\\n--------------- Starting trial:', population_size*(max_generations+1)-len(ss), \"---------------\")\n",
    "    print('Deep layers:',deep_layers,', Number of neurons:',num_units,\", Learning rate:\",learning_rate)\n",
    "#     print(\"-------------------------------------------------\")\n",
    "    \n",
    "    # Train model and predict on validation set\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(Input(shape=(int(X_train.shape[1]),)))\n",
    "    model.add(Dense(num_units, input_shape=(int(X_train.shape[1]),)))\n",
    "    \n",
    "    for i in range(deep_layers):        \n",
    "        model.add(Dense(num_units, activation='relu'))\n",
    "#             model.add(keras.layers.Dropout(0.3))\n",
    "    model.add(Dense(3, activation=tf.nn.softmax))\n",
    "    \n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate, beta_1=0.9, beta_2=0.999, epsilon=1e-3)\n",
    "    model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=[\"accuracy\"])\n",
    "    model.fit(X_train, Y_train, epochs=epochs, validation_data=(X_val, Y_val),\n",
    "              callbacks=my_callbacks, batch_size=128, shuffle=1, verbose=0)\n",
    "    \n",
    "    loss, score = model.evaluate(X_val, Y_val)    \n",
    "    t = time.time()-t\n",
    "    ss.pop(0)\n",
    "    print(\"Accuracy:\", score, \", Elapsed time:\", t)\n",
    "    print(\"-------------------------------------------------\\n\")\n",
    "#     print(loss, score)\n",
    "\n",
    "    datos.append([deep_layers, num_units, learning_rate, loss, score, t])\n",
    "    \n",
    "    return loss,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deap import tools\n",
    "from deap import algorithms\n",
    "\n",
    "def eaSimpleWithElitism(population, toolbox, cxpb, mutpb, ngen, stats=None,\n",
    "             halloffame=None, verbose=__debug__):\n",
    "    \"\"\"This algorithm is similar to DEAP eaSimple() algorithm, with the modification that\n",
    "    halloffame is used to implement an elitism mechanism. The individuals contained in the\n",
    "    halloffame are directly injected into the next generation and are not subject to the\n",
    "    genetic operators of selection, crossover and mutation.\n",
    "    \"\"\"\n",
    "    logbook = tools.Logbook()\n",
    "    logbook.header = ['gen', 'nevals'] + (stats.fields if stats else [])\n",
    "\n",
    "    # Evaluate the individuals with an invalid fitness\n",
    "    invalid_ind = [ind for ind in population if not ind.fitness.valid]\n",
    "    fitnesses = toolbox.map(toolbox.evaluate, invalid_ind)\n",
    "    for ind, fit in zip(invalid_ind, fitnesses):\n",
    "        ind.fitness.values = fit\n",
    "\n",
    "    if halloffame is None:\n",
    "        raise ValueError(\"halloffame parameter must not be empty!\")\n",
    "\n",
    "    halloffame.update(population)\n",
    "    hof_size = len(halloffame.items) if halloffame.items else 0\n",
    "\n",
    "    record = stats.compile(population) if stats else {}\n",
    "    logbook.record(gen=0, nevals=len(invalid_ind), **record)\n",
    "    if verbose:\n",
    "        print(logbook.stream)\n",
    "\n",
    "    # Begin the generational process\n",
    "    for gen in range(1, ngen + 1):\n",
    "\n",
    "        # Select the next generation individuals\n",
    "        offspring = toolbox.select(population, len(population) - hof_size)\n",
    "\n",
    "        # Vary the pool of individuals\n",
    "        offspring = algorithms.varAnd(offspring, toolbox, cxpb, mutpb)\n",
    "\n",
    "        # Evaluate the individuals with an invalid fitness\n",
    "        invalid_ind = [ind for ind in offspring if not ind.fitness.valid]\n",
    "        fitnesses = toolbox.map(toolbox.evaluate, invalid_ind)\n",
    "        for ind, fit in zip(invalid_ind, fitnesses):\n",
    "            ind.fitness.values = fit\n",
    "\n",
    "        # add the best back to population:\n",
    "        offspring.extend(halloffame.items)\n",
    "\n",
    "        # Update the hall of fame with the generated individuals\n",
    "        halloffame.update(offspring)\n",
    "\n",
    "        # Replace the current population by the offspring\n",
    "        population[:] = offspring\n",
    "\n",
    "        # Append the current generation statistics to the logbook\n",
    "        record = stats.compile(population) if stats else {}\n",
    "        logbook.record(gen=gen, nevals=len(invalid_ind), **record)\n",
    "        if verbose:\n",
    "            print(logbook.stream)\n",
    "\n",
    "    return population, logbook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def geneticAlgorithm_with_elitism(population_size, max_generations, gene_length, k):\n",
    "    \n",
    "    # Genetic Algorithm constants:\n",
    "    P_CROSSOVER = 0.5      # probability for crossover\n",
    "    P_MUTATION = 0.2         # probability for mutating an individual\n",
    "    HALL_OF_FAME_SIZE = 1  # Best individuals that pass to the other generation\n",
    "    \n",
    "    # set the random seed:\n",
    "    toolbox = base.Toolbox()\n",
    "\n",
    "    # As we are trying to minimize the RMSE score, that's why using -1.0. \n",
    "    # In case, when you want to maximize accuracy for instance, use 1.0\n",
    "    creator.create('FitnessMin', base.Fitness, weights = [-1.0])\n",
    "    creator.create('Individual', list , fitness = creator.FitnessMin)\n",
    "\n",
    "    # create the individual operator to fill up an Individual instance:\n",
    "    toolbox.register('binary', bernoulli.rvs, 0.5)\n",
    "    toolbox.register('individual', tools.initRepeat, creator.Individual, toolbox.binary, n = gene_length)\n",
    "\n",
    "    # create the population operator to generate a list of individuals:\n",
    "    toolbox.register('population', tools.initRepeat, list , toolbox.individual)\n",
    "\n",
    "    # genetic operators:\n",
    "    toolbox.register('evaluate', train_evaluate)\n",
    "    toolbox.register('select', tools.selTournament, tournsize = 2)\n",
    "    toolbox.register('mutate', tools.mutFlipBit, indpb = 0.11)\n",
    "    toolbox.register('mate', tools.cxUniform, indpb = 0.5)\n",
    "    \n",
    "    # create initial population (generation 0):\n",
    "    population = toolbox.population(n=population_size)\n",
    "\n",
    "    # prepare the statistics object:\n",
    "    stats = tools.Statistics(lambda ind: ind.fitness.values)\n",
    "    stats.register(\"min\", np.min)\n",
    "    stats.register(\"avg\", np.mean)\n",
    "    stats.register(\"max\", np.max)\n",
    "\n",
    "    # define the hall-of-fame object:\n",
    "    hof = tools.HallOfFame(HALL_OF_FAME_SIZE)\n",
    "\n",
    "    # Genetic Algorithm flow with elitism:\n",
    "    population, logbook = eaSimpleWithElitism(population, toolbox, cxpb=P_CROSSOVER, mutpb=P_MUTATION,\n",
    "                                              ngen=max_generations, stats=stats, halloffame=hof, verbose=True)\n",
    "\n",
    "    # print info for best solution found:\n",
    "    best = hof.items[0]\n",
    "    print(\"-- Best Individual = \", best)\n",
    "    print(\"-- Best Fitness = \", best.fitness.values[0])\n",
    "\n",
    "    # extract statistics:\n",
    "    minFitnessValues, meanFitnessValues, maxFitnessValues = logbook.select(\"min\", \"max\", \"avg\")\n",
    "\n",
    "    # plot statistics:\n",
    "    sns.set_style(\"whitegrid\")\n",
    "    plt.plot(minFitnessValues, color='blue', label=\"Min\")\n",
    "    plt.plot(meanFitnessValues, color='green', label=\"Mean\")\n",
    "    plt.plot(maxFitnessValues, color='red', label=\"Max\")\n",
    "    plt.xlabel('Generation'); plt.ylabel('Max / Min / Average Fitness')\n",
    "    plt.legend()\n",
    "    plt.title('Max, Min and Average fitness over Generations')\n",
    "    plt.show()\n",
    "    \n",
    "    best_population = tools.selBest(population,k = k)\n",
    "    return best_population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------------- Starting trial: 1 ---------------\n",
      "Deep layers: 4 , Number of neurons: 50 , Learning rate: 0.0001\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.3902 - accuracy: 0.8582\n",
      "Accuracy: 0.8582000136375427 , Elapsed time: 49.48821306228638\n",
      "-------------------------------------------------\n",
      "\n",
      "\n",
      "--------------- Starting trial: 2 ---------------\n",
      "Deep layers: 2 , Number of neurons: 100 , Learning rate: 0.01\n",
      "313/313 [==============================] - 0s 911us/step - loss: 0.3342 - accuracy: 0.8760\n",
      "Accuracy: 0.8759999871253967 , Elapsed time: 47.22623324394226\n",
      "-------------------------------------------------\n",
      "\n",
      "\n",
      "--------------- Starting trial: 3 ---------------\n",
      "Deep layers: 4 , Number of neurons: 150 , Learning rate: 0.0001\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.3562 - accuracy: 0.8705\n",
      "Accuracy: 0.8705000281333923 , Elapsed time: 76.79654502868652\n",
      "-------------------------------------------------\n",
      "\n",
      "\n",
      "--------------- Starting trial: 4 ---------------\n",
      "Deep layers: 4 , Number of neurons: 50 , Learning rate: 0.0001\n",
      "313/313 [==============================] - 0s 980us/step - loss: 0.3928 - accuracy: 0.8562\n",
      "Accuracy: 0.8561999797821045 , Elapsed time: 46.718350648880005\n",
      "-------------------------------------------------\n",
      "\n",
      "\n",
      "--------------- Starting trial: 5 ---------------\n",
      "Deep layers: 2 , Number of neurons: 200 , Learning rate: 0.001\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.3407 - accuracy: 0.8765\n",
      "Accuracy: 0.8765000104904175 , Elapsed time: 62.65753769874573\n",
      "-------------------------------------------------\n",
      "\n",
      "gen\tnevals\tmin     \tavg     \tmax     \n",
      "0  \t5     \t0.334189\t0.362842\t0.392829\n",
      "\n",
      "--------------- Starting trial: 6 ---------------\n",
      "Deep layers: 4 , Number of neurons: 50 , Learning rate: 1e-05\n",
      "313/313 [==============================] - 0s 932us/step - loss: 0.5437 - accuracy: 0.7893\n",
      "Accuracy: 0.7893000245094299 , Elapsed time: 48.33119606971741\n",
      "-------------------------------------------------\n",
      "\n",
      "\n",
      "--------------- Starting trial: 7 ---------------\n",
      "Deep layers: 4 , Number of neurons: 150 , Learning rate: 0.0001\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.3571 - accuracy: 0.8705\n",
      "Accuracy: 0.8705000281333923 , Elapsed time: 74.2317943572998\n",
      "-------------------------------------------------\n",
      "\n",
      "\n",
      "--------------- Starting trial: 8 ---------------\n",
      "Deep layers: 2 , Number of neurons: 100 , Learning rate: 0.01\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.3390 - accuracy: 0.8757\n",
      "Accuracy: 0.8756999969482422 , Elapsed time: 48.03197145462036\n",
      "-------------------------------------------------\n",
      "\n",
      "1  \t3     \t0.334189\t0.381641\t0.543693\n",
      "\n",
      "--------------- Starting trial: 9 ---------------\n",
      "Deep layers: 2 , Number of neurons: 100 , Learning rate: 0.01\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.3565 - accuracy: 0.8731\n",
      "Accuracy: 0.8730999827384949 , Elapsed time: 48.98345875740051\n",
      "-------------------------------------------------\n",
      "\n",
      "2  \t1     \t0.334189\t0.338653\t0.356511\n",
      "\n",
      "--------------- Starting trial: 10 ---------------\n",
      "Deep layers: 2 , Number of neurons: 100 , Learning rate: 0.01\n",
      "313/313 [==============================] - 0s 958us/step - loss: 0.3328 - accuracy: 0.8779\n",
      "Accuracy: 0.8779000043869019 , Elapsed time: 49.741375207901\n",
      "-------------------------------------------------\n",
      "\n",
      "\n",
      "--------------- Starting trial: 11 ---------------\n",
      "Deep layers: 2 , Number of neurons: 100 , Learning rate: 0.01\n",
      "313/313 [==============================] - 0s 971us/step - loss: 0.3503 - accuracy: 0.8706\n",
      "Accuracy: 0.8705999851226807 , Elapsed time: 49.673754930496216\n",
      "-------------------------------------------------\n",
      "\n",
      "3  \t2     \t0.33278 \t0.337121\t0.350258\n",
      "\n",
      "--------------- Starting trial: 12 ---------------\n",
      "Deep layers: 2 , Number of neurons: 100 , Learning rate: 0.01\n",
      "313/313 [==============================] - 0s 942us/step - loss: 0.3626 - accuracy: 0.8710\n",
      "Accuracy: 0.8709999918937683 , Elapsed time: 49.28780508041382\n",
      "-------------------------------------------------\n",
      "\n",
      "4  \t1     \t0.33278 \t0.339585\t0.362578\n",
      "\n",
      "--------------- Starting trial: 13 ---------------\n",
      "Deep layers: 2 , Number of neurons: 100 , Learning rate: 0.01\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.3350 - accuracy: 0.8786\n",
      "Accuracy: 0.878600001335144 , Elapsed time: 49.319950103759766\n",
      "-------------------------------------------------\n",
      "\n",
      "5  \t1     \t0.334189\t0.334361\t0.335048\n",
      "6  \t0     \t0.334189\t0.334189\t0.334189\n",
      "\n",
      "--------------- Starting trial: 14 ---------------\n",
      "Deep layers: 2 , Number of neurons: 100 , Learning rate: 0.01\n",
      "313/313 [==============================] - 0s 967us/step - loss: 0.3473 - accuracy: 0.8720\n",
      "Accuracy: 0.871999979019165 , Elapsed time: 49.85332250595093\n",
      "-------------------------------------------------\n",
      "\n",
      "7  \t1     \t0.334189\t0.336806\t0.347273\n",
      "8  \t0     \t0.334189\t0.334189\t0.334189\n",
      "\n",
      "--------------- Starting trial: 15 ---------------\n",
      "Deep layers: 2 , Number of neurons: 100 , Learning rate: 0.01\n",
      "313/313 [==============================] - 0s 1000us/step - loss: 0.3306 - accuracy: 0.8816\n",
      "Accuracy: 0.881600022315979 , Elapsed time: 52.411160945892334\n",
      "-------------------------------------------------\n",
      "\n",
      "\n",
      "--------------- Starting trial: 16 ---------------\n",
      "Deep layers: 2 , Number of neurons: 100 , Learning rate: 0.01\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.3497 - accuracy: 0.8672\n",
      "Accuracy: 0.8672000169754028 , Elapsed time: 53.58390951156616\n",
      "-------------------------------------------------\n",
      "\n",
      "\n",
      "--------------- Starting trial: 17 ---------------\n",
      "Deep layers: 2 , Number of neurons: 100 , Learning rate: 0.0001\n",
      "313/313 [==============================] - 0s 982us/step - loss: 0.4104 - accuracy: 0.8511\n",
      "Accuracy: 0.8511000275611877 , Elapsed time: 53.98201322555542\n",
      "-------------------------------------------------\n",
      "\n",
      "\n",
      "--------------- Starting trial: 18 ---------------\n",
      "Deep layers: 2 , Number of neurons: 100 , Learning rate: 0.01\n",
      "313/313 [==============================] - 0s 971us/step - loss: 0.3315 - accuracy: 0.8783\n",
      "Accuracy: 0.8783000111579895 , Elapsed time: 52.30102729797363\n",
      "-------------------------------------------------\n",
      "\n",
      "9  \t4     \t0.330592\t0.351285\t0.410444\n",
      "\n",
      "--------------- Starting trial: 19 ---------------\n",
      "Deep layers: 2 , Number of neurons: 100 , Learning rate: 0.01\n",
      "313/313 [==============================] - 0s 980us/step - loss: 0.3279 - accuracy: 0.8784\n",
      "Accuracy: 0.8784000277519226 , Elapsed time: 52.013569355010986\n",
      "-------------------------------------------------\n",
      "\n",
      "\n",
      "--------------- Starting trial: 20 ---------------\n",
      "Deep layers: 2 , Number of neurons: 100 , Learning rate: 0.01\n",
      "313/313 [==============================] - 0s 936us/step - loss: 0.3486 - accuracy: 0.8745\n",
      "Accuracy: 0.8744999766349792 , Elapsed time: 48.735710859298706\n",
      "-------------------------------------------------\n",
      "\n",
      "\n",
      "--------------- Starting trial: 21 ---------------\n",
      "Deep layers: 2 , Number of neurons: 150 , Learning rate: 0.01\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.3334 - accuracy: 0.8780\n",
      "Accuracy: 0.878000020980835 , Elapsed time: 54.16569638252258\n",
      "-------------------------------------------------\n",
      "\n",
      "10 \t3     \t0.327865\t0.335104\t0.348586\n",
      "-- Best Individual =  [0, 1, 0, 0, 1, 1]\n",
      "-- Best Fitness =  0.33338794112205505\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total elapsed time: 18.629293676217397 minutes\n"
     ]
    }
   ],
   "source": [
    "population_size = 5  # max of individuals per generation\n",
    "max_generations = 10   # number of generations\n",
    "gene_length = 6      # lenght of the gene, depends on how many hiperparameters are tested  \n",
    "k = 1;                 # num. of finalist individuals\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    t = time.time(); \n",
    "    datos = [];\n",
    "    ss = [i for i in range(1,population_size*(max_generations+1))]\n",
    "    best_population = geneticAlgorithm_with_elitism(population_size, max_generations, gene_length, k)\n",
    "    print(\"Total elapsed time:\", (time.time()-t)/60, \"minutes\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k= 1 \n",
      "Deep layers: 2 , Number of neurons: 100 , Learning rate: 0.01\n"
     ]
    }
   ],
   "source": [
    "best_deep_layers   = []\n",
    "best_num_units     = []\n",
    "best_learning_rate = []\n",
    "# best_batch_size    = []\n",
    "# best_activation_f  = []\n",
    "best_f_names       = []\n",
    "\n",
    "t = 0\n",
    "\n",
    "for bi in best_population:\n",
    "    deep_layers_bits   = BitArray(bi[0:2])    # (8)\n",
    "    num_units_bits     = BitArray(bi[2:4])    # (16)\n",
    "    learning_rate_bits = BitArray(bi[4:6])   # (8)\n",
    "#     batch_size_bits    = BitArray(bi[10:12])  # (4)\n",
    "#     activation_f_bits  = BitArray(bi[12:13])  # (2)\n",
    "    t += 1 \n",
    "    \n",
    "    best_deep_layers.append(SC_DEEP[deep_layers_bits.uint])\n",
    "    best_num_units.append(SC_NUM_UNITS[num_units_bits.uint])\n",
    "    best_learning_rate.append(SC_LEARNING[learning_rate_bits.uint])\n",
    "#     best_batch_size.append(SC_BATCH[batch_size_bits.uint])\n",
    "#     best_activation_f.append(SC_ACTIVATION[activation_f_bits.uint])\n",
    "#     best_f_names.append(f_names[activation_f_bits.uint])\n",
    "    \n",
    "    print('k=',t,'\\nDeep layers:', best_deep_layers[-1], ', Number of neurons:', best_num_units[-1], ', Learning rate:', best_learning_rate[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Deep layers</th>\n",
       "      <th>Num units</th>\n",
       "      <th>Learning rate</th>\n",
       "      <th>Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Elapsed time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.01000</td>\n",
       "      <td>0.330592</td>\n",
       "      <td>0.8816</td>\n",
       "      <td>52.411161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.01000</td>\n",
       "      <td>0.335048</td>\n",
       "      <td>0.8786</td>\n",
       "      <td>49.319950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.01000</td>\n",
       "      <td>0.327865</td>\n",
       "      <td>0.8784</td>\n",
       "      <td>52.013569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.01000</td>\n",
       "      <td>0.331493</td>\n",
       "      <td>0.8783</td>\n",
       "      <td>52.301027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>150</td>\n",
       "      <td>0.01000</td>\n",
       "      <td>0.333388</td>\n",
       "      <td>0.8780</td>\n",
       "      <td>54.165696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.01000</td>\n",
       "      <td>0.332780</td>\n",
       "      <td>0.8779</td>\n",
       "      <td>49.741375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2</td>\n",
       "      <td>200</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>0.340730</td>\n",
       "      <td>0.8765</td>\n",
       "      <td>62.657538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.01000</td>\n",
       "      <td>0.334189</td>\n",
       "      <td>0.8760</td>\n",
       "      <td>47.226233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.01000</td>\n",
       "      <td>0.338988</td>\n",
       "      <td>0.8757</td>\n",
       "      <td>48.031971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.01000</td>\n",
       "      <td>0.348586</td>\n",
       "      <td>0.8745</td>\n",
       "      <td>48.735711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.01000</td>\n",
       "      <td>0.356511</td>\n",
       "      <td>0.8731</td>\n",
       "      <td>48.983459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.01000</td>\n",
       "      <td>0.347273</td>\n",
       "      <td>0.8720</td>\n",
       "      <td>49.853323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.01000</td>\n",
       "      <td>0.362578</td>\n",
       "      <td>0.8710</td>\n",
       "      <td>49.287805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.01000</td>\n",
       "      <td>0.350258</td>\n",
       "      <td>0.8706</td>\n",
       "      <td>49.673755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>4</td>\n",
       "      <td>150</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>0.357144</td>\n",
       "      <td>0.8705</td>\n",
       "      <td>74.231794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>4</td>\n",
       "      <td>150</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>0.356246</td>\n",
       "      <td>0.8705</td>\n",
       "      <td>76.796545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.01000</td>\n",
       "      <td>0.349709</td>\n",
       "      <td>0.8672</td>\n",
       "      <td>53.583910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>4</td>\n",
       "      <td>50</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>0.390216</td>\n",
       "      <td>0.8582</td>\n",
       "      <td>49.488213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>4</td>\n",
       "      <td>50</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>0.392829</td>\n",
       "      <td>0.8562</td>\n",
       "      <td>46.718351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>0.410444</td>\n",
       "      <td>0.8511</td>\n",
       "      <td>53.982013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>4</td>\n",
       "      <td>50</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.543693</td>\n",
       "      <td>0.7893</td>\n",
       "      <td>48.331196</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Deep layers  Num units  Learning rate      Loss  Accuracy  Elapsed time\n",
       "0             2        100        0.01000  0.330592    0.8816     52.411161\n",
       "1             2        100        0.01000  0.335048    0.8786     49.319950\n",
       "2             2        100        0.01000  0.327865    0.8784     52.013569\n",
       "3             2        100        0.01000  0.331493    0.8783     52.301027\n",
       "4             2        150        0.01000  0.333388    0.8780     54.165696\n",
       "5             2        100        0.01000  0.332780    0.8779     49.741375\n",
       "6             2        200        0.00100  0.340730    0.8765     62.657538\n",
       "7             2        100        0.01000  0.334189    0.8760     47.226233\n",
       "8             2        100        0.01000  0.338988    0.8757     48.031971\n",
       "9             2        100        0.01000  0.348586    0.8745     48.735711\n",
       "10            2        100        0.01000  0.356511    0.8731     48.983459\n",
       "11            2        100        0.01000  0.347273    0.8720     49.853323\n",
       "12            2        100        0.01000  0.362578    0.8710     49.287805\n",
       "13            2        100        0.01000  0.350258    0.8706     49.673755\n",
       "14            4        150        0.00010  0.357144    0.8705     74.231794\n",
       "15            4        150        0.00010  0.356246    0.8705     76.796545\n",
       "16            2        100        0.01000  0.349709    0.8672     53.583910\n",
       "17            4         50        0.00010  0.390216    0.8582     49.488213\n",
       "18            4         50        0.00010  0.392829    0.8562     46.718351\n",
       "19            2        100        0.00010  0.410444    0.8511     53.982013\n",
       "20            4         50        0.00001  0.543693    0.7893     48.331196"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename = \"historial_sdss.txt\"\n",
    "df = pd.DataFrame(datos, columns = [\"Deep layers\", \"Num units\", \"Learning rate\", \"Loss\", \"Accuracy\", \"Elapsed time\"])\n",
    "\n",
    "df.sort_values(by=[\"Accuracy\", \"Elapsed time\"], ascending=[0,1], ignore_index=True, inplace=True)\n",
    "\n",
    "df.to_csv(filename, header=True, index=False, sep='\\t', mode='w') # a=append, w=overwrite\n",
    "df.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time 18.626 minutes\n"
     ]
    }
   ],
   "source": [
    "total_time = float(np.sum(df[[\"Elapsed time\"]])/60)\n",
    "\n",
    "print(\"Elapsed time {:.3f} minutes\".format(total_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
