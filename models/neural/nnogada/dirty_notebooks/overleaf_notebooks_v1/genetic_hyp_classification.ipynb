{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elitism succesfully imported\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import time, os\n",
    "import random\n",
    "import seaborn as sns\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Input, Dense, LeakyReLU\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorboard.plugins.hparams import api as hp\n",
    "\n",
    "from tensorflow.keras import activations\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split as split\n",
    "from scipy.stats import bernoulli\n",
    "\n",
    "# import deap\n",
    "from deap import base, creator, tools, algorithms\n",
    "\n",
    "from bitstring import BitArray\n",
    "\n",
    "# from elitism import eaSimpleWithElitism, main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "\n",
    "# tf.config.optimizer.set_jit(True)\n",
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alpha</th>\n",
       "      <th>delta</th>\n",
       "      <th>u</th>\n",
       "      <th>g</th>\n",
       "      <th>r</th>\n",
       "      <th>i</th>\n",
       "      <th>z</th>\n",
       "      <th>redshift</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>135.689107</td>\n",
       "      <td>32.494632</td>\n",
       "      <td>23.87882</td>\n",
       "      <td>22.27530</td>\n",
       "      <td>20.39501</td>\n",
       "      <td>19.16573</td>\n",
       "      <td>18.79371</td>\n",
       "      <td>0.634794</td>\n",
       "      <td>GALAXY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>144.826101</td>\n",
       "      <td>31.274185</td>\n",
       "      <td>24.77759</td>\n",
       "      <td>22.83188</td>\n",
       "      <td>22.58444</td>\n",
       "      <td>21.16812</td>\n",
       "      <td>21.61427</td>\n",
       "      <td>0.779136</td>\n",
       "      <td>GALAXY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>142.188790</td>\n",
       "      <td>35.582444</td>\n",
       "      <td>25.26307</td>\n",
       "      <td>22.66389</td>\n",
       "      <td>20.60976</td>\n",
       "      <td>19.34857</td>\n",
       "      <td>18.94827</td>\n",
       "      <td>0.644195</td>\n",
       "      <td>GALAXY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>338.741038</td>\n",
       "      <td>-0.402828</td>\n",
       "      <td>22.13682</td>\n",
       "      <td>23.77656</td>\n",
       "      <td>21.61162</td>\n",
       "      <td>20.50454</td>\n",
       "      <td>19.25010</td>\n",
       "      <td>0.932346</td>\n",
       "      <td>GALAXY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>345.282593</td>\n",
       "      <td>21.183866</td>\n",
       "      <td>19.43718</td>\n",
       "      <td>17.58028</td>\n",
       "      <td>16.49747</td>\n",
       "      <td>15.97711</td>\n",
       "      <td>15.54461</td>\n",
       "      <td>0.116123</td>\n",
       "      <td>GALAXY</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        alpha      delta         u         g         r         i         z  \\\n",
       "0  135.689107  32.494632  23.87882  22.27530  20.39501  19.16573  18.79371   \n",
       "1  144.826101  31.274185  24.77759  22.83188  22.58444  21.16812  21.61427   \n",
       "2  142.188790  35.582444  25.26307  22.66389  20.60976  19.34857  18.94827   \n",
       "3  338.741038  -0.402828  22.13682  23.77656  21.61162  20.50454  19.25010   \n",
       "4  345.282593  21.183866  19.43718  17.58028  16.49747  15.97711  15.54461   \n",
       "\n",
       "   redshift   class  \n",
       "0  0.634794  GALAXY  \n",
       "1  0.779136  GALAXY  \n",
       "2  0.644195  GALAXY  \n",
       "3  0.932346  GALAXY  \n",
       "4  0.116123  GALAXY  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = \"https://raw.githubusercontent.com/igomezv/neurapprox/main/data/star_classification.csv\"\n",
    "data = pd.read_csv(url)\n",
    "cols = ['alpha','delta','u','g','r','i','z','redshift','class']\n",
    "data = data[cols]\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        alpha      delta         u         g         r         i         z  \\\n",
      "0  135.689107  32.494632  23.87882  22.27530  20.39501  19.16573  18.79371   \n",
      "1  144.826101  31.274185  24.77759  22.83188  22.58444  21.16812  21.61427   \n",
      "2  142.188790  35.582444  25.26307  22.66389  20.60976  19.34857  18.94827   \n",
      "3  338.741038  -0.402828  22.13682  23.77656  21.61162  20.50454  19.25010   \n",
      "4  345.282593  21.183866  19.43718  17.58028  16.49747  15.97711  15.54461   \n",
      "\n",
      "   redshift  class  \n",
      "0  0.634794      0  \n",
      "1  0.779136      0  \n",
      "2  0.644195      0  \n",
      "3  0.932346      0  \n",
      "4  0.116123      0  \n"
     ]
    }
   ],
   "source": [
    "data[\"class\"]=[0 if i == \"GALAXY\" else 1 if i == \"STAR\" else 2 for i in data[\"class\"]]\n",
    "print(data.head())\n",
    "data = data.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Activation function layers\n",
    "\n",
    "# f1 = lambda x: Dense(x, activation='relu')      #ReLU\n",
    "# f2 = lambda x: Dense(x, activation='elu')       #ELU\n",
    "# f3 = lambda x: keras.layers.LeakyReLU(0.3)      #LReLU\n",
    "# f4 = lambda x: Dense(x, kernel_initializer='lecun_normal', activation='selu')   #SELU\n",
    "\n",
    "# f_names = [\"ReLU\", \"ELU\", \"LReLU\", \"SELU\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "SC_DEEP       = np.array([2,3,4])                           # Number of deep layers (8)\n",
    "SC_NUM_UNITS  = np.array([50,100,200]) # Number of fully conected neurons (16)\n",
    "SC_LEARNING   = np.array([1e-5,1e-4,5e-3])   # Learning rates (8)\n",
    "# SC_BATCH      = np.array([64,128,256,512])                            # Batch sizes (4)\n",
    "# SC_ACTIVATION = [f1, f2, f3, f4]                                      # Activation function layers (2)\n",
    "\n",
    "my_callbacks = [tf.keras.callbacks.EarlyStopping(\n",
    "                               monitor='val_loss', mode='min',\n",
    "                               min_delta=0, \n",
    "                               patience=6,\n",
    "                               verbose=1,\n",
    "                            #    baseline=0,\n",
    "                               restore_best_weights=1)\n",
    "#                 keras.callbacks.TensorBoard(\n",
    "#                                log_dir='./logs'),\n",
    "#                 keras.callbacks.ReduceLROnPlateau(\n",
    "#                                monitor='val_loss', factor=0.5,\n",
    "#                                patience=6, min_lr=0,\n",
    "#                                verbose=1)\n",
    "               ] \n",
    "    \n",
    "epochs = 50\n",
    "# epochs = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divide data into X and Y and implement hot_ones in Y\n",
    "def prepare_dataset(data):\n",
    "    X, Y = np.empty((0)), np.empty((0))\n",
    "    X = data[:,0:8]\n",
    "    Y = data[:,8]\n",
    "    Y = to_categorical(Y, num_classes=3)\n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dataset into train, validation and test sets\n",
    "X,Y = prepare_dataset(data)\n",
    "\n",
    "# Defines ratios, w.r.t. whole dataset.\n",
    "ratio_train = 0.8\n",
    "ratio_val = 0.1\n",
    "ratio_test = 0.1\n",
    "\n",
    "# Produces test split.\n",
    "x_, X_test, y_, Y_test = split(X, Y, test_size = ratio_test, random_state=0)\n",
    "\n",
    "# Adjusts val ratio, w.r.t. remaining dataset.\n",
    "ratio_remaining = 1 - ratio_test\n",
    "ratio_val_adjusted = ratio_val / ratio_remaining\n",
    "\n",
    "# Produces train and val splits.\n",
    "X_train, X_val, Y_train, Y_val = split(x_, y_, test_size=ratio_val_adjusted, random_state=0)\n",
    "\n",
    "# Normalize and scale the input sets.\n",
    "scaler.fit(X)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test  = scaler.transform(X_test)\n",
    "X_val   = scaler.transform(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_evaluate(ga_individual_solution):   \n",
    "    t = time.time()\n",
    "    t_total = 0\n",
    "    \n",
    "    # Decode GA solution to integer for window_size and num_units\n",
    "    deep_layers_bits   = BitArray(ga_individual_solution[0:1])     # (8)\n",
    "    num_units_bits     = BitArray(ga_individual_solution[1:2])     # (16)\n",
    "    learning_rate_bits = BitArray(ga_individual_solution[2:3])    # (8)\n",
    "# #     batch_size_bits    = BitArray(ga_individual_solution[10:12])   # (4)\n",
    "# #     activation_f_bits  = BitArray(ga_individual_solution[12:13])   # (2)   Solo se consideran las 2 primeras\n",
    "    \n",
    "    deep_layers   = SC_DEEP[deep_layers_bits.uint]\n",
    "    num_units     = SC_NUM_UNITS[num_units_bits.uint]\n",
    "    learning_rate = SC_LEARNING[learning_rate_bits.uint]\n",
    "#     batch_size   = SC_BATCH[batch_size_bits.uint]\n",
    "#     activation_f  = SC_ACTIVATION[activation_f_bits.uint]\n",
    "\n",
    "    \n",
    "    print('\\n--------------- Starting trial:', population_size*(max_generations+1)-len(ss), \"---------------\")\n",
    "    print('Deep layers:',deep_layers,', Number of neurons:',num_units,\", Learning rate:\",learning_rate)\n",
    "#     print(\"-------------------------------------------------\")\n",
    "    \n",
    "    # Train model and predict on validation set\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(Input(shape=(int(X_train.shape[1]),)))\n",
    "    model.add(Dense(num_units, input_shape=(int(X_train.shape[1]),)))\n",
    "    \n",
    "    for i in range(deep_layers):        \n",
    "        model.add(Dense(num_units, activation='relu'))\n",
    "#             model.add(keras.layers.Dropout(0.3))\n",
    "    model.add(Dense(3, activation=tf.nn.softmax))\n",
    "    \n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate, beta_1=0.9, beta_2=0.999, epsilon=1e-3)\n",
    "    model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=[\"accuracy\"])\n",
    "    model.fit(X_train, Y_train, epochs=epochs, validation_data=(X_val, Y_val),\n",
    "              callbacks=my_callbacks, batch_size=128, shuffle=1, verbose=0)\n",
    "    \n",
    "    loss, score = model.evaluate(X_val, Y_val)    \n",
    "    t = time.time()-t\n",
    "    ss.pop(0)\n",
    "    print(\"Accuracy:\", score, \", Elapsed time:\", t)\n",
    "    print(\"-------------------------------------------------\\n\")\n",
    "#     print(loss, score)\n",
    "\n",
    "    datos.append([deep_layers, num_units, learning_rate, loss, score, t])\n",
    "    \n",
    "    return loss,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deap import tools\n",
    "from deap import algorithms\n",
    "\n",
    "def eaSimpleWithElitism(population, toolbox, cxpb, mutpb, ngen, stats=None,\n",
    "             halloffame=None, verbose=__debug__):\n",
    "    \"\"\"This algorithm is similar to DEAP eaSimple() algorithm, with the modification that\n",
    "    halloffame is used to implement an elitism mechanism. The individuals contained in the\n",
    "    halloffame are directly injected into the next generation and are not subject to the\n",
    "    genetic operators of selection, crossover and mutation.\n",
    "    \"\"\"\n",
    "    logbook = tools.Logbook()\n",
    "    logbook.header = ['gen', 'nevals'] + (stats.fields if stats else [])\n",
    "\n",
    "    # Evaluate the individuals with an invalid fitness\n",
    "    invalid_ind = [ind for ind in population if not ind.fitness.valid]\n",
    "    fitnesses = toolbox.map(toolbox.evaluate, invalid_ind)\n",
    "    for ind, fit in zip(invalid_ind, fitnesses):\n",
    "        ind.fitness.values = fit\n",
    "\n",
    "    if halloffame is None:\n",
    "        raise ValueError(\"halloffame parameter must not be empty!\")\n",
    "\n",
    "    halloffame.update(population)\n",
    "    hof_size = len(halloffame.items) if halloffame.items else 0\n",
    "\n",
    "    record = stats.compile(population) if stats else {}\n",
    "    logbook.record(gen=0, nevals=len(invalid_ind), **record)\n",
    "    if verbose:\n",
    "        print(logbook.stream)\n",
    "\n",
    "    # Begin the generational process\n",
    "    for gen in range(1, ngen + 1):\n",
    "\n",
    "        # Select the next generation individuals\n",
    "        offspring = toolbox.select(population, len(population) - hof_size)\n",
    "\n",
    "        # Vary the pool of individuals\n",
    "        offspring = algorithms.varAnd(offspring, toolbox, cxpb, mutpb)\n",
    "\n",
    "        # Evaluate the individuals with an invalid fitness\n",
    "        invalid_ind = [ind for ind in offspring if not ind.fitness.valid]\n",
    "        fitnesses = toolbox.map(toolbox.evaluate, invalid_ind)\n",
    "        for ind, fit in zip(invalid_ind, fitnesses):\n",
    "            ind.fitness.values = fit\n",
    "\n",
    "        # add the best back to population:\n",
    "        offspring.extend(halloffame.items)\n",
    "\n",
    "        # Update the hall of fame with the generated individuals\n",
    "        halloffame.update(offspring)\n",
    "\n",
    "        # Replace the current population by the offspring\n",
    "        population[:] = offspring\n",
    "\n",
    "        # Append the current generation statistics to the logbook\n",
    "        record = stats.compile(population) if stats else {}\n",
    "        logbook.record(gen=gen, nevals=len(invalid_ind), **record)\n",
    "        if verbose:\n",
    "            print(logbook.stream)\n",
    "\n",
    "    return population, logbook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def geneticAlgorithm_with_elitism(population_size, max_generations, gene_length, k):\n",
    "    \n",
    "    # Genetic Algorithm constants:\n",
    "    P_CROSSOVER = 0.5        # probability for crossover\n",
    "    P_MUTATION = 0.5         # probability for mutating an individual\n",
    "    HALL_OF_FAME_SIZE = 1    # Best individuals that pass to the other generation\n",
    "    \n",
    "    # set the random seed:\n",
    "    toolbox = base.Toolbox()\n",
    "\n",
    "    # As we are trying to minimize the RMSE score, that's why using -1.0. \n",
    "    # In case, when you want to maximize accuracy for instance, use 1.0\n",
    "    creator.create('FitnessMin', base.Fitness, weights = [-1.0])\n",
    "    creator.create('Individual', list , fitness = creator.FitnessMin)\n",
    "\n",
    "    # create the individual operator to fill up an Individual instance:\n",
    "    toolbox.register('binary', bernoulli.rvs, 0.5)\n",
    "    toolbox.register('individual', tools.initRepeat, creator.Individual, toolbox.binary, n = gene_length)\n",
    "\n",
    "    # create the population operator to generate a list of individuals:\n",
    "    toolbox.register('population', tools.initRepeat, list , toolbox.individual)\n",
    "\n",
    "    # genetic operators:\n",
    "    toolbox.register('evaluate', train_evaluate)\n",
    "    toolbox.register('select', tools.selTournament, tournsize = 2)\n",
    "    toolbox.register('mutate', tools.mutFlipBit, indpb = 0.11)\n",
    "    toolbox.register('mate', tools.cxUniform, indpb = 0.5)\n",
    "    \n",
    "    # create initial population (generation 0):\n",
    "    population = toolbox.population(n=population_size)\n",
    "\n",
    "    # prepare the statistics object:\n",
    "    stats = tools.Statistics(lambda ind: ind.fitness.values)\n",
    "    stats.register(\"min\", np.min)\n",
    "    stats.register(\"avg\", np.mean)\n",
    "    stats.register(\"max\", np.max)\n",
    "\n",
    "    # define the hall-of-fame object:\n",
    "    hof = tools.HallOfFame(HALL_OF_FAME_SIZE)\n",
    "\n",
    "    # Genetic Algorithm flow with elitism:\n",
    "    population, logbook = eaSimpleWithElitism(population, toolbox, cxpb=P_CROSSOVER, mutpb=P_MUTATION,\n",
    "                                              ngen=max_generations, stats=stats, halloffame=hof, verbose=True)\n",
    "\n",
    "    # print info for best solution found:\n",
    "    best = hof.items[0]\n",
    "    print(\"-- Best Individual = \", best)\n",
    "    print(\"-- Best Fitness = \", best.fitness.values[0])\n",
    "\n",
    "    # extract statistics:\n",
    "    minFitnessValues, meanFitnessValues, maxFitnessValues = logbook.select(\"min\", \"max\", \"avg\")\n",
    "\n",
    "    # plot statistics:\n",
    "    sns.set_style(\"whitegrid\")\n",
    "    plt.plot(minFitnessValues, color='blue', label=\"Min\")\n",
    "    plt.plot(meanFitnessValues, color='green', label=\"Mean\")\n",
    "    plt.plot(maxFitnessValues, color='red', label=\"Max\")\n",
    "    plt.xlabel('Generation'); plt.ylabel('Max / Min / Average Fitness')\n",
    "    plt.legend()\n",
    "    plt.title('Max, Min and Average fitness over Generations')\n",
    "    plt.show()\n",
    "    \n",
    "    best_population = tools.selBest(population,k = k)\n",
    "    return best_population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------------- Starting trial: 1 ---------------\n",
      "Deep layers: 3 , Number of neurons: 100 , Learning rate: 0.0001\n",
      "Restoring model weights from the end of the best epoch: 22.\n",
      "Epoch 28: early stopping\n",
      "313/313 [==============================] - 0s 639us/step - loss: 0.1028 - accuracy: 0.9686\n",
      "Accuracy: 0.9685999751091003 , Elapsed time: 19.64182949066162\n",
      "-------------------------------------------------\n",
      "\n",
      "\n",
      "--------------- Starting trial: 2 ---------------\n",
      "Deep layers: 3 , Number of neurons: 100 , Learning rate: 0.0001\n",
      "313/313 [==============================] - 0s 632us/step - loss: 0.0972 - accuracy: 0.9704\n",
      "Accuracy: 0.9703999757766724 , Elapsed time: 33.77818703651428\n",
      "-------------------------------------------------\n",
      "\n",
      "\n",
      "--------------- Starting trial: 3 ---------------\n",
      "Deep layers: 3 , Number of neurons: 100 , Learning rate: 1e-05\n",
      "313/313 [==============================] - 0s 640us/step - loss: 0.1352 - accuracy: 0.9593\n",
      "Accuracy: 0.9592999815940857 , Elapsed time: 33.79049873352051\n",
      "-------------------------------------------------\n",
      "\n",
      "\n",
      "--------------- Starting trial: 4 ---------------\n",
      "Deep layers: 2 , Number of neurons: 100 , Learning rate: 1e-05\n",
      "313/313 [==============================] - 0s 660us/step - loss: 0.1571 - accuracy: 0.9544\n",
      "Accuracy: 0.9544000029563904 , Elapsed time: 30.13193392753601\n",
      "-------------------------------------------------\n",
      "\n",
      "\n",
      "--------------- Starting trial: 5 ---------------\n",
      "Deep layers: 2 , Number of neurons: 50 , Learning rate: 0.0001\n",
      "313/313 [==============================] - 0s 599us/step - loss: 0.1038 - accuracy: 0.9691\n",
      "Accuracy: 0.9690999984741211 , Elapsed time: 25.222798824310303\n",
      "-------------------------------------------------\n",
      "\n",
      "\n",
      "--------------- Starting trial: 6 ---------------\n",
      "Deep layers: 3 , Number of neurons: 50 , Learning rate: 0.0001\n",
      "313/313 [==============================] - 0s 590us/step - loss: 0.0991 - accuracy: 0.9694\n",
      "Accuracy: 0.9693999886512756 , Elapsed time: 26.73545479774475\n",
      "-------------------------------------------------\n",
      "\n",
      "gen\tnevals\tmin      \tavg     \tmax     \n",
      "0  \t6     \t0.0972242\t0.115871\t0.157059\n",
      "\n",
      "--------------- Starting trial: 7 ---------------\n",
      "Deep layers: 3 , Number of neurons: 100 , Learning rate: 0.0001\n",
      "Restoring model weights from the end of the best epoch: 35.\n",
      "Epoch 41: early stopping\n",
      "313/313 [==============================] - 0s 637us/step - loss: 0.0962 - accuracy: 0.9696\n",
      "Accuracy: 0.9696000218391418 , Elapsed time: 27.933034896850586\n",
      "-------------------------------------------------\n",
      "\n",
      "\n",
      "--------------- Starting trial: 8 ---------------\n",
      "Deep layers: 3 , Number of neurons: 100 , Learning rate: 1e-05\n",
      "313/313 [==============================] - 0s 644us/step - loss: 0.1311 - accuracy: 0.9612\n",
      "Accuracy: 0.9611999988555908 , Elapsed time: 34.002626180648804\n",
      "-------------------------------------------------\n",
      "\n",
      "\n",
      "--------------- Starting trial: 9 ---------------\n",
      "Deep layers: 2 , Number of neurons: 100 , Learning rate: 0.0001\n",
      "313/313 [==============================] - 0s 609us/step - loss: 0.0979 - accuracy: 0.9696\n",
      "Accuracy: 0.9696000218391418 , Elapsed time: 30.06874990463257\n",
      "-------------------------------------------------\n",
      "\n",
      "\n",
      "--------------- Starting trial: 10 ---------------\n",
      "Deep layers: 3 , Number of neurons: 100 , Learning rate: 0.0001\n",
      "313/313 [==============================] - 0s 635us/step - loss: 0.0971 - accuracy: 0.9707\n",
      "Accuracy: 0.9707000255584717 , Elapsed time: 33.85500168800354\n",
      "-------------------------------------------------\n",
      "\n",
      "1  \t4     \t0.0961658\t0.103104\t0.131145\n",
      "\n",
      "--------------- Starting trial: 11 ---------------\n",
      "Deep layers: 3 , Number of neurons: 100 , Learning rate: 0.0001\n",
      "313/313 [==============================] - 0s 627us/step - loss: 0.0977 - accuracy: 0.9704\n",
      "Accuracy: 0.9703999757766724 , Elapsed time: 33.99117159843445\n",
      "-------------------------------------------------\n",
      "\n",
      "\n",
      "--------------- Starting trial: 12 ---------------\n",
      "Deep layers: 3 , Number of neurons: 100 , Learning rate: 0.0001\n",
      "313/313 [==============================] - 0s 636us/step - loss: 0.0947 - accuracy: 0.9708\n",
      "Accuracy: 0.97079998254776 , Elapsed time: 33.97128129005432\n",
      "-------------------------------------------------\n",
      "\n",
      "\n",
      "--------------- Starting trial: 13 ---------------\n",
      "Deep layers: 3 , Number of neurons: 100 , Learning rate: 0.0001\n",
      "Restoring model weights from the end of the best epoch: 35.\n",
      "Epoch 41: early stopping\n",
      "313/313 [==============================] - 0s 633us/step - loss: 0.0956 - accuracy: 0.9701\n",
      "Accuracy: 0.9700999855995178 , Elapsed time: 27.86694860458374\n",
      "-------------------------------------------------\n",
      "\n",
      "\n",
      "--------------- Starting trial: 14 ---------------\n",
      "Deep layers: 3 , Number of neurons: 100 , Learning rate: 0.0001\n",
      "313/313 [==============================] - 0s 630us/step - loss: 0.0948 - accuracy: 0.9706\n",
      "Accuracy: 0.9706000089645386 , Elapsed time: 34.015069007873535\n",
      "-------------------------------------------------\n",
      "\n",
      "2  \t4     \t0.0946647\t0.0958441\t0.0976518\n",
      "\n",
      "--------------- Starting trial: 15 ---------------\n",
      "Deep layers: 3 , Number of neurons: 100 , Learning rate: 0.0001\n",
      "313/313 [==============================] - 0s 634us/step - loss: 0.0986 - accuracy: 0.9698\n",
      "Accuracy: 0.9697999954223633 , Elapsed time: 34.01834011077881\n",
      "-------------------------------------------------\n",
      "\n",
      "3  \t1     \t0.0946647\t0.0958672\t0.0986278\n",
      "\n",
      "--------------- Starting trial: 16 ---------------\n",
      "Deep layers: 2 , Number of neurons: 100 , Learning rate: 0.0001\n",
      "313/313 [==============================] - 0s 604us/step - loss: 0.1000 - accuracy: 0.9701\n",
      "Accuracy: 0.9700999855995178 , Elapsed time: 30.290807723999023\n",
      "-------------------------------------------------\n",
      "\n",
      "\n",
      "--------------- Starting trial: 17 ---------------\n",
      "Deep layers: 3 , Number of neurons: 100 , Learning rate: 0.0001\n",
      "313/313 [==============================] - 0s 620us/step - loss: 0.0943 - accuracy: 0.9713\n",
      "Accuracy: 0.9713000059127808 , Elapsed time: 34.152706146240234\n",
      "-------------------------------------------------\n",
      "\n",
      "4  \t2     \t0.0943125\t0.0955413\t0.100027 \n",
      "\n",
      "--------------- Starting trial: 18 ---------------\n",
      "Deep layers: 3 , Number of neurons: 50 , Learning rate: 1e-05\n",
      "313/313 [==============================] - 0s 633us/step - loss: 0.1615 - accuracy: 0.9546\n",
      "Accuracy: 0.9545999765396118 , Elapsed time: 27.02402114868164\n",
      "-------------------------------------------------\n",
      "\n",
      "\n",
      "--------------- Starting trial: 19 ---------------\n",
      "Deep layers: 3 , Number of neurons: 50 , Learning rate: 0.0001\n",
      "313/313 [==============================] - 0s 626us/step - loss: 0.0952 - accuracy: 0.9703\n",
      "Accuracy: 0.970300018787384 , Elapsed time: 26.794257640838623\n",
      "-------------------------------------------------\n",
      "\n",
      "\n",
      "--------------- Starting trial: 20 ---------------\n",
      "Deep layers: 3 , Number of neurons: 100 , Learning rate: 0.0001\n",
      "Restoring model weights from the end of the best epoch: 44.\n",
      "Epoch 50: early stopping\n",
      "313/313 [==============================] - 0s 631us/step - loss: 0.0971 - accuracy: 0.9710\n",
      "Accuracy: 0.9710000157356262 , Elapsed time: 33.93140983581543\n",
      "-------------------------------------------------\n",
      "\n",
      "\n",
      "--------------- Starting trial: 21 ---------------\n",
      "Deep layers: 2 , Number of neurons: 100 , Learning rate: 0.0001\n",
      "313/313 [==============================] - 0s 620us/step - loss: 0.0985 - accuracy: 0.9701\n",
      "Accuracy: 0.9700999855995178 , Elapsed time: 30.093494653701782\n",
      "-------------------------------------------------\n",
      "\n",
      "\n",
      "--------------- Starting trial: 22 ---------------\n",
      "Deep layers: 2 , Number of neurons: 100 , Learning rate: 0.0001\n",
      "313/313 [==============================] - 0s 638us/step - loss: 0.0985 - accuracy: 0.9697\n",
      "Accuracy: 0.9696999788284302 , Elapsed time: 30.140045881271362\n",
      "-------------------------------------------------\n",
      "\n",
      "5  \t5     \t0.0946647\t0.107594 \t0.161508 \n",
      "\n",
      "--------------- Starting trial: 23 ---------------\n",
      "Deep layers: 3 , Number of neurons: 100 , Learning rate: 0.0001\n",
      "313/313 [==============================] - 0s 628us/step - loss: 0.0947 - accuracy: 0.9702\n",
      "Accuracy: 0.9702000021934509 , Elapsed time: 34.10094475746155\n",
      "-------------------------------------------------\n",
      "\n",
      "6  \t1     \t0.0946647\t0.0962256\t0.0985313\n",
      "\n",
      "--------------- Starting trial: 24 ---------------\n",
      "Deep layers: 2 , Number of neurons: 100 , Learning rate: 0.0001\n",
      "Restoring model weights from the end of the best epoch: 42.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48: early stopping\n",
      "313/313 [==============================] - 0s 643us/step - loss: 0.0997 - accuracy: 0.9690\n",
      "Accuracy: 0.968999981880188 , Elapsed time: 28.974069833755493\n",
      "-------------------------------------------------\n",
      "\n",
      "\n",
      "--------------- Starting trial: 25 ---------------\n",
      "Deep layers: 3 , Number of neurons: 50 , Learning rate: 0.0001\n",
      "Restoring model weights from the end of the best epoch: 34.\n",
      "Epoch 40: early stopping\n",
      "313/313 [==============================] - 0s 631us/step - loss: 0.1023 - accuracy: 0.9689\n",
      "Accuracy: 0.9689000248908997 , Elapsed time: 21.496236324310303\n",
      "-------------------------------------------------\n",
      "\n",
      "\n",
      "--------------- Starting trial: 26 ---------------\n",
      "Deep layers: 3 , Number of neurons: 100 , Learning rate: 0.0001\n",
      "313/313 [==============================] - 0s 634us/step - loss: 0.0977 - accuracy: 0.9703\n",
      "Accuracy: 0.970300018787384 , Elapsed time: 35.46355700492859\n",
      "-------------------------------------------------\n",
      "\n",
      "\n",
      "--------------- Starting trial: 27 ---------------\n",
      "Deep layers: 3 , Number of neurons: 100 , Learning rate: 0.0001\n",
      "313/313 [==============================] - 0s 683us/step - loss: 0.0986 - accuracy: 0.9715\n",
      "Accuracy: 0.9714999794960022 , Elapsed time: 34.2783043384552\n",
      "-------------------------------------------------\n",
      "\n",
      "7  \t4     \t0.0946647\t0.0983419\t0.102266 \n",
      "-- Best Individual =  [1, 1, 1, 1, 0, 1, 1, 1, 0, 0]\n",
      "-- Best Fitness =  0.09466465562582016\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total elapsed time: 13.76584788163503 minutes\n"
     ]
    }
   ],
   "source": [
    "population_size = 6   # max of individuals per generation\n",
    "max_generations = 7   # number of generations\n",
    "gene_length = 10       # lenght of the gene, depends on how many hiperparameters are tested  \n",
    "k = 1;                 # num. of finalist individuals\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    t = time.time(); \n",
    "    datos = [];\n",
    "    ss = [i for i in range(1,population_size*(max_generations+1))]\n",
    "    best_population = geneticAlgorithm_with_elitism(population_size, max_generations, gene_length, k)\n",
    "    print(\"Total elapsed time:\", (time.time()-t)/60, \"minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k= 1 \n",
      "Deep layers: 3 , Number of neurons: 100 , Learning rate: 0.0001\n"
     ]
    }
   ],
   "source": [
    "best_deep_layers   = []\n",
    "best_num_units     = []\n",
    "best_learning_rate = []\n",
    "# best_batch_size    = []\n",
    "# best_activation_f  = []\n",
    "best_f_names       = []\n",
    "\n",
    "t = 0\n",
    "\n",
    "for bi in best_population:\n",
    "    deep_layers_bits   = BitArray(bi[0:1])    # (8)\n",
    "    num_units_bits     = BitArray(bi[1:2])    # (16)\n",
    "    learning_rate_bits = BitArray(bi[2:3])   # (8)\n",
    "#     batch_size_bits    = BitArray(bi[10:12])  # (4)\n",
    "#     activation_f_bits  = BitArray(bi[12:13])  # (2)\n",
    "    t += 1 \n",
    "    \n",
    "    best_deep_layers.append(SC_DEEP[deep_layers_bits.uint])\n",
    "    best_num_units.append(SC_NUM_UNITS[num_units_bits.uint])\n",
    "    best_learning_rate.append(SC_LEARNING[learning_rate_bits.uint])\n",
    "#     best_batch_size.append(SC_BATCH[batch_size_bits.uint])\n",
    "#     best_activation_f.append(SC_ACTIVATION[activation_f_bits.uint])\n",
    "#     best_f_names.append(f_names[activation_f_bits.uint])\n",
    "    \n",
    "    print('k=',t,'\\nDeep layers:', best_deep_layers[-1], ', Number of neurons:', best_num_units[-1], ', Learning rate:', best_learning_rate[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Deep layers</th>\n",
       "      <th>Num units</th>\n",
       "      <th>Learning rate</th>\n",
       "      <th>Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Elapsed time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>0.098573</td>\n",
       "      <td>0.9715</td>\n",
       "      <td>34.278304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>0.094312</td>\n",
       "      <td>0.9713</td>\n",
       "      <td>34.152706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>0.097111</td>\n",
       "      <td>0.9710</td>\n",
       "      <td>33.931410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>0.094665</td>\n",
       "      <td>0.9708</td>\n",
       "      <td>33.971281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>0.097102</td>\n",
       "      <td>0.9707</td>\n",
       "      <td>33.855002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>0.094790</td>\n",
       "      <td>0.9706</td>\n",
       "      <td>34.015069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>0.097224</td>\n",
       "      <td>0.9704</td>\n",
       "      <td>33.778187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>0.097652</td>\n",
       "      <td>0.9704</td>\n",
       "      <td>33.991172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3</td>\n",
       "      <td>50</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>0.095246</td>\n",
       "      <td>0.9703</td>\n",
       "      <td>26.794258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>0.097720</td>\n",
       "      <td>0.9703</td>\n",
       "      <td>35.463557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>0.094689</td>\n",
       "      <td>0.9702</td>\n",
       "      <td>34.100945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>0.095627</td>\n",
       "      <td>0.9701</td>\n",
       "      <td>27.866949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>0.098500</td>\n",
       "      <td>0.9701</td>\n",
       "      <td>30.093495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>0.100027</td>\n",
       "      <td>0.9701</td>\n",
       "      <td>30.290808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>0.098628</td>\n",
       "      <td>0.9698</td>\n",
       "      <td>34.018340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>0.098531</td>\n",
       "      <td>0.9697</td>\n",
       "      <td>30.140046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>0.096166</td>\n",
       "      <td>0.9696</td>\n",
       "      <td>27.933035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>0.097914</td>\n",
       "      <td>0.9696</td>\n",
       "      <td>30.068750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>3</td>\n",
       "      <td>50</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>0.099072</td>\n",
       "      <td>0.9694</td>\n",
       "      <td>26.735455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>0.103841</td>\n",
       "      <td>0.9691</td>\n",
       "      <td>25.222799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>0.099716</td>\n",
       "      <td>0.9690</td>\n",
       "      <td>28.974070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>3</td>\n",
       "      <td>50</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>0.102266</td>\n",
       "      <td>0.9689</td>\n",
       "      <td>21.496236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>0.102798</td>\n",
       "      <td>0.9686</td>\n",
       "      <td>19.641829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.131145</td>\n",
       "      <td>0.9612</td>\n",
       "      <td>34.002626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.135234</td>\n",
       "      <td>0.9593</td>\n",
       "      <td>33.790499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>3</td>\n",
       "      <td>50</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.161508</td>\n",
       "      <td>0.9546</td>\n",
       "      <td>27.024021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.157059</td>\n",
       "      <td>0.9544</td>\n",
       "      <td>30.131934</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Deep layers  Num units  Learning rate      Loss  Accuracy  Elapsed time\n",
       "0             3        100        0.00010  0.098573    0.9715     34.278304\n",
       "1             3        100        0.00010  0.094312    0.9713     34.152706\n",
       "2             3        100        0.00010  0.097111    0.9710     33.931410\n",
       "3             3        100        0.00010  0.094665    0.9708     33.971281\n",
       "4             3        100        0.00010  0.097102    0.9707     33.855002\n",
       "5             3        100        0.00010  0.094790    0.9706     34.015069\n",
       "6             3        100        0.00010  0.097224    0.9704     33.778187\n",
       "7             3        100        0.00010  0.097652    0.9704     33.991172\n",
       "8             3         50        0.00010  0.095246    0.9703     26.794258\n",
       "9             3        100        0.00010  0.097720    0.9703     35.463557\n",
       "10            3        100        0.00010  0.094689    0.9702     34.100945\n",
       "11            3        100        0.00010  0.095627    0.9701     27.866949\n",
       "12            2        100        0.00010  0.098500    0.9701     30.093495\n",
       "13            2        100        0.00010  0.100027    0.9701     30.290808\n",
       "14            3        100        0.00010  0.098628    0.9698     34.018340\n",
       "15            2        100        0.00010  0.098531    0.9697     30.140046\n",
       "16            3        100        0.00010  0.096166    0.9696     27.933035\n",
       "17            2        100        0.00010  0.097914    0.9696     30.068750\n",
       "18            3         50        0.00010  0.099072    0.9694     26.735455\n",
       "19            2         50        0.00010  0.103841    0.9691     25.222799\n",
       "20            2        100        0.00010  0.099716    0.9690     28.974070\n",
       "21            3         50        0.00010  0.102266    0.9689     21.496236\n",
       "22            3        100        0.00010  0.102798    0.9686     19.641829\n",
       "23            3        100        0.00001  0.131145    0.9612     34.002626\n",
       "24            3        100        0.00001  0.135234    0.9593     33.790499\n",
       "25            3         50        0.00001  0.161508    0.9546     27.024021\n",
       "26            2        100        0.00001  0.157059    0.9544     30.131934"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename = \"historial_sdss.txt\"\n",
    "df = pd.DataFrame(datos, columns = [\"Deep layers\", \"Num units\", \"Learning rate\", \"Loss\", \"Accuracy\", \"Elapsed time\"])\n",
    "\n",
    "df.sort_values(by=[\"Accuracy\", \"Elapsed time\"], ascending=[0,1], ignore_index=True, inplace=True)\n",
    "\n",
    "df.to_csv(filename, header=True, index=False, sep='\\t', mode='w') # a=append, w=overwrite\n",
    "df.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time 13.763 minutes\n"
     ]
    }
   ],
   "source": [
    "total_time = float(np.sum(df[[\"Elapsed time\"]])/60)\n",
    "\n",
    "print(\"Elapsed time {:.3f} minutes\".format(total_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
