{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import time, os\n",
    "import random\n",
    "import seaborn as sns\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Input, Dense, LeakyReLU\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorboard.plugins.hparams import api as hp\n",
    "\n",
    "from tensorflow.keras import activations\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split as split\n",
    "from scipy.stats import bernoulli\n",
    "\n",
    "# import deap\n",
    "from deap import base, creator, tools, algorithms\n",
    "\n",
    "from bitstring import BitArray\n",
    "\n",
    "# from elitism import eaSimpleWithElitism, main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "\n",
    "# tf.config.optimizer.set_jit(True)\n",
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alpha</th>\n",
       "      <th>delta</th>\n",
       "      <th>u</th>\n",
       "      <th>g</th>\n",
       "      <th>r</th>\n",
       "      <th>i</th>\n",
       "      <th>z</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>135.689107</td>\n",
       "      <td>32.494632</td>\n",
       "      <td>23.87882</td>\n",
       "      <td>22.27530</td>\n",
       "      <td>20.39501</td>\n",
       "      <td>19.16573</td>\n",
       "      <td>18.79371</td>\n",
       "      <td>GALAXY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>144.826101</td>\n",
       "      <td>31.274185</td>\n",
       "      <td>24.77759</td>\n",
       "      <td>22.83188</td>\n",
       "      <td>22.58444</td>\n",
       "      <td>21.16812</td>\n",
       "      <td>21.61427</td>\n",
       "      <td>GALAXY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>142.188790</td>\n",
       "      <td>35.582444</td>\n",
       "      <td>25.26307</td>\n",
       "      <td>22.66389</td>\n",
       "      <td>20.60976</td>\n",
       "      <td>19.34857</td>\n",
       "      <td>18.94827</td>\n",
       "      <td>GALAXY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>338.741038</td>\n",
       "      <td>-0.402828</td>\n",
       "      <td>22.13682</td>\n",
       "      <td>23.77656</td>\n",
       "      <td>21.61162</td>\n",
       "      <td>20.50454</td>\n",
       "      <td>19.25010</td>\n",
       "      <td>GALAXY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>345.282593</td>\n",
       "      <td>21.183866</td>\n",
       "      <td>19.43718</td>\n",
       "      <td>17.58028</td>\n",
       "      <td>16.49747</td>\n",
       "      <td>15.97711</td>\n",
       "      <td>15.54461</td>\n",
       "      <td>GALAXY</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        alpha      delta         u         g         r         i         z  \\\n",
       "0  135.689107  32.494632  23.87882  22.27530  20.39501  19.16573  18.79371   \n",
       "1  144.826101  31.274185  24.77759  22.83188  22.58444  21.16812  21.61427   \n",
       "2  142.188790  35.582444  25.26307  22.66389  20.60976  19.34857  18.94827   \n",
       "3  338.741038  -0.402828  22.13682  23.77656  21.61162  20.50454  19.25010   \n",
       "4  345.282593  21.183866  19.43718  17.58028  16.49747  15.97711  15.54461   \n",
       "\n",
       "    class  \n",
       "0  GALAXY  \n",
       "1  GALAXY  \n",
       "2  GALAXY  \n",
       "3  GALAXY  \n",
       "4  GALAXY  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = \"https://raw.githubusercontent.com/igomezv/nnogada/main/data/star_classification.csv\"\n",
    "data = pd.read_csv(url)\n",
    "cols = ['alpha','delta','u','g','r','i','z','class']\n",
    "data = data[cols]\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        alpha      delta         u         g         r         i         z  \\\n",
      "0  135.689107  32.494632  23.87882  22.27530  20.39501  19.16573  18.79371   \n",
      "1  144.826101  31.274185  24.77759  22.83188  22.58444  21.16812  21.61427   \n",
      "2  142.188790  35.582444  25.26307  22.66389  20.60976  19.34857  18.94827   \n",
      "3  338.741038  -0.402828  22.13682  23.77656  21.61162  20.50454  19.25010   \n",
      "4  345.282593  21.183866  19.43718  17.58028  16.49747  15.97711  15.54461   \n",
      "\n",
      "   class  \n",
      "0      0  \n",
      "1      0  \n",
      "2      0  \n",
      "3      0  \n",
      "4      0  \n"
     ]
    }
   ],
   "source": [
    "data[\"class\"]=[0 if i == \"GALAXY\" else 1 if i == \"STAR\" else 2 for i in data[\"class\"]]\n",
    "print(data.head())\n",
    "data = data.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Activation function layers\n",
    "\n",
    "# f1 = lambda x: Dense(x, activation='relu')      #ReLU\n",
    "# f2 = lambda x: Dense(x, activation='elu')       #ELU\n",
    "# f3 = lambda x: keras.layers.LeakyReLU(0.3)      #LReLU\n",
    "# f4 = lambda x: Dense(x, kernel_initializer='lecun_normal', activation='selu')   #SELU\n",
    "\n",
    "# f_names = [\"ReLU\", \"ELU\", \"LReLU\", \"SELU\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "SC_DEEP       = np.array([2,3,4])                           # Number of deep layers (8)\n",
    "SC_NUM_UNITS  = np.array([50,100,200]) # Number of fully conected neurons (16)\n",
    "SC_LEARNING   = np.array([1e-5,1e-4,5e-3])   # Learning rates (8)\n",
    "# SC_BATCH      = np.array([64,128,256,512])                            # Batch sizes (4)\n",
    "# SC_ACTIVATION = [f1, f2, f3, f4]                                      # Activation function layers (2)\n",
    "\n",
    "my_callbacks = [tf.keras.callbacks.EarlyStopping(\n",
    "                               monitor='val_loss', mode='min',\n",
    "                               min_delta=0, \n",
    "                               patience=6,\n",
    "                               verbose=1,\n",
    "                            #    baseline=0,\n",
    "                               restore_best_weights=1)\n",
    "#                 keras.callbacks.TensorBoard(\n",
    "#                                log_dir='./logs'),\n",
    "#                 keras.callbacks.ReduceLROnPlateau(\n",
    "#                                monitor='val_loss', factor=0.5,\n",
    "#                                patience=6, min_lr=0,\n",
    "#                                verbose=1)\n",
    "               ] \n",
    "    \n",
    "epochs = 50\n",
    "# epochs = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divide data into X and Y and implement hot_ones in Y\n",
    "def prepare_dataset(data):\n",
    "    X, Y = np.empty((0)), np.empty((0))\n",
    "    X = data[:,0:7]\n",
    "    Y = data[:,7]\n",
    "    Y = to_categorical(Y, num_classes=3)\n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dataset into train, validation and test sets\n",
    "X,Y = prepare_dataset(data)\n",
    "\n",
    "# Defines ratios, w.r.t. whole dataset.\n",
    "ratio_train = 0.8\n",
    "ratio_val = 0.1\n",
    "ratio_test = 0.1\n",
    "\n",
    "# Produces test split.\n",
    "x_, X_test, y_, Y_test = split(X, Y, test_size = ratio_test, random_state=0)\n",
    "\n",
    "# Adjusts val ratio, w.r.t. remaining dataset.\n",
    "ratio_remaining = 1 - ratio_test\n",
    "ratio_val_adjusted = ratio_val / ratio_remaining\n",
    "\n",
    "# Produces train and val splits.\n",
    "X_train, X_val, Y_train, Y_val = split(x_, y_, test_size=ratio_val_adjusted, random_state=0)\n",
    "\n",
    "# Normalize and scale the input sets.\n",
    "scaler.fit(X)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test  = scaler.transform(X_test)\n",
    "X_val   = scaler.transform(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_evaluate(ga_individual_solution):   \n",
    "    t = time.time()\n",
    "    t_total = 0\n",
    "    \n",
    "    # Decode GA solution to integer for window_size and num_units\n",
    "    deep_layers_bits   = BitArray(ga_individual_solution[0:1])     # (8)\n",
    "    num_units_bits     = BitArray(ga_individual_solution[1:2])     # (16)\n",
    "    learning_rate_bits = BitArray(ga_individual_solution[2:3])    # (8)\n",
    "# #     batch_size_bits    = BitArray(ga_individual_solution[10:12])   # (4)\n",
    "# #     activation_f_bits  = BitArray(ga_individual_solution[12:13])   # (2)   Solo se consideran las 2 primeras\n",
    "    \n",
    "    deep_layers   = SC_DEEP[deep_layers_bits.uint]\n",
    "    num_units     = SC_NUM_UNITS[num_units_bits.uint]\n",
    "    learning_rate = SC_LEARNING[learning_rate_bits.uint]\n",
    "#     batch_size   = SC_BATCH[batch_size_bits.uint]\n",
    "#     activation_f  = SC_ACTIVATION[activation_f_bits.uint]\n",
    "\n",
    "    \n",
    "    print('\\n--------------- Starting trial:', population_size*(max_generations+1)-len(ss), \"---------------\")\n",
    "    print('Deep layers:',deep_layers,', Number of neurons:',num_units,\", Learning rate:\",learning_rate)\n",
    "#     print(\"-------------------------------------------------\")\n",
    "    \n",
    "    # Train model and predict on validation set\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(Input(shape=(int(X_train.shape[1]),)))\n",
    "    model.add(Dense(num_units, input_shape=(int(X_train.shape[1]),)))\n",
    "    \n",
    "    for i in range(deep_layers):        \n",
    "        model.add(Dense(num_units, activation='relu'))\n",
    "#             model.add(keras.layers.Dropout(0.3))\n",
    "    model.add(Dense(3, activation=tf.nn.softmax))\n",
    "    \n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate, beta_1=0.9, beta_2=0.999, epsilon=1e-3)\n",
    "    model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=[\"accuracy\"])\n",
    "    model.fit(X_train, Y_train, epochs=epochs, validation_data=(X_val, Y_val),\n",
    "              callbacks=my_callbacks, batch_size=128, shuffle=1, verbose=0)\n",
    "    \n",
    "    loss, score = model.evaluate(X_val, Y_val)    \n",
    "    t = time.time()-t\n",
    "    ss.pop(0)\n",
    "    print(\"Accuracy:\", score, \", Elapsed time:\", t)\n",
    "    print(\"-------------------------------------------------\\n\")\n",
    "#     print(loss, score)\n",
    "\n",
    "    datos.append([deep_layers, num_units, learning_rate, loss, score, t])\n",
    "    \n",
    "    return loss,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deap import tools\n",
    "from deap import algorithms\n",
    "\n",
    "def eaSimpleWithElitism(population, toolbox, cxpb, mutpb, ngen, stats=None,\n",
    "             halloffame=None, verbose=__debug__):\n",
    "    \"\"\"This algorithm is similar to DEAP eaSimple() algorithm, with the modification that\n",
    "    halloffame is used to implement an elitism mechanism. The individuals contained in the\n",
    "    halloffame are directly injected into the next generation and are not subject to the\n",
    "    genetic operators of selection, crossover and mutation.\n",
    "    \"\"\"\n",
    "    logbook = tools.Logbook()\n",
    "    logbook.header = ['gen', 'nevals'] + (stats.fields if stats else [])\n",
    "\n",
    "    # Evaluate the individuals with an invalid fitness\n",
    "    invalid_ind = [ind for ind in population if not ind.fitness.valid]\n",
    "    fitnesses = toolbox.map(toolbox.evaluate, invalid_ind)\n",
    "    for ind, fit in zip(invalid_ind, fitnesses):\n",
    "        ind.fitness.values = fit\n",
    "\n",
    "    if halloffame is None:\n",
    "        raise ValueError(\"halloffame parameter must not be empty!\")\n",
    "\n",
    "    halloffame.update(population)\n",
    "    hof_size = len(halloffame.items) if halloffame.items else 0\n",
    "\n",
    "    record = stats.compile(population) if stats else {}\n",
    "    logbook.record(gen=0, nevals=len(invalid_ind), **record)\n",
    "    if verbose:\n",
    "        print(logbook.stream)\n",
    "\n",
    "    # Begin the generational process\n",
    "    for gen in range(1, ngen + 1):\n",
    "\n",
    "        # Select the next generation individuals\n",
    "        offspring = toolbox.select(population, len(population) - hof_size)\n",
    "\n",
    "        # Vary the pool of individuals\n",
    "        offspring = algorithms.varAnd(offspring, toolbox, cxpb, mutpb)\n",
    "\n",
    "        # Evaluate the individuals with an invalid fitness\n",
    "        invalid_ind = [ind for ind in offspring if not ind.fitness.valid]\n",
    "        fitnesses = toolbox.map(toolbox.evaluate, invalid_ind)\n",
    "        for ind, fit in zip(invalid_ind, fitnesses):\n",
    "            ind.fitness.values = fit\n",
    "\n",
    "        # add the best back to population:\n",
    "        offspring.extend(halloffame.items)\n",
    "\n",
    "        # Update the hall of fame with the generated individuals\n",
    "        halloffame.update(offspring)\n",
    "\n",
    "        # Replace the current population by the offspring\n",
    "        population[:] = offspring\n",
    "\n",
    "        # Append the current generation statistics to the logbook\n",
    "        record = stats.compile(population) if stats else {}\n",
    "        logbook.record(gen=gen, nevals=len(invalid_ind), **record)\n",
    "        if verbose:\n",
    "            print(logbook.stream)\n",
    "\n",
    "    return population, logbook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def geneticAlgorithm_with_elitism(population_size, max_generations, gene_length, k):\n",
    "    \n",
    "    # Genetic Algorithm constants:\n",
    "    P_CROSSOVER = 0.5        # probability for crossover\n",
    "    P_MUTATION = 0.5         # probability for mutating an individual\n",
    "    HALL_OF_FAME_SIZE = 1    # Best individuals that pass to the other generation\n",
    "    \n",
    "    # set the random seed:\n",
    "    toolbox = base.Toolbox()\n",
    "\n",
    "    # As we are trying to minimize the RMSE score, that's why using -1.0. \n",
    "    # In case, when you want to maximize accuracy for instance, use 1.0\n",
    "    creator.create('FitnessMin', base.Fitness, weights = [-1.0])\n",
    "    creator.create('Individual', list , fitness = creator.FitnessMin)\n",
    "\n",
    "    # create the individual operator to fill up an Individual instance:\n",
    "    toolbox.register('binary', bernoulli.rvs, 0.5)\n",
    "    toolbox.register('individual', tools.initRepeat, creator.Individual, toolbox.binary, n = gene_length)\n",
    "\n",
    "    # create the population operator to generate a list of individuals:\n",
    "    toolbox.register('population', tools.initRepeat, list , toolbox.individual)\n",
    "\n",
    "    # genetic operators:\n",
    "    toolbox.register('evaluate', train_evaluate)\n",
    "    toolbox.register('select', tools.selTournament, tournsize = 2)\n",
    "    toolbox.register('mutate', tools.mutFlipBit, indpb = 0.11)\n",
    "    toolbox.register('mate', tools.cxUniform, indpb = 0.5)\n",
    "    \n",
    "    # create initial population (generation 0):\n",
    "    population = toolbox.population(n=population_size)\n",
    "\n",
    "    # prepare the statistics object:\n",
    "    stats = tools.Statistics(lambda ind: ind.fitness.values)\n",
    "    stats.register(\"min\", np.min)\n",
    "    stats.register(\"avg\", np.mean)\n",
    "    stats.register(\"max\", np.max)\n",
    "\n",
    "    # define the hall-of-fame object:\n",
    "    hof = tools.HallOfFame(HALL_OF_FAME_SIZE)\n",
    "\n",
    "    # Genetic Algorithm flow with elitism:\n",
    "    population, logbook = eaSimpleWithElitism(population, toolbox, cxpb=P_CROSSOVER, mutpb=P_MUTATION,\n",
    "                                              ngen=max_generations, stats=stats, halloffame=hof, verbose=True)\n",
    "\n",
    "    # print info for best solution found:\n",
    "    best = hof.items[0]\n",
    "    print(\"-- Best Individual = \", best)\n",
    "    print(\"-- Best Fitness = \", best.fitness.values[0])\n",
    "\n",
    "    # extract statistics:\n",
    "    minFitnessValues, meanFitnessValues, maxFitnessValues = logbook.select(\"min\", \"max\", \"avg\")\n",
    "\n",
    "    # plot statistics:\n",
    "    sns.set_style(\"whitegrid\")\n",
    "    plt.plot(minFitnessValues, color='blue', label=\"Min\")\n",
    "    plt.plot(meanFitnessValues, color='green', label=\"Mean\")\n",
    "    plt.plot(maxFitnessValues, color='red', label=\"Max\")\n",
    "    plt.xlabel('Generation'); plt.ylabel('Max / Min / Average Fitness')\n",
    "    plt.legend()\n",
    "    plt.title('Max, Min and Average fitness over Generations')\n",
    "    plt.show()\n",
    "    \n",
    "    best_population = tools.selBest(population,k = k)\n",
    "    return best_population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------------- Starting trial: 1 ---------------\n",
      "Deep layers: 3 , Number of neurons: 100 , Learning rate: 0.0001\n",
      "313/313 [==============================] - 0s 922us/step - loss: 0.3780 - accuracy: 0.8629\n",
      "Accuracy: 0.8629000186920166 , Elapsed time: 47.13958120346069\n",
      "-------------------------------------------------\n",
      "\n",
      "\n",
      "--------------- Starting trial: 2 ---------------\n",
      "Deep layers: 3 , Number of neurons: 100 , Learning rate: 0.0001\n",
      "313/313 [==============================] - 0s 959us/step - loss: 0.3729 - accuracy: 0.8631\n",
      "Accuracy: 0.863099992275238 , Elapsed time: 48.48483872413635\n",
      "-------------------------------------------------\n",
      "\n",
      "\n",
      "--------------- Starting trial: 3 ---------------\n",
      "Deep layers: 3 , Number of neurons: 100 , Learning rate: 1e-05\n",
      "313/313 [==============================] - 0s 867us/step - loss: 0.5359 - accuracy: 0.7939\n",
      "Accuracy: 0.7939000129699707 , Elapsed time: 48.35863709449768\n",
      "-------------------------------------------------\n",
      "\n",
      "\n",
      "--------------- Starting trial: 4 ---------------\n",
      "Deep layers: 2 , Number of neurons: 100 , Learning rate: 1e-05\n",
      "313/313 [==============================] - 0s 847us/step - loss: 0.5764 - accuracy: 0.7806\n",
      "Accuracy: 0.7806000113487244 , Elapsed time: 42.79781532287598\n",
      "-------------------------------------------------\n",
      "\n",
      "\n",
      "--------------- Starting trial: 5 ---------------\n",
      "Deep layers: 2 , Number of neurons: 50 , Learning rate: 0.0001\n",
      "313/313 [==============================] - 0s 815us/step - loss: 0.4269 - accuracy: 0.8419\n",
      "Accuracy: 0.8418999910354614 , Elapsed time: 37.64839172363281\n",
      "-------------------------------------------------\n",
      "\n",
      "\n",
      "--------------- Starting trial: 6 ---------------\n",
      "Deep layers: 3 , Number of neurons: 50 , Learning rate: 0.0001\n",
      "313/313 [==============================] - 0s 911us/step - loss: 0.4280 - accuracy: 0.8461\n",
      "Accuracy: 0.8460999727249146 , Elapsed time: 41.646912813186646\n",
      "-------------------------------------------------\n",
      "\n",
      "gen\tnevals\tmin     \tavg     \tmax     \n",
      "0  \t6     \t0.372858\t0.453002\t0.576436\n",
      "\n",
      "--------------- Starting trial: 7 ---------------\n",
      "Deep layers: 3 , Number of neurons: 100 , Learning rate: 0.0001\n",
      "313/313 [==============================] - 0s 935us/step - loss: 0.3877 - accuracy: 0.8576\n",
      "Accuracy: 0.8575999736785889 , Elapsed time: 51.20516276359558\n",
      "-------------------------------------------------\n",
      "\n",
      "\n",
      "--------------- Starting trial: 8 ---------------\n",
      "Deep layers: 2 , Number of neurons: 50 , Learning rate: 0.0001\n",
      "313/313 [==============================] - 0s 899us/step - loss: 0.4570 - accuracy: 0.8318\n",
      "Accuracy: 0.8317999839782715 , Elapsed time: 38.59357929229736\n",
      "-------------------------------------------------\n",
      "\n",
      "1  \t2     \t0.372858\t0.450463\t0.576436\n",
      "\n",
      "--------------- Starting trial: 9 ---------------\n",
      "Deep layers: 3 , Number of neurons: 100 , Learning rate: 0.0001\n",
      "313/313 [==============================] - 0s 868us/step - loss: 0.3720 - accuracy: 0.8652\n",
      "Accuracy: 0.8651999831199646 , Elapsed time: 50.04459547996521\n",
      "-------------------------------------------------\n",
      "\n",
      "\n",
      "--------------- Starting trial: 10 ---------------\n",
      "Deep layers: 3 , Number of neurons: 100 , Learning rate: 0.0001\n",
      "313/313 [==============================] - 0s 887us/step - loss: 0.3777 - accuracy: 0.8629\n",
      "Accuracy: 0.8629000186920166 , Elapsed time: 47.800636291503906\n",
      "-------------------------------------------------\n",
      "\n",
      "\n",
      "--------------- Starting trial: 11 ---------------\n",
      "Deep layers: 2 , Number of neurons: 100 , Learning rate: 0.0001\n",
      "313/313 [==============================] - 0s 805us/step - loss: 0.4259 - accuracy: 0.8451\n",
      "Accuracy: 0.8450999855995178 , Elapsed time: 42.316898822784424\n",
      "-------------------------------------------------\n",
      "\n",
      "\n",
      "--------------- Starting trial: 12 ---------------\n",
      "Deep layers: 3 , Number of neurons: 100 , Learning rate: 0.0001\n",
      "313/313 [==============================] - 0s 878us/step - loss: 0.3740 - accuracy: 0.8625\n",
      "Accuracy: 0.862500011920929 , Elapsed time: 48.376370429992676\n",
      "-------------------------------------------------\n",
      "\n",
      "2  \t4     \t0.372042\t0.396582\t0.457019\n",
      "\n",
      "--------------- Starting trial: 13 ---------------\n",
      "Deep layers: 3 , Number of neurons: 100 , Learning rate: 0.0001\n",
      "313/313 [==============================] - 0s 977us/step - loss: 0.3874 - accuracy: 0.8593\n",
      "Accuracy: 0.8593000173568726 , Elapsed time: 49.48283362388611\n",
      "-------------------------------------------------\n",
      "\n",
      "\n",
      "--------------- Starting trial: 14 ---------------\n",
      "Deep layers: 3 , Number of neurons: 100 , Learning rate: 0.0001\n",
      "313/313 [==============================] - 0s 943us/step - loss: 0.3778 - accuracy: 0.8624\n",
      "Accuracy: 0.8623999953269958 , Elapsed time: 50.719078063964844\n",
      "-------------------------------------------------\n",
      "\n",
      "\n",
      "--------------- Starting trial: 15 ---------------\n",
      "Deep layers: 3 , Number of neurons: 100 , Learning rate: 0.0001\n",
      "313/313 [==============================] - 0s 964us/step - loss: 0.3787 - accuracy: 0.8635\n",
      "Accuracy: 0.8634999990463257 , Elapsed time: 51.617905378341675\n",
      "-------------------------------------------------\n",
      "\n",
      "\n",
      "--------------- Starting trial: 16 ---------------\n",
      "Deep layers: 3 , Number of neurons: 100 , Learning rate: 0.0001\n",
      "313/313 [==============================] - 0s 792us/step - loss: 0.3887 - accuracy: 0.8566\n",
      "Accuracy: 0.8565999865531921 , Elapsed time: 51.0170624256134\n",
      "-------------------------------------------------\n",
      "\n",
      "3  \t4     \t0.372042\t0.379763\t0.388694\n",
      "\n",
      "--------------- Starting trial: 17 ---------------\n",
      "Deep layers: 3 , Number of neurons: 100 , Learning rate: 0.0001\n",
      "313/313 [==============================] - 0s 871us/step - loss: 0.3780 - accuracy: 0.8640\n",
      "Accuracy: 0.8640000224113464 , Elapsed time: 48.067343950271606\n",
      "-------------------------------------------------\n",
      "\n",
      "\n",
      "--------------- Starting trial: 18 ---------------\n",
      "Deep layers: 3 , Number of neurons: 100 , Learning rate: 0.0001\n",
      "313/313 [==============================] - 0s 907us/step - loss: 0.3771 - accuracy: 0.8632\n",
      "Accuracy: 0.8632000088691711 , Elapsed time: 47.96320724487305\n",
      "-------------------------------------------------\n",
      "\n",
      "4  \t2     \t0.372042\t0.375313\t0.378699\n",
      "\n",
      "--------------- Starting trial: 19 ---------------\n",
      "Deep layers: 2 , Number of neurons: 100 , Learning rate: 0.0001\n",
      "313/313 [==============================] - 0s 869us/step - loss: 0.4160 - accuracy: 0.8485\n",
      "Accuracy: 0.8485000133514404 , Elapsed time: 43.21087718009949\n",
      "-------------------------------------------------\n",
      "\n",
      "\n",
      "--------------- Starting trial: 20 ---------------\n",
      "Deep layers: 3 , Number of neurons: 100 , Learning rate: 0.0001\n",
      "313/313 [==============================] - 0s 889us/step - loss: 0.3786 - accuracy: 0.8623\n",
      "Accuracy: 0.8622999787330627 , Elapsed time: 48.699950218200684\n",
      "-------------------------------------------------\n",
      "\n",
      "\n",
      "--------------- Starting trial: 21 ---------------\n",
      "Deep layers: 3 , Number of neurons: 100 , Learning rate: 0.0001\n",
      "313/313 [==============================] - 0s 860us/step - loss: 0.3769 - accuracy: 0.8637\n",
      "Accuracy: 0.8636999726295471 , Elapsed time: 48.23644042015076\n",
      "-------------------------------------------------\n",
      "\n",
      "\n",
      "--------------- Starting trial: 22 ---------------\n",
      "Deep layers: 3 , Number of neurons: 100 , Learning rate: 0.0001\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.3881 - accuracy: 0.8572\n",
      "Accuracy: 0.857200026512146 , Elapsed time: 50.31621241569519\n",
      "-------------------------------------------------\n",
      "\n",
      "5  \t4     \t0.372042\t0.384279\t0.415961\n",
      "\n",
      "--------------- Starting trial: 23 ---------------\n",
      "Deep layers: 3 , Number of neurons: 100 , Learning rate: 1e-05\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.5344 - accuracy: 0.7937\n",
      "Accuracy: 0.7936999797821045 , Elapsed time: 52.1025390625\n",
      "-------------------------------------------------\n",
      "\n",
      "\n",
      "--------------- Starting trial: 24 ---------------\n",
      "Deep layers: 3 , Number of neurons: 100 , Learning rate: 0.0001\n",
      "313/313 [==============================] - 0s 996us/step - loss: 0.3706 - accuracy: 0.8624\n",
      "Accuracy: 0.8623999953269958 , Elapsed time: 51.531920433044434\n",
      "-------------------------------------------------\n",
      "\n",
      "6  \t2     \t0.370593\t0.401092\t0.534383\n",
      "\n",
      "--------------- Starting trial: 25 ---------------\n",
      "Deep layers: 3 , Number of neurons: 50 , Learning rate: 0.0001\n",
      "313/313 [==============================] - 0s 963us/step - loss: 0.4173 - accuracy: 0.8491\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8490999937057495 , Elapsed time: 42.92973804473877\n",
      "-------------------------------------------------\n",
      "\n",
      "7  \t1     \t0.370593\t0.379667\t0.417301\n",
      "-- Best Individual =  [1, 1, 1, 0, 0, 1, 0, 0, 1, 0]\n",
      "-- Best Fitness =  0.3705928921699524\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total elapsed time: 19.681350207328798 minutes\n"
     ]
    }
   ],
   "source": [
    "population_size = 6   # max of individuals per generation\n",
    "max_generations = 7   # number of generations\n",
    "gene_length = 10       # lenght of the gene, depends on how many hiperparameters are tested  \n",
    "k = 1;                 # num. of finalist individuals\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    t = time.time(); \n",
    "    datos = [];\n",
    "    ss = [i for i in range(1,population_size*(max_generations+1))]\n",
    "    best_population = geneticAlgorithm_with_elitism(population_size, max_generations, gene_length, k)\n",
    "    print(\"Total elapsed time:\", (time.time()-t)/60, \"minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k= 1 \n",
      "Deep layers: 3 , Number of neurons: 100 , Learning rate: 0.0001\n"
     ]
    }
   ],
   "source": [
    "best_deep_layers   = []\n",
    "best_num_units     = []\n",
    "best_learning_rate = []\n",
    "# best_batch_size    = []\n",
    "# best_activation_f  = []\n",
    "best_f_names       = []\n",
    "\n",
    "t = 0\n",
    "\n",
    "for bi in best_population:\n",
    "    deep_layers_bits   = BitArray(bi[0:1])    # (8)\n",
    "    num_units_bits     = BitArray(bi[1:2])    # (16)\n",
    "    learning_rate_bits = BitArray(bi[2:3])   # (8)\n",
    "#     batch_size_bits    = BitArray(bi[10:12])  # (4)\n",
    "#     activation_f_bits  = BitArray(bi[12:13])  # (2)\n",
    "    t += 1 \n",
    "    \n",
    "    best_deep_layers.append(SC_DEEP[deep_layers_bits.uint])\n",
    "    best_num_units.append(SC_NUM_UNITS[num_units_bits.uint])\n",
    "    best_learning_rate.append(SC_LEARNING[learning_rate_bits.uint])\n",
    "#     best_batch_size.append(SC_BATCH[batch_size_bits.uint])\n",
    "#     best_activation_f.append(SC_ACTIVATION[activation_f_bits.uint])\n",
    "#     best_f_names.append(f_names[activation_f_bits.uint])\n",
    "    \n",
    "    print('k=',t,'\\nDeep layers:', best_deep_layers[-1], ', Number of neurons:', best_num_units[-1], ', Learning rate:', best_learning_rate[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Deep layers</th>\n",
       "      <th>Num units</th>\n",
       "      <th>Learning rate</th>\n",
       "      <th>Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Elapsed time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>0.372042</td>\n",
       "      <td>0.8652</td>\n",
       "      <td>50.044595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>0.378047</td>\n",
       "      <td>0.8640</td>\n",
       "      <td>48.067344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>0.376901</td>\n",
       "      <td>0.8637</td>\n",
       "      <td>48.236440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>0.378699</td>\n",
       "      <td>0.8635</td>\n",
       "      <td>51.617905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>0.377061</td>\n",
       "      <td>0.8632</td>\n",
       "      <td>47.963207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>0.372858</td>\n",
       "      <td>0.8631</td>\n",
       "      <td>48.484839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>0.377995</td>\n",
       "      <td>0.8629</td>\n",
       "      <td>47.139581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>0.377685</td>\n",
       "      <td>0.8629</td>\n",
       "      <td>47.800636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>0.373985</td>\n",
       "      <td>0.8625</td>\n",
       "      <td>48.376370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>0.377757</td>\n",
       "      <td>0.8624</td>\n",
       "      <td>50.719078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>0.370593</td>\n",
       "      <td>0.8624</td>\n",
       "      <td>51.531920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>0.378646</td>\n",
       "      <td>0.8623</td>\n",
       "      <td>48.699950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>0.387399</td>\n",
       "      <td>0.8593</td>\n",
       "      <td>49.482834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>0.387693</td>\n",
       "      <td>0.8576</td>\n",
       "      <td>51.205163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>0.388139</td>\n",
       "      <td>0.8572</td>\n",
       "      <td>50.316212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>0.388694</td>\n",
       "      <td>0.8566</td>\n",
       "      <td>51.017062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>3</td>\n",
       "      <td>50</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>0.417301</td>\n",
       "      <td>0.8491</td>\n",
       "      <td>42.929738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>0.415961</td>\n",
       "      <td>0.8485</td>\n",
       "      <td>43.210877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>3</td>\n",
       "      <td>50</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>0.427957</td>\n",
       "      <td>0.8461</td>\n",
       "      <td>41.646913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>0.425903</td>\n",
       "      <td>0.8451</td>\n",
       "      <td>42.316899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>0.426854</td>\n",
       "      <td>0.8419</td>\n",
       "      <td>37.648392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>0.457019</td>\n",
       "      <td>0.8318</td>\n",
       "      <td>38.593579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.535913</td>\n",
       "      <td>0.7939</td>\n",
       "      <td>48.358637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.534383</td>\n",
       "      <td>0.7937</td>\n",
       "      <td>52.102539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.576436</td>\n",
       "      <td>0.7806</td>\n",
       "      <td>42.797815</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Deep layers  Num units  Learning rate      Loss  Accuracy  Elapsed time\n",
       "0             3        100        0.00010  0.372042    0.8652     50.044595\n",
       "1             3        100        0.00010  0.378047    0.8640     48.067344\n",
       "2             3        100        0.00010  0.376901    0.8637     48.236440\n",
       "3             3        100        0.00010  0.378699    0.8635     51.617905\n",
       "4             3        100        0.00010  0.377061    0.8632     47.963207\n",
       "5             3        100        0.00010  0.372858    0.8631     48.484839\n",
       "6             3        100        0.00010  0.377995    0.8629     47.139581\n",
       "7             3        100        0.00010  0.377685    0.8629     47.800636\n",
       "8             3        100        0.00010  0.373985    0.8625     48.376370\n",
       "9             3        100        0.00010  0.377757    0.8624     50.719078\n",
       "10            3        100        0.00010  0.370593    0.8624     51.531920\n",
       "11            3        100        0.00010  0.378646    0.8623     48.699950\n",
       "12            3        100        0.00010  0.387399    0.8593     49.482834\n",
       "13            3        100        0.00010  0.387693    0.8576     51.205163\n",
       "14            3        100        0.00010  0.388139    0.8572     50.316212\n",
       "15            3        100        0.00010  0.388694    0.8566     51.017062\n",
       "16            3         50        0.00010  0.417301    0.8491     42.929738\n",
       "17            2        100        0.00010  0.415961    0.8485     43.210877\n",
       "18            3         50        0.00010  0.427957    0.8461     41.646913\n",
       "19            2        100        0.00010  0.425903    0.8451     42.316899\n",
       "20            2         50        0.00010  0.426854    0.8419     37.648392\n",
       "21            2         50        0.00010  0.457019    0.8318     38.593579\n",
       "22            3        100        0.00001  0.535913    0.7939     48.358637\n",
       "23            3        100        0.00001  0.534383    0.7937     52.102539\n",
       "24            2        100        0.00001  0.576436    0.7806     42.797815"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename = \"historial_sdss.txt\"\n",
    "df = pd.DataFrame(datos, columns = [\"Deep layers\", \"Num units\", \"Learning rate\", \"Loss\", \"Accuracy\", \"Elapsed time\"])\n",
    "\n",
    "df.sort_values(by=[\"Accuracy\", \"Elapsed time\"], ascending=[0,1], ignore_index=True, inplace=True)\n",
    "\n",
    "df.to_csv(filename, header=True, index=False, sep='\\t', mode='w') # a=append, w=overwrite\n",
    "df.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time 19.672 minutes\n"
     ]
    }
   ],
   "source": [
    "total_time = float(np.sum(df[[\"Elapsed time\"]])/60)\n",
    "\n",
    "print(\"Elapsed time {:.3f} minutes\".format(total_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
