{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gS9bn7bhqpCG",
    "outputId": "38bcc44c-8019-449a-e1ee-2de1e086c68e"
   },
   "outputs": [],
   "source": [
    "# Clear any logs from previous runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "iD0I8HwdqpCb"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time, os\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Input, Dense\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorboard.plugins.hparams import api as hp\n",
    "\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split as split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "aFY-8_lrqpCg"
   },
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "\n",
    "tf.config.optimizer.set_jit(True)\n",
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4XMjPqjMqpCm"
   },
   "source": [
    "### Conjunto de datos: SDSS DR17"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "fsRv8kuNqpCw",
    "outputId": "773d68d4-3c4e-42e4-c9ca-be5c60ac5412"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alpha</th>\n",
       "      <th>delta</th>\n",
       "      <th>u</th>\n",
       "      <th>g</th>\n",
       "      <th>r</th>\n",
       "      <th>i</th>\n",
       "      <th>z</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>135.689107</td>\n",
       "      <td>32.494632</td>\n",
       "      <td>23.87882</td>\n",
       "      <td>22.27530</td>\n",
       "      <td>20.39501</td>\n",
       "      <td>19.16573</td>\n",
       "      <td>18.79371</td>\n",
       "      <td>GALAXY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>144.826101</td>\n",
       "      <td>31.274185</td>\n",
       "      <td>24.77759</td>\n",
       "      <td>22.83188</td>\n",
       "      <td>22.58444</td>\n",
       "      <td>21.16812</td>\n",
       "      <td>21.61427</td>\n",
       "      <td>GALAXY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>142.188790</td>\n",
       "      <td>35.582444</td>\n",
       "      <td>25.26307</td>\n",
       "      <td>22.66389</td>\n",
       "      <td>20.60976</td>\n",
       "      <td>19.34857</td>\n",
       "      <td>18.94827</td>\n",
       "      <td>GALAXY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>338.741038</td>\n",
       "      <td>-0.402828</td>\n",
       "      <td>22.13682</td>\n",
       "      <td>23.77656</td>\n",
       "      <td>21.61162</td>\n",
       "      <td>20.50454</td>\n",
       "      <td>19.25010</td>\n",
       "      <td>GALAXY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>345.282593</td>\n",
       "      <td>21.183866</td>\n",
       "      <td>19.43718</td>\n",
       "      <td>17.58028</td>\n",
       "      <td>16.49747</td>\n",
       "      <td>15.97711</td>\n",
       "      <td>15.54461</td>\n",
       "      <td>GALAXY</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        alpha      delta         u         g         r         i         z  \\\n",
       "0  135.689107  32.494632  23.87882  22.27530  20.39501  19.16573  18.79371   \n",
       "1  144.826101  31.274185  24.77759  22.83188  22.58444  21.16812  21.61427   \n",
       "2  142.188790  35.582444  25.26307  22.66389  20.60976  19.34857  18.94827   \n",
       "3  338.741038  -0.402828  22.13682  23.77656  21.61162  20.50454  19.25010   \n",
       "4  345.282593  21.183866  19.43718  17.58028  16.49747  15.97711  15.54461   \n",
       "\n",
       "    class  \n",
       "0  GALAXY  \n",
       "1  GALAXY  \n",
       "2  GALAXY  \n",
       "3  GALAXY  \n",
       "4  GALAXY  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = \"https://raw.githubusercontent.com/igomezv/nnogada/main/data/star_classification.csv\"\n",
    "data = pd.read_csv(url)\n",
    "cols = ['alpha','delta','u','g','r','i','z','class']\n",
    "data = data[cols]\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-lZvOiig278D",
    "outputId": "d8a53f6c-c595-4c76-c8ea-6441c76cd9d8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        alpha      delta         u         g         r         i         z  \\\n",
      "0  135.689107  32.494632  23.87882  22.27530  20.39501  19.16573  18.79371   \n",
      "1  144.826101  31.274185  24.77759  22.83188  22.58444  21.16812  21.61427   \n",
      "2  142.188790  35.582444  25.26307  22.66389  20.60976  19.34857  18.94827   \n",
      "3  338.741038  -0.402828  22.13682  23.77656  21.61162  20.50454  19.25010   \n",
      "4  345.282593  21.183866  19.43718  17.58028  16.49747  15.97711  15.54461   \n",
      "\n",
      "   class  \n",
      "0      0  \n",
      "1      0  \n",
      "2      0  \n",
      "3      0  \n",
      "4      0  \n"
     ]
    }
   ],
   "source": [
    "data[\"class\"]=[0 if i == \"GALAXY\" else 1 if i == \"STAR\" else 2 for i in data[\"class\"]]\n",
    "print(data.head())\n",
    "data = data.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "hC6T8iZ03An2"
   },
   "outputs": [],
   "source": [
    "# Divide data into X and Y and implement hot_ones in Y\n",
    "def prepare_dataset(data):\n",
    "    X, Y = np.empty((0)), np.empty((0))\n",
    "    X = data[:,0:7]\n",
    "    Y = data[:,7]\n",
    "    Y = to_categorical(Y, num_classes=3)\n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "vaLXQeaMqm0S"
   },
   "outputs": [],
   "source": [
    "# Split dataset into train, validation and test sets\n",
    "X,Y = prepare_dataset(data)\n",
    "\n",
    "# Defines ratios, w.r.t. whole dataset.\n",
    "ratio_train = 0.8\n",
    "ratio_val = 0.1\n",
    "ratio_test = 0.1\n",
    "\n",
    "# Produces test split.\n",
    "x_, X_test, y_, Y_test = split(X, Y, test_size = ratio_test, random_state=0)\n",
    "\n",
    "# Adjusts val ratio, w.r.t. remaining dataset.\n",
    "ratio_remaining = 1 - ratio_test\n",
    "ratio_val_adjusted = ratio_val / ratio_remaining\n",
    "\n",
    "# Produces train and val splits.\n",
    "X_train, X_val, Y_train, Y_val = split(x_, y_, test_size=ratio_val_adjusted, random_state=0)\n",
    "\n",
    "# Normalize and scale the input sets.\n",
    "scaler.fit(X)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test  = scaler.transform(X_test)\n",
    "X_val   = scaler.transform(X_val)\n",
    "\n",
    "lenx, input_shape = np.shape(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CgjOFB8kqpC_"
   },
   "source": [
    "### Hiperparámetros del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "ABViOAgTqpDI"
   },
   "outputs": [],
   "source": [
    "HP_LAYERS =    hp.HParam('layers', hp.Discrete([3, 4]))\n",
    "HP_NUM_UNITS = hp.HParam('num_units', hp.Discrete([100, 200]))\n",
    "HP_LEARNING  = hp.HParam('learning_rate', hp.Discrete([1e-5,1e-4,1e-3,0.01]))\n",
    "HP_BATCHSIZE = hp.HParam('batch_size', hp.Discrete([128,256]))\n",
    "\n",
    "callbacks = [tf.keras.callbacks.EarlyStopping(monitor='val_categorical_accuracy', mode='max',\n",
    "                                   min_delta=0,\n",
    "                                   patience=50,\n",
    "                                   restore_best_weights=True)]\n",
    "# batch_size = 128\n",
    "epochs = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "lXRw_6G8qpDL"
   },
   "outputs": [],
   "source": [
    "# METRIC_ACCURACY = 'accuracy'\n",
    "with tf.summary.create_file_writer('logs/hparam_tuning').as_default():\n",
    "# with tf.summary.FileWriter('logs/hparam_tuning', sess.graph):\n",
    "#     init = tf.initialize_all_variables()\n",
    "#     sess.run(init)\n",
    "    hp.hparams_config(\n",
    "        hparams=[HP_LAYERS,\n",
    "                 HP_NUM_UNITS,\n",
    "                 HP_LEARNING, \n",
    "                 HP_BATCHSIZE],\n",
    "        metrics=[hp.Metric('loss', display_name=\"Accuracy\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "6JG3WeEOqpDY"
   },
   "outputs": [],
   "source": [
    "def train_test_model(hparams):    \n",
    "    \n",
    "    # Train LSTM model and predict on validation set\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(Input(shape=(int(X_train.shape[1]),)))\n",
    "    model.add(Dense(hparams[HP_NUM_UNITS], input_shape=(int(X_train.shape[1]),)))\n",
    "    \n",
    "    for i in range(hparams[HP_LAYERS]):        \n",
    "        model.add(Dense(hparams[HP_NUM_UNITS], activation='relu'))\n",
    "    model.add(Dense(3, activation=tf.nn.softmax))\n",
    "     \n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=hparams[HP_LEARNING], beta_1=0.9, beta_2=0.999, epsilon=1e-3)\n",
    "    model.compile(\n",
    "            optimizer=optimizer,\n",
    "            loss=CategoricalCrossentropy(),\n",
    "            metrics=[\"categorical_accuracy\"])\n",
    "    \n",
    "    # Run with 1 epoch to speed things up for demo purposes\n",
    "\n",
    "    model.fit(X_train, Y_train, epochs=epochs, validation_data=(X_test, Y_test),\n",
    "              callbacks=callbacks, batch_size=hparams[HP_BATCHSIZE], shuffle=True, verbose=0)\n",
    "\n",
    "    _, loss = model.evaluate(X_test, Y_test)\n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "fnLlAKGuqpDp"
   },
   "outputs": [],
   "source": [
    "def run(run_dir, hparams):\n",
    "    with tf.summary.create_file_writer(run_dir).as_default():\n",
    "        hp.hparams(hparams)  # record the values used in this trial\n",
    "        loss = train_test_model(hparams)\n",
    "        tf.summary.scalar(\"loss\", loss, step=1)\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5tu8q13lqpDs",
    "outputId": "80f9eb4f-dc3a-445e-ff6d-3d42dcb085c3",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Starting trial: run-0\n",
      "{'layers': 3, 'num_units': 100, 'learning_rate': 1e-05, 'batch_size': 128}\n",
      "313/313 [==============================] - 0s 856us/step - loss: 0.5420 - categorical_accuracy: 0.8001\n",
      "Accuracy: 0.8001000285148621 Tiempo transcurrido: 48.041342973709106\n",
      "\n",
      "--- Starting trial: run-1\n",
      "{'layers': 3, 'num_units': 100, 'learning_rate': 1e-05, 'batch_size': 256}\n",
      "313/313 [==============================] - 0s 822us/step - loss: 0.5943 - categorical_accuracy: 0.7870\n",
      "Accuracy: 0.7870000004768372 Tiempo transcurrido: 29.612002849578857\n",
      "\n",
      "--- Starting trial: run-2\n",
      "{'layers': 3, 'num_units': 100, 'learning_rate': 0.0001, 'batch_size': 128}\n",
      "313/313 [==============================] - 0s 824us/step - loss: 0.3792 - categorical_accuracy: 0.8668\n",
      "Accuracy: 0.8668000102043152 Tiempo transcurrido: 47.545562982559204\n",
      "\n",
      "--- Starting trial: run-3\n",
      "{'layers': 3, 'num_units': 100, 'learning_rate': 0.0001, 'batch_size': 256}\n",
      "313/313 [==============================] - 0s 911us/step - loss: 0.4281 - categorical_accuracy: 0.8541\n",
      "Accuracy: 0.8540999889373779 Tiempo transcurrido: 29.383008241653442\n",
      "\n",
      "--- Starting trial: run-4\n",
      "{'layers': 3, 'num_units': 100, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "313/313 [==============================] - 0s 904us/step - loss: 0.3212 - categorical_accuracy: 0.8882\n",
      "Accuracy: 0.8881999850273132 Tiempo transcurrido: 48.22286939620972\n",
      "\n",
      "--- Starting trial: run-5\n",
      "{'layers': 3, 'num_units': 100, 'learning_rate': 0.001, 'batch_size': 256}\n",
      "313/313 [==============================] - 0s 923us/step - loss: 0.3475 - categorical_accuracy: 0.8749\n",
      "Accuracy: 0.8748999834060669 Tiempo transcurrido: 30.015848875045776\n",
      "\n",
      "--- Starting trial: run-6\n",
      "{'layers': 3, 'num_units': 100, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "313/313 [==============================] - 0s 911us/step - loss: 0.3486 - categorical_accuracy: 0.8772\n",
      "Accuracy: 0.8772000074386597 Tiempo transcurrido: 48.04510498046875\n",
      "\n",
      "--- Starting trial: run-7\n",
      "{'layers': 3, 'num_units': 100, 'learning_rate': 0.01, 'batch_size': 256}\n",
      "313/313 [==============================] - 0s 930us/step - loss: 0.3493 - categorical_accuracy: 0.8734\n",
      "Accuracy: 0.8733999729156494 Tiempo transcurrido: 30.288976192474365\n",
      "\n",
      "--- Starting trial: run-8\n",
      "{'layers': 3, 'num_units': 200, 'learning_rate': 1e-05, 'batch_size': 128}\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.5168 - categorical_accuracy: 0.8114\n",
      "Accuracy: 0.8113999962806702 Tiempo transcurrido: 66.26361346244812\n",
      "\n",
      "--- Starting trial: run-9\n",
      "{'layers': 3, 'num_units': 200, 'learning_rate': 1e-05, 'batch_size': 256}\n",
      "313/313 [==============================] - 0s 996us/step - loss: 0.5491 - categorical_accuracy: 0.7985\n",
      "Accuracy: 0.7985000014305115 Tiempo transcurrido: 43.20211720466614\n",
      "\n",
      "--- Starting trial: run-10\n",
      "{'layers': 3, 'num_units': 200, 'learning_rate': 0.0001, 'batch_size': 128}\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.3672 - categorical_accuracy: 0.8714\n",
      "Accuracy: 0.871399998664856 Tiempo transcurrido: 65.62309217453003\n",
      "\n",
      "--- Starting trial: run-11\n",
      "{'layers': 3, 'num_units': 200, 'learning_rate': 0.0001, 'batch_size': 256}\n",
      "313/313 [==============================] - 0s 886us/step - loss: 0.3842 - categorical_accuracy: 0.8667\n",
      "Accuracy: 0.8666999936103821 Tiempo transcurrido: 42.87505578994751\n",
      "\n",
      "--- Starting trial: run-12\n",
      "{'layers': 3, 'num_units': 200, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "313/313 [==============================] - 0s 910us/step - loss: 0.3210 - categorical_accuracy: 0.8864\n",
      "Accuracy: 0.8863999843597412 Tiempo transcurrido: 64.50584888458252\n",
      "\n",
      "--- Starting trial: run-13\n",
      "{'layers': 3, 'num_units': 200, 'learning_rate': 0.001, 'batch_size': 256}\n",
      "313/313 [==============================] - 0s 984us/step - loss: 0.3297 - categorical_accuracy: 0.8830\n",
      "Accuracy: 0.8830000162124634 Tiempo transcurrido: 41.93746900558472\n",
      "\n",
      "--- Starting trial: run-14\n",
      "{'layers': 3, 'num_units': 200, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "313/313 [==============================] - 0s 984us/step - loss: 0.3890 - categorical_accuracy: 0.8700\n",
      "Accuracy: 0.8700000047683716 Tiempo transcurrido: 63.81507349014282\n",
      "\n",
      "--- Starting trial: run-15\n",
      "{'layers': 3, 'num_units': 200, 'learning_rate': 0.01, 'batch_size': 256}\n",
      "313/313 [==============================] - 0s 987us/step - loss: 0.3941 - categorical_accuracy: 0.8605\n",
      "Accuracy: 0.8604999780654907 Tiempo transcurrido: 41.710275173187256\n",
      "\n",
      "--- Starting trial: run-16\n",
      "{'layers': 4, 'num_units': 100, 'learning_rate': 1e-05, 'batch_size': 128}\n",
      "313/313 [==============================] - 0s 942us/step - loss: 0.5202 - categorical_accuracy: 0.8117\n",
      "Accuracy: 0.8116999864578247 Tiempo transcurrido: 54.82812690734863\n",
      "\n",
      "--- Starting trial: run-17\n",
      "{'layers': 4, 'num_units': 100, 'learning_rate': 1e-05, 'batch_size': 256}\n",
      "313/313 [==============================] - 0s 941us/step - loss: 0.5492 - categorical_accuracy: 0.7983\n",
      "Accuracy: 0.79830002784729 Tiempo transcurrido: 34.497379302978516\n",
      "\n",
      "--- Starting trial: run-18\n",
      "{'layers': 4, 'num_units': 100, 'learning_rate': 0.0001, 'batch_size': 128}\n",
      "313/313 [==============================] - 0s 961us/step - loss: 0.3687 - categorical_accuracy: 0.8694\n",
      "Accuracy: 0.8694000244140625 Tiempo transcurrido: 54.330161809921265\n",
      "\n",
      "--- Starting trial: run-19\n",
      "{'layers': 4, 'num_units': 100, 'learning_rate': 0.0001, 'batch_size': 256}\n",
      "313/313 [==============================] - 0s 948us/step - loss: 0.4062 - categorical_accuracy: 0.8548\n",
      "Accuracy: 0.8547999858856201 Tiempo transcurrido: 34.532944679260254\n",
      "\n",
      "--- Starting trial: run-20\n",
      "{'layers': 4, 'num_units': 100, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "313/313 [==============================] - 0s 950us/step - loss: 0.3179 - categorical_accuracy: 0.8878\n",
      "Accuracy: 0.8877999782562256 Tiempo transcurrido: 54.622474908828735\n",
      "\n",
      "--- Starting trial: run-21\n",
      "{'layers': 4, 'num_units': 100, 'learning_rate': 0.001, 'batch_size': 256}\n",
      "313/313 [==============================] - 0s 959us/step - loss: 0.3284 - categorical_accuracy: 0.8823\n",
      "Accuracy: 0.8823000192642212 Tiempo transcurrido: 35.18902826309204\n",
      "\n",
      "--- Starting trial: run-22\n",
      "{'layers': 4, 'num_units': 100, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "313/313 [==============================] - 0s 882us/step - loss: 0.3319 - categorical_accuracy: 0.8848\n",
      "Accuracy: 0.8848000168800354 Tiempo transcurrido: 54.82783079147339\n",
      "\n",
      "--- Starting trial: run-23\n",
      "{'layers': 4, 'num_units': 100, 'learning_rate': 0.01, 'batch_size': 256}\n",
      "313/313 [==============================] - 0s 957us/step - loss: 0.3369 - categorical_accuracy: 0.8831\n",
      "Accuracy: 0.8830999732017517 Tiempo transcurrido: 34.50872492790222\n",
      "\n",
      "--- Starting trial: run-24\n",
      "{'layers': 4, 'num_units': 200, 'learning_rate': 1e-05, 'batch_size': 128}\n",
      "313/313 [==============================] - 0s 892us/step - loss: 0.5035 - categorical_accuracy: 0.8132\n",
      "Accuracy: 0.8131999969482422 Tiempo transcurrido: 72.29581236839294\n",
      "\n",
      "--- Starting trial: run-25\n",
      "{'layers': 4, 'num_units': 200, 'learning_rate': 1e-05, 'batch_size': 256}\n",
      "313/313 [==============================] - 0s 910us/step - loss: 0.5228 - categorical_accuracy: 0.8092\n",
      "Accuracy: 0.8091999888420105 Tiempo transcurrido: 44.93865132331848\n",
      "\n",
      "--- Starting trial: run-26\n",
      "{'layers': 4, 'num_units': 200, 'learning_rate': 0.0001, 'batch_size': 128}\n",
      "313/313 [==============================] - 0s 916us/step - loss: 0.3527 - categorical_accuracy: 0.8748\n",
      "Accuracy: 0.8748000264167786 Tiempo transcurrido: 69.87997245788574\n",
      "\n",
      "--- Starting trial: run-27\n",
      "{'layers': 4, 'num_units': 200, 'learning_rate': 0.0001, 'batch_size': 256}\n",
      "313/313 [==============================] - 0s 898us/step - loss: 0.3738 - categorical_accuracy: 0.8671\n",
      "Accuracy: 0.8671000003814697 Tiempo transcurrido: 45.13688540458679\n",
      "\n",
      "--- Starting trial: run-28\n",
      "{'layers': 4, 'num_units': 200, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "313/313 [==============================] - 0s 982us/step - loss: 0.3213 - categorical_accuracy: 0.8865\n",
      "Accuracy: 0.8865000009536743 Tiempo transcurrido: 70.19983696937561\n",
      "\n",
      "--- Starting trial: run-29\n",
      "{'layers': 4, 'num_units': 200, 'learning_rate': 0.001, 'batch_size': 256}\n",
      "313/313 [==============================] - 0s 878us/step - loss: 0.3176 - categorical_accuracy: 0.8863\n",
      "Accuracy: 0.8863000273704529 Tiempo transcurrido: 46.50965857505798\n",
      "\n",
      "--- Starting trial: run-30\n",
      "{'layers': 4, 'num_units': 200, 'learning_rate': 0.01, 'batch_size': 128}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 1ms/step - loss: 0.3683 - categorical_accuracy: 0.8687\n",
      "Accuracy: 0.8687000274658203 Tiempo transcurrido: 82.09161949157715\n",
      "\n",
      "--- Starting trial: run-31\n",
      "{'layers': 4, 'num_units': 200, 'learning_rate': 0.01, 'batch_size': 256}\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.3616 - categorical_accuracy: 0.8699\n",
      "Accuracy: 0.8698999881744385 Tiempo transcurrido: 62.115299463272095\n",
      "32\n"
     ]
    }
   ],
   "source": [
    "session_num = 0\n",
    "datos = []\n",
    "\n",
    "for deep_layers in HP_LAYERS.domain.values:\n",
    "    for num_units in HP_NUM_UNITS.domain.values:\n",
    "        for learning_rate in HP_LEARNING.domain.values:\n",
    "            for batch_size in HP_BATCHSIZE.domain.values:\n",
    "                t = time.time()\n",
    "                hparams = {\n",
    "\n",
    "                    HP_LAYERS: deep_layers,\n",
    "                    HP_NUM_UNITS: num_units,\n",
    "                    HP_LEARNING: learning_rate,\n",
    "                    HP_BATCHSIZE: batch_size\n",
    "                }\n",
    "                run_name = \"run-%d\" % session_num\n",
    "                print('\\n--- Starting trial: %s' % run_name)\n",
    "                print({h.name: hparams[h] for h in hparams})\n",
    "                score = run('logs/hparam_tuning/' + run_name, hparams)\n",
    "                t = time.time()-t\n",
    "                session_num += 1\n",
    "                print(\"Accuracy:\", score, \"Tiempo transcurrido:\", t)\n",
    "\n",
    "                datos.append([deep_layers, num_units, learning_rate, batch_size, score, t])\n",
    "\n",
    "print(session_num)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X1ct8OIfqpD3"
   },
   "source": [
    "### Guardar datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "_6xZZqEhqpD5"
   },
   "outputs": [],
   "source": [
    "filename = \"historial_sdss_tunning.txt\"\n",
    "df = pd.DataFrame(datos, columns = [\"Deep size\", \"Num units\", \"Learning rate\", \"Batch size\", \"Accuracy\", \"Tiempo de ejecución\"])\n",
    "\n",
    "df.sort_values(by=[\"Accuracy\", \"Tiempo de ejecución\"], ascending=[0,0], ignore_index=True, inplace=True)\n",
    "\n",
    "df.to_csv(filename, header=True, index=False, sep='\\t', mode='w') # a=append, w=overwrite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "z9BerX2yqpD-",
    "outputId": "992e08c9-0adb-4f57-e50e-df65c91fe142",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Deep size</th>\n",
       "      <th>Num units</th>\n",
       "      <th>Learning rate</th>\n",
       "      <th>Batch size</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Tiempo de ejecución</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>128</td>\n",
       "      <td>0.8882</td>\n",
       "      <td>48.222869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>100</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>128</td>\n",
       "      <td>0.8878</td>\n",
       "      <td>54.622475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>200</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>128</td>\n",
       "      <td>0.8865</td>\n",
       "      <td>70.199837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>200</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>128</td>\n",
       "      <td>0.8864</td>\n",
       "      <td>64.505849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>200</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>256</td>\n",
       "      <td>0.8863</td>\n",
       "      <td>46.509659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4</td>\n",
       "      <td>100</td>\n",
       "      <td>0.01000</td>\n",
       "      <td>128</td>\n",
       "      <td>0.8848</td>\n",
       "      <td>54.827831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4</td>\n",
       "      <td>100</td>\n",
       "      <td>0.01000</td>\n",
       "      <td>256</td>\n",
       "      <td>0.8831</td>\n",
       "      <td>34.508725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3</td>\n",
       "      <td>200</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>256</td>\n",
       "      <td>0.8830</td>\n",
       "      <td>41.937469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4</td>\n",
       "      <td>100</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>256</td>\n",
       "      <td>0.8823</td>\n",
       "      <td>35.189028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>0.01000</td>\n",
       "      <td>128</td>\n",
       "      <td>0.8772</td>\n",
       "      <td>48.045105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>256</td>\n",
       "      <td>0.8749</td>\n",
       "      <td>30.015849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>4</td>\n",
       "      <td>200</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>128</td>\n",
       "      <td>0.8748</td>\n",
       "      <td>69.879972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>0.01000</td>\n",
       "      <td>256</td>\n",
       "      <td>0.8734</td>\n",
       "      <td>30.288976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>3</td>\n",
       "      <td>200</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>128</td>\n",
       "      <td>0.8714</td>\n",
       "      <td>65.623092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>3</td>\n",
       "      <td>200</td>\n",
       "      <td>0.01000</td>\n",
       "      <td>128</td>\n",
       "      <td>0.8700</td>\n",
       "      <td>63.815073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>4</td>\n",
       "      <td>200</td>\n",
       "      <td>0.01000</td>\n",
       "      <td>256</td>\n",
       "      <td>0.8699</td>\n",
       "      <td>62.115299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>4</td>\n",
       "      <td>100</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>128</td>\n",
       "      <td>0.8694</td>\n",
       "      <td>54.330162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>4</td>\n",
       "      <td>200</td>\n",
       "      <td>0.01000</td>\n",
       "      <td>128</td>\n",
       "      <td>0.8687</td>\n",
       "      <td>82.091619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>4</td>\n",
       "      <td>200</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>256</td>\n",
       "      <td>0.8671</td>\n",
       "      <td>45.136885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>128</td>\n",
       "      <td>0.8668</td>\n",
       "      <td>47.545563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>3</td>\n",
       "      <td>200</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>256</td>\n",
       "      <td>0.8667</td>\n",
       "      <td>42.875056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>3</td>\n",
       "      <td>200</td>\n",
       "      <td>0.01000</td>\n",
       "      <td>256</td>\n",
       "      <td>0.8605</td>\n",
       "      <td>41.710275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>4</td>\n",
       "      <td>100</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>256</td>\n",
       "      <td>0.8548</td>\n",
       "      <td>34.532945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>256</td>\n",
       "      <td>0.8541</td>\n",
       "      <td>29.383008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>4</td>\n",
       "      <td>200</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>128</td>\n",
       "      <td>0.8132</td>\n",
       "      <td>72.295812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>4</td>\n",
       "      <td>100</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>128</td>\n",
       "      <td>0.8117</td>\n",
       "      <td>54.828127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>3</td>\n",
       "      <td>200</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>128</td>\n",
       "      <td>0.8114</td>\n",
       "      <td>66.263613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>4</td>\n",
       "      <td>200</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>256</td>\n",
       "      <td>0.8092</td>\n",
       "      <td>44.938651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>128</td>\n",
       "      <td>0.8001</td>\n",
       "      <td>48.041343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>3</td>\n",
       "      <td>200</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>256</td>\n",
       "      <td>0.7985</td>\n",
       "      <td>43.202117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>4</td>\n",
       "      <td>100</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>256</td>\n",
       "      <td>0.7983</td>\n",
       "      <td>34.497379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>256</td>\n",
       "      <td>0.7870</td>\n",
       "      <td>29.612003</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Deep size  Num units  Learning rate  Batch size  Accuracy  \\\n",
       "0           3        100        0.00100         128    0.8882   \n",
       "1           4        100        0.00100         128    0.8878   \n",
       "2           4        200        0.00100         128    0.8865   \n",
       "3           3        200        0.00100         128    0.8864   \n",
       "4           4        200        0.00100         256    0.8863   \n",
       "5           4        100        0.01000         128    0.8848   \n",
       "6           4        100        0.01000         256    0.8831   \n",
       "7           3        200        0.00100         256    0.8830   \n",
       "8           4        100        0.00100         256    0.8823   \n",
       "9           3        100        0.01000         128    0.8772   \n",
       "10          3        100        0.00100         256    0.8749   \n",
       "11          4        200        0.00010         128    0.8748   \n",
       "12          3        100        0.01000         256    0.8734   \n",
       "13          3        200        0.00010         128    0.8714   \n",
       "14          3        200        0.01000         128    0.8700   \n",
       "15          4        200        0.01000         256    0.8699   \n",
       "16          4        100        0.00010         128    0.8694   \n",
       "17          4        200        0.01000         128    0.8687   \n",
       "18          4        200        0.00010         256    0.8671   \n",
       "19          3        100        0.00010         128    0.8668   \n",
       "20          3        200        0.00010         256    0.8667   \n",
       "21          3        200        0.01000         256    0.8605   \n",
       "22          4        100        0.00010         256    0.8548   \n",
       "23          3        100        0.00010         256    0.8541   \n",
       "24          4        200        0.00001         128    0.8132   \n",
       "25          4        100        0.00001         128    0.8117   \n",
       "26          3        200        0.00001         128    0.8114   \n",
       "27          4        200        0.00001         256    0.8092   \n",
       "28          3        100        0.00001         128    0.8001   \n",
       "29          3        200        0.00001         256    0.7985   \n",
       "30          4        100        0.00001         256    0.7983   \n",
       "31          3        100        0.00001         256    0.7870   \n",
       "\n",
       "    Tiempo de ejecución  \n",
       "0             48.222869  \n",
       "1             54.622475  \n",
       "2             70.199837  \n",
       "3             64.505849  \n",
       "4             46.509659  \n",
       "5             54.827831  \n",
       "6             34.508725  \n",
       "7             41.937469  \n",
       "8             35.189028  \n",
       "9             48.045105  \n",
       "10            30.015849  \n",
       "11            69.879972  \n",
       "12            30.288976  \n",
       "13            65.623092  \n",
       "14            63.815073  \n",
       "15            62.115299  \n",
       "16            54.330162  \n",
       "17            82.091619  \n",
       "18            45.136885  \n",
       "19            47.545563  \n",
       "20            42.875056  \n",
       "21            41.710275  \n",
       "22            34.532945  \n",
       "23            29.383008  \n",
       "24            72.295812  \n",
       "25            54.828127  \n",
       "26            66.263613  \n",
       "27            44.938651  \n",
       "28            48.041343  \n",
       "29            43.202117  \n",
       "30            34.497379  \n",
       "31            29.612003  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vZ3JJWuZqpEB",
    "outputId": "230a8ed2-6429-49df-f611-d68381c31fc3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tiempo de ejecución    26.526528\n",
       "dtype: float64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(df[[\"Tiempo de ejecución\"]])/60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xh9rbb8kqpED"
   },
   "outputs": [],
   "source": [
    "# rm -rf /tmp/tb_logs/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Gm044iKXqpEM"
   },
   "source": [
    "### Now in terminal:\n",
    "`python3 -m tensorboard.main --logdir='/home/isidro/Documents/github/neurapprox/logs/hparam_tuning'`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "tunning_classifier.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
