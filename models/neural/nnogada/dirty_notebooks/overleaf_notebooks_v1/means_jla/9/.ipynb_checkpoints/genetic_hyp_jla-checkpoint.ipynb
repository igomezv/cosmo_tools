{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-16 20:40:38.153584: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-12-16 20:40:38.277016: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-12-16 20:40:38.277037: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2022-12-16 20:40:39.132523: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2022-12-16 20:40:39.132640: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2022-12-16 20:40:39.132648: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import time, os\n",
    "import random\n",
    "import seaborn as sns\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Input, Dense, LeakyReLU\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorboard.plugins.hparams import api as hp\n",
    "\n",
    "from tensorflow.keras import activations\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "import random\n",
    "from math import floor\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import optimizers\n",
    "from scipy.integrate import odeint\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split as split\n",
    "from scipy.stats import bernoulli\n",
    "\n",
    "# import deap\n",
    "from deap import base, creator, tools, algorithms\n",
    "\n",
    "from bitstring import BitArray\n",
    "\n",
    "# from elitism import eaSimpleWithElitism, main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "\n",
    "# tf.config.optimizer.set_jit(True)\n",
    "# scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "url = 'https://raw.githubusercontent.com/igomezv/nnogada/main/data/jla.csv'\n",
    "df=pd.read_csv(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = len(df.values)\n",
    "randomize = np.random.permutation(N)\n",
    "data = df.values[randomize]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(740, 2)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N = len(df.values)\n",
    "z = data[:,0] \n",
    "y = data[:,1:3] ### coge el resto de variables a predecir \n",
    "y[:,1] = y[:,1]**2+data[:,2]\n",
    "np.shape(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "scalerz = StandardScaler()\n",
    "scalerz.fit(z.reshape(-1,1))\n",
    "z = scalerz.transform(z.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((592, 1), (148, 1), (592, 2), (148, 2))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Modificar para incluir phanteon como test\n",
    "split = 0.8\n",
    "ntrain = int(split * len(z))\n",
    "indx = [ntrain]\n",
    "X_train, X_val = np.split(z, indx)\n",
    "Y_train, Y_val = np.split(y, indx)\n",
    "# X_train, X_test = np.split(z, indx)\n",
    "# Y_train, Y_test = np.split(y, indx)\n",
    "np.shape(X_train), np.shape(X_val), Y_train.shape, Y_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "SC_DEEP       = np.array([1,2,3,4])                           # Number of deep layers (8)\n",
    "SC_NUM_UNITS  = np.array([50,100,150,200]) # Number of fully conected neurons (16)\n",
    "SC_LEARNING   = np.array([1e-4,5e-3])   # Learning rates (8)\n",
    "SC_BATCH      = np.array([2, 4, 8, 16])                            # Batch sizes (4)\n",
    "# SC_ACTIVATION = [f1, f2, f3, f4]                                      # Activation function layers (2)\n",
    "\n",
    "my_callbacks = [tf.keras.callbacks.EarlyStopping(\n",
    "                               monitor='val_loss', mode='min',\n",
    "                               min_delta=0, \n",
    "                               patience=200,\n",
    "                               verbose=1,\n",
    "                            #    baseline=0,\n",
    "                               restore_best_weights=True)\n",
    "#                 keras.callbacks.TensorBoard(\n",
    "#                                log_dir='./logs'),\n",
    "#                 keras.callbacks.ReduceLROnPlateau(\n",
    "#                                monitor='val_loss', factor=0.5,\n",
    "#                                patience=6, min_lr=0,\n",
    "#                                verbose=1)\n",
    "               ] \n",
    "    \n",
    "epochs = 200\n",
    "# epochs = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_evaluate(ga_individual_solution):   \n",
    "    t = time.time()\n",
    "    t_total = 0\n",
    "    \n",
    "    # Decode GA solution to integer for window_size and num_units\n",
    "    deep_layers_bits   = BitArray(ga_individual_solution[0:2])     # (8)\n",
    "    num_units_bits     = BitArray(ga_individual_solution[2:4])     # (16)\n",
    "    learning_rate_bits = BitArray(ga_individual_solution[4:5])    # (8)\n",
    "    batch_size_bits    = BitArray(ga_individual_solution[5:7])   # (4)\n",
    "# #     activation_f_bits  = BitArray(ga_individual_solution[12:13])   # (2)   Solo se consideran las 2 primeras\n",
    "    \n",
    "    deep_layers   = SC_DEEP[deep_layers_bits.uint]\n",
    "    num_units     = SC_NUM_UNITS[num_units_bits.uint]\n",
    "    learning_rate = SC_LEARNING[learning_rate_bits.uint]\n",
    "    batch_size   = SC_BATCH[batch_size_bits.uint]\n",
    "#     activation_f  = SC_ACTIVATION[activation_f_bits.uint]\n",
    "\n",
    "    \n",
    "    print('\\n--------------- Starting trial:', population_size*(max_generations+1)-len(ss), \"---------------\")\n",
    "    print('Deep layers:',deep_layers,', Number of neurons:',num_units,\", Learning rate:\",learning_rate)\n",
    "#     print(\"-------------------------------------------------\")\n",
    "    \n",
    "    # Train model and predict on validation set\n",
    "    model = tf.keras.Sequential()\n",
    "#     model.add(Input(shape=(int(X_train.shape[1]),)))\n",
    "    model.add(Dense(int(X_train.shape[1])))\n",
    "    \n",
    "    for i in range(deep_layers):        \n",
    "        model.add(Dense(num_units, activation='relu'))\n",
    "#             model.add(keras.layers.Dropout(0.3))\n",
    "    model.add(Dense(2, activation='linear'))\n",
    "    \n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate, beta_1=0.9, beta_2=0.999, epsilon=1e-3)\n",
    "    model.compile(optimizer=optimizer, loss='mse', metrics=['mean_squared_error'])\n",
    "    model.fit(X_train, Y_train, epochs=epochs, validation_data=(X_val, Y_val),\n",
    "              callbacks=my_callbacks, batch_size=batch_size, shuffle=False, verbose=0)\n",
    "    \n",
    "    loss, score = model.evaluate(X_val, Y_val)    \n",
    "    t = time.time()-t\n",
    "    ss.pop(0)\n",
    "    print(\"Loss:\", score, \", Elapsed time:\", t)\n",
    "    print(\"-------------------------------------------------\\n\")\n",
    "#     print(loss, score)\n",
    "\n",
    "    datos.append([deep_layers, num_units, learning_rate, batch_size, loss, score, t])\n",
    "    \n",
    "    return loss,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deap import tools\n",
    "from deap import algorithms\n",
    "\n",
    "def eaSimpleWithElitism(population, toolbox, cxpb, mutpb, ngen, stats=None,\n",
    "             halloffame=None, verbose=__debug__):\n",
    "    \"\"\"This algorithm is similar to DEAP eaSimple() algorithm, with the modification that\n",
    "    halloffame is used to implement an elitism mechanism. The individuals contained in the\n",
    "    halloffame are directly injected into the next generation and are not subject to the\n",
    "    genetic operators of selection, crossover and mutation.\n",
    "    \"\"\"\n",
    "    logbook = tools.Logbook()\n",
    "    logbook.header = ['gen', 'nevals'] + (stats.fields if stats else [])\n",
    "\n",
    "    # Evaluate the individuals with an invalid fitness\n",
    "    invalid_ind = [ind for ind in population if not ind.fitness.valid]\n",
    "    fitnesses = toolbox.map(toolbox.evaluate, invalid_ind)\n",
    "    for ind, fit in zip(invalid_ind, fitnesses):\n",
    "        ind.fitness.values = fit\n",
    "\n",
    "    if halloffame is None:\n",
    "        raise ValueError(\"halloffame parameter must not be empty!\")\n",
    "\n",
    "    halloffame.update(population)\n",
    "    hof_size = len(halloffame.items) if halloffame.items else 0\n",
    "\n",
    "    record = stats.compile(population) if stats else {}\n",
    "    logbook.record(gen=0, nevals=len(invalid_ind), **record)\n",
    "    if verbose:\n",
    "        print(logbook.stream)\n",
    "\n",
    "    # Begin the generational process\n",
    "    for gen in range(1, ngen + 1):\n",
    "\n",
    "        # Select the next generation individuals\n",
    "        offspring = toolbox.select(population, len(population) - hof_size)\n",
    "\n",
    "        # Vary the pool of individuals\n",
    "        offspring = algorithms.varAnd(offspring, toolbox, cxpb, mutpb)\n",
    "\n",
    "        # Evaluate the individuals with an invalid fitness\n",
    "        invalid_ind = [ind for ind in offspring if not ind.fitness.valid]\n",
    "        fitnesses = toolbox.map(toolbox.evaluate, invalid_ind)\n",
    "        for ind, fit in zip(invalid_ind, fitnesses):\n",
    "            ind.fitness.values = fit\n",
    "\n",
    "        # add the best back to population:\n",
    "        offspring.extend(halloffame.items)\n",
    "\n",
    "        # Update the hall of fame with the generated individuals\n",
    "        halloffame.update(offspring)\n",
    "\n",
    "        # Replace the current population by the offspring\n",
    "        population[:] = offspring\n",
    "\n",
    "        # Append the current generation statistics to the logbook\n",
    "        record = stats.compile(population) if stats else {}\n",
    "        logbook.record(gen=gen, nevals=len(invalid_ind), **record)\n",
    "        if verbose:\n",
    "            print(logbook.stream)\n",
    "\n",
    "    return population, logbook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def geneticAlgorithm_with_elitism(population_size, max_generations, gene_length, k):\n",
    "    \n",
    "    # Genetic Algorithm constants:\n",
    "    P_CROSSOVER = 0.5        # probability for crossover\n",
    "    P_MUTATION = 0.5         # probability for mutating an individual\n",
    "    HALL_OF_FAME_SIZE = 1    # Best individuals that pass to the other generation\n",
    "    \n",
    "    # set the random seed:\n",
    "    toolbox = base.Toolbox()\n",
    "\n",
    "    # As we are trying to minimize the RMSE score, that's why using -1.0. \n",
    "    # In case, when you want to maximize accuracy for instance, use 1.0\n",
    "    creator.create('FitnessMin', base.Fitness, weights = [-1.0])\n",
    "    creator.create('Individual', list , fitness = creator.FitnessMin)\n",
    "\n",
    "    # create the individual operator to fill up an Individual instance:\n",
    "    toolbox.register('binary', bernoulli.rvs, 0.5)\n",
    "    toolbox.register('individual', tools.initRepeat, creator.Individual, toolbox.binary, n = gene_length)\n",
    "\n",
    "    # create the population operator to generate a list of individuals:\n",
    "    toolbox.register('population', tools.initRepeat, list , toolbox.individual)\n",
    "\n",
    "    # genetic operators:\n",
    "    toolbox.register('evaluate', train_evaluate)\n",
    "    toolbox.register('select', tools.selTournament, tournsize = 2)\n",
    "    toolbox.register('mutate', tools.mutFlipBit, indpb = 0.11)\n",
    "    toolbox.register('mate', tools.cxUniform, indpb = 0.5)\n",
    "    \n",
    "    # create initial population (generation 0):\n",
    "    population = toolbox.population(n=population_size)\n",
    "\n",
    "    # prepare the statistics object:\n",
    "    stats = tools.Statistics(lambda ind: ind.fitness.values)\n",
    "    stats.register(\"min\", np.min)\n",
    "    stats.register(\"avg\", np.mean)\n",
    "    stats.register(\"max\", np.max)\n",
    "\n",
    "    # define the hall-of-fame object:\n",
    "    hof = tools.HallOfFame(HALL_OF_FAME_SIZE)\n",
    "\n",
    "    # Genetic Algorithm flow with elitism:\n",
    "    population, logbook = eaSimpleWithElitism(population, toolbox, cxpb=P_CROSSOVER, mutpb=P_MUTATION,\n",
    "                                              ngen=max_generations, stats=stats, halloffame=hof, verbose=True)\n",
    "\n",
    "    # print info for best solution found:\n",
    "    best = hof.items[0]\n",
    "    print(\"-- Best Individual = \", best)\n",
    "    print(\"-- Best Fitness = \", best.fitness.values[0])\n",
    "\n",
    "    # extract statistics:\n",
    "    minFitnessValues, meanFitnessValues, maxFitnessValues = logbook.select(\"min\", \"max\", \"avg\")\n",
    "\n",
    "    # plot statistics:\n",
    "    sns.set_style(\"whitegrid\")\n",
    "    plt.plot(minFitnessValues, color='blue', label=\"Min\")\n",
    "    plt.plot(meanFitnessValues, color='green', label=\"Mean\")\n",
    "    plt.plot(maxFitnessValues, color='red', label=\"Max\")\n",
    "    plt.xlabel('Generation'); plt.ylabel('Max / Min / Average Fitness')\n",
    "    plt.legend()\n",
    "    plt.title('Max, Min and Average fitness over Generations')\n",
    "    plt.show()\n",
    "    \n",
    "    best_population = tools.selBest(population,k = k)\n",
    "    return best_population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------------- Starting trial: 1 ---------------\n",
      "Deep layers: 3 , Number of neurons: 100 , Learning rate: 0.005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-16 20:40:40.178111: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-16 20:40:40.178619: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-12-16 20:40:40.178710: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory\n",
      "2022-12-16 20:40:40.178786: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory\n",
      "2022-12-16 20:40:40.178840: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcufft.so.10'; dlerror: libcufft.so.10: cannot open shared object file: No such file or directory\n",
      "2022-12-16 20:40:40.178900: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcurand.so.10'; dlerror: libcurand.so.10: cannot open shared object file: No such file or directory\n",
      "2022-12-16 20:40:40.178963: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory\n",
      "2022-12-16 20:40:40.179027: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory\n",
      "2022-12-16 20:40:40.179079: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2022-12-16 20:40:40.179090: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1934] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2022-12-16 20:40:40.179302: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1193 - mean_squared_error: 0.1193\n",
      "Loss: 0.11928996443748474 , Elapsed time: 147.49718499183655\n",
      "-------------------------------------------------\n",
      "\n",
      "\n",
      "--------------- Starting trial: 2 ---------------\n",
      "Deep layers: 2 , Number of neurons: 200 , Learning rate: 0.0001\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0554 - mean_squared_error: 0.0554\n",
      "Loss: 0.055394455790519714 , Elapsed time: 27.996490001678467\n",
      "-------------------------------------------------\n",
      "\n",
      "\n",
      "--------------- Starting trial: 3 ---------------\n",
      "Deep layers: 4 , Number of neurons: 200 , Learning rate: 0.005\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0463 - mean_squared_error: 0.0463\n",
      "Loss: 0.04629556089639664 , Elapsed time: 42.680277824401855\n",
      "-------------------------------------------------\n",
      "\n",
      "\n",
      "--------------- Starting trial: 4 ---------------\n",
      "Deep layers: 1 , Number of neurons: 100 , Learning rate: 0.0001\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0806 - mean_squared_error: 0.0806\n",
      "Loss: 0.08056522905826569 , Elapsed time: 73.09369659423828\n",
      "-------------------------------------------------\n",
      "\n",
      "\n",
      "--------------- Starting trial: 5 ---------------\n",
      "Deep layers: 2 , Number of neurons: 100 , Learning rate: 0.0001\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0362 - mean_squared_error: 0.0362\n",
      "Loss: 0.03615817427635193 , Elapsed time: 83.1842520236969\n",
      "-------------------------------------------------\n",
      "\n",
      "gen\tnevals\tmin      \tavg      \tmax    \n",
      "0  \t5     \t0.0361582\t0.0675407\t0.11929\n",
      "\n",
      "--------------- Starting trial: 6 ---------------\n",
      "Deep layers: 4 , Number of neurons: 100 , Learning rate: 0.0001\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0338 - mean_squared_error: 0.0338\n",
      "Loss: 0.03375308960676193 , Elapsed time: 93.7650055885315\n",
      "-------------------------------------------------\n",
      "\n",
      "\n",
      "--------------- Starting trial: 7 ---------------\n",
      "Deep layers: 1 , Number of neurons: 200 , Learning rate: 0.005\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0432 - mean_squared_error: 0.0432\n",
      "Loss: 0.04322715476155281 , Elapsed time: 30.206787824630737\n",
      "-------------------------------------------------\n",
      "\n",
      "\n",
      "--------------- Starting trial: 8 ---------------\n",
      "Deep layers: 2 , Number of neurons: 100 , Learning rate: 0.0001\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0391 - mean_squared_error: 0.0391\n",
      "Loss: 0.03913724422454834 , Elapsed time: 83.2522132396698\n",
      "-------------------------------------------------\n",
      "\n",
      "1  \t3     \t0.0337531\t0.0376868\t0.0432272\n",
      "\n",
      "--------------- Starting trial: 9 ---------------\n",
      "Deep layers: 2 , Number of neurons: 100 , Learning rate: 0.0001\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0373 - mean_squared_error: 0.0373\n",
      "Loss: 0.037343062460422516 , Elapsed time: 83.15376400947571\n",
      "-------------------------------------------------\n",
      "\n",
      "\n",
      "--------------- Starting trial: 10 ---------------\n",
      "Deep layers: 4 , Number of neurons: 100 , Learning rate: 0.005\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0349 - mean_squared_error: 0.0349\n",
      "Loss: 0.03493712469935417 , Elapsed time: 91.05553793907166\n",
      "-------------------------------------------------\n",
      "\n",
      "\n",
      "--------------- Starting trial: 11 ---------------\n",
      "Deep layers: 2 , Number of neurons: 100 , Learning rate: 0.0001\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0375 - mean_squared_error: 0.0375\n",
      "Loss: 0.037508003413677216 , Elapsed time: 83.28252863883972\n",
      "-------------------------------------------------\n",
      "\n",
      "\n",
      "--------------- Starting trial: 12 ---------------\n",
      "Deep layers: 1 , Number of neurons: 100 , Learning rate: 0.0001\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1372 - mean_squared_error: 0.1372\n",
      "Loss: 0.13719657063484192 , Elapsed time: 83.05509066581726\n",
      "-------------------------------------------------\n",
      "\n",
      "2  \t4     \t0.0337531\t0.0561476\t0.137197 \n",
      "\n",
      "--------------- Starting trial: 13 ---------------\n",
      "Deep layers: 4 , Number of neurons: 100 , Learning rate: 0.0001\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0348 - mean_squared_error: 0.0348\n",
      "Loss: 0.03476056456565857 , Elapsed time: 143.71357131004333\n",
      "-------------------------------------------------\n",
      "\n",
      "\n",
      "--------------- Starting trial: 14 ---------------\n",
      "Deep layers: 3 , Number of neurons: 100 , Learning rate: 0.0001\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0311 - mean_squared_error: 0.0311\n",
      "Loss: 0.03113039769232273 , Elapsed time: 143.451318025589\n",
      "-------------------------------------------------\n",
      "\n",
      "3  \t2     \t0.0311304\t0.0336669\t0.0349371\n",
      "\n",
      "--------------- Starting trial: 15 ---------------\n",
      "Deep layers: 3 , Number of neurons: 100 , Learning rate: 0.0001\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0310 - mean_squared_error: 0.0310\n",
      "Loss: 0.030971545726060867 , Elapsed time: 143.3996183872223\n",
      "-------------------------------------------------\n",
      "\n",
      "\n",
      "--------------- Starting trial: 16 ---------------\n",
      "Deep layers: 3 , Number of neurons: 100 , Learning rate: 0.0001\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0314 - mean_squared_error: 0.0314\n",
      "Loss: 0.03144703805446625 , Elapsed time: 86.41651678085327\n",
      "-------------------------------------------------\n",
      "\n",
      "\n",
      "--------------- Starting trial: 17 ---------------\n",
      "Deep layers: 4 , Number of neurons: 100 , Learning rate: 0.0001\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0341 - mean_squared_error: 0.0341\n",
      "Loss: 0.03414478898048401 , Elapsed time: 144.71432495117188\n",
      "-------------------------------------------------\n",
      "\n",
      "4  \t3     \t0.0309715\t0.0322894\t0.0341448\n",
      "\n",
      "--------------- Starting trial: 18 ---------------\n",
      "Deep layers: 3 , Number of neurons: 100 , Learning rate: 0.0001\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0304 - mean_squared_error: 0.0304\n",
      "Loss: 0.030372697860002518 , Elapsed time: 81.42525100708008\n",
      "-------------------------------------------------\n",
      "\n",
      "5  \t1     \t0.0303727\t0.0309786\t0.031447 \n",
      "\n",
      "--------------- Starting trial: 19 ---------------\n",
      "Deep layers: 3 , Number of neurons: 100 , Learning rate: 0.0001\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0388 - mean_squared_error: 0.0388\n",
      "Loss: 0.03883473575115204 , Elapsed time: 42.41537356376648\n",
      "-------------------------------------------------\n",
      "\n",
      "\n",
      "--------------- Starting trial: 20 ---------------\n",
      "Deep layers: 3 , Number of neurons: 100 , Learning rate: 0.0001\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0339 - mean_squared_error: 0.0339\n",
      "Loss: 0.033921197056770325 , Elapsed time: 76.50114870071411\n",
      "-------------------------------------------------\n",
      "\n",
      "\n",
      "--------------- Starting trial: 21 ---------------\n",
      "Deep layers: 3 , Number of neurons: 200 , Learning rate: 0.0001\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0345 - mean_squared_error: 0.0345\n",
      "Loss: 0.03445948287844658 , Elapsed time: 100.0972888469696\n",
      "-------------------------------------------------\n",
      "\n",
      "\n",
      "--------------- Starting trial: 22 ---------------\n",
      "Deep layers: 3 , Number of neurons: 100 , Learning rate: 0.0001\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0306 - mean_squared_error: 0.0306\n",
      "Loss: 0.03059309907257557 , Elapsed time: 90.56424641609192\n",
      "-------------------------------------------------\n",
      "\n",
      "6  \t4     \t0.0305931\t0.0337878\t0.0388347\n",
      "\n",
      "--------------- Starting trial: 23 ---------------\n",
      "Deep layers: 3 , Number of neurons: 100 , Learning rate: 0.0001\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0328 - mean_squared_error: 0.0328\n",
      "Loss: 0.03276181221008301 , Elapsed time: 91.36591696739197\n",
      "-------------------------------------------------\n",
      "\n",
      "\n",
      "--------------- Starting trial: 24 ---------------\n",
      "Deep layers: 3 , Number of neurons: 100 , Learning rate: 0.0001\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0305 - mean_squared_error: 0.0305\n",
      "Loss: 0.030462568625807762 , Elapsed time: 76.6839189529419\n",
      "-------------------------------------------------\n",
      "\n",
      "\n",
      "--------------- Starting trial: 25 ---------------\n",
      "Deep layers: 3 , Number of neurons: 200 , Learning rate: 0.0001\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0315 - mean_squared_error: 0.0315\n",
      "Loss: 0.03153089061379433 , Elapsed time: 114.21243262290955\n",
      "-------------------------------------------------\n",
      "\n",
      "7  \t3     \t0.0304626\t0.0319614\t0.0339212\n",
      "\n",
      "--------------- Starting trial: 26 ---------------\n",
      "Deep layers: 3 , Number of neurons: 200 , Learning rate: 0.0001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0399 - mean_squared_error: 0.0399\n",
      "Loss: 0.03992725536227226 , Elapsed time: 42.83681893348694\n",
      "-------------------------------------------------\n",
      "\n",
      "\n",
      "--------------- Starting trial: 27 ---------------\n",
      "Deep layers: 3 , Number of neurons: 100 , Learning rate: 0.0001\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0314 - mean_squared_error: 0.0314\n",
      "Loss: 0.03142112120985985 , Elapsed time: 143.70012998580933\n",
      "-------------------------------------------------\n",
      "\n",
      "\n",
      "--------------- Starting trial: 28 ---------------\n",
      "Deep layers: 3 , Number of neurons: 100 , Learning rate: 0.0001\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0320 - mean_squared_error: 0.0320\n",
      "Loss: 0.032044582068920135 , Elapsed time: 143.57199215888977\n",
      "-------------------------------------------------\n",
      "\n",
      "8  \t3     \t0.0311304\t0.0332108\t0.0399273\n",
      "\n",
      "--------------- Starting trial: 29 ---------------\n",
      "Deep layers: 3 , Number of neurons: 200 , Learning rate: 0.0001\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0336 - mean_squared_error: 0.0336\n",
      "Loss: 0.033618830144405365 , Elapsed time: 108.32845544815063\n",
      "-------------------------------------------------\n",
      "\n",
      "\n",
      "--------------- Starting trial: 30 ---------------\n",
      "Deep layers: 1 , Number of neurons: 100 , Learning rate: 0.0001\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0728 - mean_squared_error: 0.0728\n",
      "Loss: 0.0728280171751976 , Elapsed time: 69.30746483802795\n",
      "-------------------------------------------------\n",
      "\n",
      "9  \t2     \t0.0311304\t0.0399676\t0.072828 \n",
      "\n",
      "--------------- Starting trial: 31 ---------------\n",
      "Deep layers: 3 , Number of neurons: 200 , Learning rate: 0.0001\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0331 - mean_squared_error: 0.0331\n",
      "Loss: 0.033109329640865326 , Elapsed time: 143.50401663780212\n",
      "-------------------------------------------------\n",
      "\n",
      "\n",
      "--------------- Starting trial: 32 ---------------\n",
      "Deep layers: 3 , Number of neurons: 100 , Learning rate: 0.0001\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0305 - mean_squared_error: 0.0305\n",
      "Loss: 0.030516544356942177 , Elapsed time: 204.6116042137146\n",
      "-------------------------------------------------\n",
      "\n",
      "\n",
      "--------------- Starting trial: 33 ---------------\n",
      "Deep layers: 3 , Number of neurons: 100 , Learning rate: 0.0001\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0349 - mean_squared_error: 0.0349\n",
      "Loss: 0.03489787504076958 , Elapsed time: 69.31775856018066\n",
      "-------------------------------------------------\n",
      "\n",
      "\n",
      "--------------- Starting trial: 34 ---------------\n",
      "Deep layers: 3 , Number of neurons: 100 , Learning rate: 0.0001\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0318 - mean_squared_error: 0.0318\n",
      "Loss: 0.03181558474898338 , Elapsed time: 143.6532301902771\n",
      "-------------------------------------------------\n",
      "\n",
      "10 \t4     \t0.0305165\t0.0322939\t0.0348979\n",
      "-- Best Individual =  [1, 0, 0, 1, 0, 0, 0]\n",
      "-- Best Fitness =  0.030516544356942177\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEWCAYAAAB8LwAVAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAABl8UlEQVR4nO3dd1iT19sH8G9CCBvZIMOFCkEUUSHQqlQUUdGKo47+xLrqqmIdtda9ta+tbV21Vmu1VVvrooobB7YVHKiA4EBFBSVBEJkJITnvH0+TggQSIINxPtfFFUiecZ8k5M4ZzzksQggBRVEURb2Fre8AKIqiqPqJJgiKoihKKZogKIqiKKVogqAoiqKUogmCoiiKUoomCIqiKEopmiAaqRcvXsDX1xdSqVTfoSA4OBj//POPvsPQqf379+Odd96Br68vXr9+DV9fXzx//lzfYVFaMGnSJBw9elTfYWgFTRA1FBwcDG9vb+Tm5la4f/DgwfDw8EBGRoZWz3/kyBF4eHhg3bp1Fe4/f/48PDw8sGDBAgCAs7Mzbt26BQMDA63GoymbN2+Gh4cHEhMT9R1KnUkkEqxfvx4//fQTbt26BWtra9y6dQtubm4AgAULFuCbb77Rc5T1R1JSEqZMmQI/Pz9069YNAwYMwDfffIM3b97oO7RKNm/ejHnz5lW4b+fOnRgyZIieItIumiBqwcXFBdHR0Yq/79+/D5FIpLPzt2jRAidPnkRZWZnivmPHjqFVq1Y6i0GTCCGIioqClZWV1r6J6bImlZOTA7FYjLZt2+rsnA1B+ferXEJCAsaOHYsuXbrg1KlTuHHjBnbu3AkDAwPcu3dP7/E1dTRB1MLgwYNx7Ngxxd/Hjh1DeHh4hW0uXbqE8PBwdOnSBUFBQdi8ebPisZMnT6J3794oLCwEAFy+fBnvvvtupVpJVezs7NC+fXv89ddfAIC8vDzcunULwcHBim0yMjLg4eGheNNHRETg22+/xahRo+Dr64sJEyZUeb43b95gypQpCAgIgJ+fH6ZMmYKsrCzF46qOdezYMfTq1Qt8Ph/ff/+9yvLcuHEDQqEQCxcuxMmTJ1FaWgoAmDhxIn799dcK277//vs4e/YsAODRo0cYP348/P39ERoaipMnTyq2W7BgAZYtW4aPP/4YnTt3Rnx8fLWvydtxb926tULTmEwmw44dO9CnTx/w+XzMmjULeXl5lcry5MkT9OvXDwDg5+eHsWPHAgA8PDzw9OlT/P777zh+/Dh27doFX19fTJ06FQBTM921axcGDRqErl274tNPP4VYLFYc9+LFixg8eDC6deuGUaNGVfjw3LFjB3r06AFfX1+Ehobi6tWrAIDExEQMHToUXbp0wTvvvFOp1lnewYMHERISAn9/f0ydOhUCgQAAsHTpUnz55ZcVtp02bRp2794NABAIBJg5cyYCAgIQHByMvXv3KrbbvHkzIiMjMW/ePHTp0kVp8t+wYQOGDh2KKVOmwM7ODgBT+42MjASfz1dsd+jQIfTv3x9+fn6YOHEiMjMzFY95eHjgwIED6Nu3L/z8/LBixQqUnyBC1b779u1D37590bdvXwDA6tWrERQUhC5dumDo0KG4ceMGACA2NhY//PADTp06BV9fX7z//vsAmP+HP/74AwDzPtm2bRt69eqFwMBAzJ8/HwUFBQD++588evQo3nvvvUr/HzV5vXSGUDXSq1cv8vfff5O+ffuStLQ0UlZWRnr27EkyMjJI+/btyfPnzwkhhMTFxZF79+4RqVRKUlNTSWBgIDl37pziOHPmzCGff/45yc3NJe+++y65cOGCWuc/fPgwGTVqFPnzzz/JrFmzCCGE/Prrr2TJkiVk48aN5PPPPyeEEPL8+XPSvn17IpFICCGEjBkzhvTu3Zs8fvyYlJSUkDFjxpANGzYoPUdubi45ffo0KS4uJgUFBWTmzJlk2rRpiserO9bDhw9J586dybVr14hYLCZr164lPB6P/P3331WW6YsvviCRkZGktLSU+Pv7kzNnzhBCCDl69CgZOXKkYruHDx+Srl27ErFYTIqKikjPnj3JoUOHiEQiIcnJycTf3588ePCAEELI559/Trp06UJu3LhBpFIpEYlE1b4m8rivX79OxGIxWb9+PfHy8lLEvXv3bvLBBx+Qly9fErFYTJYsWUJmz56ttDxvP/eEENK+fXuSnp6uiG3jxo0V9unVqxcZNmwYycrKIq9fvyb9+vUj+/fvJ4QQkpycTAICAsjt27dJWVkZOXLkCOnVqxcRi8Xk0aNHpGfPniQrK0tx7qdPnxJCCBkxYgQ5evQoIYSQwsJCcuvWLaXx/vPPP8Tf358kJycTsVhMVq5cST788ENCCCHXrl0jPXv2JDKZjBBCSF5eHunYsSPJysoiUqmUDBkyhGzevJmIxWLy7NkzEhwcTGJjYwkhhGzatIl4eXmRc+fOEalUSkpKSiqct6ioiHh6epK4uDilccmdO3eO9OnTh6SlpRGJREK2bt1a4X3Rvn17MnnyZPLmzRuSmZlJ+Hw+uXz5str7jhs3jrx+/VoR37Fjx0hubi6RSCRk165d5J133iEikUhRprlz51aIb8yYMeTgwYOEEEL++OMP0qdPH/Ls2TNSWFhIPvnkEzJv3jzFa9O+fXuyaNEiUlJSQlJTU0mHDh1IWlpajV4vXaI1iFqS1yL+/vtvtGnTBo6OjhUe5/P58PDwAJvNhqenJ8LCwnDt2jXF48uWLUNcXBzGjh2L4OBg9OrVq0bnDwkJwbVr11BQUICoqCgMHjxY5T5Dhw5F69atYWxsjH79+iE1NVXpdtbW1ggNDYWJiQnMzc0xbdo0XL9+Xa1jnT59Gu+99x78/PzA5XIxa9YssNlVv81KSkpw+vRpDBo0CIaGhggNDVV80+zTpw/u3bun+MZ3/PhxhISEgMvl4tKlS3BxccGwYcPA4XDQoUMHhIaG4syZM4pj9+7dG127dgWbzYaRkVG1r8np06fRq1cvdOvWDVwuF5GRkWCxWIpj/f7775g9ezacnJzA5XIxY8YMnDlzRqPNEhEREXB0dISVlRV69eqleE4PHjyIkSNHwsfHBwYGBhgyZAgMDQ1x+/ZtGBgYoLS0FI8ePYJEIoGrqytatGgBAOBwOHj27Blyc3NhZmaGzp07Kz3v8ePHMWzYMHTo0AFcLhdz5szB7du3kZGRgW7duoHFYim+RZ85cwadO3eGo6MjkpKSkJubixkzZoDL5cLNzQ0jRoyoUJPr3Lkz+vTpAzabDWNj4wrnzc/Ph0wmU9QcAOD//u//0K1bN3Tu3Bnbtm0DAPz222+YPHky3N3dweFwMHXqVKSmplaoCXz88cewtLSEs7Mz+Hy+ooalzr6TJ0+GlZWVIr7BgwfD2toaHA4HEyZMQGlpKZ48eaLWa3j8+HGMGzcObm5uMDMzw5w5cyo1B8+YMQPGxsbw9PSEp6enIlZ1Xy9d4ug7gIZq8ODBGDNmDDIyMpR+ON+5cwdfffUVHj58CIlEgtLSUkXTAwBYWlqiX79+2L17NzZt2lTj8xsbGyMoKAjbtm3D69ev0bVrV8TGxla7j729veJ3ExMTFBcXK92upKQE69atw5UrVxQdhUVFRZBKpYpO76qOJRQK4eTkpHjM1NQUVlZWVcZ07tw5cDgc9OzZEwAwaNAgjB8/Hrm5ubCxsUFQUBCio6MxefJkREdHY9WqVQCAzMxMJCYmolu3bopjSaVSRbUfAJo3b17hXNW9Jm/HbWJiUiHuFy9e4JNPPqmQ7NhsNnJycip9Oaitt59ToVCoOPexY8cqNLdJJBIIhUL4+/tj4cKF2Lx5M9LS0tC9e3csWLAAjo6OWLNmDTZt2oT+/fvD1dUVM2bMUPpFRCgUokOHDoq/zczMYGVlBYFAAFdXVwwYMAAnTpyAn58fjh8/rniOMzMzIRQKK70G5f8u/5y+zdLSEmw2G9nZ2XB3dwcAzJ8/H/Pnz8e8efMU/UYvXrzA2rVrKzR1EUIgEAjg4uKi9LkrKipSe9+33yc//fQT/vjjDwiFQrBYLBQWFuL169dVlqM8oVCoOC7A9FeWlZUhJydHcV/5hFj+f0fd10uXaIKoJRcXF7i6uuLy5ctYs2ZNpcfnzp2LMWPGYOfOnTAyMsKaNWsqvMlSU1Nx+PBhDBw4EKtXr8auXbtqHEN4eDg++ugjzJgxo05ledtPP/2EJ0+e4ODBg7C3t0dqairCw8MrtOtWxcHBAY8ePVL8XVJSorStXu7YsWMoLi5W/CMQQiCRSHDixAmMHTsWAwcOxJYtW+Dn5weRSKRol27evDn8/PwUbeHqqO41cXBwqPAtUSQSVYjbyckJa9euRdeuXdU+X1XK10zU0bx5c0ydOhXTpk1T+vigQYMwaNAgFBYWYunSpfjqq6+wYcMGtGrVChs3boRMJsPZs2cRGRmJ+Ph4mJqaVtjfwcGhwjfq4uJi5OXlKRLfwIEDMWHCBEyePBmJiYnYunWrIi5XV1dFn1BNy2pqagofHx+cO3cOAQEBKstfPvmrS519y8d448YN/Pjjj/j555/Rrl07sNls+Pn5Kd77ql67t5/LFy9egMPhwNbWtkI/njLqvl66RJuY6mDNmjXYs2eP0hewqKgIzZo1g5GRERITE3HixAnFY2KxGJ999hlmz56NdevWQSgUYt++fYrHIyIiKnWgKuPv74/du3djzJgxmilQudiNjIxgaWmJvLw8bNmyRe19Q0NDcenSJdy4cQOlpaXYtGkTZDKZ0m0FAgGuXr2K7du349ixYzh27BiioqLw8ccfKwYBBAUF4cWLF9i0aRMGDBig+Ab/3nvvIT09HceOHYNEIoFEIkFiYmKF5KSsXFW9JqGhobhw4QISEhIUcZdPiKNHj8a3336r+OfPzc3F+fPn1X5eyrO1ta3RcOgPPvgAv/32G+7cuQNCCIqLi3Hp0iUUFhbi8ePHuHr1KkpLS8HlcmFkZKSo5UVFRSE3NxdsNhuWlpYAoHTY86BBg3DkyBGkpqaitLQUGzduRKdOneDq6goA8PLygo2NDRYvXozu3bsrjtWpUyeYm5tjx44dEIlEkEqlePDgQY2GKs+bNw+HDx/Gjh07FN+ys7KyKjw/o0aNwo4dO/Dw4UMAQEFBAU6dOqXW8Wu6b1FREQwMDGBjY4OysjJs2bJFMZgEYF67zMzMKt/TAwcOxJ49e/D8+XMUFRXhm2++Qf/+/cHhqP4uru7rpUs0QdRBixYt0LFjR6WPLVu2DJs2bYKvry+2bt2K/v37Kx77+uuv4ejoiA8//BBcLhcbNmzAd999h/T0dADAy5cv0aVLF5XnZ7FYCAwMrLYJpzY++ugjiMViBAQEYOTIkejRo4fa+7Zr1w5Lly7FvHnz0KNHD1haWlbZzBAVFQUej4fu3bvD3t5e8RMREYH79+/jwYMH4HK5CAkJwT///IOBAwcq9jU3N8euXbtw8uRJ9OjRA927d8dXX32lGAGlTHWvSbt27bBkyRLMmTMHPXr0gJmZGWxsbMDlcgFA0Vc0YcIE+Pr6YsSIEbW+ZmP48OFIS0tDt27dMH36dJXbd+zYEatWrcLKlSvh5+eHvn374siRIwCA0tJSfP311+Dz+ejevTtyc3Mxe/ZsAMCVK1cQFhYGX19frFmzBt988w2MjIwqHT8wMBCzZs3CzJkz0b17dzx//rzSdRphYWGVXgMDAwN8//33uHfvHnr37o2AgAAsXry4wgeqKt26dcOePXtw/fp1hIaGolu3bpg0aRL4fL7ii09ISAgmTZqEOXPmoEuXLhg4cKDK5lS5mu7bvXt39OzZE6GhoQgODoaRkVGFJih5kySfz1d67cOwYcPw/vvvY8yYMejduze4XC6WLFmiVqzqvl66xCLqtBtQOpOVlYVZs2bh999/13coTVpRURH8/Pxw5swZxQVuFNXU0ARBUf+6cOECAgMDQQjB+vXrkZiYiKNHj9a4z4CiGgvaxERR/4qJiUGPHj3Qo0cPPH36FBs3bqTJgWrSaA2CoiiKUorWICiKoiilGtV1ELdv3651r79YLNb7iAFdo2Vu/JpaeQFa5trsW9VV240qQRgZGYHH49Vq39TU1Frv21DRMjd+Ta28AC1zbfatilabmGJjYxEaGoqQkBDs2LGj0uOPHj3CyJEj4e3trfRKYqlUivDwcEyZMkWbYVIURVFKaK0GIZVKsXLlSuzevRuOjo4YPnw4goODK8yRb2VlhUWLFiEmJkbpMfbu3Qt3d/caXXhDURRFaYbWahCJiYlo2bIl3NzcwOVyERYWVikR2NraolOnTkovQ8/KysKlS5cwfPhwbYVIURRFVUNrNQiBQFBhigVHR8caTU2wdu1afPbZZ4pZGdUhFourbU+rjkgkqvW+DRUtc+PX1MoLqC4zIQRSqVStyScbCkKIys9XFosFAwODGl3bo7UEoezJVzewixcvwsbGBt7e3oiPj1f7nLSTumZomRu/plZeQHWZnzx5AgsLC9ja2jaaCyFLSkpgYmJS5eOEEOTk5KCgoACtW7eu8Fh1yVRrCcLJyanC9LYCgQAODg5q7ZuQkIALFy4gNjYWYrEYhYWFmDdvHr766itthUtRVBMhEonQqlWrRpMc1MFisWBra4vs7Owa7ae1PoiOHTsiPT0dz58/R2lpKaKjoyusmVyduXPnIjY2FhcuXMDGjRsREBBAkwNFURrTlJKDXG3KrLUaBIfDwdKlSzFp0iRIpVIMGzYM7dq1w4EDBwAw8+tnZ2dj2LBhKCwsBJvNxp49e3Dy5EmYm5trKyzqX/sS96GNrI2+w6Aoqh7T6oVyQUFBCAoKqnDf6NGjFb/b29urnNedz+crVhGjNCMtNw1jjo7BnI5zENg5UN/hUFST4+Hhgffffx8bNmwAAJSVlaF79+7w8fHBDz/8gJiYGDx69AiTJ0/Wa5yN6kpqSj2JAma0w6P8qldfoyhKe0xNTfHw4UOIRCIYGxvj77//rrC2ee/evdG7d289Rsigk/U1QUmCJADA44LHeo6Eopqunj174tKlSwCA6OhohIWFKR47cuQIVq5cCQBYsGABVq9ejVGjRqF37944ffq0zmKkNYgmKEn4b4LIfwxCSJPssKMoANi7F/jpJ80ec8IEYOxY1dsNGDAA27ZtQ69evXD//n0MGzYMN2/eVLqtUCjE/v378fjxY0ybNk2x9Km20RpEE5QsTAYLLBSVFSGzIFPf4VBUk+Tp6YmMjAycOHGiUl/t2/r06QM2m422bdvi1atXOoqQ1iCanBJJCR7mPkT3Ft1x5dkVpGanwtXSVd9hUZRejB2r3rd9bQkODsb//d//Ye/evcjLy6tyOy6Xq7ugyqE1iCYm9VUqZESGER1GKP6mKEo/hg8fjunTp8PDw0PfoShFE0QTI++g7tOmDywNLZGSnaLniCiq6XJycsJHH32k7zCqRJuYmpgkYRKMDIzQ1qYt3C3daQ2CovTg1q1ble4rf83X0KFDMXToUADA+vXrVe6rLbQG0cQkC5PhZe8FDpuDNpZtkJpNEwRFUcrRBNHEJAmT0NGxIwCgjWUbZBdnI6c4R89RURRVH9EE0YTkluTiRcELeNt7A2ASBEA7qimKUo4miCZE3kEtr0G4W7gDAG1moihKKZogmhD5FdQdHZgE4WzmDBOOCR3JRFGUUjRBNCFJgiRYG1vD2cIZAMBmseFp50mbmCiKUoomiCYkOTsZHR07Vph7iWfPowmConTMw8MDn332meLvsrIyBAQEYMqUKXqMqjKaIJoIQgiShcmK5iU5nh0Pz948Q2FpoZ4io6imp/x03wAqTfddX9AE0UQ8e/MM+eJ8eDt4V7ifZ8cs7n7/1X19hEVRTVZ1030XFxfjiy++wLBhwxAeHo7z588DADIyMvDhhx9iyJAhGDJkCBISEgAA169fR0REBCIjI9GvXz/MnTsXhJA6x0ivpG4i3u6gluPZMwkiJTsFXZ276jwuitKnvXf24qdbmp3ve4LvBIz1UT0DYHXTfW/fvh0BAQFYt24d8vPz8cEHH+Cdd96Bra0tdu/eDSMjI6Snp2POnDk4cuQIACAlJQXR0dFwcHDA6NGjcfPmTXTr1q1OZaEJoomQD3F9uwbR1qYtOGwO7YegKB2rbrrvv/76CxcuXMBP/y5WIRaL8fLlSzg4OGDlypW4d+8e2Gw20tPTFft06tQJTk5OimNnZmbSBEGpJzk7GS2atUAz42YV7ucacNHWpi1NEFSTNNZnrFrf9rWluum+N23ahDZt2lS4b/PmzbCzs0NUVBRkMhk6deqkeKz8lOAGBgaQSqV1jo/2QTQRSYKkSs1Lcjw7Hr1YjqL0oKrpvrt3745ff/1V0Y+QksJcq1RQUAB7e3uw2WxERUVpJAlUhyaIJkAileDeq3uVmpfkeHY8pOWmoVRaquPIKKppq2q67+nTp6OsrAzvv/8+Bg4ciO+++w4A8OGHH+Lo0aMYMWIE0tPTYWpqqtX4aBNTE3A/5z4kMknVNQh7HqREirTcNHjZe+k4OopqelRN921sbIyVK1dW2qZVq1Y4fvy44u+5c+cCAPz8/NCzZ0/F/UuXLtVInLQG0QS8PQfT2+RDXemUGxRFlUcTRBOQLEwGh82Bp52n0sfl99N+CIqiyqMJoglIEibBw9YDXAPlC5+bcc3QsllLOpKJoqgKaIJoApKESVV2UMvROZkoinobTRCNXIG4AOl56VV2UMvx7Hi4/+o+ZESmo8goiqrvtJogYmNjERoaipCQEOzYsaPS448ePcLIkSPh7e2NXbt2Ke5/+fIlIiIi0L9/f4SFhWHPnj3aDLNRSxYmA6i6g1qOZ8dDSVkJnuY91UVYFEU1AFpLEFKpFCtXrsTOnTsRHR2NEydOIC0trcI2VlZWWLRoESZOnFjhfgMDAyxYsACnTp3C77//jv3791fal1KPIkGoqEHIh7fSkUwUpX1NfrrvxMREtGzZEm5ubuByuQgLC0NMTEyFbWxtbdGpUydwOBUvx3BwcECHDh0AAObm5mjTpg0EAoG2Qm3UkoRJMOeao6VVy2q3k0/aR/shKEr7Gsp03zW6UE4mk6G4uBjm5uYqtxUIBIqJowDA0dERiYmJNQ4wIyMDqamp8PHxUbmtWCxGamrNP+BSX6fCjmMHNMLPxvgn8Whj3gb371WezlskElV4vmyNbHE17SpSrRvhE/Gvt8vc2DW18gKqyyyRSFBSUqLDiCojhCAwMBBnz55FSEgI/vzzT4SGhiIhIQElJSVISkrChg0bIBaLYWRkhJUrV6JVq1b45ZdfkJaWhhUrVuDhw4dYsGABfv31VxgbG6tVJolEUqP3g8oEMXfuXKxYsQJsNhtDhw5FYWEhxo0bh0mTJql8At5WfiUzdRQVFSEyMhILFy5UKykZGRmBx+PV6BwA0P/b/njX/l3s+9++Gu9bnxFC8Oj4IwzxHKL0eUlNTa1wv3e8N15KXtbqOWwo3i5zY9fUyguoLnNqaipMTEyYP/buBX7S7HTfmDABGFv9BIAsFguDBw/Gtm3bEBoairS0NIwYMQJ37tyBiYkJvLy8cODAAXA4HPzzzz/Ytm0bNm/ejEmTJiEiIgJ//fUXvv/+e6xatQo2NjYoKSn5r0zVMDQ0rPTcVJcwVDYxpaWlwdzcHOfPn0dQUBAuXryIqKgolYE4OTkhKytL8bdAIICDg4PK/eQkEgkiIyMxaNAg9O3bV+39asPdxh23XlW+9L2hyyrMQk5JjsoOajmeHTPUVRMLjVAUVb3qpvsuKCjArFmzMHDgQKxbtw4PHz4EALDZbKxfvx7z58+Hv78/unbV7houKmsQZWVlkEgkOH/+PMaMGQNDQ0O1agIdO3ZEeno6nj9/DkdHR0RHR+Prr79WKyhCCBYtWoQ2bdpg/Pjxau1TFwEuAfgy/UsUS4phaqjdya90Sd0OajmePQ95ojxkFWahuUVzbYZGUfXD2LEqv+1rU1XTfX/33Xfg8/nYunUrMjIyMLZcjPJJ+oRCodbjU1mDGDlyJIKDg1FSUgI/Pz9kZmaq1dzD4XCwdOlSTJo0CQMGDED//v3Rrl07HDhwAAcOHAAAZGdno2fPnti9eze+//579OzZE4WFhbh58yaioqIQFxeHwYMHY/Dgwbh8+XLdS1sFvisfUiJFwssErZ1DH+SryKm6SE5OPpKJdlRTlG5UNd13QUGBotP66NGjFe5fs2YNfv31V+Tl5eH06dNajU9lDWLs2LEVspeLiwv27t2r1sGDgoIqVZ1Gjx6t+N3e3h6xsbGV9uvWrRvu39fdGsl8F2YGxbiMOHRv0V1n59W2JGESHM0cYW9mr9b28kn7UrNTEdw6WJuhURSFqqf7njRpEhYsWIDdu3cjICBAcf/atWvx4YcfonXr1lizZg3Gjh0LPz8/rU37rTJB7NmzB8OGDYOZmRkWLVqE1NRUzJ07F927N54PUkdzR7iYuSA+M17foWhUkiBJ7f4HAHC2cIYF14LWIChKy1RN9+3r64szZ84oHvv0008BAOvWrVPc17x5c5w7dw4AtDYqS2UT0+HDh2Fubo6//voLubm5WLdundp9CQ1JJ5tOiMuI03cYGiOVSXE3+67a/Q8AM7KCzslEUZScygQhH9Fy+fJlDBs2DJ6eno1ylIuPrQ8y8jPwouCFvkPRiMevH0NUJqpRggDo8qMURf1HZYLw9vbGhAkTEBsbi+7du6OwsBBsduOb46+TDbP4d3xG42hmkndQ16SJCWA6ql8WvkSeKE8LUVFU/dAYv+SqUpsyq/ykX7NmDebOnYtDhw7BxMQEEokEa9eurVWA9RnPmgdDtmGjaWZKEiSBBVaNlxAt31FNUY2RsbExcnJymlSSIIQgJycHxsbGNdpPZSc1i8VCWloaLl68iBkzZqCkpASlpY1vcXsjAyN0durcaDqqk4RJcLdxr/F1HeXnZAp0C9RGaBSlV66ursjIyEB2dra+Q9EYiUQCQ0PDarcxNjaGq6trjY6rMkEsX74cbDYbcXFxmDFjBszMzDBz5kwcPny4RidqCPgufOy+vRtlsjJw2DWapqreSRIm1bj/AQBaW7WGkYERrUFQjZahoSFat26t7zA0SltTqqhsYkpMTMSyZctgZGQEAGjWrBkkEonGA6kP+K58FEmKcFd4V9+h1EmJpARpuWm1ShAGbAO0t21PRzJRFKU6QXA4HEilUsX0Grm5uY2ykxoAAlyZC1IaejNT6qtUyIisxh3UcnSoK0VRgBoJIiIiAp988glycnLwzTffYPTo0fVuUQtNcbd2h62JbYMfyZQk+HcEUy1qEADgZeeFJ6+foESi3ymRKYrSL5UN7e+//z46dOiAuLg4EEKwbds2uLu76yI2nWOxWPB38UdcZsMeyZQkTIKRgRHcbWr3OvHseSAguJ9zH52dOms2OIqiGgy1emJbtWoFc3NzSKVSAMCLFy/g7Oys1cD0JcA1AKfTTiNfnA9LI0t9h1MrScIkeNl71bqjvfxQV5ogKKrpUvkJ8ssvv2DLli2ws7Or0Pdw/PhxrQamL3wXPggIrmdeR+82vfUdTq0kCZIQ4h5S6/3b27YHm8Wm/RAU1cSpTBB79+7F6dOnYW1trYt49M7fxR8AM7NrQ0wQOcU5eFn4stb9DwBgxDFCG+s2NEFQVBOnspPayckJFhYWuoilXrA2sYaHrUeDHclU00WCquJl74WU7BRNhERRVAOlsgbh5uaGiIgIvPfee+ByuYr7dbHSm77wXfk49fAUCCE1Xkdb32q6SFBVeHY8nHp4qlFcNEhRVO2orEE4Ozvj3XffhUQiQVFRkeKnMQtwCUB2cTbS89L1HUqNJQmSYG1sDWeLug0i4NnxIJFJ8Cj3kYYioyiqoVH51dDd3R39+/evcN+pU6e0FlB9wHdlFu2Iz4xHa+uGdUl+kpBZJKiuNZ/yczJ52Hmo2JqiqMZIZQ1ix44dat3XmHR06AhjjnGDm9mVEIJkYXKd+x8AwNPOEwCd1ZWimrIqaxCXL19GbGwsBAIBVq9erbi/sLAQBgYGOglOXwwNDNHNuVuD66h+9uYZCkoLNJIgLI0s4WLhQkcyUVQTVmWCcHR0hLe3Ny5cuIAOHToo7jczM8MXX3yhk+D0ie/Cx5ZrWyAuE8OIY6TvcNSiqQ5qOTqSiaKatioThKenJzw9PTFo0CBwOE1vFAvfhY+vpV/jjuCO4tqI+k4+B5OmEgTPjoddt3ZBRmRgsxrnBI0URVWtyk/+WbNm4bvvvsOQIUOUPt5Yr6SWU8zsmhHfcBKEMAktmrVAM+NmGjkez56HIkkRMvIz0KJZC40ck6KohqPKBLFgwQIAwPbt23UWTH3iaumK5ubNEZ8Zj5mYqe9w1KKpDmq58nMy0QRBUU1Ple0G06dPBwC4uLjgp59+gouLS4Wfxo7FYoHvym8wI5kkUgnuvbqn2QRRbqgrRVFNT5UJovyC3gkJCToJpr4JcAnAo9eP8Kr4lb5DUel+zn1IZBKN9T8AgL2pPWxNbGlHNUU1UVUmiIY2xYQ2yC+Yu5Z5Tc+RqKZYJKiWq8gpw2Kx6OpyFNWEVdkH8fjxYwwaNAgA8OzZM8Xvco29kxoAujl3A5vFRlxGHAa0G6DvcKqVJEwCh81RXOCmKTw7Ho6kHtHoMSmKahiqTBAnT56s88FjY2OxZs0ayGQyfPDBB5g8eXKFxx89eoSFCxfi7t27mD17NiZOnKj2vrpgzjWHt4N3g7hgLlmYDA9bD3ANuKo3rgGeHQ85JTnILsqGvZm9Ro9NUVT9VmWCqGtHtFQqxcqVK7F79244Ojpi+PDhCA4ORtu2bRXbWFlZYdGiRYiJianxvrrCd+Hjj5Q/6v21AEnCJMXQXE0q31FNEwRFNS1a+8RLTExEy5Yt4ebmBi6Xi7CwsEqJwNbWFp06dap0IZ46++pKgGsA8kR5eJDzQC/nV0eBuADpeenwttdcB7Vc+aGuFEU1LVq7RFogEMDJyUnxt6OjIxITE7W6r1gsRmpq7T7IRCKR0n3txHYAgKPXjyK8VXitjq1tt1/dBgBYlVrVqPxVlbk8GZHBhGOCvx78hZ5mPesSZr2gTpkbk6ZWXoCWWZPUShAikQgvXrxAmzZt1D5w+WGycuqOjKrtvkZGRuDxeGqd422pqalK920vaw+LixZ4Jn1W62Nr25WbVwAAA7oOqNH05FWV+W1ef3lBIBXU2/LXhLplbiyaWnkBWuba7FsVlU1MFy5cwODBgzFp0iTFwaZOnarypE5OTsjKylL8LRAI4ODgoE68ddpX0wzYBvB38a/XHdXJwmSYc83R0qqlVo5Ph7pSVNOkMkFs2bIFhw4dgqWlJQCAx+MhMzNT5YE7duyI9PR0PH/+HKWlpYiOjkZwcLBaQdVlX23gu/CRKEhEsaRYbzFUJ0mYBG8Hb611ovPseMjIz0CBuEArx6coqn5S2cRkYGAACwuLmh+Yw8HSpUsxadIkSKVSDBs2DO3atcOBAwcAAKNHj0Z2djaGDRuGwsJCsNls7NmzBydPnoS5ubnSffWF78qHlEhx88VN9GjZQ29xKEMIQZIgCUM8lU+qqAnyjup7r+7Bz8VPa+ehKKp+UZkg2rVrh+PHj0MqlSI9PR2//PILfH191Tp4UFAQgoKCKtw3evRoxe/29vaIjY1Ve1994bv8twRpfUsQWYVZyCnJ0egV1G/zsvcCwAx1pQmCopoOlW0SS5YsQVpaGrhcLubMmQNzc3MsWrRIF7HVG47mjmhl1ape9kPIFwnS5CR9b3O3cYch25DOyURRTYzKGoSJiQlmz56N2bNn6yKeeivANQB/PftL32FUoo05mN7GYXPQzrYd7aimqCZGZYJQNmLJwsIC3t7eGDVqFIyMGsZynHXFd+Hjt+Tf8KLgBZwtnPUdjkJydjKczJ1gZ2qn1fPw7HhIFKh3HQtFUY2DyiYmV1dXmJmZYcSIERgxYgTMzc1hZ2eH9PR0LF68WBcx1guKfoiM+tXMlCRI0mrzkhzPjodHrx9BXCbW+rkoiqofVNYgUlNTsW/fPsXfwcHB+N///od9+/YhLCxMq8HVJ77NfWHINkRcRhyG8LQ3YqgmpDIp7mbfxbRu07R+Lp49DzIiw8Pchxpdc4KiqPpLZQ0iNzcXL168UPz94sULvH79GgBgaGiovcjqGWOOMTo7da5XHdWPXj+CqEykkxqEfCQT7aimqKZDZQ1iwYIF+PDDD+Hm5gYAyMjIwLJly1BcXIzw8HBtx1ev8F342H17N8pkZeCwtTaNldp00UEt52HrARZYdNI+impCVH7KBQUF4ezZs3j8+DEIIWjTpo2iY3rcuHHajq9eCXANwJbrW3BXeBc+Tj76DgfJwmSwwFJ8u9cmE0MTtLJqRUcyUVQTotbX4PT0dDx+/BilpaW4f/8+ADS52gPw3xKk8Znx9SJBJAmT0NamLUwNTXVyPjonE0U1LSoTxJYtWxAfH49Hjx4hKCgIsbGx6Nq1a5NMEO7W7rA1sUVcRhwmd9X9Cndvk8/BpCs8Ox5iHsdAKpPCgG2gs/NSFKUfKjupz5w5gz179sDOzg7r1q1DVFQUSktLdRFbvcNiscB35deLjuoSSQnSctN00kEt52XvBbFUjPS8dJ2dk6Io/VGZIIyMjMBms8HhcFBYWAhbW1s8f/5cF7HVS3wXPlKzU/FG9EavcaRkp0BGZDrpoJaTT9pHRzJRVNOgMkF4e3sjPz8fH3zwAYYOHYohQ4agU6dOuoitXuK78EFAcP3Fdb3GkSxMBqDdOZjeVn59aoqiGr9q+yAIIZgyZQosLS0xevRo9OjRA4WFhfD09NRVfPWOv4s/AOaK6j5t+ugtjiRhEowMjNDWpq3OzmllbAUncyeaICiqiai2BsFisfDJJ58o/nZ1dW3SyQEArE2s4WHrofd+iCRhErzsvXTeWcyz49FrISiqiVDZxOTj44PERDpJW3kBrgGIy4hTuna2riQJknTa/yDHs2OGuuqz7BRF6YbKYa7x8fH47bff4OLiAhMTE8X9x48f12pg9RnfhY89d/YgPS8dra1b6/z8OcU5eFn4Uqf9D3Je9l7IF+fjZeHLejWrLUVRmqcyQfz444+6iKNBKX/BnD4ShD46qOXkHdUp2Sk0QVBUI6eyicnFxQUvX75EXFycohYhk8l0EVu91dGhI0w4JojLiNPL+RWryOmpiQkA7YegqCZAZYLYsmULdu7ciR07dgAAJBIJPvvsM60HVp8ZGhiiq3NXvXVUJwmSYG1sjebmzXV+bidzJzQzakZHMlFUE6AyQZw7dw7ff/+9ov/B0dERRUVFWg+svuO78HHr5S29LKCTJGQ6qFksls7PzWKx6JxMFNVEqEwQhoaGYLFYig+j4uJirQfVEAS4BkAsFeOO4I5Oz0sIQbIwWS/9D3Jedl60iYmimgCVCaJ///5YunQp8vPzcfDgQYwfPx4jRozQRWz1mr6WIH325hkKSgv0miB49jwIigTILcnVWwwURWmfygQxceJEhIaGom/fvnjy5AkiIyMRERGhi9jqNVdLVzQ3b464TN12VOuzg1qOdlRTVNOgcpjrzz//jH79+uHdd9/VRTwNBovFQoBrgM5rEPJV5DrYd9DpecsrPyfTuy3o+4KiGiuVNYjCwkJMnDgRH374Ifbt24dXr17pIq4Gge/Cx6PXj/CqWHfPSZIwCS2atUAz42Y6O+fbWjZrCWOOMa1BUFQjpzJBzJgxA9HR0Vi6dCmEQiHGjBnT5JYarUqAawAA3fZDJAmT9Nr/AAAGbAN42HrQkUwU1cipTBBytra2sLOzg5WVFXJycrQZU4PR1bkr2Cy2zq6HKJWW4t6re3pPEAAz5QZNEBTVuKlMEPv370dERATGjRuH169fY/Xq1WrPwxQbG4vQ0FCEhIQoLrQrjxCC1atXIyQkBIMGDcLdu3cVj/38888ICwvDwIEDMWfOHIjFur/eQBVzrjm8Hbx1liAe5DxAmaxMrx3Ucjw7HtLz0lFUSq+JoajGSmWCePHiBRYuXIjo6GhERkbCzc0Np06dUnlgqVSKlStXYufOnYiOjsaJEyeQlpZWYZvY2Fikp6fj7NmzWLVqFZYvXw4AEAgE2Lt3Lw4fPowTJ05AKpUiOjq6diXUsgAXpqNaRrQ//Yi8g1qX61BXRd5RfT/nvp4joShKW1QmiHnz5qF9+/a4fPky5s+fj169eqmVIBITE9GyZUu4ubmBy+UiLCwMMTExFbaJiYlBeHg4WCwWOnfujPz8fAiFQgBMghGJRCgrK4NIJIKDg0Mti6hdfFc+3ojf4EHOA62fK0mYBA6bA087/a/JQYe6UlTjV+0w1+vXr+P48eO4fPkyOnXqhISEBMTExFSY9rsqAoEATk5Oir8dHR0rrSvx9jZOTk4QCATo2LEjJkyYgF69esHIyAjvvvsuunfvrvKcYrEYqam1+8ASiUS12tdObAcAOHr9KMJbhdfq3Oq6+ugqWpm3wqMHjzRyvNqWGQDKpGUwYBngyr0r6GLYRSPx6EJdytwQNbXyArTMmlRlgujZsyecnZ0xatQozJ8/H+bm5ggODlYrOQBQuqDM23MHVbXNmzdvEBMTg5iYGFhYWGDWrFmIiorC4MGDqz2nkZEReDyeWvG9LTU1tVb7ehAPWF6yxDPps1qfW11PzjxBYItAjZ2ntmWWa3upLbKRrfVya1Jdy9zQNLXyArTMtdm3KlU2MfXt2xcCgQCnTp3CxYsXUVxcXKPJ4ZycnJCVlaX4WyAQVGomenubrKwsODg44J9//oGrqytsbGxgaGiIvn374tatW2qfW5fYLDb8nP203lGdL87H0zdP68UIJjmePV1+lKIasyoTxOLFi3HhwgWMGzcO8fHxCA0NRW5uLk6ePKnWbK4dO3ZEeno6nj9/jtLSUkRHRyM4OLjCNsHBwTh27BgIIbh9+zYsLCzg4OAAZ2dn3LlzByUlJSCE4OrVq3B3d697abWE78JHoiARxRLtTWR4V8iM8KpXCcKOh4e5DyGRSvQdCkVRWlBtHwSLxUJgYCACAwMhkUhw5coVREdHY8WKFYiPr/4bM4fDwdKlSzFp0iRIpVIMGzYM7dq1w4EDBwAAo0ePRlBQEC5fvoyQkBCYmJhg7dq1AJh1sENDQzFkyBBwOBzweDyMHDlSQ0XWvADXAEiJFDdf3ESPlj20cg75HEz1YQSTHM+OhzJZGdJy0xSjmiiKajxUzsUkZ2hoiODgYAQHB0MkEqm1T1BQEIKCgircN3r0aMXvLBYLy5YtU7pvZGQkIiMj1Q1Pr8ovQaq1BCFIgjnXHC2tWmrl+LVRfk4mmiAoqvFR+0rq8oyNjTUdR4PmYOaA1lattboEaZIwCd4O3mCzavWSaYV8uC3th6Coxqn+fNo0cHxXvtY6quvDIkHKmHPN0aJZCzrlBkU1UlUmiB9++AEpKSm6jKVB47vwkZGfgcz8TI0fO6swCzklOfUuQQBMP0RKNn2fUFRjVGWCcHV1xd69exEeHo4FCxbg5MmTePPmjS5ja1AUM7tqoRZRHzuo5Xh2PNx7dU8nU41QFKVbVXZSh4WFISwsDACQkpKCK1euYMaMGZDJZAgMDETPnj3RqVMnnQVa33V26gxDtiHiM+IxlDdUo8eWz8FUHybpexvPnoeSshI8e/MMraxa6TsciqI0SK1RTF5eXvDy8sKUKVNQWFiIv//+G3/88QdNEOUYc4zR2amz1moQTuZOsDO10/ix66r8nEw0QVBU41LjTmpzc3OEhoZi1apV2oinQQtwDcD1F9dRJivT6HHrYwe1nJe9FwDQjmqqybv45CLyRHn6DkOj6CgmDeK78FEsKVZc9awJUpkUd7Pv1tsEYWtqC3tTezrUlWrSEl4mIHhvMOafm6/vUDSKJggNKn/BnKY8ev0IojJRveygluPZ85Dyio5kopquFZdXAAB+SfwFOcWNZ8VNtRKEQCBAQkICrl+/rvihKnO3doetia1GL5irzx3Ucjw7ZtI+ZbPzUlRjl/AyAX/e/xOjvEdBVCbCjwk/6jskjVHZSb1hwwacOnUK7u7uMDAwUNzv5+en1cAaIhaLpfEL5pKESWCBpWjrr494djy8Fr2GsEgIR3NHfYdDUTq14vIKWBtbY3vYdgiLhNh6fSvmBs6FoYGhvkOrM5UJ4vz58zh9+jS4XK4u4mnw+C58nHp4Cm9Eb9DMuFmdj5csTEZbm7YwNTTVQHTaUX5OJpogqKZEXntY1WsVmhk3wyz+LAz+bTCO3juKER1G6Du8OlPZxOTm5gaJhE7nrK4A1wAQEFx/oZlmuCRhUr1uXgLKjWSiHdVUEyOvPcz0nwkACGsXhjbWbfBd/Hd6jkwzVNYgTExMEB4ejsDAwAq1iMWLF2s1sIbK38UfABCfEY8+bfrU6VglkhKk5aZhVIdRmghNa1wsXGDBtaBDXakm5e3aAwAYsA0w038mZp+ZjRsvbqCbczc9R1k3KhOEfIpvSj1WxlbwtPNEXGbdO6pTslMgI7J6X4NgsVjwtPOkczJRTcrbtQe58Z3HY8nFJfgu/jv8MuQXPUWnGSoTxJAhQ3QRR6PCd+Hj5MOTIITUaJnWt8nnYKqv10CUx7Pn4fzj8/oOg6J0QlntQa6ZcTOM7zwe229sx//1+T80t2iupyjrrso+iFmzZgEABg0apPSnUdm5E0YPHmjscHwXPrKLs5Gel16n4yQLk2HMMUZbm7aaCUyLeHY8vCh4gTciOqEj1fhVVXuQm+k/E2WyMmy/sV3HkWlWlTWIRYsWAQC2b2/YBVTLDz/AJTcXCAsDOGovslcl+cyucRlxaG3dutbHSRImwcveCwZsA9Ub65m8o/req3uKCwYpqjGqrvYg1862HQa0G4DtN7djYY+FMOIY6ThKzaiyBuHg4AAAcHFxUfrTqCxcCKPHj4GfftLI4To6doQJx6TO10MkCZLq9RXU5Skm7aMd1VQjp6r2IDeLPwvCIiF+S/5NR5FpXpVfl319fSu0n8vb0+W3CQkJOglQJ8LDUdylC0yXLgU+/BAwN6/T4ThsDro6d61TgsgpzsHLwpcNov8BAFpbtwbXgEs7qqlGTZ3ag1yfNn3gZe+F7+K/w1ifsXXqj9SXKmsQgYGBaNu2LaZNm4YTJ07g1q1bSEhIUNw2KiwWBJ99BggEwFdfaeSQAS4BSHiZAHGZuFb7N6QOaoBJiu1t29MaBNWoqVt7AJjRfZH+kbiVdQt/PftLB9FpXpUJYtu2bdi1axdsbGywZMkSjBkzBvv27UNeXp4Ow9MdkY8P8MEHwIYNwMuXdT4e35WPUmkp7gju1Gr/ZGEygPo9B9Pb5HMyUVRjJK89zAmco/YsCRE+EbA2tm6wF85VeyW1hYUFhg0bhh9//BGjRo3Cpk2bcPToUV3Fpnvr1gESCbBsWZ0PxXf5d2bXjNo1MyUJkmBjYoPm5g1niBzPjocneU8gKhPpOxSK0ria1B7kTA1N8XGXj3H03lE8zXuqxei0o9oEkZCQgFWrVmHIkCFISEjA1q1bMX78eF3Fpnvu7sD06cCuXcDduq3p4GrpCmcL51pfMJckZDqoG1K7pZe9F2REhgc5mhsyTFH1QW1qD3Kf+H8CFljYen2rlqLTnioTRHBwMFasWAFHR0esWrUKw4YNg4mJCe7evYu7dfzwrNeWLAEsLIDPP6/TYVgsFvgu/FrVIAgh9XoVuaooJu2jzUxUI1Ob2oNci2YtMIQ3BD8m/Iii0iItRKc9VY5ikg9lvXLlCv76668Kc/2zWCzs3btX+9Hpg60tsHAhkyAuXgR69ar1oQJcA3D03lG8Kn5Vo/Wkn755ioLSggaXINrbtgebxaYjmahGpSYjl6oyiz8Lh1IO4ZfEXzC121QNR6g9VSaIX35p2HOI1ElkJLB1KzBvHnD9OsCu3cJ75fshwtqHqb1fQ1gkSBljjjFaW7WmI5moRqUutQe5d93eRZfmXbApfhOmdJ3SYJqO6ZKjyhgbA2vXAgkJwIEDtT5MV+euYLPYNb4eQj6CqaFcJFcez55HEwTVaNSl76E8FouFWfxZSH2VinOPz2kwQu3SaoKIjY1FaGgoQkJCsGPHjkqPE0KwevVqhISEYNCgQRX6NvLz8xEZGYl+/fqhf//+uHXrljZDrWz0aKBLF6a5SVS7UTnmXHN0dOhY4wSRJExCy2YtYWlkWavz6pOXnRce5DxAmaxM36FQVJ1povYgN7LDSDiaOTaoIa9VJoiysrr9g0ulUqxcuRI7d+5EdHQ0Tpw4gbS0tArbxMbGIj09HWfPnsWqVauwfPlyxWNr1qxBjx49cPr0aURFRcHd3b1O8dQYm81cNPfsGbBpU60PI++olhGZ2vvIRzA1RDx7HkqlpXjy+om+Q6GoOtFU7UHOiGOEad2m4eTDkw1mpF+VCWLEiBGYPn06Dhw4gIyMjBofODExES1btoSbmxu4XC7CwsIQExNTYZuYmBiEh4eDxWKhc+fOyM/Ph1AoRGFhIa5fv47hw4cDALhcLiwt9fBtulcvZgK/tWuBnJxaHYLvyscb8Ru13xCl0lLce3WvwXVQy9E5majGQpO1B7mp3aaCa8DF5vjNGjumNlXZSX3kyBFkZmYiNjYWa9euhUAgQNeuXdGzZ0/4+/urXKNaIBDAyclJ8bejoyMSExOr3cbJyQkCgQAcDgc2Njb44osvcO/ePXTo0AGLFi2CqWn16zKLxWKkptbug0kkEindlztlCtqcOoXXs2dD8MUXNT6uvdgeAHDk2hEMaa16bY0HeUzzjE2ZTa3Loq6qylwXrFKm8+3S3UtoJ2un0WNrgjbKXJ81tfICmilzyusU/Hn/T0R6R+LFkxd4gRcaig7o79ofP936CREuEbDgWmjkmNp6naud29rFxQWjR4/G6NGjIZFIcOPGDVy5cgXffvstbGxslPYryJUfFiv3ds99VduUlZUhJSUFS5YsgY+PD1avXo0dO3bg008/rbYwRkZG4PF41W5TldTUVOX78njAxImw+fln2CxbxlxMVwMexAOWlyzxXPZcrdhuJ90GAPTz7QeeY+3Koq4qy1xHzjHOyGHnaOXYdaWtMtdXTa28gGbKvOC3BbA2tsbKsJUaaV4qb6nVUkTtiMLfxX9jts9sjRyzLmWuLrGo3UltaGiIwMBAzJ8/H4cOHcKqVauq3d7JyQlZWVmKvwUCgWIK8aq2ycrKgoODA5ycnODk5AQfHx8AQL9+/ZCSosex9StWAFwuUIsaBJvFhp+zn9od1UnCJHDYHHjYedT4XPUFnZOJasg03ffwti7Nu6B7i+7YfG0zpDKpxo+vSbUexeTo6Fjt4x07dkR6ejqeP3+O0tJSREdHV1rbOjg4GMeOHQMhBLdv34aFhQUcHBxgb28PJycnPH78GABw9epV3XdSl9e8OXNNxB9/AHE1nzojwDUAiYJEFEuKVW6bJEyCh60HuAbVN+HVZ172Xrj36p7SGiJF1Xfa6Ht42yz+LDzJe4ITD05o7RyaoLVhrhwOB0uXLsWkSZMwYMAA9O/fH+3atcOBAwdw4N9rC4KCguDm5oaQkBAsWbIEy8pNkrdkyRLMmzcPgwYNQmpqKqZO1fPVh/PmAU5OzG0NP/j4LnxIiRQ3X9xUuW2SIKnBXSD3Np4dDwWlBcgsyNR3KBRVI9quPciFe4ajRbMW9X7Iq8r1NcViMYyMKi6Xl5ubCxsbG5UHDwoKQlBQUIX7Ro8erfidxWJVSArl8Xg8HDlyROU5dMbcnGlqmjIFOHYMGKK6w1lOvgRnfGY8erTsUeV2+eJ8PH3zFJO7Tq5rtHoln5MpJTsFrpaueo6GotSni9oDwKyf8onfJ/j8/OdIFCSik2MnrZ6vtlTWIIYPH47bt28r/j5z5kyFD/kmZcIEptP688+ZacHV5GDmgNZWrRGXUX3z1F0hc6Gg1oe4lpUBO3aAIxRq5fCKoa60H4JqQHRVe5Cb1GUSTDgm2BRf++ustE1lDeKrr77CwoUL4e/vD6FQiLy8POzZs0cXsdU/HA7wf/8HDBoE7NgBfPKJ2rvyXfkqV5VSrCKnzSYmQoAZM4AffoBrp07AjRuAoaFGT+Fg5gBrY2t6LQTVoOiq9iBnY2KDsT5jsefOHqzvs75GE3rqisoahIeHB6ZNm4bffvsN8fHxWLp0aYVrF5qcsDDgvfeY5qb8fLV3C3AJQEZ+BjLzq26XTxIkwZxrjhbNWmgg0CqsXQv88APQty9MEhOZ6c01jMVi0TmZqAZF17UHuUh+JERlIuy4WfUlA/qkMkEsXLgQe/bswZ9//ol169Zh6tSp2Ldvny5iq59YLGYKjuxs4Msv1d6tfD9EVeRTbLBZWho78PPPwOLFwJgxwKlTeP3BB0wZzml+8jAvOy/axEQ1GLquPch52XshpE0Itl3fBolU/WZrXVH5SdS+fXvs3bsXbm5u6NGjBw4ePNi4FwxSR9euwIcfAhs3AmpOQ9LZqTMM2YZVLiBECEGSMEl7/Q+nTgGTJgF9+jAr5rHZECxYAHToAEREAAKBRk/Hs+chuzgbr4pfafS4FKVp+qo9yM3iz0JmQSYOpx7W+blVUZkgxo0bV+EKaAsLC6xdu1arQTUIa9YAMpnaTTTGHGP4NvetsgaRVZiF3JJc7SSIGzeADz4AOnYEDh9mLvoDQExMgN9+A968AT76iCmPhtCOaqqh0FftQa5/u/5oZ9OuXg55VZkg0tPTERkZiQEDBqB3796KnyavVStmYaE9e4A7d9Tahe/Cx/UX15VOha21DupHj5h+E3t74ORJ4O1JD729gW++Ac6cAb7+WmOnVSw/SvshqHpM37UHgJltYab/TMRlxOFa5jW9xFAVlQniiy++wOjRo2FgYIC9e/ciPDwcgwcP1kVs9d/ChYCVFTB/vlqb8134KJYUK4azlidfRU6j03xnZwP9+jHDWk+fZq4IV2bKFGDYMKY81zTzBm3RrAVMDU1pDYKq1/Rde5Ab13kcLI0s610tQmWCEIvFCAwMBMBM3jdz5kzE1WK6iUbJ2pppYjp7lvlRIcA1AACUXg+RJEyCk7mT5oa6FRUxNYeMDODECcCjmrmdWCzgxx8BZ2dmoaQ3b+p8ejaLDU87T1qDoOqt+lB7kLMwssCEzhNw8O5BvCjQ3MyxdaUyQXC5XMhkMrRs2RK//vorzp07h5xaro3QKE2fDrRpA3z2GSCtfuKtNtZtYGdqp7QfQqMd1GVlwIgRwM2bTB/Dvwm+WtbWzPKqT58CU6fWeDoRZXh2dKgrVX/Vl9qD3Ez+TEhlUnx//Xt9h6Kg1jDXkpISLF68GHfv3kVUVBS+rMHwzkbPyAhYtw5ITAT27q12UxaLBX8X/0oJQiqTIiU7RTMJghDmA/7kSWDbNqAmzYHvvAOsXMkkld276xwKz46HZ2+eobC0sM7HoihNqk+1B7k21m0wyGMQfrj5A0RltVvmWNNUJohOnTrBzMwMTk5OWLduHbZs2YLOnTvrILQG5IMPAD6fucaguPoZWwNcApCanYo3ov+acR69fgRRmUgzHdQrVjDDWBcvZvoWaurzz4HgYGDmTKCOC5DIO6rvvbpXp+NQlKbVt9qD3Cz+LGQXZ+NA0gF9hwKgmqk2VM2eun37do0H02DJL57r0YMZEbRoUZWb8l35ICC4/uI6+rTpA0CDHdQ//sgkiHHjmJpAbRgYAL/8Avj4AKNGAfHxgLFxrQ5VfqhrN+dutYuHojRMXntY1WtVvak9yPVq1QveDt74Lv47jOs8rtIia7pWZYK4ffs2mjdvjrCwMPj4+NC5/VXp3h0ID2euTP74Y+CtxZHk/F38AQDxGfH/JQhhElhgwcveq/bnP3GCaVrq14+ZJ6oubyxnZ2b4blgYM735li21Okxbm7bgsDm0H4KqV+pr7QFgmqFn8Wfh4+MfI/ZpLIJaBaneSYuqbGL6+++/MXv2bDx8+BBr1qzB33//DWtra/j7+8Pf31+XMTYc69czTUwrVlS5iZWxFTztPBGX+d9IpiRhEtratIWpYfVrblcpPp7plPb1ZRY10sTkewMGAHPmAFu3MtOb14KhgSHa2bSjCYKqN+pj38Pb/tfxf7A1sa0XQ16rTBAGBgbo2bMnvvzySxw8eBAtW7ZEREQEfvnlF13G17B4eDDt/j/8ANy/X+VmfBc+4jPiFbWyZGFy7fsfHjwABg5krnGIjmbWrdCUdeuYaUUmTACeP6/VIXj2dPlRqv6oz7UHORNDE0zuOhlR96OQnpeu11iq7aQuLS3F2bNnMW/ePOzbtw8RERHo27evrmJrmJYtA0xNgQULqtwkwDUA2cXZSM9LR4mkBGm5abUbwSQQME1KAHMhnIplYGuMy2VGNEkkzNxTZZWvAFeFZ8dDWm4aSqWlmo2NomqoIdQe5Kb7TQcLLGy5VrvmXU2pMkF8/vnnGDVqFO7evYsZM2bg8OHD+OSTT1SuRd3kOTgwI4GOHQOuXFG6Cd+Fmdk1LiMOKdkpkBFZzTuoCwqYZiCBgKk5tGtXx8Cr0LYtsH078NdfwKpVNd6dZ8eDlEjxMOehFoKjKPU1hNqDnKulK4Z7DcfOhJ16HSZeZYKIiorCkydPsHfvXowaNQpdunRBly5d4Ovriy5duugyxoZn9mzAxYW5eE5J535Hx44w4ZggPjP+vzmYalKDkEiYobV37gAHDwLa7hP63/+YyfxWrwYuXarRrnROJqo+aEi1B7lZ/Fl4I36DvXeqv75Km6ocxXTvHh27Xmumpsy37QkTmE7jESMqPMxhc9DNuRviM+NhwDKAMccYbW3aqndsQphpu8+cAXbuZEYa6cKWLcDVq0yyuHMHsFNvShBPO0+wwKL9EJReNaTag1yAawD8nP2wKX4Tpnabqr11Yqqh+zM2FWPHMtNrf/EFIBZXepjvwkfCywTcfHkTXvZeMGAbqHfcxYuZK7ZXrAAmTtRw0NUwN2f6I169YhKfmsOeTQ1N0dKqJa1BUHrTEGsPwH9DXu/n3MfZR6rnetMGmiC0xcAA2LABePwY+L7y3Cp8Vz5KpaWIfRqrfvPStm3MkqEff6yVpUJV8vVlynT8OLB5s9q70TmZKH1qiLUHuQ86fIDm5s31NuSVJghtCg0FQkKY5qa8vAoPyWd2JSDqJYijR4EZM5ghrdu21e1CuLqYORMYNIjpX7l1S61deHY83Ht1D1JZ9ZMZUpSmNdTagxzXgItp3abhdNppvUxZQxOEtm3YALx+zXzzL8fV0hXOFs4A1Jhi4++/mWGm/v5MMw+nyq4j7WOxgJ9+YhYgGjkSKFQ9woJnz4OoTISnb57qIECK+k9Drj3ITek2BVwDLjbHq19r1xSaILTNx4fpj9i0iZlKuxz5cNdqL5JLTWW+sbu5MU07ZmbajFY9dnbAvn3ManUzZqjcnC4/SulDQ689yDmYOeDDjh9iz509yBPl6fTcNEHowurVzDfvtybxG+szFkN5Q9HcvIqV3l68YC6EMzRkLoSzt9dBsGoKCmI6zPfsAX79tdpN6VBXSh8aQ+1BbhZ/FookRdiVsEun56UJQhdcXZlrI/btYxbx+Ve4ZzgOjzisfMbG/HzmQricHGZthzZtdBiwmpYsYWawnTYNeFj1hXA2JjZwNHOkNQhKZxpL7UGus1Nn9GzZE1uub9FpXx5NELry+edM08y8eaqHiJaWAkOHAnfvAocOMfMh1UccDpP0DA2ZpUpLq55Og2dPRzJRutOYag9ys/izkJ6Xjj/v/6mzc2o1QcTGxiI0NBQhISHYsWNHpccJIVi9ejVCQkIwaNAg3L17t8LjUqkU4eHhmFKbhW/qm2bNgOXLmSuRo6Or3k4mA8aPB2JimAvh5HMt1VdubszqczdvMtd8VIFnx0NKdgqdNp7SupTXKY2q9iA32GMwWjZrqdMhr1pLEFKpFCtXrsTOnTsRHR2NEydOIC0trcI2sbGxSE9Px9mzZ7Fq1SosX768wuN79+6Fu7u7tkLUvcmTgfbtgfnzq574bsECYP9+ZtTTRx/pNr7aGjyY6azeuJFpDlOCZ8fDG/EbZBVm6Tg4qqnZendro6s9AIAB2wAz/Gfg8tPLuJ11Wyfn1FqCSExMRMuWLeHm5gYul4uwsDDExMRU2CYmJgbh4eFgsVjo3Lkz8vPzIRQKAQBZWVm4dOkShg8frq0Qdc/QkFkzIjWVGSr6tu++Y4bFTp9e7Wyw9dKGDcyIrY8+YjrX3yJfDIk2M1HaUiYrw8G7B3HxxUXd1x7u3WNWcYyKYloBtGSi70SYGppiU/wmrZ2jPK0NqBcIBHByclL87ejoiMTExGq3cXJygkAggIODA9auXYvPPvsMRUVFap9TLBYjtZbrKItEolrvWyMeHmjZpQu4CxcirUsXkH+HrVqcPg2XuXNR2Ls3MqZNY95wWqbpMnPXrEHrDz5AydCheLZzJ3M1+b84Jcxb7WLSRTQXVTFqSwd09jrXE02hvPfy7iEqPQrRz6LxSvQKzU2ao2+zvtovt0QCi5gYWP/+O8zi4xV3i9u0Qc7EiXgTFsZMma9h77d4H/sS92Fii4mwMbYBoL3XWWsJQllb89ujdara5uLFi7CxsYG3tzfiyz3xqhgZGYHH49U8WACpqam13rfGtm4FAgPheeIE0y9x+TJTYwgMhMXx4+CZmOgkDI2XmccDtmyB2cSJ4P35J7BwoeIhT+IJy7OWeM15rbvnWQmdvs56lpqdikNXD2FItyHo0ryLXiZ705YXBS+wL3Effkn8BUnCJBiyDRHWPgwRnSLgLnWHj7eP9k7+/Dmz/vuPPwJZWUDLlkyT8NixwOXLMFq/Hs6LFsH5+++ZVRk//lijC3kts1+G37b+hosFF7HYdzGAur2vq0ssWnvHODk5ISvrv/Zmec2gum2ysrLg4OCAhIQEXLhwAcHBwZgzZw7i4uIwb948bYWqewEBzHTdGzYA588zbfht2gB//gnoKDlozfjxzIimpUuBf/5R3M1isRQd1ZT2EEIQ8zgGA/YNgNc2L6y9tRZ+P/rBdaMrPv7zY/x5/08UlapfK69PikqL8Gvir+j7S1+4feOG+efnw9TQFFsHbMXLuS9xdORRDOUNBddA89/aIZMxMyiHhwOtWjHXNnXpwly8+ugRM0DDxYWZ8eDOHaYvzt2dSRAtWjD/D9nZGgnF084Toe6h2HZ9m/YX4iJaIpFISHBwMHn27BkRi8Vk0KBB5MGDBxW2uXjxIpk4cSKRyWTk1q1bZNiwYZWOExcXRyZPnqzWOVNSUmodb132rZW0NEIMDQkBCGnenJD0dN2en2ixzG/eENKmDSEtWhCSm6u4e9yxccTpKyftnFNNOn+ddURcJiZ7b+8lnbd3JlgO4rDBgay8tJKcjD9J9t7eSz44+AGxXGdJsBzEaJURGbBvANl2bRt5lvdM36FXq0xaRs49OkfGHh1LzNaYESwHafVtK7I4ZjG5/+q+0n00+hq/ekXIhg2EuLsz/6v29oQsWEDI48fq7X/1KiHh4cy+JiaEzJhByJMndQ7r5IOTBMtB9iXuI4Ro77NPawmCEEIuXbpE+vbtS3r37k22bdtGCCFk//79ZP/+/YQQQmQyGVm+fDnp3bs3GThwIElMTKx0jEabIAgh5PPPCbGyIuTWLd2fm2i5zPHxhHA4hAwbRohMRggh5Mu/viRYDvK65LX2zqtCY0sQr0tek/VX1hOXr10IloN4bfUiO2/uJCWSEkJIxfKKy8Tk/KPz5NNTnxL379wJloNgOYjP9z5kUcwiEvc8jkhlUn0VpYJkQTKZf3a+olyW6yzJpKhJ5HL6ZZUx1vk1lskI+ecfQiIiCDEyYj7cu3cnZP9+QkSi2h0zJYWQ8eOZL4UGBoT873+E3LlT6xClMilpv7k98f/R/9/DN8AEoWsNLkHIZIQUF+v+vP/Sepk3bGD+ub7/nhBCyPH7xwmWg/zz7B/tnrcajSVBPM59TCJPRiq+Vffe05ucfHCSyP5NxnJVlVcmk5HU7FTyf3/9H+m5uycxWGGgqHmMPzaeHE45TPJF+booikJWQRb55uo3xHe7L8FyEIMVBiRsXxj5Pfl3Ulyq/v9JrV/jggJCtm8nxMeHed9aWBAyfTohSr641trz54TMmUOImRlzjgEDCLl8WfElqia2xG8hWA5y9flVmiDUUdsn6eBBQubPzyJ//klIaiohYrGGA6untP5hKZUSEhpKiLExIUlJJC0njWA5yK6EXdo9bzUaeoK4+vwqGX5wOGGvYBPOSg6JOBJBbr28VeX26pY3pziH7EvcR0YdGkWarWtGsByEu4pL+v7Sl2yO30yevH6imQK8pbi0mBxIOkAG7BugSFJdf+hKvr36LREUCmp1zBq/xsnJhHzyCZMQACZBbN9OSL4WE2RODiGrVjFNVgAhgYGEHDvG/M+oqUBcQJqta0ZGHRpFE4Q6avsk9evHvEbyHzabaULv14+QmTMJ2byZkNOnCXn0iJCyMg0HrUc6+bDMyiLE0ZEQLy9SVpBPjFYZkXln5mn/vFVoiAmiTFpGDqccJu/seodgOYjVeivy+bnPScabDJX71qa8pWWl5OKTi2Tumbmk/eb2iqYo723eZMG5BeTvZ3+TMmnt/xGkMim5+OQimXBsArFYa0GwHMR1oytZcG4BuSu8W+vjyqlVZpGIaTLq0YP5p+dyCRkzhmlaqsW3+VorKiJkyxZCWrVi4uDxCNm9W+1vqXNOzyGclRxy8cbFWodQ3fPFIqTxzH1Ql6FeV68+AIvVHg8fAg8eMHPPyX8vv+QBl8sMOGrfHmjX7r/bdu2YQQz6WsenNnQ25PP8eaBvX2DSJPh0iYcF1wJf9/0a5lxzmHPNYWFkAXOuuXZGn7ylIQ1zLSotwu7bu/Ft3Ld49PoRWlu1xqcBn2KC7wSYc9UbNqmJ8j7IeYATD07gxIMTiH0aCymRwtbEFgPaDcCg9oPQ172vWhel3Xt1D7/c+QW/Jv2KZ2+ewZxrjuFewxHRKQLvtXpPY8Nwqy1zejqwYwczjU12NvPPPHUqM/pOzXXWtaKsjFm/fv16IDGRmeBTjSGyT14/QdvNbTHJcxJ+GPFDrU5d3fNFE4SKfQkBBIL/kkb55PHwYcXlpk1NgbZtKyYN+e/29vUveej0w/KLL4D167H1s/cww+yS0k0M2YaKZGHONYcF16JiEjGsmFCUblPufjOuGTjsipf6NIQE8bLgJTZf24ztN7bjteg1AlwDMDdwLoZ4DlF/7fJ/abq8eaI8nEk7g+MPjuPkw5N4LXoNDpuDoJZBGNh+IAa1HwR3m/+mx3lV/Aq/Jf+GvXf24vqL62Cz2AhpE4KxPmMx2GMwzLiaX9+kUpmlUma6/O+/Z4afsljMyozTpzMrPrLr0fUhhDCxfvklc32UtTUzjc3MmVVO9z/84HCkZqXibuRdpY+rQhOElvaVyYCMDOXJ4/HjitMtNWtWucbRvj3zRUEf708WC8jOTkWHDjr6sJRIgJ49QVJTcf3EDuQ4WqCgtACFpYUoLC1Egbjc76VV/P7vNiVlJWqf1phjrEgilkaWcDR0RECbAHjZe8HL3gvtbdvDiGOkxYKrL1GQiI1XN2J/0n5IiRRDPIdgbuBcBLoF1u6AYjHSrlxB23feYb69aFiZrAxXn1/FiQcncPzBccU0Kp52nhjQdgDSXqfh5MOTKJOVwcfRBxGdIvBhxw/R3EK7V9Ir/peFQmDXLqbGkJ4OODkBkyYx38pbtNBqDBoRF8ckimPHmOujJk4E5s5lrsMop1hSjKt3rqJ3t961Og1NEFreVxmJhFlA7u3mqocPmfvrw7NubCyDpycbPB4UP56eTPIy0sZn5pMnQOfOTHZq2ZL5RmRvDzg4KL+1twesrCpVvaQyqSJpVJVElCWa1yWvkfwyGc+LnkNGmPly2Cw22tq0ZRKGnZcicXjYecDUUPMfqm8jhODso7P4+urXOPf4HEwNTTGh8wR8GvBphW/i1SorA9LSgORkZor45GTm5+FD5tszwHwTdXNjvpHIb9/+vY6rFT7KfcQ0RT08gcvpl2Fnaof/dfwfInwi0MmxU52OrTaRCOl//IFWp04xU+VLJMB77zG1hfBwZj60hubePeai2l9+Yb6VjhrFTPjZ6b/nVFuffTRBaGDfmhKJmBrGgwfAy5c6OWUlZWXAzZs5EAptkZrKfMGSMzBgmmbLJw3575aWdTzx338DP//MtP8Khf/d5ucr397QkGkbVpY8lCUWS8tq2/JSU1PRul1rPMh5gJTslAo/D3MfokzGVPtYYKG1detKicPTzhMWRhZ1fBIAcZkY+5P2Y2PcRiQLk9HcvDlm+s/ElG5TYGNio3wnmYx5ocongeRk5gNEvhYHi8VcwevtDXh74yWXi+YcDlPVff78v9tXryofv3wSKZ88apFESiQl4Bpwa9wkpkAIUFzMxJmT899t+d+V3RYXM/s3a8ZMHDl1KvPGbQwyMoBvvwV++IHpGO3fn5mip0cPpN67RxOEKg0lQdQX5ctcXAzcv89MNHvvHnObmsokMYnkv32cnZUnDienOvaxiMXMP3j5pKHsVv57QYHy4xgaVlsreS4Swc3Xl0k68hrKv218pdJSpOWmVUoc93PuV5jSoEWzFpUSB8+eBytjK5XFzCnOwfYb27Hl+hZkFWaho0NHzA2ci9EdR//XSU8IkJlZMRHcvcv8yD8AAaaZxNsb6NBBkRDg6VmhOanK97VIxHzgyH/KJw9VSaSq5CH//e0kQgjzBUCdD/jy25Tv4HublRXzGtra/nf77++ZhoZwmT69fqzfrg2vXwPbtjGzP2dnAwEBSJ8+Ha0iImp1OJogtLxvQ6VOmcvKmNpO+aQh/yn/Gd2sWeWkweMBrVtXmNRVc0SiigmjumSSnV1xKFp5Bgb/fcjIk0b5Wzs7SG1tkMEV4R4rB3ekmUjMf4iU7BSkvkqFqEykOJSzhXOlxOFl7wVbU1uk5abhm6vfYPft3SgpK0GoeyjmBs5FHwsfsOSJoHxCePPmvxidnComgQ4dAC8v5klXoU7va5GISVRvJ4/yvyubX0ieRGSy/z70q1r/hM0GbGwqftBX8cGvuLW2ZlYz1EaZG5KSEmaxrg0bUGRnB7Pr12t1GJogtLxvQ1WXMhPCLPugLHGUm38RRkZMZ3z5xOHqynwus9nMj/z32t4qu69SbaakBMjOxpNr19DawoL54MrOrnhb/vecnKrn9Tc1BeztQezsUGJlhlwzNl6alOEppwgPWLlIkmUhw0iMbFPglSlgYGuL0tc58MnhYLyhHwaWtobt45dMIij/AWttXTEJyG/rMPxS6+/rt5NI+eTB4VT/QW9rW6EGV1MyGfOyFhUxFaviYub3+/fT0eqtjlxdMTJi+pNNTSveGhpqcRSjTMY0MXl51Wr36t4jWpvum2rcWCzmug8XF6D3W4Mn8vIqJ46EBODwYa2upVIpvoqJwwQGBi1gaOgMc3OO4h+3/D+xSXPA1P3f+4yksGHnwUb2CtZl2WhW9gqWomyYi1/BrOQVTAuzYVT4CkZZ2XB88wrOudnwK1Y+S6qMlQM2AYAyAFcB8yTmg3/QoP8Sgrd3hXY6Qpj+5bIyQFr076208q2y+8rfPnligpyc/xKpJn+Y59YYbCd3sJ3dwQ6s+LhYXPGDW3FbABQLKn+wl79VdV9xMZMclGul+TdUHRkYVE4aym5rtw0bpRLtDIWkCYLSOCsrZkbzgICK94tEzMCarCwmUUilym+re6wu+5SVAS9fFsDY2FrxAVNSwjSVCYXM7//db4DiYlsAtgA81Cq3MUpgixzYIxsu3FdobvgKzTnZcDTIhohthnuGHXHPoAOeoQXKnrNR9gSQRin/YNdcvb6Vpg6kdWw2021gavrfrfz35s0r3/f27/JbgeAZWrbU/TBWQpixAvL3kLJbZffl5zP/E2/fLxKpPqccn++GuDjNl4kmCEpnjI2Bjh2ZH31JTc0Cj2et1raEMN+CKyaO6n43QUmJK0pKXBX3Z5YAD4uZBMXhAK0NgLYGzO8G1dxW91hNtnn+/ClatGipSKKa/CmfnJX9cLmqP8zL/87laqYZJjW1qFEMXJLJmCRRXcKR35qZCQG01ngMNEFQVBVYLCapGRsz3QMNUWpqcaP4sGyK2Oz/kqgqqak1qG7UJAatHJWiKIpq8GiCoCiKopSiCYKiKIpSiiYIiqIoSimaICiKoiilaIKgKIqilKIJgqIoilKKJgiKoihKqUY1Wd/t27dhpJWVbiiKohonsViMzp07K32sUSUIiqIoSnNoExNFURSlFE0QFEVRlFI0QVAURVFK0QRBURRFKUUTBEVRFKUUTRAURVGUUk0+QcTGxiI0NBQhISHYsWOHvsPRupcvXyIiIgL9+/dHWFgY9uzZo++QdEYqlSI8PBxTpkzRdyg6kZ+fj8jISPTr1w/9+/fHrVu39B2S1v38888ICwvDwIEDMWfOHIjFYn2HpHFffPEFAgMDMXDgQMV9eXl5GD9+PPr27Yvx48fjzZs3GjlXk04QUqkUK1euxM6dOxEdHY0TJ04gLS1N32FplYGBARYsWIBTp07h999/x/79+xt9meX27t0Ld3d3fYehM2vWrEGPHj1w+vRpREVFNfqyCwQC7N27F4cPH8aJEycglUoRHR2t77A0bujQodi5c2eF+3bs2IHAwECcPXsWgYGBGvuy26QTRGJiIlq2bAk3NzdwuVyEhYUhJiZG32FplYODAzp06AAAMDc3R5s2bSAQCPQclfZlZWXh0qVLGD58uL5D0YnCwkJcv35dUV4ulwtLS0s9R6V9UqkUIpEIZWVlEIlEcHBw0HdIGufn54dmzZpVuC8mJgbh4eEAgPDwcJw/f14j52rSCUIgEMDJyUnxt6OjY5P4sJTLyMhAamoqfHx89B2K1q1duxafffYZ2Oym8ZZ//vw5bGxs8MUXXyA8PByLFi1CcXGxvsPSKkdHR0yYMAG9evVC9+7dYW5uju7du+s7LJ3IyclRJEMHBwfk5uZq5LhN47+lCspmGWGxWHqIRPeKiooQGRmJhQsXwtzcXN/haNXFixdhY2MDb29vfYeiM2VlZUhJScHo0aNx7NgxmJiYNPo+tjdv3iAmJgYxMTG4cuUKSkpKEBUVpe+wGrQmnSCcnJyQlZWl+FsgEDTKKunbJBIJIiMjMWjQIPTt21ff4WhdQkICLly4gODgYMyZMwdxcXGYN2+evsPSKicnJzg5OSlqh/369UNKSoqeo9Kuf/75B66urrCxsYGhoSH69u3bJDrmAcDW1hZCoRAAIBQKYWNjo5HjNukE0bFjR6Snp+P58+coLS1FdHQ0goOD9R2WVhFCsGjRIrRp0wbjx4/Xdzg6MXfuXMTGxuLChQvYuHEjAgIC8NVXX+k7LK2yt7eHk5MTHj9+DAC4evVqo++kdnZ2xp07d1BSUgJCSJMos1xwcDCOHTsGADh27Bh69+6tkeNyNHKUBorD4WDp0qWYNGkSpFIphg0bhnbt2uk7LK26efMmoqKi0L59ewwePBgAMGfOHAQFBek5MkrTlixZgnnz5kEikcDNzQ3r1q3Td0ha5ePjg9DQUAwZMgQcDgc8Hg8jR47Ud1gaN2fOHFy7dg2vX79Gz549MXPmTEyePBmffvopDh06hObNm+O7777TyLnodN8URVGUUk26iYmiKIqqGk0QFEVRlFI0QVAURVFK0QRBURRFKUUTBEVRFKVUkx7mSlGvXr3CunXrcPv2bTRr1gyGhoaYNGkSQkJCdB5LfHw8DA0N0aVLFwDAgQMHYGJiophjh6J0jSYIqskihOCTTz5BeHg4vv76awBAZmYmLly4oLVzlpWVgcNR/m937do1mJqaKhLE6NGjtRYHRamDXgdBNVlXr17F1q1b8euvv1Z6TCqV4quvvsK1a9dQWlqK//3vfxg1ahTi4+OxZcsWWFtb48GDB+jQoQO++uorsFgsJCcnY/369SguLoa1tTXWrVsHBwcHREREwNfXFwkJCQgODkarVq3w/fffQyKRwMrKCl999RVEIhFGjhwJNpsNGxsbLFmyBFevXoWpqSkmTpyI1NRULFu2DCUlJWjRogXWrl2LZs2aISIiAp06dUJ8fDwKCgqwZs0adOvWTQ/PJtUY0T4Iqsl6+PAhvLy8lD526NAhWFhY4PDhwzh8+DAOHjyI58+fAwBSUlKwcOFCnDx5EhkZGbh58yYkEglWr16NTZs24ciRIxg2bBi++eYbxfHy8/Px66+/YsKECejatSsOHjyIY8eOISwsDDt37oSrqytGjRqFcePGISoqqtKH/Pz58zFv3jwcP34c7du3x5YtWxSPSaVSHDp0CAsXLqxwP0XVFW1ioqh/rVixAjdv3oShoSFcXFxw//59nDlzBgBQUFCAp0+fwtDQEJ06dVJME+/p6YnMzExYWlriwYMHivmtZDIZ7O3tFcceMGCA4vesrCzMnj0b2dnZKC0thaura7VxFRQUoKCgAP7+/gCAIUOGYNasWYrH5f0lHTp0QGZmpgaeCYpi0ARBNVnt2rXD2bNnFX8vW7YMubm5GD58OJydnbF48WL06NGjwj7x8fHgcrmKvw0MDCCVSkEIQbt27fD7778rPZeJiYni99WrV2PcuHHo3bu3osmqLuTxsNlsSKXSOh2LosqjTUxUkxUQEACxWIz9+/cr7hOJRACA7t2748CBA5BIJACAJ0+eVLvgTuvWrZGbm6uYXloikeDhw4dKty0oKICjoyMAKGbgBAAzMzMUFRVV2t7CwgKWlpa4ceMGACAqKgp+fn41KClF1Q6tQVBNFovFwtatW7Fu3Trs3LkTNjY2MDExwbx589CvXz9kZmZi6NChIITA2toa27Ztq/JYXC4XmzZtwurVq1FQUACpVIqPPvpI6ezAM2bMwKxZs+Do6AgfHx9kZGQAAHr16oXIyEjExMRgyZIlFfb58ssvFZ3UTWFmVqp+oKOYKIqiKKVoExNFURSlFE0QFEVRlFI0QVAURVFK0QRBURRFKUUTBEVRFKUUTRAURVGUUjRBUBRFUUr9P4KMQ3eP0nSwAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total elapsed time: 55.43826323747635 minutes\n"
     ]
    }
   ],
   "source": [
    "population_size = 5   # max of individuals per generation\n",
    "max_generations = 10  # number of generations\n",
    "gene_length = 7      # lenght of the gene, depends on how many hiperparameters are tested  \n",
    "k = 1;                 # num. of finalist individuals\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    t = time.time(); \n",
    "    datos = [];\n",
    "    ss = [i for i in range(1,population_size*(max_generations+1))]\n",
    "    best_population = geneticAlgorithm_with_elitism(population_size, max_generations, gene_length, k)\n",
    "    print(\"Total elapsed time:\", (time.time()-t)/60, \"minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k= 1 \n",
      "Deep layers: 2 , Number of neurons: 50\n",
      "Batch size 4 , Learning rate: 0.0001\n"
     ]
    }
   ],
   "source": [
    "best_deep_layers   = []\n",
    "best_num_units     = []\n",
    "best_learning_rate = []\n",
    "best_batch_size    = []\n",
    "# best_activation_f  = []\n",
    "best_f_names       = []\n",
    "\n",
    "t = 0\n",
    "\n",
    "for bi in best_population:\n",
    "    deep_layers_bits   = BitArray(bi[0:1])    # (8)\n",
    "    num_units_bits     = BitArray(bi[1:2])    # (16)\n",
    "    learning_rate_bits = BitArray(bi[2:3])   # (8)\n",
    "    batch_size_bits    = BitArray(bi[3:4])  # (4)\n",
    "#     activation_f_bits  = BitArray(bi[12:13])  # (2)\n",
    "    t += 1 \n",
    "    \n",
    "    best_deep_layers.append(SC_DEEP[deep_layers_bits.uint])\n",
    "    best_num_units.append(SC_NUM_UNITS[num_units_bits.uint])\n",
    "    best_learning_rate.append(SC_LEARNING[learning_rate_bits.uint])\n",
    "    best_batch_size.append(SC_BATCH[batch_size_bits.uint])\n",
    "#     best_activation_f.append(SC_ACTIVATION[activation_f_bits.uint])\n",
    "#     best_f_names.append(f_names[activation_f_bits.uint])\n",
    "    print('k=',t,'\\nDeep layers:', best_deep_layers[-1], ', Number of neurons:', best_num_units[-1])\n",
    "    print('Batch size', best_batch_size[-1], ', Learning rate:', best_learning_rate[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Deep layers</th>\n",
       "      <th>Num units</th>\n",
       "      <th>Learning rate</th>\n",
       "      <th>Batch size</th>\n",
       "      <th>Loss</th>\n",
       "      <th>Score</th>\n",
       "      <th>Elapsed time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>4</td>\n",
       "      <td>0.030373</td>\n",
       "      <td>0.030373</td>\n",
       "      <td>81.425251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>4</td>\n",
       "      <td>0.030463</td>\n",
       "      <td>0.030463</td>\n",
       "      <td>76.683919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>2</td>\n",
       "      <td>0.030517</td>\n",
       "      <td>0.030517</td>\n",
       "      <td>204.611604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>4</td>\n",
       "      <td>0.030593</td>\n",
       "      <td>0.030593</td>\n",
       "      <td>90.564246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>4</td>\n",
       "      <td>0.030972</td>\n",
       "      <td>0.030972</td>\n",
       "      <td>143.399618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>4</td>\n",
       "      <td>0.031130</td>\n",
       "      <td>0.031130</td>\n",
       "      <td>143.451318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>4</td>\n",
       "      <td>0.031421</td>\n",
       "      <td>0.031421</td>\n",
       "      <td>143.700130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>4</td>\n",
       "      <td>0.031447</td>\n",
       "      <td>0.031447</td>\n",
       "      <td>86.416517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3</td>\n",
       "      <td>200</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>4</td>\n",
       "      <td>0.031531</td>\n",
       "      <td>0.031531</td>\n",
       "      <td>114.212433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>4</td>\n",
       "      <td>0.031816</td>\n",
       "      <td>0.031816</td>\n",
       "      <td>143.653230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>4</td>\n",
       "      <td>0.032045</td>\n",
       "      <td>0.032045</td>\n",
       "      <td>143.571992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>4</td>\n",
       "      <td>0.032762</td>\n",
       "      <td>0.032762</td>\n",
       "      <td>91.365917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>3</td>\n",
       "      <td>200</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>4</td>\n",
       "      <td>0.033109</td>\n",
       "      <td>0.033109</td>\n",
       "      <td>143.504017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>3</td>\n",
       "      <td>200</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>4</td>\n",
       "      <td>0.033619</td>\n",
       "      <td>0.033619</td>\n",
       "      <td>108.328455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>4</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>4</td>\n",
       "      <td>0.033753</td>\n",
       "      <td>0.033753</td>\n",
       "      <td>93.765006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>4</td>\n",
       "      <td>0.033921</td>\n",
       "      <td>0.033921</td>\n",
       "      <td>76.501149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>4</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>4</td>\n",
       "      <td>0.034145</td>\n",
       "      <td>0.034145</td>\n",
       "      <td>144.714325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>3</td>\n",
       "      <td>200</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>4</td>\n",
       "      <td>0.034459</td>\n",
       "      <td>0.034459</td>\n",
       "      <td>100.097289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>4</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>4</td>\n",
       "      <td>0.034761</td>\n",
       "      <td>0.034761</td>\n",
       "      <td>143.713571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>4</td>\n",
       "      <td>0.034898</td>\n",
       "      <td>0.034898</td>\n",
       "      <td>69.317759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>4</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0050</td>\n",
       "      <td>4</td>\n",
       "      <td>0.034937</td>\n",
       "      <td>0.034937</td>\n",
       "      <td>91.055538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>4</td>\n",
       "      <td>0.036158</td>\n",
       "      <td>0.036158</td>\n",
       "      <td>83.184252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>4</td>\n",
       "      <td>0.037343</td>\n",
       "      <td>0.037343</td>\n",
       "      <td>83.153764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>4</td>\n",
       "      <td>0.037508</td>\n",
       "      <td>0.037508</td>\n",
       "      <td>83.282529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>16</td>\n",
       "      <td>0.038835</td>\n",
       "      <td>0.038835</td>\n",
       "      <td>42.415374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>4</td>\n",
       "      <td>0.039137</td>\n",
       "      <td>0.039137</td>\n",
       "      <td>83.252213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>3</td>\n",
       "      <td>200</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>16</td>\n",
       "      <td>0.039927</td>\n",
       "      <td>0.039927</td>\n",
       "      <td>42.836819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1</td>\n",
       "      <td>200</td>\n",
       "      <td>0.0050</td>\n",
       "      <td>16</td>\n",
       "      <td>0.043227</td>\n",
       "      <td>0.043227</td>\n",
       "      <td>30.206788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>4</td>\n",
       "      <td>200</td>\n",
       "      <td>0.0050</td>\n",
       "      <td>16</td>\n",
       "      <td>0.046296</td>\n",
       "      <td>0.046296</td>\n",
       "      <td>42.680278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2</td>\n",
       "      <td>200</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>16</td>\n",
       "      <td>0.055394</td>\n",
       "      <td>0.055394</td>\n",
       "      <td>27.996490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>4</td>\n",
       "      <td>0.072828</td>\n",
       "      <td>0.072828</td>\n",
       "      <td>69.307465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>4</td>\n",
       "      <td>0.080565</td>\n",
       "      <td>0.080565</td>\n",
       "      <td>73.093697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0050</td>\n",
       "      <td>2</td>\n",
       "      <td>0.119290</td>\n",
       "      <td>0.119290</td>\n",
       "      <td>147.497185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>4</td>\n",
       "      <td>0.137197</td>\n",
       "      <td>0.137197</td>\n",
       "      <td>83.055091</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Deep layers  Num units  Learning rate  Batch size      Loss     Score  \\\n",
       "0             3        100         0.0001           4  0.030373  0.030373   \n",
       "1             3        100         0.0001           4  0.030463  0.030463   \n",
       "2             3        100         0.0001           2  0.030517  0.030517   \n",
       "3             3        100         0.0001           4  0.030593  0.030593   \n",
       "4             3        100         0.0001           4  0.030972  0.030972   \n",
       "5             3        100         0.0001           4  0.031130  0.031130   \n",
       "6             3        100         0.0001           4  0.031421  0.031421   \n",
       "7             3        100         0.0001           4  0.031447  0.031447   \n",
       "8             3        200         0.0001           4  0.031531  0.031531   \n",
       "9             3        100         0.0001           4  0.031816  0.031816   \n",
       "10            3        100         0.0001           4  0.032045  0.032045   \n",
       "11            3        100         0.0001           4  0.032762  0.032762   \n",
       "12            3        200         0.0001           4  0.033109  0.033109   \n",
       "13            3        200         0.0001           4  0.033619  0.033619   \n",
       "14            4        100         0.0001           4  0.033753  0.033753   \n",
       "15            3        100         0.0001           4  0.033921  0.033921   \n",
       "16            4        100         0.0001           4  0.034145  0.034145   \n",
       "17            3        200         0.0001           4  0.034459  0.034459   \n",
       "18            4        100         0.0001           4  0.034761  0.034761   \n",
       "19            3        100         0.0001           4  0.034898  0.034898   \n",
       "20            4        100         0.0050           4  0.034937  0.034937   \n",
       "21            2        100         0.0001           4  0.036158  0.036158   \n",
       "22            2        100         0.0001           4  0.037343  0.037343   \n",
       "23            2        100         0.0001           4  0.037508  0.037508   \n",
       "24            3        100         0.0001          16  0.038835  0.038835   \n",
       "25            2        100         0.0001           4  0.039137  0.039137   \n",
       "26            3        200         0.0001          16  0.039927  0.039927   \n",
       "27            1        200         0.0050          16  0.043227  0.043227   \n",
       "28            4        200         0.0050          16  0.046296  0.046296   \n",
       "29            2        200         0.0001          16  0.055394  0.055394   \n",
       "30            1        100         0.0001           4  0.072828  0.072828   \n",
       "31            1        100         0.0001           4  0.080565  0.080565   \n",
       "32            3        100         0.0050           2  0.119290  0.119290   \n",
       "33            1        100         0.0001           4  0.137197  0.137197   \n",
       "\n",
       "    Elapsed time  \n",
       "0      81.425251  \n",
       "1      76.683919  \n",
       "2     204.611604  \n",
       "3      90.564246  \n",
       "4     143.399618  \n",
       "5     143.451318  \n",
       "6     143.700130  \n",
       "7      86.416517  \n",
       "8     114.212433  \n",
       "9     143.653230  \n",
       "10    143.571992  \n",
       "11     91.365917  \n",
       "12    143.504017  \n",
       "13    108.328455  \n",
       "14     93.765006  \n",
       "15     76.501149  \n",
       "16    144.714325  \n",
       "17    100.097289  \n",
       "18    143.713571  \n",
       "19     69.317759  \n",
       "20     91.055538  \n",
       "21     83.184252  \n",
       "22     83.153764  \n",
       "23     83.282529  \n",
       "24     42.415374  \n",
       "25     83.252213  \n",
       "26     42.836819  \n",
       "27     30.206788  \n",
       "28     42.680278  \n",
       "29     27.996490  \n",
       "30     69.307465  \n",
       "31     73.093697  \n",
       "32    147.497185  \n",
       "33     83.055091  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename = \"historial_genetic_jla1.txt\"\n",
    "df = pd.DataFrame(datos, columns = [\"Deep layers\", \"Num units\", \"Learning rate\", \"Batch size\", \"Loss\", \"Score\", \"Elapsed time\"])\n",
    "\n",
    "df.sort_values(by=[\"Loss\", \"Elapsed time\"], ascending=[True, True], ignore_index=True, inplace=True)\n",
    "\n",
    "df.to_csv(filename, header=True, index=False, sep='\\t', mode='w') # a=append, w=overwrite\n",
    "df.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time 55.434 minutes\n"
     ]
    }
   ],
   "source": [
    "total_time = float(np.sum(df[[\"Elapsed time\"]])/60)\n",
    "\n",
    "print(\"Elapsed time {:.3f} minutes\".format(total_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
