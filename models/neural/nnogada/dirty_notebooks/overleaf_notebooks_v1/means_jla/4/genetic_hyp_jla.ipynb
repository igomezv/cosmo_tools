{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-16 16:44:01.895148: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-12-16 16:44:02.067127: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-12-16 16:44:02.067159: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2022-12-16 16:44:03.201023: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2022-12-16 16:44:03.201157: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2022-12-16 16:44:03.201170: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import time, os\n",
    "import random\n",
    "import seaborn as sns\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Input, Dense, LeakyReLU\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorboard.plugins.hparams import api as hp\n",
    "\n",
    "from tensorflow.keras import activations\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "import random\n",
    "from math import floor\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import optimizers\n",
    "from scipy.integrate import odeint\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split as split\n",
    "from scipy.stats import bernoulli\n",
    "\n",
    "# import deap\n",
    "from deap import base, creator, tools, algorithms\n",
    "\n",
    "from bitstring import BitArray\n",
    "\n",
    "# from elitism import eaSimpleWithElitism, main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "\n",
    "# tf.config.optimizer.set_jit(True)\n",
    "# scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "url = 'https://raw.githubusercontent.com/igomezv/nnogada/main/data/jla.csv'\n",
    "df=pd.read_csv(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = len(df.values)\n",
    "randomize = np.random.permutation(N)\n",
    "data = df.values[randomize]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(740, 2)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N = len(df.values)\n",
    "z = data[:,0] \n",
    "y = data[:,1:3] ### coge el resto de variables a predecir \n",
    "y[:,1] = y[:,1]**2+data[:,2]\n",
    "np.shape(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "scalerz = StandardScaler()\n",
    "scalerz.fit(z.reshape(-1,1))\n",
    "z = scalerz.transform(z.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((592, 1), (148, 1), (592, 2), (148, 2))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Modificar para incluir phanteon como test\n",
    "split = 0.8\n",
    "ntrain = int(split * len(z))\n",
    "indx = [ntrain]\n",
    "X_train, X_val = np.split(z, indx)\n",
    "Y_train, Y_val = np.split(y, indx)\n",
    "# X_train, X_test = np.split(z, indx)\n",
    "# Y_train, Y_test = np.split(y, indx)\n",
    "np.shape(X_train), np.shape(X_val), Y_train.shape, Y_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "SC_DEEP       = np.array([1,2,3,4])                           # Number of deep layers (8)\n",
    "SC_NUM_UNITS  = np.array([50,100,150,200]) # Number of fully conected neurons (16)\n",
    "SC_LEARNING   = np.array([1e-4,5e-3])   # Learning rates (8)\n",
    "SC_BATCH      = np.array([2, 4, 8, 16])                            # Batch sizes (4)\n",
    "# SC_ACTIVATION = [f1, f2, f3, f4]                                      # Activation function layers (2)\n",
    "\n",
    "my_callbacks = [tf.keras.callbacks.EarlyStopping(\n",
    "                               monitor='val_loss', mode='min',\n",
    "                               min_delta=0, \n",
    "                               patience=200,\n",
    "                               verbose=1,\n",
    "                            #    baseline=0,\n",
    "                               restore_best_weights=True)\n",
    "#                 keras.callbacks.TensorBoard(\n",
    "#                                log_dir='./logs'),\n",
    "#                 keras.callbacks.ReduceLROnPlateau(\n",
    "#                                monitor='val_loss', factor=0.5,\n",
    "#                                patience=6, min_lr=0,\n",
    "#                                verbose=1)\n",
    "               ] \n",
    "    \n",
    "epochs = 200\n",
    "# epochs = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_evaluate(ga_individual_solution):   \n",
    "    t = time.time()\n",
    "    t_total = 0\n",
    "    \n",
    "    # Decode GA solution to integer for window_size and num_units\n",
    "    deep_layers_bits   = BitArray(ga_individual_solution[0:2])     # (8)\n",
    "    num_units_bits     = BitArray(ga_individual_solution[2:4])     # (16)\n",
    "    learning_rate_bits = BitArray(ga_individual_solution[4:5])    # (8)\n",
    "    batch_size_bits    = BitArray(ga_individual_solution[5:7])   # (4)\n",
    "# #     activation_f_bits  = BitArray(ga_individual_solution[12:13])   # (2)   Solo se consideran las 2 primeras\n",
    "    \n",
    "    deep_layers   = SC_DEEP[deep_layers_bits.uint]\n",
    "    num_units     = SC_NUM_UNITS[num_units_bits.uint]\n",
    "    learning_rate = SC_LEARNING[learning_rate_bits.uint]\n",
    "    batch_size   = SC_BATCH[batch_size_bits.uint]\n",
    "#     activation_f  = SC_ACTIVATION[activation_f_bits.uint]\n",
    "\n",
    "    \n",
    "    print('\\n--------------- Starting trial:', population_size*(max_generations+1)-len(ss), \"---------------\")\n",
    "    print('Deep layers:',deep_layers,', Number of neurons:',num_units,\", Learning rate:\",learning_rate)\n",
    "#     print(\"-------------------------------------------------\")\n",
    "    \n",
    "    # Train model and predict on validation set\n",
    "    model = tf.keras.Sequential()\n",
    "#     model.add(Input(shape=(int(X_train.shape[1]),)))\n",
    "    model.add(Dense(int(X_train.shape[1])))\n",
    "    \n",
    "    for i in range(deep_layers):        \n",
    "        model.add(Dense(num_units, activation='relu'))\n",
    "#             model.add(keras.layers.Dropout(0.3))\n",
    "    model.add(Dense(2, activation='linear'))\n",
    "    \n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate, beta_1=0.9, beta_2=0.999, epsilon=1e-3)\n",
    "    model.compile(optimizer=optimizer, loss='mse', metrics=['mean_squared_error'])\n",
    "    model.fit(X_train, Y_train, epochs=epochs, validation_data=(X_val, Y_val),\n",
    "              callbacks=my_callbacks, batch_size=batch_size, shuffle=False, verbose=0)\n",
    "    \n",
    "    loss, score = model.evaluate(X_val, Y_val)    \n",
    "    t = time.time()-t\n",
    "    ss.pop(0)\n",
    "    print(\"Loss:\", score, \", Elapsed time:\", t)\n",
    "    print(\"-------------------------------------------------\\n\")\n",
    "#     print(loss, score)\n",
    "\n",
    "    datos.append([deep_layers, num_units, learning_rate, batch_size, loss, score, t])\n",
    "    \n",
    "    return loss,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deap import tools\n",
    "from deap import algorithms\n",
    "\n",
    "def eaSimpleWithElitism(population, toolbox, cxpb, mutpb, ngen, stats=None,\n",
    "             halloffame=None, verbose=__debug__):\n",
    "    \"\"\"This algorithm is similar to DEAP eaSimple() algorithm, with the modification that\n",
    "    halloffame is used to implement an elitism mechanism. The individuals contained in the\n",
    "    halloffame are directly injected into the next generation and are not subject to the\n",
    "    genetic operators of selection, crossover and mutation.\n",
    "    \"\"\"\n",
    "    logbook = tools.Logbook()\n",
    "    logbook.header = ['gen', 'nevals'] + (stats.fields if stats else [])\n",
    "\n",
    "    # Evaluate the individuals with an invalid fitness\n",
    "    invalid_ind = [ind for ind in population if not ind.fitness.valid]\n",
    "    fitnesses = toolbox.map(toolbox.evaluate, invalid_ind)\n",
    "    for ind, fit in zip(invalid_ind, fitnesses):\n",
    "        ind.fitness.values = fit\n",
    "\n",
    "    if halloffame is None:\n",
    "        raise ValueError(\"halloffame parameter must not be empty!\")\n",
    "\n",
    "    halloffame.update(population)\n",
    "    hof_size = len(halloffame.items) if halloffame.items else 0\n",
    "\n",
    "    record = stats.compile(population) if stats else {}\n",
    "    logbook.record(gen=0, nevals=len(invalid_ind), **record)\n",
    "    if verbose:\n",
    "        print(logbook.stream)\n",
    "\n",
    "    # Begin the generational process\n",
    "    for gen in range(1, ngen + 1):\n",
    "\n",
    "        # Select the next generation individuals\n",
    "        offspring = toolbox.select(population, len(population) - hof_size)\n",
    "\n",
    "        # Vary the pool of individuals\n",
    "        offspring = algorithms.varAnd(offspring, toolbox, cxpb, mutpb)\n",
    "\n",
    "        # Evaluate the individuals with an invalid fitness\n",
    "        invalid_ind = [ind for ind in offspring if not ind.fitness.valid]\n",
    "        fitnesses = toolbox.map(toolbox.evaluate, invalid_ind)\n",
    "        for ind, fit in zip(invalid_ind, fitnesses):\n",
    "            ind.fitness.values = fit\n",
    "\n",
    "        # add the best back to population:\n",
    "        offspring.extend(halloffame.items)\n",
    "\n",
    "        # Update the hall of fame with the generated individuals\n",
    "        halloffame.update(offspring)\n",
    "\n",
    "        # Replace the current population by the offspring\n",
    "        population[:] = offspring\n",
    "\n",
    "        # Append the current generation statistics to the logbook\n",
    "        record = stats.compile(population) if stats else {}\n",
    "        logbook.record(gen=gen, nevals=len(invalid_ind), **record)\n",
    "        if verbose:\n",
    "            print(logbook.stream)\n",
    "\n",
    "    return population, logbook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def geneticAlgorithm_with_elitism(population_size, max_generations, gene_length, k):\n",
    "    \n",
    "    # Genetic Algorithm constants:\n",
    "    P_CROSSOVER = 0.5        # probability for crossover\n",
    "    P_MUTATION = 0.5         # probability for mutating an individual\n",
    "    HALL_OF_FAME_SIZE = 1    # Best individuals that pass to the other generation\n",
    "    \n",
    "    # set the random seed:\n",
    "    toolbox = base.Toolbox()\n",
    "\n",
    "    # As we are trying to minimize the RMSE score, that's why using -1.0. \n",
    "    # In case, when you want to maximize accuracy for instance, use 1.0\n",
    "    creator.create('FitnessMin', base.Fitness, weights = [-1.0])\n",
    "    creator.create('Individual', list , fitness = creator.FitnessMin)\n",
    "\n",
    "    # create the individual operator to fill up an Individual instance:\n",
    "    toolbox.register('binary', bernoulli.rvs, 0.5)\n",
    "    toolbox.register('individual', tools.initRepeat, creator.Individual, toolbox.binary, n = gene_length)\n",
    "\n",
    "    # create the population operator to generate a list of individuals:\n",
    "    toolbox.register('population', tools.initRepeat, list , toolbox.individual)\n",
    "\n",
    "    # genetic operators:\n",
    "    toolbox.register('evaluate', train_evaluate)\n",
    "    toolbox.register('select', tools.selTournament, tournsize = 2)\n",
    "    toolbox.register('mutate', tools.mutFlipBit, indpb = 0.11)\n",
    "    toolbox.register('mate', tools.cxUniform, indpb = 0.5)\n",
    "    \n",
    "    # create initial population (generation 0):\n",
    "    population = toolbox.population(n=population_size)\n",
    "\n",
    "    # prepare the statistics object:\n",
    "    stats = tools.Statistics(lambda ind: ind.fitness.values)\n",
    "    stats.register(\"min\", np.min)\n",
    "    stats.register(\"avg\", np.mean)\n",
    "    stats.register(\"max\", np.max)\n",
    "\n",
    "    # define the hall-of-fame object:\n",
    "    hof = tools.HallOfFame(HALL_OF_FAME_SIZE)\n",
    "\n",
    "    # Genetic Algorithm flow with elitism:\n",
    "    population, logbook = eaSimpleWithElitism(population, toolbox, cxpb=P_CROSSOVER, mutpb=P_MUTATION,\n",
    "                                              ngen=max_generations, stats=stats, halloffame=hof, verbose=True)\n",
    "\n",
    "    # print info for best solution found:\n",
    "    best = hof.items[0]\n",
    "    print(\"-- Best Individual = \", best)\n",
    "    print(\"-- Best Fitness = \", best.fitness.values[0])\n",
    "\n",
    "    # extract statistics:\n",
    "    minFitnessValues, meanFitnessValues, maxFitnessValues = logbook.select(\"min\", \"max\", \"avg\")\n",
    "\n",
    "    # plot statistics:\n",
    "    sns.set_style(\"whitegrid\")\n",
    "    plt.plot(minFitnessValues, color='blue', label=\"Min\")\n",
    "    plt.plot(meanFitnessValues, color='green', label=\"Mean\")\n",
    "    plt.plot(maxFitnessValues, color='red', label=\"Max\")\n",
    "    plt.xlabel('Generation'); plt.ylabel('Max / Min / Average Fitness')\n",
    "    plt.legend()\n",
    "    plt.title('Max, Min and Average fitness over Generations')\n",
    "    plt.show()\n",
    "    \n",
    "    best_population = tools.selBest(population,k = k)\n",
    "    return best_population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------------- Starting trial: 1 ---------------\n",
      "Deep layers: 3 , Number of neurons: 100 , Learning rate: 0.005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-16 16:44:04.457598: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-16 16:44:04.458430: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-12-16 16:44:04.458563: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory\n",
      "2022-12-16 16:44:04.458645: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory\n",
      "2022-12-16 16:44:04.458722: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcufft.so.10'; dlerror: libcufft.so.10: cannot open shared object file: No such file or directory\n",
      "2022-12-16 16:44:04.458802: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcurand.so.10'; dlerror: libcurand.so.10: cannot open shared object file: No such file or directory\n",
      "2022-12-16 16:44:04.458873: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory\n",
      "2022-12-16 16:44:04.458944: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory\n",
      "2022-12-16 16:44:04.459018: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2022-12-16 16:44:04.459035: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1934] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2022-12-16 16:44:04.459313: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1587 - mean_squared_error: 0.1587\n",
      "Loss: 0.15871165692806244 , Elapsed time: 112.51046299934387\n",
      "-------------------------------------------------\n",
      "\n",
      "\n",
      "--------------- Starting trial: 2 ---------------\n",
      "Deep layers: 2 , Number of neurons: 200 , Learning rate: 0.0001\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0483 - mean_squared_error: 0.0483\n",
      "Loss: 0.04832365736365318 , Elapsed time: 41.98940968513489\n",
      "-------------------------------------------------\n",
      "\n",
      "\n",
      "--------------- Starting trial: 3 ---------------\n",
      "Deep layers: 4 , Number of neurons: 200 , Learning rate: 0.005\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0572 - mean_squared_error: 0.0572\n",
      "Loss: 0.05717616528272629 , Elapsed time: 26.14364242553711\n",
      "-------------------------------------------------\n",
      "\n",
      "\n",
      "--------------- Starting trial: 4 ---------------\n",
      "Deep layers: 1 , Number of neurons: 100 , Learning rate: 0.0001\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0714 - mean_squared_error: 0.0714\n",
      "Loss: 0.0714382454752922 , Elapsed time: 46.92672085762024\n",
      "-------------------------------------------------\n",
      "\n",
      "\n",
      "--------------- Starting trial: 5 ---------------\n",
      "Deep layers: 2 , Number of neurons: 100 , Learning rate: 0.0001\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0387 - mean_squared_error: 0.0387\n",
      "Loss: 0.03872941806912422 , Elapsed time: 51.87900638580322\n",
      "-------------------------------------------------\n",
      "\n",
      "gen\tnevals\tmin      \tavg      \tmax     \n",
      "0  \t5     \t0.0387294\t0.0748758\t0.158712\n",
      "\n",
      "--------------- Starting trial: 6 ---------------\n",
      "Deep layers: 2 , Number of neurons: 200 , Learning rate: 0.0001\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0492 - mean_squared_error: 0.0492\n",
      "Loss: 0.0491643063724041 , Elapsed time: 22.44952368736267\n",
      "-------------------------------------------------\n",
      "\n",
      "\n",
      "--------------- Starting trial: 7 ---------------\n",
      "Deep layers: 3 , Number of neurons: 100 , Learning rate: 0.0001\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0310 - mean_squared_error: 0.0310\n",
      "Loss: 0.03098871186375618 , Elapsed time: 62.66527485847473\n",
      "-------------------------------------------------\n",
      "\n",
      "\n",
      "--------------- Starting trial: 8 ---------------\n",
      "Deep layers: 2 , Number of neurons: 100 , Learning rate: 0.0001\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0361 - mean_squared_error: 0.0361\n",
      "Loss: 0.036063969135284424 , Elapsed time: 59.77940130233765\n",
      "-------------------------------------------------\n",
      "\n",
      "1  \t3     \t0.0309887\t0.0387352\t0.0491643\n",
      "\n",
      "--------------- Starting trial: 9 ---------------\n",
      "Deep layers: 2 , Number of neurons: 100 , Learning rate: 0.0001\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0775 - mean_squared_error: 0.0775\n",
      "Loss: 0.0774533823132515 , Elapsed time: 20.859578371047974\n",
      "-------------------------------------------------\n",
      "\n",
      "\n",
      "--------------- Starting trial: 10 ---------------\n",
      "Deep layers: 2 , Number of neurons: 100 , Learning rate: 0.0001\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0312 - mean_squared_error: 0.0312\n",
      "Loss: 0.031189093366265297 , Elapsed time: 100.1621310710907\n",
      "-------------------------------------------------\n",
      "\n",
      "2  \t2     \t0.0309887\t0.0413368\t0.0774534\n",
      "\n",
      "--------------- Starting trial: 11 ---------------\n",
      "Deep layers: 1 , Number of neurons: 100 , Learning rate: 0.005\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0487 - mean_squared_error: 0.0487\n",
      "Loss: 0.04870586842298508 , Elapsed time: 50.722256660461426\n",
      "-------------------------------------------------\n",
      "\n",
      "\n",
      "--------------- Starting trial: 12 ---------------\n",
      "Deep layers: 3 , Number of neurons: 100 , Learning rate: 0.0001\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0314 - mean_squared_error: 0.0314\n",
      "Loss: 0.03143072500824928 , Elapsed time: 143.40061807632446\n",
      "-------------------------------------------------\n",
      "\n",
      "\n",
      "--------------- Starting trial: 13 ---------------\n",
      "Deep layers: 1 , Number of neurons: 100 , Learning rate: 0.0001\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1126 - mean_squared_error: 0.1126\n",
      "Loss: 0.11258042603731155 , Elapsed time: 52.682414054870605\n",
      "-------------------------------------------------\n",
      "\n",
      "3  \t3     \t0.0309887\t0.0509389\t0.11258  \n",
      "\n",
      "--------------- Starting trial: 14 ---------------\n",
      "Deep layers: 3 , Number of neurons: 100 , Learning rate: 0.0001\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0313 - mean_squared_error: 0.0313\n",
      "Loss: 0.03131646662950516 , Elapsed time: 56.580554723739624\n",
      "-------------------------------------------------\n",
      "\n",
      "\n",
      "--------------- Starting trial: 15 ---------------\n",
      "Deep layers: 3 , Number of neurons: 100 , Learning rate: 0.0001\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0326 - mean_squared_error: 0.0326\n",
      "Loss: 0.032614052295684814 , Elapsed time: 50.605493783950806\n",
      "-------------------------------------------------\n",
      "\n",
      "\n",
      "--------------- Starting trial: 16 ---------------\n",
      "Deep layers: 3 , Number of neurons: 200 , Learning rate: 0.0001\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0345 - mean_squared_error: 0.0345\n",
      "Loss: 0.03451565280556679 , Elapsed time: 139.03488683700562\n",
      "-------------------------------------------------\n",
      "\n",
      "4  \t3     \t0.0309887\t0.0321731\t0.0345157\n",
      "\n",
      "--------------- Starting trial: 17 ---------------\n",
      "Deep layers: 3 , Number of neurons: 100 , Learning rate: 0.0001\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0317 - mean_squared_error: 0.0317\n",
      "Loss: 0.03169496729969978 , Elapsed time: 63.521127223968506\n",
      "-------------------------------------------------\n",
      "\n",
      "\n",
      "--------------- Starting trial: 18 ---------------\n",
      "Deep layers: 3 , Number of neurons: 100 , Learning rate: 0.0001\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0324 - mean_squared_error: 0.0324\n",
      "Loss: 0.032351262867450714 , Elapsed time: 144.07088565826416\n",
      "-------------------------------------------------\n",
      "\n",
      "5  \t2     \t0.0309887\t0.0318159\t0.0326141\n",
      "\n",
      "--------------- Starting trial: 19 ---------------\n",
      "Deep layers: 3 , Number of neurons: 50 , Learning rate: 0.0001\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0342 - mean_squared_error: 0.0342\n",
      "Loss: 0.034215617924928665 , Elapsed time: 83.67383050918579\n",
      "-------------------------------------------------\n",
      "\n",
      "\n",
      "--------------- Starting trial: 20 ---------------\n",
      "Deep layers: 1 , Number of neurons: 100 , Learning rate: 0.0001\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1257 - mean_squared_error: 0.1257\n",
      "Loss: 0.12567107379436493 , Elapsed time: 53.42173361778259\n",
      "-------------------------------------------------\n",
      "\n",
      "6  \t2     \t0.0309887\t0.0509315\t0.125671 \n",
      "\n",
      "--------------- Starting trial: 21 ---------------\n",
      "Deep layers: 3 , Number of neurons: 100 , Learning rate: 0.0001\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0314 - mean_squared_error: 0.0314\n",
      "Loss: 0.0313691720366478 , Elapsed time: 55.3254451751709\n",
      "-------------------------------------------------\n",
      "\n",
      "\n",
      "--------------- Starting trial: 22 ---------------\n",
      "Deep layers: 3 , Number of neurons: 100 , Learning rate: 0.0001\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0330 - mean_squared_error: 0.0330\n",
      "Loss: 0.03304321691393852 , Elapsed time: 64.61754393577576\n",
      "-------------------------------------------------\n",
      "\n",
      "7  \t2     \t0.0309887\t0.0321211\t0.0342156\n",
      "\n",
      "--------------- Starting trial: 23 ---------------\n",
      "Deep layers: 3 , Number of neurons: 100 , Learning rate: 0.0001\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0301 - mean_squared_error: 0.0301\n",
      "Loss: 0.0300836693495512 , Elapsed time: 83.33621168136597\n",
      "-------------------------------------------------\n",
      "\n",
      "8  \t1     \t0.0300837\t0.0308077\t0.0309887\n",
      "\n",
      "--------------- Starting trial: 24 ---------------\n",
      "Deep layers: 1 , Number of neurons: 100 , Learning rate: 0.0001\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0786 - mean_squared_error: 0.0786\n",
      "Loss: 0.07862576097249985 , Elapsed time: 48.49121809005737\n",
      "-------------------------------------------------\n",
      "\n",
      "\n",
      "--------------- Starting trial: 25 ---------------\n",
      "Deep layers: 3 , Number of neurons: 100 , Learning rate: 0.0001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0318 - mean_squared_error: 0.0318\n",
      "Loss: 0.0317952036857605 , Elapsed time: 62.11705231666565\n",
      "-------------------------------------------------\n",
      "\n",
      "9  \t2     \t0.0300837\t0.0404964\t0.0786258\n",
      "\n",
      "--------------- Starting trial: 26 ---------------\n",
      "Deep layers: 3 , Number of neurons: 100 , Learning rate: 0.0001\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0409 - mean_squared_error: 0.0409\n",
      "Loss: 0.04094398766756058 , Elapsed time: 23.17906403541565\n",
      "-------------------------------------------------\n",
      "\n",
      "\n",
      "--------------- Starting trial: 27 ---------------\n",
      "Deep layers: 3 , Number of neurons: 100 , Learning rate: 0.0001\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0316 - mean_squared_error: 0.0316\n",
      "Loss: 0.03161363676190376 , Elapsed time: 65.17209434509277\n",
      "-------------------------------------------------\n",
      "\n",
      "\n",
      "--------------- Starting trial: 28 ---------------\n",
      "Deep layers: 1 , Number of neurons: 100 , Learning rate: 0.005\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0481 - mean_squared_error: 0.0481\n",
      "Loss: 0.04811215028166771 , Elapsed time: 54.57931590080261\n",
      "-------------------------------------------------\n",
      "\n",
      "10 \t3     \t0.0300837\t0.0363484\t0.0481122\n",
      "-- Best Individual =  [1, 0, 0, 1, 0, 0, 1]\n",
      "-- Best Fitness =  0.03098871186375618\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total elapsed time: 30.669883064428966 minutes\n"
     ]
    }
   ],
   "source": [
    "population_size = 5   # max of individuals per generation\n",
    "max_generations = 10  # number of generations\n",
    "gene_length = 7      # lenght of the gene, depends on how many hiperparameters are tested  \n",
    "k = 1;                 # num. of finalist individuals\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    t = time.time(); \n",
    "    datos = [];\n",
    "    ss = [i for i in range(1,population_size*(max_generations+1))]\n",
    "    best_population = geneticAlgorithm_with_elitism(population_size, max_generations, gene_length, k)\n",
    "    print(\"Total elapsed time:\", (time.time()-t)/60, \"minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k= 1 \n",
      "Deep layers: 2 , Number of neurons: 50\n",
      "Batch size 4 , Learning rate: 0.0001\n"
     ]
    }
   ],
   "source": [
    "best_deep_layers   = []\n",
    "best_num_units     = []\n",
    "best_learning_rate = []\n",
    "best_batch_size    = []\n",
    "# best_activation_f  = []\n",
    "best_f_names       = []\n",
    "\n",
    "t = 0\n",
    "\n",
    "for bi in best_population:\n",
    "    deep_layers_bits   = BitArray(bi[0:1])    # (8)\n",
    "    num_units_bits     = BitArray(bi[1:2])    # (16)\n",
    "    learning_rate_bits = BitArray(bi[2:3])   # (8)\n",
    "    batch_size_bits    = BitArray(bi[3:4])  # (4)\n",
    "#     activation_f_bits  = BitArray(bi[12:13])  # (2)\n",
    "    t += 1 \n",
    "    \n",
    "    best_deep_layers.append(SC_DEEP[deep_layers_bits.uint])\n",
    "    best_num_units.append(SC_NUM_UNITS[num_units_bits.uint])\n",
    "    best_learning_rate.append(SC_LEARNING[learning_rate_bits.uint])\n",
    "    best_batch_size.append(SC_BATCH[batch_size_bits.uint])\n",
    "#     best_activation_f.append(SC_ACTIVATION[activation_f_bits.uint])\n",
    "#     best_f_names.append(f_names[activation_f_bits.uint])\n",
    "    print('k=',t,'\\nDeep layers:', best_deep_layers[-1], ', Number of neurons:', best_num_units[-1])\n",
    "    print('Batch size', best_batch_size[-1], ', Learning rate:', best_learning_rate[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Deep layers</th>\n",
       "      <th>Num units</th>\n",
       "      <th>Learning rate</th>\n",
       "      <th>Batch size</th>\n",
       "      <th>Loss</th>\n",
       "      <th>Score</th>\n",
       "      <th>Elapsed time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>4</td>\n",
       "      <td>0.030084</td>\n",
       "      <td>0.030084</td>\n",
       "      <td>83.336212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>4</td>\n",
       "      <td>0.030989</td>\n",
       "      <td>0.030989</td>\n",
       "      <td>62.665275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>2</td>\n",
       "      <td>0.031189</td>\n",
       "      <td>0.031189</td>\n",
       "      <td>100.162131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>4</td>\n",
       "      <td>0.031316</td>\n",
       "      <td>0.031316</td>\n",
       "      <td>56.580555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>4</td>\n",
       "      <td>0.031369</td>\n",
       "      <td>0.031369</td>\n",
       "      <td>55.325445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>2</td>\n",
       "      <td>0.031431</td>\n",
       "      <td>0.031431</td>\n",
       "      <td>143.400618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>4</td>\n",
       "      <td>0.031614</td>\n",
       "      <td>0.031614</td>\n",
       "      <td>65.172094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>4</td>\n",
       "      <td>0.031695</td>\n",
       "      <td>0.031695</td>\n",
       "      <td>63.521127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>4</td>\n",
       "      <td>0.031795</td>\n",
       "      <td>0.031795</td>\n",
       "      <td>62.117052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>2</td>\n",
       "      <td>0.032351</td>\n",
       "      <td>0.032351</td>\n",
       "      <td>144.070886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>4</td>\n",
       "      <td>0.032614</td>\n",
       "      <td>0.032614</td>\n",
       "      <td>50.605494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>4</td>\n",
       "      <td>0.033043</td>\n",
       "      <td>0.033043</td>\n",
       "      <td>64.617544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>3</td>\n",
       "      <td>50</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>4</td>\n",
       "      <td>0.034216</td>\n",
       "      <td>0.034216</td>\n",
       "      <td>83.673831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>3</td>\n",
       "      <td>200</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>2</td>\n",
       "      <td>0.034516</td>\n",
       "      <td>0.034516</td>\n",
       "      <td>139.034887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>4</td>\n",
       "      <td>0.036064</td>\n",
       "      <td>0.036064</td>\n",
       "      <td>59.779401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>4</td>\n",
       "      <td>0.038729</td>\n",
       "      <td>0.038729</td>\n",
       "      <td>51.879006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>16</td>\n",
       "      <td>0.040944</td>\n",
       "      <td>0.040944</td>\n",
       "      <td>23.179064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0050</td>\n",
       "      <td>4</td>\n",
       "      <td>0.048112</td>\n",
       "      <td>0.048112</td>\n",
       "      <td>54.579316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2</td>\n",
       "      <td>200</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>16</td>\n",
       "      <td>0.048324</td>\n",
       "      <td>0.048324</td>\n",
       "      <td>41.989410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0050</td>\n",
       "      <td>4</td>\n",
       "      <td>0.048706</td>\n",
       "      <td>0.048706</td>\n",
       "      <td>50.722257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2</td>\n",
       "      <td>200</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>16</td>\n",
       "      <td>0.049164</td>\n",
       "      <td>0.049164</td>\n",
       "      <td>22.449524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>4</td>\n",
       "      <td>200</td>\n",
       "      <td>0.0050</td>\n",
       "      <td>16</td>\n",
       "      <td>0.057176</td>\n",
       "      <td>0.057176</td>\n",
       "      <td>26.143642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>4</td>\n",
       "      <td>0.071438</td>\n",
       "      <td>0.071438</td>\n",
       "      <td>46.926721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>16</td>\n",
       "      <td>0.077453</td>\n",
       "      <td>0.077453</td>\n",
       "      <td>20.859578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>4</td>\n",
       "      <td>0.078626</td>\n",
       "      <td>0.078626</td>\n",
       "      <td>48.491218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>4</td>\n",
       "      <td>0.112580</td>\n",
       "      <td>0.112580</td>\n",
       "      <td>52.682414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>4</td>\n",
       "      <td>0.125671</td>\n",
       "      <td>0.125671</td>\n",
       "      <td>53.421734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0050</td>\n",
       "      <td>2</td>\n",
       "      <td>0.158712</td>\n",
       "      <td>0.158712</td>\n",
       "      <td>112.510463</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Deep layers  Num units  Learning rate  Batch size      Loss     Score  \\\n",
       "0             3        100         0.0001           4  0.030084  0.030084   \n",
       "1             3        100         0.0001           4  0.030989  0.030989   \n",
       "2             2        100         0.0001           2  0.031189  0.031189   \n",
       "3             3        100         0.0001           4  0.031316  0.031316   \n",
       "4             3        100         0.0001           4  0.031369  0.031369   \n",
       "5             3        100         0.0001           2  0.031431  0.031431   \n",
       "6             3        100         0.0001           4  0.031614  0.031614   \n",
       "7             3        100         0.0001           4  0.031695  0.031695   \n",
       "8             3        100         0.0001           4  0.031795  0.031795   \n",
       "9             3        100         0.0001           2  0.032351  0.032351   \n",
       "10            3        100         0.0001           4  0.032614  0.032614   \n",
       "11            3        100         0.0001           4  0.033043  0.033043   \n",
       "12            3         50         0.0001           4  0.034216  0.034216   \n",
       "13            3        200         0.0001           2  0.034516  0.034516   \n",
       "14            2        100         0.0001           4  0.036064  0.036064   \n",
       "15            2        100         0.0001           4  0.038729  0.038729   \n",
       "16            3        100         0.0001          16  0.040944  0.040944   \n",
       "17            1        100         0.0050           4  0.048112  0.048112   \n",
       "18            2        200         0.0001          16  0.048324  0.048324   \n",
       "19            1        100         0.0050           4  0.048706  0.048706   \n",
       "20            2        200         0.0001          16  0.049164  0.049164   \n",
       "21            4        200         0.0050          16  0.057176  0.057176   \n",
       "22            1        100         0.0001           4  0.071438  0.071438   \n",
       "23            2        100         0.0001          16  0.077453  0.077453   \n",
       "24            1        100         0.0001           4  0.078626  0.078626   \n",
       "25            1        100         0.0001           4  0.112580  0.112580   \n",
       "26            1        100         0.0001           4  0.125671  0.125671   \n",
       "27            3        100         0.0050           2  0.158712  0.158712   \n",
       "\n",
       "    Elapsed time  \n",
       "0      83.336212  \n",
       "1      62.665275  \n",
       "2     100.162131  \n",
       "3      56.580555  \n",
       "4      55.325445  \n",
       "5     143.400618  \n",
       "6      65.172094  \n",
       "7      63.521127  \n",
       "8      62.117052  \n",
       "9     144.070886  \n",
       "10     50.605494  \n",
       "11     64.617544  \n",
       "12     83.673831  \n",
       "13    139.034887  \n",
       "14     59.779401  \n",
       "15     51.879006  \n",
       "16     23.179064  \n",
       "17     54.579316  \n",
       "18     41.989410  \n",
       "19     50.722257  \n",
       "20     22.449524  \n",
       "21     26.143642  \n",
       "22     46.926721  \n",
       "23     20.859578  \n",
       "24     48.491218  \n",
       "25     52.682414  \n",
       "26     53.421734  \n",
       "27    112.510463  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename = \"historial_genetic_jla1.txt\"\n",
    "df = pd.DataFrame(datos, columns = [\"Deep layers\", \"Num units\", \"Learning rate\", \"Batch size\", \"Loss\", \"Score\", \"Elapsed time\"])\n",
    "\n",
    "df.sort_values(by=[\"Loss\", \"Elapsed time\"], ascending=[True, True], ignore_index=True, inplace=True)\n",
    "\n",
    "df.to_csv(filename, header=True, index=False, sep='\\t', mode='w') # a=append, w=overwrite\n",
    "df.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time 30.665 minutes\n"
     ]
    }
   ],
   "source": [
    "total_time = float(np.sum(df[[\"Elapsed time\"]])/60)\n",
    "\n",
    "print(\"Elapsed time {:.3f} minutes\".format(total_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
