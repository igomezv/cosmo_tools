{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-16 20:41:08.498347: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-12-16 20:41:08.682158: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-12-16 20:41:08.682214: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2022-12-16 20:41:09.932650: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2022-12-16 20:41:09.932804: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2022-12-16 20:41:09.932819: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import time, os\n",
    "import random\n",
    "import seaborn as sns\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Input, Dense, LeakyReLU\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorboard.plugins.hparams import api as hp\n",
    "\n",
    "from tensorflow.keras import activations\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "import random\n",
    "from math import floor\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import optimizers\n",
    "from scipy.integrate import odeint\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split as split\n",
    "from scipy.stats import bernoulli\n",
    "\n",
    "# import deap\n",
    "from deap import base, creator, tools, algorithms\n",
    "\n",
    "from bitstring import BitArray\n",
    "\n",
    "# from elitism import eaSimpleWithElitism, main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "\n",
    "# tf.config.optimizer.set_jit(True)\n",
    "# scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "url = 'https://raw.githubusercontent.com/igomezv/nnogada/main/data/jla.csv'\n",
    "df=pd.read_csv(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = len(df.values)\n",
    "randomize = np.random.permutation(N)\n",
    "data = df.values[randomize]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(740, 2)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N = len(df.values)\n",
    "z = data[:,0] \n",
    "y = data[:,1:3] ### coge el resto de variables a predecir \n",
    "y[:,1] = y[:,1]**2+data[:,2]\n",
    "np.shape(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "scalerz = StandardScaler()\n",
    "scalerz.fit(z.reshape(-1,1))\n",
    "z = scalerz.transform(z.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((592, 1), (148, 1), (592, 2), (148, 2))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Modificar para incluir phanteon como test\n",
    "split = 0.8\n",
    "ntrain = int(split * len(z))\n",
    "indx = [ntrain]\n",
    "X_train, X_val = np.split(z, indx)\n",
    "Y_train, Y_val = np.split(y, indx)\n",
    "# X_train, X_test = np.split(z, indx)\n",
    "# Y_train, Y_test = np.split(y, indx)\n",
    "np.shape(X_train), np.shape(X_val), Y_train.shape, Y_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "SC_DEEP       = np.array([1,2,3,4])                           # Number of deep layers (8)\n",
    "SC_NUM_UNITS  = np.array([50,100,150,200]) # Number of fully conected neurons (16)\n",
    "SC_LEARNING   = np.array([1e-4,5e-3])   # Learning rates (8)\n",
    "SC_BATCH      = np.array([2, 4, 8, 16])                            # Batch sizes (4)\n",
    "# SC_ACTIVATION = [f1, f2, f3, f4]                                      # Activation function layers (2)\n",
    "\n",
    "my_callbacks = [tf.keras.callbacks.EarlyStopping(\n",
    "                               monitor='val_loss', mode='min',\n",
    "                               min_delta=0, \n",
    "                               patience=200,\n",
    "                               verbose=1,\n",
    "                            #    baseline=0,\n",
    "                               restore_best_weights=True)\n",
    "#                 keras.callbacks.TensorBoard(\n",
    "#                                log_dir='./logs'),\n",
    "#                 keras.callbacks.ReduceLROnPlateau(\n",
    "#                                monitor='val_loss', factor=0.5,\n",
    "#                                patience=6, min_lr=0,\n",
    "#                                verbose=1)\n",
    "               ] \n",
    "    \n",
    "epochs = 200\n",
    "# epochs = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_evaluate(ga_individual_solution):   \n",
    "    t = time.time()\n",
    "    t_total = 0\n",
    "    \n",
    "    # Decode GA solution to integer for window_size and num_units\n",
    "    deep_layers_bits   = BitArray(ga_individual_solution[0:2])     # (8)\n",
    "    num_units_bits     = BitArray(ga_individual_solution[2:4])     # (16)\n",
    "    learning_rate_bits = BitArray(ga_individual_solution[4:5])    # (8)\n",
    "    batch_size_bits    = BitArray(ga_individual_solution[5:7])   # (4)\n",
    "# #     activation_f_bits  = BitArray(ga_individual_solution[12:13])   # (2)   Solo se consideran las 2 primeras\n",
    "    \n",
    "    deep_layers   = SC_DEEP[deep_layers_bits.uint]\n",
    "    num_units     = SC_NUM_UNITS[num_units_bits.uint]\n",
    "    learning_rate = SC_LEARNING[learning_rate_bits.uint]\n",
    "    batch_size   = SC_BATCH[batch_size_bits.uint]\n",
    "#     activation_f  = SC_ACTIVATION[activation_f_bits.uint]\n",
    "\n",
    "    \n",
    "    print('\\n--------------- Starting trial:', population_size*(max_generations+1)-len(ss), \"---------------\")\n",
    "    print('Deep layers:',deep_layers,', Number of neurons:',num_units,\", Learning rate:\",learning_rate)\n",
    "#     print(\"-------------------------------------------------\")\n",
    "    \n",
    "    # Train model and predict on validation set\n",
    "    model = tf.keras.Sequential()\n",
    "#     model.add(Input(shape=(int(X_train.shape[1]),)))\n",
    "    model.add(Dense(int(X_train.shape[1])))\n",
    "    \n",
    "    for i in range(deep_layers):        \n",
    "        model.add(Dense(num_units, activation='relu'))\n",
    "#             model.add(keras.layers.Dropout(0.3))\n",
    "    model.add(Dense(2, activation='linear'))\n",
    "    \n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate, beta_1=0.9, beta_2=0.999, epsilon=1e-3)\n",
    "    model.compile(optimizer=optimizer, loss='mse', metrics=['mean_squared_error'])\n",
    "    model.fit(X_train, Y_train, epochs=epochs, validation_data=(X_val, Y_val),\n",
    "              callbacks=my_callbacks, batch_size=batch_size, shuffle=False, verbose=0)\n",
    "    \n",
    "    loss, score = model.evaluate(X_val, Y_val)    \n",
    "    t = time.time()-t\n",
    "    ss.pop(0)\n",
    "    print(\"Loss:\", score, \", Elapsed time:\", t)\n",
    "    print(\"-------------------------------------------------\\n\")\n",
    "#     print(loss, score)\n",
    "\n",
    "    datos.append([deep_layers, num_units, learning_rate, batch_size, loss, score, t])\n",
    "    \n",
    "    return loss,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deap import tools\n",
    "from deap import algorithms\n",
    "\n",
    "def eaSimpleWithElitism(population, toolbox, cxpb, mutpb, ngen, stats=None,\n",
    "             halloffame=None, verbose=__debug__):\n",
    "    \"\"\"This algorithm is similar to DEAP eaSimple() algorithm, with the modification that\n",
    "    halloffame is used to implement an elitism mechanism. The individuals contained in the\n",
    "    halloffame are directly injected into the next generation and are not subject to the\n",
    "    genetic operators of selection, crossover and mutation.\n",
    "    \"\"\"\n",
    "    logbook = tools.Logbook()\n",
    "    logbook.header = ['gen', 'nevals'] + (stats.fields if stats else [])\n",
    "\n",
    "    # Evaluate the individuals with an invalid fitness\n",
    "    invalid_ind = [ind for ind in population if not ind.fitness.valid]\n",
    "    fitnesses = toolbox.map(toolbox.evaluate, invalid_ind)\n",
    "    for ind, fit in zip(invalid_ind, fitnesses):\n",
    "        ind.fitness.values = fit\n",
    "\n",
    "    if halloffame is None:\n",
    "        raise ValueError(\"halloffame parameter must not be empty!\")\n",
    "\n",
    "    halloffame.update(population)\n",
    "    hof_size = len(halloffame.items) if halloffame.items else 0\n",
    "\n",
    "    record = stats.compile(population) if stats else {}\n",
    "    logbook.record(gen=0, nevals=len(invalid_ind), **record)\n",
    "    if verbose:\n",
    "        print(logbook.stream)\n",
    "\n",
    "    # Begin the generational process\n",
    "    for gen in range(1, ngen + 1):\n",
    "\n",
    "        # Select the next generation individuals\n",
    "        offspring = toolbox.select(population, len(population) - hof_size)\n",
    "\n",
    "        # Vary the pool of individuals\n",
    "        offspring = algorithms.varAnd(offspring, toolbox, cxpb, mutpb)\n",
    "\n",
    "        # Evaluate the individuals with an invalid fitness\n",
    "        invalid_ind = [ind for ind in offspring if not ind.fitness.valid]\n",
    "        fitnesses = toolbox.map(toolbox.evaluate, invalid_ind)\n",
    "        for ind, fit in zip(invalid_ind, fitnesses):\n",
    "            ind.fitness.values = fit\n",
    "\n",
    "        # add the best back to population:\n",
    "        offspring.extend(halloffame.items)\n",
    "\n",
    "        # Update the hall of fame with the generated individuals\n",
    "        halloffame.update(offspring)\n",
    "\n",
    "        # Replace the current population by the offspring\n",
    "        population[:] = offspring\n",
    "\n",
    "        # Append the current generation statistics to the logbook\n",
    "        record = stats.compile(population) if stats else {}\n",
    "        logbook.record(gen=gen, nevals=len(invalid_ind), **record)\n",
    "        if verbose:\n",
    "            print(logbook.stream)\n",
    "\n",
    "    return population, logbook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def geneticAlgorithm_with_elitism(population_size, max_generations, gene_length, k):\n",
    "    \n",
    "    # Genetic Algorithm constants:\n",
    "    P_CROSSOVER = 0.5        # probability for crossover\n",
    "    P_MUTATION = 0.5         # probability for mutating an individual\n",
    "    HALL_OF_FAME_SIZE = 1    # Best individuals that pass to the other generation\n",
    "    \n",
    "    # set the random seed:\n",
    "    toolbox = base.Toolbox()\n",
    "\n",
    "    # As we are trying to minimize the RMSE score, that's why using -1.0. \n",
    "    # In case, when you want to maximize accuracy for instance, use 1.0\n",
    "    creator.create('FitnessMin', base.Fitness, weights = [-1.0])\n",
    "    creator.create('Individual', list , fitness = creator.FitnessMin)\n",
    "\n",
    "    # create the individual operator to fill up an Individual instance:\n",
    "    toolbox.register('binary', bernoulli.rvs, 0.5)\n",
    "    toolbox.register('individual', tools.initRepeat, creator.Individual, toolbox.binary, n = gene_length)\n",
    "\n",
    "    # create the population operator to generate a list of individuals:\n",
    "    toolbox.register('population', tools.initRepeat, list , toolbox.individual)\n",
    "\n",
    "    # genetic operators:\n",
    "    toolbox.register('evaluate', train_evaluate)\n",
    "    toolbox.register('select', tools.selTournament, tournsize = 2)\n",
    "    toolbox.register('mutate', tools.mutFlipBit, indpb = 0.11)\n",
    "    toolbox.register('mate', tools.cxUniform, indpb = 0.5)\n",
    "    \n",
    "    # create initial population (generation 0):\n",
    "    population = toolbox.population(n=population_size)\n",
    "\n",
    "    # prepare the statistics object:\n",
    "    stats = tools.Statistics(lambda ind: ind.fitness.values)\n",
    "    stats.register(\"min\", np.min)\n",
    "    stats.register(\"avg\", np.mean)\n",
    "    stats.register(\"max\", np.max)\n",
    "\n",
    "    # define the hall-of-fame object:\n",
    "    hof = tools.HallOfFame(HALL_OF_FAME_SIZE)\n",
    "\n",
    "    # Genetic Algorithm flow with elitism:\n",
    "    population, logbook = eaSimpleWithElitism(population, toolbox, cxpb=P_CROSSOVER, mutpb=P_MUTATION,\n",
    "                                              ngen=max_generations, stats=stats, halloffame=hof, verbose=True)\n",
    "\n",
    "    # print info for best solution found:\n",
    "    best = hof.items[0]\n",
    "    print(\"-- Best Individual = \", best)\n",
    "    print(\"-- Best Fitness = \", best.fitness.values[0])\n",
    "\n",
    "    # extract statistics:\n",
    "    minFitnessValues, meanFitnessValues, maxFitnessValues = logbook.select(\"min\", \"max\", \"avg\")\n",
    "\n",
    "    # plot statistics:\n",
    "    sns.set_style(\"whitegrid\")\n",
    "    plt.plot(minFitnessValues, color='blue', label=\"Min\")\n",
    "    plt.plot(meanFitnessValues, color='green', label=\"Mean\")\n",
    "    plt.plot(maxFitnessValues, color='red', label=\"Max\")\n",
    "    plt.xlabel('Generation'); plt.ylabel('Max / Min / Average Fitness')\n",
    "    plt.legend()\n",
    "    plt.title('Max, Min and Average fitness over Generations')\n",
    "    plt.show()\n",
    "    \n",
    "    best_population = tools.selBest(population,k = k)\n",
    "    return best_population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------------- Starting trial: 1 ---------------\n",
      "Deep layers: 3 , Number of neurons: 100 , Learning rate: 0.005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-16 20:41:11.335386: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-16 20:41:11.335707: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-12-16 20:41:11.335802: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory\n",
      "2022-12-16 20:41:11.335873: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory\n",
      "2022-12-16 20:41:11.335946: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcufft.so.10'; dlerror: libcufft.so.10: cannot open shared object file: No such file or directory\n",
      "2022-12-16 20:41:11.336020: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcurand.so.10'; dlerror: libcurand.so.10: cannot open shared object file: No such file or directory\n",
      "2022-12-16 20:41:11.336094: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory\n",
      "2022-12-16 20:41:11.336168: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory\n",
      "2022-12-16 20:41:11.336239: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2022-12-16 20:41:11.336252: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1934] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2022-12-16 20:41:11.336851: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 4ms/step - loss: 0.1486 - mean_squared_error: 0.1486\n",
      "Loss: 0.14862550795078278 , Elapsed time: 157.78481030464172\n",
      "-------------------------------------------------\n",
      "\n",
      "\n",
      "--------------- Starting trial: 2 ---------------\n",
      "Deep layers: 2 , Number of neurons: 200 , Learning rate: 0.0001\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0518 - mean_squared_error: 0.0518\n",
      "Loss: 0.051843881607055664 , Elapsed time: 26.603424549102783\n",
      "-------------------------------------------------\n",
      "\n",
      "\n",
      "--------------- Starting trial: 3 ---------------\n",
      "Deep layers: 4 , Number of neurons: 200 , Learning rate: 0.005\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0446 - mean_squared_error: 0.0446\n",
      "Loss: 0.0445525236427784 , Elapsed time: 41.08995962142944\n",
      "-------------------------------------------------\n",
      "\n",
      "\n",
      "--------------- Starting trial: 4 ---------------\n",
      "Deep layers: 1 , Number of neurons: 100 , Learning rate: 0.0001\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0756 - mean_squared_error: 0.0756\n",
      "Loss: 0.07564480602741241 , Elapsed time: 83.00588655471802\n",
      "-------------------------------------------------\n",
      "\n",
      "\n",
      "--------------- Starting trial: 5 ---------------\n",
      "Deep layers: 2 , Number of neurons: 100 , Learning rate: 0.0001\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0361 - mean_squared_error: 0.0361\n",
      "Loss: 0.03611965477466583 , Elapsed time: 76.39568042755127\n",
      "-------------------------------------------------\n",
      "\n",
      "gen\tnevals\tmin      \tavg      \tmax     \n",
      "0  \t5     \t0.0361197\t0.0713573\t0.148626\n",
      "\n",
      "--------------- Starting trial: 6 ---------------\n",
      "Deep layers: 4 , Number of neurons: 200 , Learning rate: 0.005\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0410 - mean_squared_error: 0.0410\n",
      "Loss: 0.04098629206418991 , Elapsed time: 42.481741189956665\n",
      "-------------------------------------------------\n",
      "\n",
      "\n",
      "--------------- Starting trial: 7 ---------------\n",
      "Deep layers: 4 , Number of neurons: 100 , Learning rate: 0.0001\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0336 - mean_squared_error: 0.0336\n",
      "Loss: 0.033610597252845764 , Elapsed time: 143.68349957466125\n",
      "-------------------------------------------------\n",
      "\n",
      "1  \t2     \t0.0336106\t0.039736 \t0.0518439\n",
      "\n",
      "--------------- Starting trial: 8 ---------------\n",
      "Deep layers: 1 , Number of neurons: 100 , Learning rate: 0.0001\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1843 - mean_squared_error: 0.1843\n",
      "Loss: 0.18433867394924164 , Elapsed time: 82.9946391582489\n",
      "-------------------------------------------------\n",
      "\n",
      "\n",
      "--------------- Starting trial: 9 ---------------\n",
      "Deep layers: 4 , Number of neurons: 100 , Learning rate: 0.0001\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0358 - mean_squared_error: 0.0358\n",
      "Loss: 0.03575225919485092 , Elapsed time: 90.10504817962646\n",
      "-------------------------------------------------\n",
      "\n",
      "\n",
      "--------------- Starting trial: 10 ---------------\n",
      "Deep layers: 2 , Number of neurons: 100 , Learning rate: 0.0001\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0399 - mean_squared_error: 0.0399\n",
      "Loss: 0.03986607491970062 , Elapsed time: 79.85658144950867\n",
      "-------------------------------------------------\n",
      "\n",
      "\n",
      "--------------- Starting trial: 11 ---------------\n",
      "Deep layers: 4 , Number of neurons: 100 , Learning rate: 0.0001\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0301 - mean_squared_error: 0.0301\n",
      "Loss: 0.030147021636366844 , Elapsed time: 91.14852547645569\n",
      "-------------------------------------------------\n",
      "\n",
      "2  \t4     \t0.030147 \t0.0647429\t0.184339 \n",
      "\n",
      "--------------- Starting trial: 12 ---------------\n",
      "Deep layers: 4 , Number of neurons: 100 , Learning rate: 0.0001\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0333 - mean_squared_error: 0.0333\n",
      "Loss: 0.03328591585159302 , Elapsed time: 87.85457062721252\n",
      "-------------------------------------------------\n",
      "\n",
      "\n",
      "--------------- Starting trial: 13 ---------------\n",
      "Deep layers: 3 , Number of neurons: 100 , Learning rate: 0.0001\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0310 - mean_squared_error: 0.0310\n",
      "Loss: 0.03103073500096798 , Elapsed time: 83.33523297309875\n",
      "-------------------------------------------------\n",
      "\n",
      "3  \t2     \t0.0310307\t0.033458 \t0.0357523\n",
      "\n",
      "--------------- Starting trial: 14 ---------------\n",
      "Deep layers: 4 , Number of neurons: 100 , Learning rate: 0.0001\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0351 - mean_squared_error: 0.0351\n",
      "Loss: 0.03507794067263603 , Elapsed time: 90.97392702102661\n",
      "-------------------------------------------------\n",
      "\n",
      "4  \t1     \t0.0310307\t0.0323561\t0.0350779\n",
      "\n",
      "--------------- Starting trial: 15 ---------------\n",
      "Deep layers: 3 , Number of neurons: 100 , Learning rate: 0.0001\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0328 - mean_squared_error: 0.0328\n",
      "Loss: 0.032820507884025574 , Elapsed time: 143.40258383750916\n",
      "-------------------------------------------------\n",
      "\n",
      "\n",
      "--------------- Starting trial: 16 ---------------\n",
      "Deep layers: 4 , Number of neurons: 100 , Learning rate: 0.0001\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0325 - mean_squared_error: 0.0325\n",
      "Loss: 0.03253250569105148 , Elapsed time: 143.66049361228943\n",
      "-------------------------------------------------\n",
      "\n",
      "\n",
      "--------------- Starting trial: 17 ---------------\n",
      "Deep layers: 3 , Number of neurons: 100 , Learning rate: 0.0001\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0307 - mean_squared_error: 0.0307\n",
      "Loss: 0.030661270022392273 , Elapsed time: 144.4896047115326\n",
      "-------------------------------------------------\n",
      "\n",
      "\n",
      "--------------- Starting trial: 18 ---------------\n",
      "Deep layers: 4 , Number of neurons: 50 , Learning rate: 0.0001\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0355 - mean_squared_error: 0.0355\n",
      "Loss: 0.03548440337181091 , Elapsed time: 89.57542562484741\n",
      "-------------------------------------------------\n",
      "\n",
      "5  \t4     \t0.0306613\t0.0325059\t0.0354844\n",
      "\n",
      "--------------- Starting trial: 19 ---------------\n",
      "Deep layers: 3 , Number of neurons: 200 , Learning rate: 0.0001\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0312 - mean_squared_error: 0.0312\n",
      "Loss: 0.031190956011414528 , Elapsed time: 95.24879145622253\n",
      "-------------------------------------------------\n",
      "\n",
      "\n",
      "--------------- Starting trial: 20 ---------------\n",
      "Deep layers: 3 , Number of neurons: 100 , Learning rate: 0.0001\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0311 - mean_squared_error: 0.0311\n",
      "Loss: 0.031076056882739067 , Elapsed time: 85.0188193321228\n",
      "-------------------------------------------------\n",
      "\n",
      "6  \t2     \t0.0306613\t0.0309241\t0.031191 \n",
      "\n",
      "--------------- Starting trial: 21 ---------------\n",
      "Deep layers: 3 , Number of neurons: 100 , Learning rate: 0.0001\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0318 - mean_squared_error: 0.0318\n",
      "Loss: 0.031750332564115524 , Elapsed time: 90.19906497001648\n",
      "-------------------------------------------------\n",
      "\n",
      "\n",
      "--------------- Starting trial: 22 ---------------\n",
      "Deep layers: 4 , Number of neurons: 100 , Learning rate: 0.0001\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0394 - mean_squared_error: 0.0394\n",
      "Loss: 0.03942693769931793 , Elapsed time: 42.63553047180176\n",
      "-------------------------------------------------\n",
      "\n",
      "\n",
      "--------------- Starting trial: 23 ---------------\n",
      "Deep layers: 3 , Number of neurons: 100 , Learning rate: 0.0001\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0338 - mean_squared_error: 0.0338\n",
      "Loss: 0.03384587541222572 , Elapsed time: 83.56080532073975\n",
      "-------------------------------------------------\n",
      "\n",
      "7  \t3     \t0.0306613\t0.033343 \t0.0394269\n",
      "\n",
      "--------------- Starting trial: 24 ---------------\n",
      "Deep layers: 3 , Number of neurons: 50 , Learning rate: 0.0001\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0390 - mean_squared_error: 0.0390\n",
      "Loss: 0.03896611928939819 , Elapsed time: 144.36404037475586\n",
      "-------------------------------------------------\n",
      "\n",
      "\n",
      "--------------- Starting trial: 25 ---------------\n",
      "Deep layers: 3 , Number of neurons: 100 , Learning rate: 0.0001\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0309 - mean_squared_error: 0.0309\n",
      "Loss: 0.03092179074883461 , Elapsed time: 143.9559645652771\n",
      "-------------------------------------------------\n",
      "\n",
      "8  \t2     \t0.0306613\t0.0325221\t0.0389661\n",
      "\n",
      "--------------- Starting trial: 26 ---------------\n",
      "Deep layers: 3 , Number of neurons: 100 , Learning rate: 0.0001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0334 - mean_squared_error: 0.0334\n",
      "Loss: 0.0333716981112957 , Elapsed time: 95.62281084060669\n",
      "-------------------------------------------------\n",
      "\n",
      "\n",
      "--------------- Starting trial: 27 ---------------\n",
      "Deep layers: 3 , Number of neurons: 100 , Learning rate: 0.0001\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0320 - mean_squared_error: 0.0320\n",
      "Loss: 0.03196759149432182 , Elapsed time: 89.89482712745667\n",
      "-------------------------------------------------\n",
      "\n",
      "\n",
      "--------------- Starting trial: 28 ---------------\n",
      "Deep layers: 3 , Number of neurons: 100 , Learning rate: 0.005\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0608 - mean_squared_error: 0.0608\n",
      "Loss: 0.06080997362732887 , Elapsed time: 143.61149907112122\n",
      "-------------------------------------------------\n",
      "\n",
      "\n",
      "--------------- Starting trial: 29 ---------------\n",
      "Deep layers: 3 , Number of neurons: 100 , Learning rate: 0.0001\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0312 - mean_squared_error: 0.0312\n",
      "Loss: 0.03122965432703495 , Elapsed time: 89.04622673988342\n",
      "-------------------------------------------------\n",
      "\n",
      "9  \t4     \t0.0310307\t0.0376819\t0.06081  \n",
      "\n",
      "--------------- Starting trial: 30 ---------------\n",
      "Deep layers: 3 , Number of neurons: 100 , Learning rate: 0.0001\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0322 - mean_squared_error: 0.0322\n",
      "Loss: 0.03222681209445 , Elapsed time: 81.48167514801025\n",
      "-------------------------------------------------\n",
      "\n",
      "\n",
      "--------------- Starting trial: 31 ---------------\n",
      "Deep layers: 3 , Number of neurons: 100 , Learning rate: 0.0001\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0324 - mean_squared_error: 0.0324\n",
      "Loss: 0.03237937018275261 , Elapsed time: 144.56923961639404\n",
      "-------------------------------------------------\n",
      "\n",
      "10 \t2     \t0.0310307\t0.031727 \t0.0323794\n",
      "-- Best Individual =  [1, 0, 0, 1, 0, 0, 1]\n",
      "-- Best Fitness =  0.03103073500096798\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total elapsed time: 50.46592810153961 minutes\n"
     ]
    }
   ],
   "source": [
    "population_size = 5   # max of individuals per generation\n",
    "max_generations = 10  # number of generations\n",
    "gene_length = 7      # lenght of the gene, depends on how many hiperparameters are tested  \n",
    "k = 1;                 # num. of finalist individuals\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    t = time.time(); \n",
    "    datos = [];\n",
    "    ss = [i for i in range(1,population_size*(max_generations+1))]\n",
    "    best_population = geneticAlgorithm_with_elitism(population_size, max_generations, gene_length, k)\n",
    "    print(\"Total elapsed time:\", (time.time()-t)/60, \"minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k= 1 \n",
      "Deep layers: 2 , Number of neurons: 50\n",
      "Batch size 4 , Learning rate: 0.0001\n"
     ]
    }
   ],
   "source": [
    "best_deep_layers   = []\n",
    "best_num_units     = []\n",
    "best_learning_rate = []\n",
    "best_batch_size    = []\n",
    "# best_activation_f  = []\n",
    "best_f_names       = []\n",
    "\n",
    "t = 0\n",
    "\n",
    "for bi in best_population:\n",
    "    deep_layers_bits   = BitArray(bi[0:1])    # (8)\n",
    "    num_units_bits     = BitArray(bi[1:2])    # (16)\n",
    "    learning_rate_bits = BitArray(bi[2:3])   # (8)\n",
    "    batch_size_bits    = BitArray(bi[3:4])  # (4)\n",
    "#     activation_f_bits  = BitArray(bi[12:13])  # (2)\n",
    "    t += 1 \n",
    "    \n",
    "    best_deep_layers.append(SC_DEEP[deep_layers_bits.uint])\n",
    "    best_num_units.append(SC_NUM_UNITS[num_units_bits.uint])\n",
    "    best_learning_rate.append(SC_LEARNING[learning_rate_bits.uint])\n",
    "    best_batch_size.append(SC_BATCH[batch_size_bits.uint])\n",
    "#     best_activation_f.append(SC_ACTIVATION[activation_f_bits.uint])\n",
    "#     best_f_names.append(f_names[activation_f_bits.uint])\n",
    "    print('k=',t,'\\nDeep layers:', best_deep_layers[-1], ', Number of neurons:', best_num_units[-1])\n",
    "    print('Batch size', best_batch_size[-1], ', Learning rate:', best_learning_rate[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Deep layers</th>\n",
       "      <th>Num units</th>\n",
       "      <th>Learning rate</th>\n",
       "      <th>Batch size</th>\n",
       "      <th>Loss</th>\n",
       "      <th>Score</th>\n",
       "      <th>Elapsed time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>4</td>\n",
       "      <td>0.030147</td>\n",
       "      <td>0.030147</td>\n",
       "      <td>91.148525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>4</td>\n",
       "      <td>0.030661</td>\n",
       "      <td>0.030661</td>\n",
       "      <td>144.489605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>4</td>\n",
       "      <td>0.030922</td>\n",
       "      <td>0.030922</td>\n",
       "      <td>143.955965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>4</td>\n",
       "      <td>0.031031</td>\n",
       "      <td>0.031031</td>\n",
       "      <td>83.335233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>4</td>\n",
       "      <td>0.031076</td>\n",
       "      <td>0.031076</td>\n",
       "      <td>85.018819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3</td>\n",
       "      <td>200</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>4</td>\n",
       "      <td>0.031191</td>\n",
       "      <td>0.031191</td>\n",
       "      <td>95.248791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>4</td>\n",
       "      <td>0.031230</td>\n",
       "      <td>0.031230</td>\n",
       "      <td>89.046227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>4</td>\n",
       "      <td>0.031750</td>\n",
       "      <td>0.031750</td>\n",
       "      <td>90.199065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>4</td>\n",
       "      <td>0.031968</td>\n",
       "      <td>0.031968</td>\n",
       "      <td>89.894827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>4</td>\n",
       "      <td>0.032227</td>\n",
       "      <td>0.032227</td>\n",
       "      <td>81.481675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>4</td>\n",
       "      <td>0.032379</td>\n",
       "      <td>0.032379</td>\n",
       "      <td>144.569240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>4</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>4</td>\n",
       "      <td>0.032533</td>\n",
       "      <td>0.032533</td>\n",
       "      <td>143.660494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>4</td>\n",
       "      <td>0.032821</td>\n",
       "      <td>0.032821</td>\n",
       "      <td>143.402584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>4</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>4</td>\n",
       "      <td>0.033286</td>\n",
       "      <td>0.033286</td>\n",
       "      <td>87.854571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>4</td>\n",
       "      <td>0.033372</td>\n",
       "      <td>0.033372</td>\n",
       "      <td>95.622811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>4</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>4</td>\n",
       "      <td>0.033611</td>\n",
       "      <td>0.033611</td>\n",
       "      <td>143.683500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>4</td>\n",
       "      <td>0.033846</td>\n",
       "      <td>0.033846</td>\n",
       "      <td>83.560805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>4</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>4</td>\n",
       "      <td>0.035078</td>\n",
       "      <td>0.035078</td>\n",
       "      <td>90.973927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>4</td>\n",
       "      <td>50</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>4</td>\n",
       "      <td>0.035484</td>\n",
       "      <td>0.035484</td>\n",
       "      <td>89.575426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>4</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>4</td>\n",
       "      <td>0.035752</td>\n",
       "      <td>0.035752</td>\n",
       "      <td>90.105048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>4</td>\n",
       "      <td>0.036120</td>\n",
       "      <td>0.036120</td>\n",
       "      <td>76.395680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>3</td>\n",
       "      <td>50</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>4</td>\n",
       "      <td>0.038966</td>\n",
       "      <td>0.038966</td>\n",
       "      <td>144.364040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>4</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>16</td>\n",
       "      <td>0.039427</td>\n",
       "      <td>0.039427</td>\n",
       "      <td>42.635530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>4</td>\n",
       "      <td>0.039866</td>\n",
       "      <td>0.039866</td>\n",
       "      <td>79.856581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>4</td>\n",
       "      <td>200</td>\n",
       "      <td>0.0050</td>\n",
       "      <td>16</td>\n",
       "      <td>0.040986</td>\n",
       "      <td>0.040986</td>\n",
       "      <td>42.481741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>4</td>\n",
       "      <td>200</td>\n",
       "      <td>0.0050</td>\n",
       "      <td>16</td>\n",
       "      <td>0.044553</td>\n",
       "      <td>0.044553</td>\n",
       "      <td>41.089960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2</td>\n",
       "      <td>200</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>16</td>\n",
       "      <td>0.051844</td>\n",
       "      <td>0.051844</td>\n",
       "      <td>26.603425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0050</td>\n",
       "      <td>4</td>\n",
       "      <td>0.060810</td>\n",
       "      <td>0.060810</td>\n",
       "      <td>143.611499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>4</td>\n",
       "      <td>0.075645</td>\n",
       "      <td>0.075645</td>\n",
       "      <td>83.005887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0050</td>\n",
       "      <td>2</td>\n",
       "      <td>0.148626</td>\n",
       "      <td>0.148626</td>\n",
       "      <td>157.784810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>4</td>\n",
       "      <td>0.184339</td>\n",
       "      <td>0.184339</td>\n",
       "      <td>82.994639</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Deep layers  Num units  Learning rate  Batch size      Loss     Score  \\\n",
       "0             4        100         0.0001           4  0.030147  0.030147   \n",
       "1             3        100         0.0001           4  0.030661  0.030661   \n",
       "2             3        100         0.0001           4  0.030922  0.030922   \n",
       "3             3        100         0.0001           4  0.031031  0.031031   \n",
       "4             3        100         0.0001           4  0.031076  0.031076   \n",
       "5             3        200         0.0001           4  0.031191  0.031191   \n",
       "6             3        100         0.0001           4  0.031230  0.031230   \n",
       "7             3        100         0.0001           4  0.031750  0.031750   \n",
       "8             3        100         0.0001           4  0.031968  0.031968   \n",
       "9             3        100         0.0001           4  0.032227  0.032227   \n",
       "10            3        100         0.0001           4  0.032379  0.032379   \n",
       "11            4        100         0.0001           4  0.032533  0.032533   \n",
       "12            3        100         0.0001           4  0.032821  0.032821   \n",
       "13            4        100         0.0001           4  0.033286  0.033286   \n",
       "14            3        100         0.0001           4  0.033372  0.033372   \n",
       "15            4        100         0.0001           4  0.033611  0.033611   \n",
       "16            3        100         0.0001           4  0.033846  0.033846   \n",
       "17            4        100         0.0001           4  0.035078  0.035078   \n",
       "18            4         50         0.0001           4  0.035484  0.035484   \n",
       "19            4        100         0.0001           4  0.035752  0.035752   \n",
       "20            2        100         0.0001           4  0.036120  0.036120   \n",
       "21            3         50         0.0001           4  0.038966  0.038966   \n",
       "22            4        100         0.0001          16  0.039427  0.039427   \n",
       "23            2        100         0.0001           4  0.039866  0.039866   \n",
       "24            4        200         0.0050          16  0.040986  0.040986   \n",
       "25            4        200         0.0050          16  0.044553  0.044553   \n",
       "26            2        200         0.0001          16  0.051844  0.051844   \n",
       "27            3        100         0.0050           4  0.060810  0.060810   \n",
       "28            1        100         0.0001           4  0.075645  0.075645   \n",
       "29            3        100         0.0050           2  0.148626  0.148626   \n",
       "30            1        100         0.0001           4  0.184339  0.184339   \n",
       "\n",
       "    Elapsed time  \n",
       "0      91.148525  \n",
       "1     144.489605  \n",
       "2     143.955965  \n",
       "3      83.335233  \n",
       "4      85.018819  \n",
       "5      95.248791  \n",
       "6      89.046227  \n",
       "7      90.199065  \n",
       "8      89.894827  \n",
       "9      81.481675  \n",
       "10    144.569240  \n",
       "11    143.660494  \n",
       "12    143.402584  \n",
       "13     87.854571  \n",
       "14     95.622811  \n",
       "15    143.683500  \n",
       "16     83.560805  \n",
       "17     90.973927  \n",
       "18     89.575426  \n",
       "19     90.105048  \n",
       "20     76.395680  \n",
       "21    144.364040  \n",
       "22     42.635530  \n",
       "23     79.856581  \n",
       "24     42.481741  \n",
       "25     41.089960  \n",
       "26     26.603425  \n",
       "27    143.611499  \n",
       "28     83.005887  \n",
       "29    157.784810  \n",
       "30     82.994639  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename = \"historial_genetic_jla1.txt\"\n",
    "df = pd.DataFrame(datos, columns = [\"Deep layers\", \"Num units\", \"Learning rate\", \"Batch size\", \"Loss\", \"Score\", \"Elapsed time\"])\n",
    "\n",
    "df.sort_values(by=[\"Loss\", \"Elapsed time\"], ascending=[True, True], ignore_index=True, inplace=True)\n",
    "\n",
    "df.to_csv(filename, header=True, index=False, sep='\\t', mode='w') # a=append, w=overwrite\n",
    "df.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time 50.461 minutes\n"
     ]
    }
   ],
   "source": [
    "total_time = float(np.sum(df[[\"Elapsed time\"]])/60)\n",
    "\n",
    "print(\"Elapsed time {:.3f} minutes\".format(total_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
