{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load_ext tensorboard\n",
    "# Clear any logs from previous runs\n",
    "# !rm -rf ./logs/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-16 20:41:11.538215: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-12-16 20:41:11.724212: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-12-16 20:41:11.724261: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2022-12-16 20:41:12.872126: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2022-12-16 20:41:12.872278: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2022-12-16 20:41:12.872293: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time, os\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Input, Dense\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorboard.plugins.hparams import api as hp\n",
    "\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split as split\n",
    "\n",
    "import random\n",
    "from math import floor\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import optimizers\n",
    "from scipy.integrate import odeint\n",
    "import scipy\n",
    "import pandas as pd\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(740, 2)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = 'https://raw.githubusercontent.com/igomezv/nnogada/main/data/jla.csv'\n",
    "df=pd.read_csv(url)\n",
    "N = len(df.values)\n",
    "randomize = np.random.permutation(N)\n",
    "data = df.values[randomize]\n",
    "N = len(df.values)\n",
    "z = data[:,0] \n",
    "y = data[:,1:3] ### coge el resto de variables a predecir \n",
    "y[:,1] = y[:,1]**2+data[:,2]\n",
    "np.shape(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "scalerz = StandardScaler()\n",
    "scalerz.fit(z.reshape(-1,1))\n",
    "z = scalerz.transform(z.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((592, 1), (148, 1), (592, 2), (148, 2))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Modificar para incluir phanteon como test\n",
    "split = 0.8\n",
    "ntrain = int(split * len(z))\n",
    "indx = [ntrain]\n",
    "X_train, X_test = np.split(z, indx)\n",
    "Y_train, Y_test = np.split(y, indx)\n",
    "np.shape(X_train), np.shape(X_test), Y_train.shape, Y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss -> val_loss\n",
    "callbacks = [tf.keras.callbacks.EarlyStopping(monitor='val_loss', mode='min',\n",
    "                                   min_delta=0.0,\n",
    "                                   patience=200,\n",
    "                                   restore_best_weights=True, verbose=True)\n",
    "                                   ]\n",
    "\n",
    "n_cols = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "HP_BATCHSIZE = hp.HParam('batch_size', hp.Discrete([2, 4, 8, 16]))\n",
    "HP_LAYERS =    hp.HParam('layers', hp.Discrete([1, 2, 3, 4]))\n",
    "HP_NUM_UNITS = hp.HParam('num_units', hp.Discrete([50, 100, 150, 200]))\n",
    "HP_LEARNING  = hp.HParam('learning_rate', hp.Discrete([1e-4,1e-3]))\n",
    "# HP_NUM_UNITS3 = hp.HParam('num_units3', hp.Discrete([50, 100, 150, 200]))\n",
    "# HP_NUM_UNITS4 = hp.HParam('num_units4', hp.Discrete([2, 5, 10]))\n",
    "# HP_DROPOUT = hp.HParam('dropout', hp.RealInterval(0.0, 0.2))\n",
    "# HP_OPTIMIZER = hp.HParam('optimizer', hp.Discrete(['adam', 'sgd']))\n",
    "# HP_OPTIMIZER = hp.HParam('optimizer', hp.Discrete(['adam', 'Adadelta']))\n",
    "# HP_OPTIMIZER = hp.HParam('optimizer', hp.Discrete(['adam']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs=200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sess = tf.Session()\n",
    "# writer = tf.summary.FileWriter(\"/tmp/tfvgg\", sess.graph)\n",
    "# init = tf.initialize_all_variables()\n",
    "# sess.run(init)\n",
    "# with tf.summary.create_file_writer('logs/hparam_tuning').as_default():\n",
    "#     hp.hparams_config(\n",
    "#         hparams=[HP_NUM_UNITS1, HP_NUM_UNITS2, HP_NUM_UNITS3, HP_NUM_UNITS4,\n",
    "#                  HP_OPTIMIZER, HP_BATCHSIZE],\n",
    "#         metrics=[hp.Metric('loss', display_name=\"Loss\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-16 20:41:14.500521: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-16 20:41:14.501790: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-12-16 20:41:14.501946: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory\n",
      "2022-12-16 20:41:14.502034: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory\n",
      "2022-12-16 20:41:14.502111: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcufft.so.10'; dlerror: libcufft.so.10: cannot open shared object file: No such file or directory\n",
      "2022-12-16 20:41:14.502184: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcurand.so.10'; dlerror: libcurand.so.10: cannot open shared object file: No such file or directory\n",
      "2022-12-16 20:41:14.502255: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory\n",
      "2022-12-16 20:41:14.502327: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory\n",
      "2022-12-16 20:41:14.502398: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2022-12-16 20:41:14.502414: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1934] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2022-12-16 20:41:14.502964: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# METRIC_ACCURACY = 'accuracy'\n",
    "with tf.summary.create_file_writer('logs/hparam_tuning3').as_default():\n",
    "# with tf.summary.FileWriter('logs/hparam_tuning', sess.graph):\n",
    "#     init = tf.initialize_all_variables()\n",
    "#     sess.run(init)\n",
    "    hp.hparams_config(\n",
    "        hparams=[HP_LAYERS,\n",
    "                 HP_NUM_UNITS,\n",
    "                 HP_LEARNING, \n",
    "                 HP_BATCHSIZE],\n",
    "        metrics=[hp.Metric('loss', display_name=\"Loss\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_model(hparams):    \n",
    "    \n",
    "    # Train LSTM model and predict on validation set\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(Dense(int(X_train.shape[1])))\n",
    "#     model.add(Dense(hparams[HP_NUM_UNITS], input_shape=(int(X_train.shape[1]),)))\n",
    "    \n",
    "    for i in range(hparams[HP_LAYERS]):        \n",
    "        model.add(Dense(hparams[HP_NUM_UNITS], activation='relu'))\n",
    "    model.add(Dense(2, activation='linear'))\n",
    "     \n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=hparams[HP_LEARNING], beta_1=0.9, beta_2=0.999, epsilon=1e-3)\n",
    "    model.compile(\n",
    "            optimizer=optimizer,\n",
    "            loss='mse', \n",
    "            metrics=['mean_squared_error'])\n",
    "    \n",
    "    # Run with 1 epoch to speed things up for demo purposes\n",
    "\n",
    "    model.fit(X_train, Y_train, epochs=epochs, validation_data=(X_test, Y_test),\n",
    "              callbacks=callbacks, batch_size=hparams[HP_BATCHSIZE], shuffle=False, verbose=0)\n",
    "\n",
    "    _, loss = model.evaluate(X_test, Y_test)\n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(run_dir, hparams):\n",
    "    with tf.summary.create_file_writer(run_dir).as_default():\n",
    "        hp.hparams(hparams)  # record the values used in this trial\n",
    "        loss = train_test_model(hparams)\n",
    "        tf.summary.scalar(\"loss\", loss, step=1)\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Starting trial: run-0\n",
      "{'layers': 1, 'num_units': 50, 'learning_rate': 0.0001, 'batch_size': 2}\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0719 - mean_squared_error: 0.0719\n",
      "Loss: 0.07190439105033875 Tiempo transcurrido: 143.1334011554718\n",
      "\n",
      "--- Starting trial: run-1\n",
      "{'layers': 1, 'num_units': 50, 'learning_rate': 0.0001, 'batch_size': 4}\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0887 - mean_squared_error: 0.0887\n",
      "Loss: 0.0887279063463211 Tiempo transcurrido: 72.20357155799866\n",
      "\n",
      "--- Starting trial: run-2\n",
      "{'layers': 1, 'num_units': 50, 'learning_rate': 0.0001, 'batch_size': 8}\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.2440 - mean_squared_error: 0.2440\n",
      "Loss: 0.24400553107261658 Tiempo transcurrido: 41.445767879486084\n",
      "\n",
      "--- Starting trial: run-3\n",
      "{'layers': 1, 'num_units': 50, 'learning_rate': 0.0001, 'batch_size': 16}\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 16.7304 - mean_squared_error: 16.7304\n",
      "Loss: 16.730405807495117 Tiempo transcurrido: 24.01577925682068\n",
      "\n",
      "--- Starting trial: run-4\n",
      "{'layers': 1, 'num_units': 50, 'learning_rate': 0.001, 'batch_size': 2}\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0318 - mean_squared_error: 0.0318\n",
      "Loss: 0.031823232769966125 Tiempo transcurrido: 131.6856973171234\n",
      "\n",
      "--- Starting trial: run-5\n",
      "{'layers': 1, 'num_units': 50, 'learning_rate': 0.001, 'batch_size': 4}\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0336 - mean_squared_error: 0.0336\n",
      "Loss: 0.03359982743859291 Tiempo transcurrido: 83.15229320526123\n",
      "\n",
      "--- Starting trial: run-6\n",
      "{'layers': 1, 'num_units': 50, 'learning_rate': 0.001, 'batch_size': 8}\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0346 - mean_squared_error: 0.0346\n",
      "Loss: 0.034633055329322815 Tiempo transcurrido: 43.30159115791321\n",
      "\n",
      "--- Starting trial: run-7\n",
      "{'layers': 1, 'num_units': 50, 'learning_rate': 0.001, 'batch_size': 16}\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0483 - mean_squared_error: 0.0483\n",
      "Loss: 0.04834500700235367 Tiempo transcurrido: 21.632165908813477\n",
      "\n",
      "--- Starting trial: run-8\n",
      "{'layers': 1, 'num_units': 100, 'learning_rate': 0.0001, 'batch_size': 2}\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0601 - mean_squared_error: 0.0601\n",
      "Loss: 0.06006721407175064 Tiempo transcurrido: 143.49178552627563\n",
      "\n",
      "--- Starting trial: run-9\n",
      "{'layers': 1, 'num_units': 100, 'learning_rate': 0.0001, 'batch_size': 4}\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1579 - mean_squared_error: 0.1579\n",
      "Loss: 0.15792012214660645 Tiempo transcurrido: 70.21389436721802\n",
      "\n",
      "--- Starting trial: run-10\n",
      "{'layers': 1, 'num_units': 100, 'learning_rate': 0.0001, 'batch_size': 8}\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.3147 - mean_squared_error: 0.3147\n",
      "Loss: 0.3147156834602356 Tiempo transcurrido: 44.484668493270874\n",
      "\n",
      "--- Starting trial: run-11\n",
      "{'layers': 1, 'num_units': 100, 'learning_rate': 0.0001, 'batch_size': 16}\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.3227 - mean_squared_error: 1.3227\n",
      "Loss: 1.3226628303527832 Tiempo transcurrido: 28.35359239578247\n",
      "\n",
      "--- Starting trial: run-12\n",
      "{'layers': 1, 'num_units': 100, 'learning_rate': 0.001, 'batch_size': 2}\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0314 - mean_squared_error: 0.0314\n",
      "Loss: 0.031363725662231445 Tiempo transcurrido: 135.54450058937073\n",
      "\n",
      "--- Starting trial: run-13\n",
      "{'layers': 1, 'num_units': 100, 'learning_rate': 0.001, 'batch_size': 4}\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0313 - mean_squared_error: 0.0313\n",
      "Loss: 0.03131283447146416 Tiempo transcurrido: 83.10591292381287\n",
      "\n",
      "--- Starting trial: run-14\n",
      "{'layers': 1, 'num_units': 100, 'learning_rate': 0.001, 'batch_size': 8}\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0390 - mean_squared_error: 0.0390\n",
      "Loss: 0.039043787866830826 Tiempo transcurrido: 82.9837577342987\n",
      "\n",
      "--- Starting trial: run-15\n",
      "{'layers': 1, 'num_units': 100, 'learning_rate': 0.001, 'batch_size': 16}\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0482 - mean_squared_error: 0.0482\n",
      "Loss: 0.048191118985414505 Tiempo transcurrido: 25.262179851531982\n",
      "\n",
      "--- Starting trial: run-16\n",
      "{'layers': 1, 'num_units': 150, 'learning_rate': 0.0001, 'batch_size': 2}\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0610 - mean_squared_error: 0.0610\n",
      "Loss: 0.060967084020376205 Tiempo transcurrido: 143.02692317962646\n",
      "\n",
      "--- Starting trial: run-17\n",
      "{'layers': 1, 'num_units': 150, 'learning_rate': 0.0001, 'batch_size': 4}\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0565 - mean_squared_error: 0.0565\n",
      "Loss: 0.056547440588474274 Tiempo transcurrido: 75.44850564002991\n",
      "\n",
      "--- Starting trial: run-18\n",
      "{'layers': 1, 'num_units': 150, 'learning_rate': 0.0001, 'batch_size': 8}\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0940 - mean_squared_error: 0.0940\n",
      "Loss: 0.09404616057872772 Tiempo transcurrido: 45.26950740814209\n",
      "\n",
      "--- Starting trial: run-19\n",
      "{'layers': 1, 'num_units': 150, 'learning_rate': 0.0001, 'batch_size': 16}\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.3100 - mean_squared_error: 0.3100\n",
      "Loss: 0.30999070405960083 Tiempo transcurrido: 42.136067628860474\n",
      "\n",
      "--- Starting trial: run-20\n",
      "{'layers': 1, 'num_units': 150, 'learning_rate': 0.001, 'batch_size': 2}\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0352 - mean_squared_error: 0.0352\n",
      "Loss: 0.03519149869680405 Tiempo transcurrido: 132.07439970970154\n",
      "\n",
      "--- Starting trial: run-21\n",
      "{'layers': 1, 'num_units': 150, 'learning_rate': 0.001, 'batch_size': 4}\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0312 - mean_squared_error: 0.0312\n",
      "Loss: 0.03117663413286209 Tiempo transcurrido: 78.0981297492981\n",
      "\n",
      "--- Starting trial: run-22\n",
      "{'layers': 1, 'num_units': 150, 'learning_rate': 0.001, 'batch_size': 8}\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0393 - mean_squared_error: 0.0393\n",
      "Loss: 0.03928031772375107 Tiempo transcurrido: 39.4874963760376\n",
      "\n",
      "--- Starting trial: run-23\n",
      "{'layers': 1, 'num_units': 150, 'learning_rate': 0.001, 'batch_size': 16}\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0404 - mean_squared_error: 0.0404\n",
      "Loss: 0.04041144251823425 Tiempo transcurrido: 26.32261037826538\n",
      "\n",
      "--- Starting trial: run-24\n",
      "{'layers': 1, 'num_units': 200, 'learning_rate': 0.0001, 'batch_size': 2}\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0445 - mean_squared_error: 0.0445\n",
      "Loss: 0.04451208561658859 Tiempo transcurrido: 140.01277256011963\n",
      "\n",
      "--- Starting trial: run-25\n",
      "{'layers': 1, 'num_units': 200, 'learning_rate': 0.0001, 'batch_size': 4}\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0518 - mean_squared_error: 0.0518\n",
      "Loss: 0.05182833969593048 Tiempo transcurrido: 144.02222347259521\n",
      "\n",
      "--- Starting trial: run-26\n",
      "{'layers': 1, 'num_units': 200, 'learning_rate': 0.0001, 'batch_size': 8}\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0755 - mean_squared_error: 0.0755\n",
      "Loss: 0.07552791386842728 Tiempo transcurrido: 41.211554765701294\n",
      "\n",
      "--- Starting trial: run-27\n",
      "{'layers': 1, 'num_units': 200, 'learning_rate': 0.0001, 'batch_size': 16}\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1739 - mean_squared_error: 0.1739\n",
      "Loss: 0.17393718659877777 Tiempo transcurrido: 23.483869552612305\n",
      "\n",
      "--- Starting trial: run-28\n",
      "{'layers': 1, 'num_units': 200, 'learning_rate': 0.001, 'batch_size': 2}\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0344 - mean_squared_error: 0.0344\n",
      "Loss: 0.034443199634552 Tiempo transcurrido: 149.17115759849548\n",
      "\n",
      "--- Starting trial: run-29\n",
      "{'layers': 1, 'num_units': 200, 'learning_rate': 0.001, 'batch_size': 4}\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0306 - mean_squared_error: 0.0306\n",
      "Loss: 0.03055877611041069 Tiempo transcurrido: 79.70698595046997\n",
      "\n",
      "--- Starting trial: run-30\n",
      "{'layers': 1, 'num_units': 200, 'learning_rate': 0.001, 'batch_size': 8}\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0395 - mean_squared_error: 0.0395\n",
      "Loss: 0.039534058421850204 Tiempo transcurrido: 44.20717263221741\n",
      "\n",
      "--- Starting trial: run-31\n",
      "{'layers': 1, 'num_units': 200, 'learning_rate': 0.001, 'batch_size': 16}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0360 - mean_squared_error: 0.0360\n",
      "Loss: 0.036005597561597824 Tiempo transcurrido: 26.230751276016235\n",
      "\n",
      "--- Starting trial: run-32\n",
      "{'layers': 2, 'num_units': 50, 'learning_rate': 0.0001, 'batch_size': 2}\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0327 - mean_squared_error: 0.0327\n",
      "Loss: 0.03266771882772446 Tiempo transcurrido: 203.5638575553894\n",
      "\n",
      "--- Starting trial: run-33\n",
      "{'layers': 2, 'num_units': 50, 'learning_rate': 0.0001, 'batch_size': 4}\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0369 - mean_squared_error: 0.0369\n",
      "Loss: 0.03690071776509285 Tiempo transcurrido: 86.85171675682068\n",
      "\n",
      "--- Starting trial: run-34\n",
      "{'layers': 2, 'num_units': 50, 'learning_rate': 0.0001, 'batch_size': 8}\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0519 - mean_squared_error: 0.0519\n",
      "Loss: 0.05193977802991867 Tiempo transcurrido: 44.049697399139404\n",
      "\n",
      "--- Starting trial: run-35\n",
      "{'layers': 2, 'num_units': 50, 'learning_rate': 0.0001, 'batch_size': 16}\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.1396 - mean_squared_error: 0.1396\n",
      "Loss: 0.13955983519554138 Tiempo transcurrido: 32.66145133972168\n",
      "\n",
      "--- Starting trial: run-36\n",
      "{'layers': 2, 'num_units': 50, 'learning_rate': 0.001, 'batch_size': 2}\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0332 - mean_squared_error: 0.0332\n",
      "Loss: 0.03315849229693413 Tiempo transcurrido: 148.66788482666016\n",
      "\n",
      "--- Starting trial: run-37\n",
      "{'layers': 2, 'num_units': 50, 'learning_rate': 0.001, 'batch_size': 4}\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0314 - mean_squared_error: 0.0314\n",
      "Loss: 0.03140517696738243 Tiempo transcurrido: 78.2124376296997\n",
      "\n",
      "--- Starting trial: run-38\n",
      "{'layers': 2, 'num_units': 50, 'learning_rate': 0.001, 'batch_size': 8}\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0315 - mean_squared_error: 0.0315\n",
      "Loss: 0.03146663308143616 Tiempo transcurrido: 45.06856417655945\n",
      "\n",
      "--- Starting trial: run-39\n",
      "{'layers': 2, 'num_units': 50, 'learning_rate': 0.001, 'batch_size': 16}\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0359 - mean_squared_error: 0.0359\n",
      "Loss: 0.03585948422551155 Tiempo transcurrido: 25.93849229812622\n",
      "\n",
      "--- Starting trial: run-40\n",
      "{'layers': 2, 'num_units': 100, 'learning_rate': 0.0001, 'batch_size': 2}\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0306 - mean_squared_error: 0.0306\n",
      "Loss: 0.030646787956357002 Tiempo transcurrido: 143.52412033081055\n",
      "\n",
      "--- Starting trial: run-41\n",
      "{'layers': 2, 'num_units': 100, 'learning_rate': 0.0001, 'batch_size': 4}\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0353 - mean_squared_error: 0.0353\n",
      "Loss: 0.03533714637160301 Tiempo transcurrido: 81.43982553482056\n",
      "\n",
      "--- Starting trial: run-42\n",
      "{'layers': 2, 'num_units': 100, 'learning_rate': 0.0001, 'batch_size': 8}\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0410 - mean_squared_error: 0.0410\n",
      "Loss: 0.04095284268260002 Tiempo transcurrido: 41.58502221107483\n",
      "\n",
      "--- Starting trial: run-43\n",
      "{'layers': 2, 'num_units': 100, 'learning_rate': 0.0001, 'batch_size': 16}\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0609 - mean_squared_error: 0.0609\n",
      "Loss: 0.06094492971897125 Tiempo transcurrido: 22.911113739013672\n",
      "\n",
      "--- Starting trial: run-44\n",
      "{'layers': 2, 'num_units': 100, 'learning_rate': 0.001, 'batch_size': 2}\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0521 - mean_squared_error: 0.0521\n",
      "Loss: 0.052068278193473816 Tiempo transcurrido: 143.5199999809265\n",
      "\n",
      "--- Starting trial: run-45\n",
      "{'layers': 2, 'num_units': 100, 'learning_rate': 0.001, 'batch_size': 4}\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0426 - mean_squared_error: 0.0426\n",
      "Loss: 0.04258256033062935 Tiempo transcurrido: 69.12219309806824\n",
      "\n",
      "--- Starting trial: run-46\n",
      "{'layers': 2, 'num_units': 100, 'learning_rate': 0.001, 'batch_size': 8}\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0475 - mean_squared_error: 0.0475\n",
      "Loss: 0.04751524701714516 Tiempo transcurrido: 35.715370655059814\n",
      "\n",
      "--- Starting trial: run-47\n",
      "{'layers': 2, 'num_units': 100, 'learning_rate': 0.001, 'batch_size': 16}\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0368 - mean_squared_error: 0.0368\n",
      "Loss: 0.0367811881005764 Tiempo transcurrido: 23.139322519302368\n",
      "\n",
      "--- Starting trial: run-48\n",
      "{'layers': 2, 'num_units': 150, 'learning_rate': 0.0001, 'batch_size': 2}\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0314 - mean_squared_error: 0.0314\n",
      "Loss: 0.0314159169793129 Tiempo transcurrido: 109.46066856384277\n",
      "\n",
      "--- Starting trial: run-49\n",
      "{'layers': 2, 'num_units': 150, 'learning_rate': 0.0001, 'batch_size': 4}\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0375 - mean_squared_error: 0.0375\n",
      "Loss: 0.037500038743019104 Tiempo transcurrido: 67.25413846969604\n",
      "\n",
      "--- Starting trial: run-50\n",
      "{'layers': 2, 'num_units': 150, 'learning_rate': 0.0001, 'batch_size': 8}\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0371 - mean_squared_error: 0.0371\n",
      "Loss: 0.03711099177598953 Tiempo transcurrido: 46.27536082267761\n",
      "\n",
      "--- Starting trial: run-51\n",
      "{'layers': 2, 'num_units': 150, 'learning_rate': 0.0001, 'batch_size': 16}\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0567 - mean_squared_error: 0.0567\n",
      "Loss: 0.05672716349363327 Tiempo transcurrido: 28.5727961063385\n",
      "\n",
      "--- Starting trial: run-52\n",
      "{'layers': 2, 'num_units': 150, 'learning_rate': 0.001, 'batch_size': 2}\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0390 - mean_squared_error: 0.0390\n",
      "Loss: 0.03901271894574165 Tiempo transcurrido: 137.0448043346405\n",
      "\n",
      "--- Starting trial: run-53\n",
      "{'layers': 2, 'num_units': 150, 'learning_rate': 0.001, 'batch_size': 4}\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0425 - mean_squared_error: 0.0425\n",
      "Loss: 0.042506229132413864 Tiempo transcurrido: 75.24344229698181\n",
      "\n",
      "--- Starting trial: run-54\n",
      "{'layers': 2, 'num_units': 150, 'learning_rate': 0.001, 'batch_size': 8}\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0335 - mean_squared_error: 0.0335\n",
      "Loss: 0.03353526070713997 Tiempo transcurrido: 83.40481686592102\n",
      "\n",
      "--- Starting trial: run-55\n",
      "{'layers': 2, 'num_units': 150, 'learning_rate': 0.001, 'batch_size': 16}\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0506 - mean_squared_error: 0.0506\n",
      "Loss: 0.05058063194155693 Tiempo transcurrido: 24.93159008026123\n",
      "\n",
      "--- Starting trial: run-56\n",
      "{'layers': 2, 'num_units': 200, 'learning_rate': 0.0001, 'batch_size': 2}\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0312 - mean_squared_error: 0.0312\n",
      "Loss: 0.03119528293609619 Tiempo transcurrido: 152.29649996757507\n",
      "\n",
      "--- Starting trial: run-57\n",
      "{'layers': 2, 'num_units': 200, 'learning_rate': 0.0001, 'batch_size': 4}\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0345 - mean_squared_error: 0.0345\n",
      "Loss: 0.0344955250620842 Tiempo transcurrido: 75.07889366149902\n",
      "\n",
      "--- Starting trial: run-58\n",
      "{'layers': 2, 'num_units': 200, 'learning_rate': 0.0001, 'batch_size': 8}\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0356 - mean_squared_error: 0.0356\n",
      "Loss: 0.03556925430893898 Tiempo transcurrido: 37.954110860824585\n",
      "\n",
      "--- Starting trial: run-59\n",
      "{'layers': 2, 'num_units': 200, 'learning_rate': 0.0001, 'batch_size': 16}\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0511 - mean_squared_error: 0.0511\n",
      "Loss: 0.051053114235401154 Tiempo transcurrido: 26.313913822174072\n",
      "\n",
      "--- Starting trial: run-60\n",
      "{'layers': 2, 'num_units': 200, 'learning_rate': 0.001, 'batch_size': 2}\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0779 - mean_squared_error: 0.0779\n",
      "Loss: 0.07787757366895676 Tiempo transcurrido: 115.31256675720215\n",
      "\n",
      "--- Starting trial: run-61\n",
      "{'layers': 2, 'num_units': 200, 'learning_rate': 0.001, 'batch_size': 4}\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0489 - mean_squared_error: 0.0489\n",
      "Loss: 0.048936448991298676 Tiempo transcurrido: 56.28842568397522\n",
      "\n",
      "--- Starting trial: run-62\n",
      "{'layers': 2, 'num_units': 200, 'learning_rate': 0.001, 'batch_size': 8}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0330 - mean_squared_error: 0.0330\n",
      "Loss: 0.03298407047986984 Tiempo transcurrido: 33.63944411277771\n",
      "\n",
      "--- Starting trial: run-63\n",
      "{'layers': 2, 'num_units': 200, 'learning_rate': 0.001, 'batch_size': 16}\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0490 - mean_squared_error: 0.0490\n",
      "Loss: 0.04904307797551155 Tiempo transcurrido: 22.185940504074097\n",
      "\n",
      "--- Starting trial: run-64\n",
      "{'layers': 3, 'num_units': 50, 'learning_rate': 0.0001, 'batch_size': 2}\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0315 - mean_squared_error: 0.0315\n",
      "Loss: 0.0314701683819294 Tiempo transcurrido: 93.56186246871948\n",
      "\n",
      "--- Starting trial: run-65\n",
      "{'layers': 3, 'num_units': 50, 'learning_rate': 0.0001, 'batch_size': 4}\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0373 - mean_squared_error: 0.0373\n",
      "Loss: 0.03727453574538231 Tiempo transcurrido: 48.3167519569397\n",
      "\n",
      "--- Starting trial: run-66\n",
      "{'layers': 3, 'num_units': 50, 'learning_rate': 0.0001, 'batch_size': 8}\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0388 - mean_squared_error: 0.0388\n",
      "Loss: 0.03878418356180191 Tiempo transcurrido: 29.277825593948364\n",
      "\n",
      "--- Starting trial: run-67\n",
      "{'layers': 3, 'num_units': 50, 'learning_rate': 0.0001, 'batch_size': 16}\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0590 - mean_squared_error: 0.0590\n",
      "Loss: 0.05901800096035004 Tiempo transcurrido: 19.265444040298462\n",
      "\n",
      "--- Starting trial: run-68\n",
      "{'layers': 3, 'num_units': 50, 'learning_rate': 0.001, 'batch_size': 2}\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0827 - mean_squared_error: 0.0827\n",
      "Loss: 0.08273815363645554 Tiempo transcurrido: 90.23692870140076\n",
      "\n",
      "--- Starting trial: run-69\n",
      "{'layers': 3, 'num_units': 50, 'learning_rate': 0.001, 'batch_size': 4}\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0385 - mean_squared_error: 0.0385\n",
      "Loss: 0.038539811968803406 Tiempo transcurrido: 46.91512751579285\n",
      "\n",
      "--- Starting trial: run-70\n",
      "{'layers': 3, 'num_units': 50, 'learning_rate': 0.001, 'batch_size': 8}\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0356 - mean_squared_error: 0.0356\n",
      "Loss: 0.03558260574936867 Tiempo transcurrido: 42.19584894180298\n",
      "\n",
      "--- Starting trial: run-71\n",
      "{'layers': 3, 'num_units': 50, 'learning_rate': 0.001, 'batch_size': 16}\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0643 - mean_squared_error: 0.0643\n",
      "Loss: 0.06433246284723282 Tiempo transcurrido: 15.813501358032227\n",
      "\n",
      "--- Starting trial: run-72\n",
      "{'layers': 3, 'num_units': 100, 'learning_rate': 0.0001, 'batch_size': 2}\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0324 - mean_squared_error: 0.0324\n",
      "Loss: 0.03235873579978943 Tiempo transcurrido: 73.23228764533997\n",
      "\n",
      "--- Starting trial: run-73\n",
      "{'layers': 3, 'num_units': 100, 'learning_rate': 0.0001, 'batch_size': 4}\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0333 - mean_squared_error: 0.0333\n",
      "Loss: 0.033276233822107315 Tiempo transcurrido: 40.79579162597656\n",
      "\n",
      "--- Starting trial: run-74\n",
      "{'layers': 3, 'num_units': 100, 'learning_rate': 0.0001, 'batch_size': 8}\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0396 - mean_squared_error: 0.0396\n",
      "Loss: 0.03959828242659569 Tiempo transcurrido: 24.68942666053772\n",
      "\n",
      "--- Starting trial: run-75\n",
      "{'layers': 3, 'num_units': 100, 'learning_rate': 0.0001, 'batch_size': 16}\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0382 - mean_squared_error: 0.0382\n",
      "Loss: 0.03821779415011406 Tiempo transcurrido: 16.276262283325195\n",
      "\n",
      "--- Starting trial: run-76\n",
      "{'layers': 3, 'num_units': 100, 'learning_rate': 0.001, 'batch_size': 2}\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0883 - mean_squared_error: 0.0883\n",
      "Loss: 0.08830239623785019 Tiempo transcurrido: 73.74680137634277\n",
      "\n",
      "--- Starting trial: run-77\n",
      "{'layers': 3, 'num_units': 100, 'learning_rate': 0.001, 'batch_size': 4}\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0647 - mean_squared_error: 0.0647\n",
      "Loss: 0.06467192620038986 Tiempo transcurrido: 40.82426691055298\n",
      "\n",
      "--- Starting trial: run-78\n",
      "{'layers': 3, 'num_units': 100, 'learning_rate': 0.001, 'batch_size': 8}\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0343 - mean_squared_error: 0.0343\n",
      "Loss: 0.03428546339273453 Tiempo transcurrido: 25.353172063827515\n",
      "\n",
      "--- Starting trial: run-79\n",
      "{'layers': 3, 'num_units': 100, 'learning_rate': 0.001, 'batch_size': 16}\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0726 - mean_squared_error: 0.0726\n",
      "Loss: 0.07258111238479614 Tiempo transcurrido: 16.336537837982178\n",
      "\n",
      "--- Starting trial: run-80\n",
      "{'layers': 3, 'num_units': 150, 'learning_rate': 0.0001, 'batch_size': 2}\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0328 - mean_squared_error: 0.0328\n",
      "Loss: 0.03275658190250397 Tiempo transcurrido: 79.766517162323\n",
      "\n",
      "--- Starting trial: run-81\n",
      "{'layers': 3, 'num_units': 150, 'learning_rate': 0.0001, 'batch_size': 4}\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0327 - mean_squared_error: 0.0327\n",
      "Loss: 0.032675400376319885 Tiempo transcurrido: 45.604944467544556\n",
      "\n",
      "--- Starting trial: run-82\n",
      "{'layers': 3, 'num_units': 150, 'learning_rate': 0.0001, 'batch_size': 8}\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0400 - mean_squared_error: 0.0400\n",
      "Loss: 0.040005676448345184 Tiempo transcurrido: 27.121322870254517\n",
      "\n",
      "--- Starting trial: run-83\n",
      "{'layers': 3, 'num_units': 150, 'learning_rate': 0.0001, 'batch_size': 16}\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0397 - mean_squared_error: 0.0397\n",
      "Loss: 0.03971026837825775 Tiempo transcurrido: 17.801934242248535\n",
      "\n",
      "--- Starting trial: run-84\n",
      "{'layers': 3, 'num_units': 150, 'learning_rate': 0.001, 'batch_size': 2}\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1020 - mean_squared_error: 0.1020\n",
      "Loss: 0.10200880467891693 Tiempo transcurrido: 81.70073938369751\n",
      "\n",
      "--- Starting trial: run-85\n",
      "{'layers': 3, 'num_units': 150, 'learning_rate': 0.001, 'batch_size': 4}\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0331 - mean_squared_error: 0.0331\n",
      "Loss: 0.03305825591087341 Tiempo transcurrido: 46.62038326263428\n",
      "\n",
      "--- Starting trial: run-86\n",
      "{'layers': 3, 'num_units': 150, 'learning_rate': 0.001, 'batch_size': 8}\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0438 - mean_squared_error: 0.0438\n",
      "Loss: 0.04381753131747246 Tiempo transcurrido: 26.97320008277893\n",
      "\n",
      "--- Starting trial: run-87\n",
      "{'layers': 3, 'num_units': 150, 'learning_rate': 0.001, 'batch_size': 16}\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0464 - mean_squared_error: 0.0464\n",
      "Loss: 0.04638414829969406 Tiempo transcurrido: 17.662848711013794\n",
      "\n",
      "--- Starting trial: run-88\n",
      "{'layers': 3, 'num_units': 200, 'learning_rate': 0.0001, 'batch_size': 2}\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0344 - mean_squared_error: 0.0344\n",
      "Loss: 0.034404903650283813 Tiempo transcurrido: 98.73638343811035\n",
      "\n",
      "--- Starting trial: run-89\n",
      "{'layers': 3, 'num_units': 200, 'learning_rate': 0.0001, 'batch_size': 4}\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0327 - mean_squared_error: 0.0327\n",
      "Loss: 0.032652679830789566 Tiempo transcurrido: 57.94029641151428\n",
      "\n",
      "--- Starting trial: run-90\n",
      "{'layers': 3, 'num_units': 200, 'learning_rate': 0.0001, 'batch_size': 8}\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0464 - mean_squared_error: 0.0464\n",
      "Loss: 0.04641743749380112 Tiempo transcurrido: 33.424309492111206\n",
      "\n",
      "--- Starting trial: run-91\n",
      "{'layers': 3, 'num_units': 200, 'learning_rate': 0.0001, 'batch_size': 16}\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0378 - mean_squared_error: 0.0378\n",
      "Loss: 0.037756066769361496 Tiempo transcurrido: 21.21015977859497\n",
      "\n",
      "--- Starting trial: run-92\n",
      "{'layers': 3, 'num_units': 200, 'learning_rate': 0.001, 'batch_size': 2}\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1073 - mean_squared_error: 0.1073\n",
      "Loss: 0.10729777812957764 Tiempo transcurrido: 104.1364974975586\n",
      "\n",
      "--- Starting trial: run-93\n",
      "{'layers': 3, 'num_units': 200, 'learning_rate': 0.001, 'batch_size': 4}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0315 - mean_squared_error: 0.0315\n",
      "Loss: 0.03148619085550308 Tiempo transcurrido: 56.64857220649719\n",
      "\n",
      "--- Starting trial: run-94\n",
      "{'layers': 3, 'num_units': 200, 'learning_rate': 0.001, 'batch_size': 8}\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0395 - mean_squared_error: 0.0395\n",
      "Loss: 0.03948675096035004 Tiempo transcurrido: 33.042829751968384\n",
      "\n",
      "--- Starting trial: run-95\n",
      "{'layers': 3, 'num_units': 200, 'learning_rate': 0.001, 'batch_size': 16}\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0316 - mean_squared_error: 0.0316\n",
      "Loss: 0.03155450150370598 Tiempo transcurrido: 20.786914587020874\n",
      "\n",
      "--- Starting trial: run-96\n",
      "{'layers': 4, 'num_units': 50, 'learning_rate': 0.0001, 'batch_size': 2}\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0311 - mean_squared_error: 0.0311\n",
      "Loss: 0.03113345243036747 Tiempo transcurrido: 76.89717698097229\n",
      "\n",
      "--- Starting trial: run-97\n",
      "{'layers': 4, 'num_units': 50, 'learning_rate': 0.0001, 'batch_size': 4}\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0308 - mean_squared_error: 0.0308\n",
      "Loss: 0.030824271962046623 Tiempo transcurrido: 40.1299946308136\n",
      "\n",
      "--- Starting trial: run-98\n",
      "{'layers': 4, 'num_units': 50, 'learning_rate': 0.0001, 'batch_size': 8}\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0393 - mean_squared_error: 0.0393\n",
      "Loss: 0.03928893804550171 Tiempo transcurrido: 25.3365695476532\n",
      "\n",
      "--- Starting trial: run-99\n",
      "{'layers': 4, 'num_units': 50, 'learning_rate': 0.0001, 'batch_size': 16}\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0390 - mean_squared_error: 0.0390\n",
      "Loss: 0.03899766132235527 Tiempo transcurrido: 16.383368253707886\n",
      "\n",
      "--- Starting trial: run-100\n",
      "{'layers': 4, 'num_units': 50, 'learning_rate': 0.001, 'batch_size': 2}\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1146 - mean_squared_error: 0.1146\n",
      "Loss: 0.11456397920846939 Tiempo transcurrido: 72.9819724559784\n",
      "\n",
      "--- Starting trial: run-101\n",
      "{'layers': 4, 'num_units': 50, 'learning_rate': 0.001, 'batch_size': 4}\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0402 - mean_squared_error: 0.0402\n",
      "Loss: 0.04020501300692558 Tiempo transcurrido: 40.33020520210266\n",
      "\n",
      "--- Starting trial: run-102\n",
      "{'layers': 4, 'num_units': 50, 'learning_rate': 0.001, 'batch_size': 8}\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0416 - mean_squared_error: 0.0416\n",
      "Loss: 0.041634343564510345 Tiempo transcurrido: 24.305128574371338\n",
      "\n",
      "--- Starting trial: run-103\n",
      "{'layers': 4, 'num_units': 50, 'learning_rate': 0.001, 'batch_size': 16}\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0724 - mean_squared_error: 0.0724\n",
      "Loss: 0.07243025302886963 Tiempo transcurrido: 16.17339515686035\n",
      "\n",
      "--- Starting trial: run-104\n",
      "{'layers': 4, 'num_units': 100, 'learning_rate': 0.0001, 'batch_size': 2}\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0362 - mean_squared_error: 0.0362\n",
      "Loss: 0.03619128465652466 Tiempo transcurrido: 79.39935564994812\n",
      "\n",
      "--- Starting trial: run-105\n",
      "{'layers': 4, 'num_units': 100, 'learning_rate': 0.0001, 'batch_size': 4}\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0338 - mean_squared_error: 0.0338\n",
      "Loss: 0.03376361355185509 Tiempo transcurrido: 44.219407081604004\n",
      "\n",
      "--- Starting trial: run-106\n",
      "{'layers': 4, 'num_units': 100, 'learning_rate': 0.0001, 'batch_size': 8}\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0445 - mean_squared_error: 0.0445\n",
      "Loss: 0.04450511932373047 Tiempo transcurrido: 26.561662912368774\n",
      "\n",
      "--- Starting trial: run-107\n",
      "{'layers': 4, 'num_units': 100, 'learning_rate': 0.0001, 'batch_size': 16}\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0397 - mean_squared_error: 0.0397\n",
      "Loss: 0.039719872176647186 Tiempo transcurrido: 17.405810594558716\n",
      "\n",
      "--- Starting trial: run-108\n",
      "{'layers': 4, 'num_units': 100, 'learning_rate': 0.001, 'batch_size': 2}\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0599 - mean_squared_error: 0.0599\n",
      "Loss: 0.059899285435676575 Tiempo transcurrido: 79.1056067943573\n",
      "\n",
      "--- Starting trial: run-109\n",
      "{'layers': 4, 'num_units': 100, 'learning_rate': 0.001, 'batch_size': 4}\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0320 - mean_squared_error: 0.0320\n",
      "Loss: 0.032043375074863434 Tiempo transcurrido: 43.40425777435303\n",
      "\n",
      "--- Starting trial: run-110\n",
      "{'layers': 4, 'num_units': 100, 'learning_rate': 0.001, 'batch_size': 8}\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0438 - mean_squared_error: 0.0438\n",
      "Loss: 0.043772757053375244 Tiempo transcurrido: 26.221773386001587\n",
      "\n",
      "--- Starting trial: run-111\n",
      "{'layers': 4, 'num_units': 100, 'learning_rate': 0.001, 'batch_size': 16}\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0359 - mean_squared_error: 0.0359\n",
      "Loss: 0.035927753895521164 Tiempo transcurrido: 17.708653926849365\n",
      "\n",
      "--- Starting trial: run-112\n",
      "{'layers': 4, 'num_units': 150, 'learning_rate': 0.0001, 'batch_size': 2}\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0322 - mean_squared_error: 0.0322\n",
      "Loss: 0.03215634077787399 Tiempo transcurrido: 88.44043731689453\n",
      "\n",
      "--- Starting trial: run-113\n",
      "{'layers': 4, 'num_units': 150, 'learning_rate': 0.0001, 'batch_size': 4}\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0327 - mean_squared_error: 0.0327\n",
      "Loss: 0.03269195556640625 Tiempo transcurrido: 50.58175230026245\n",
      "\n",
      "--- Starting trial: run-114\n",
      "{'layers': 4, 'num_units': 150, 'learning_rate': 0.0001, 'batch_size': 8}\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0331 - mean_squared_error: 0.0331\n",
      "Loss: 0.03308473899960518 Tiempo transcurrido: 29.887192010879517\n",
      "\n",
      "--- Starting trial: run-115\n",
      "{'layers': 4, 'num_units': 150, 'learning_rate': 0.0001, 'batch_size': 16}\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0337 - mean_squared_error: 0.0337\n",
      "Loss: 0.033721961081027985 Tiempo transcurrido: 19.100475788116455\n",
      "\n",
      "--- Starting trial: run-116\n",
      "{'layers': 4, 'num_units': 150, 'learning_rate': 0.001, 'batch_size': 2}\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0948 - mean_squared_error: 0.0948\n",
      "Loss: 0.09477470070123672 Tiempo transcurrido: 89.68777084350586\n",
      "\n",
      "--- Starting trial: run-117\n",
      "{'layers': 4, 'num_units': 150, 'learning_rate': 0.001, 'batch_size': 4}\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0323 - mean_squared_error: 0.0323\n",
      "Loss: 0.032299913465976715 Tiempo transcurrido: 51.11414647102356\n",
      "\n",
      "--- Starting trial: run-118\n",
      "{'layers': 4, 'num_units': 150, 'learning_rate': 0.001, 'batch_size': 8}\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0368 - mean_squared_error: 0.0368\n",
      "Loss: 0.03682195395231247 Tiempo transcurrido: 29.55484366416931\n",
      "\n",
      "--- Starting trial: run-119\n",
      "{'layers': 4, 'num_units': 150, 'learning_rate': 0.001, 'batch_size': 16}\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0532 - mean_squared_error: 0.0532\n",
      "Loss: 0.05322708562016487 Tiempo transcurrido: 18.68226432800293\n",
      "\n",
      "--- Starting trial: run-120\n",
      "{'layers': 4, 'num_units': 200, 'learning_rate': 0.0001, 'batch_size': 2}\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0350 - mean_squared_error: 0.0350\n",
      "Loss: 0.03502216935157776 Tiempo transcurrido: 116.13387656211853\n",
      "\n",
      "--- Starting trial: run-121\n",
      "{'layers': 4, 'num_units': 200, 'learning_rate': 0.0001, 'batch_size': 4}\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0319 - mean_squared_error: 0.0319\n",
      "Loss: 0.03185321018099785 Tiempo transcurrido: 67.04130744934082\n",
      "\n",
      "--- Starting trial: run-122\n",
      "{'layers': 4, 'num_units': 200, 'learning_rate': 0.0001, 'batch_size': 8}\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0326 - mean_squared_error: 0.0326\n",
      "Loss: 0.032630495727062225 Tiempo transcurrido: 36.73371481895447\n",
      "\n",
      "--- Starting trial: run-123\n",
      "{'layers': 4, 'num_units': 200, 'learning_rate': 0.0001, 'batch_size': 16}\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0328 - mean_squared_error: 0.0328\n",
      "Loss: 0.032846588641405106 Tiempo transcurrido: 22.668042421340942\n",
      "\n",
      "--- Starting trial: run-124\n",
      "{'layers': 4, 'num_units': 200, 'learning_rate': 0.001, 'batch_size': 2}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0811 - mean_squared_error: 0.0811\n",
      "Loss: 0.08106818050146103 Tiempo transcurrido: 129.92039966583252\n",
      "\n",
      "--- Starting trial: run-125\n",
      "{'layers': 4, 'num_units': 200, 'learning_rate': 0.001, 'batch_size': 4}\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0339 - mean_squared_error: 0.0339\n",
      "Loss: 0.03393424674868584 Tiempo transcurrido: 72.5933883190155\n",
      "\n",
      "--- Starting trial: run-126\n",
      "{'layers': 4, 'num_units': 200, 'learning_rate': 0.001, 'batch_size': 8}\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0401 - mean_squared_error: 0.0401\n",
      "Loss: 0.040135458111763 Tiempo transcurrido: 39.38761878013611\n",
      "\n",
      "--- Starting trial: run-127\n",
      "{'layers': 4, 'num_units': 200, 'learning_rate': 0.001, 'batch_size': 16}\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0780 - mean_squared_error: 0.0780\n",
      "Loss: 0.07798406481742859 Tiempo transcurrido: 22.530592918395996\n",
      "128\n"
     ]
    }
   ],
   "source": [
    "session_num = 0\n",
    "datos = []\n",
    "\n",
    "for deep_layers in HP_LAYERS.domain.values:\n",
    "    for num_units in HP_NUM_UNITS.domain.values:\n",
    "        for learning_rate in HP_LEARNING.domain.values:\n",
    "            for batch_size in HP_BATCHSIZE.domain.values:\n",
    "                t = time.time()\n",
    "                hparams = {\n",
    "\n",
    "                    HP_LAYERS: deep_layers,\n",
    "                    HP_NUM_UNITS: num_units,\n",
    "                    HP_LEARNING: learning_rate,\n",
    "                    HP_BATCHSIZE: batch_size,\n",
    "                }\n",
    "                run_name = \"run-%d\" % session_num\n",
    "                print('\\n--- Starting trial: %s' % run_name)\n",
    "                print({h.name: hparams[h] for h in hparams})\n",
    "                score = run('logs/hparam_tuning3/' + run_name, hparams)\n",
    "                t = time.time()-t\n",
    "                session_num += 1\n",
    "                print(\"Loss:\", score, \"Tiempo transcurrido:\", t)\n",
    "            \n",
    "            datos.append([deep_layers, num_units, learning_rate, batch_size, score, t])\n",
    "\n",
    "print(session_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"historial_jla_tunning.txt\"\n",
    "df = pd.DataFrame(datos, columns = [\"Deep size\", \"Num units\", \"Learning rate\", \"Batch size\", \"MSE\", \"Tiempo de ejecución\"])\n",
    "\n",
    "df.sort_values(by=[\"MSE\", \"Tiempo de ejecución\"], ascending=[True, True], ignore_index=True, inplace=True)\n",
    "\n",
    "df.to_csv(filename, header=True, index=False, sep='\\t', mode='w') # a=append, w=overwrite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Deep size</th>\n",
       "      <th>Num units</th>\n",
       "      <th>Learning rate</th>\n",
       "      <th>Batch size</th>\n",
       "      <th>MSE</th>\n",
       "      <th>Tiempo de ejecución</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>200</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>16</td>\n",
       "      <td>0.031555</td>\n",
       "      <td>20.786915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>200</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>16</td>\n",
       "      <td>0.032847</td>\n",
       "      <td>22.668042</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Deep size  Num units  Learning rate  Batch size       MSE  \\\n",
       "0          3        200         0.0010          16  0.031555   \n",
       "1          4        200         0.0001          16  0.032847   \n",
       "\n",
       "   Tiempo de ejecución  \n",
       "0            20.786915  \n",
       "1            22.668042  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time 11.998 minutes\n"
     ]
    }
   ],
   "source": [
    "total_time = float(np.sum(df[[\"Tiempo de ejecución\"]])/60)\n",
    "\n",
    "print(\"Elapsed time {:.3f} minutes\".format(total_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     20.786915\n",
       "1     22.668042\n",
       "2     19.100476\n",
       "3     25.938492\n",
       "4     17.708654\n",
       "5     26.230751\n",
       "6     23.139323\n",
       "7     21.210160\n",
       "8     16.276262\n",
       "9     16.383368\n",
       "10    17.801934\n",
       "11    17.405811\n",
       "12    26.322610\n",
       "13    17.662849\n",
       "14    25.262180\n",
       "15    21.632166\n",
       "16    22.185941\n",
       "17    24.931590\n",
       "18    26.313914\n",
       "19    18.682264\n",
       "20    28.572796\n",
       "21    19.265444\n",
       "22    22.911114\n",
       "23    15.813501\n",
       "24    16.173395\n",
       "25    16.336538\n",
       "26    22.530593\n",
       "27    32.661451\n",
       "28    23.483870\n",
       "29    42.136068\n",
       "30    28.353592\n",
       "31    24.015779\n",
       "Name: Tiempo de ejecución, dtype: float64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"Tiempo de ejecución\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
