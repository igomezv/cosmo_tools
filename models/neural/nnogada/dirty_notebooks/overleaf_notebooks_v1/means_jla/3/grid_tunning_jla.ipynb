{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load_ext tensorboard\n",
    "# Clear any logs from previous runs\n",
    "# !rm -rf ./logs/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-16 16:43:49.664360: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-12-16 16:43:49.799241: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-12-16 16:43:49.799260: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2022-12-16 16:43:50.743668: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2022-12-16 16:43:50.743808: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2022-12-16 16:43:50.743822: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time, os\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Input, Dense\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorboard.plugins.hparams import api as hp\n",
    "\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split as split\n",
    "\n",
    "import random\n",
    "from math import floor\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import optimizers\n",
    "from scipy.integrate import odeint\n",
    "import scipy\n",
    "import pandas as pd\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(740, 2)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = 'https://raw.githubusercontent.com/igomezv/nnogada/main/data/jla.csv'\n",
    "df=pd.read_csv(url)\n",
    "N = len(df.values)\n",
    "randomize = np.random.permutation(N)\n",
    "data = df.values[randomize]\n",
    "N = len(df.values)\n",
    "z = data[:,0] \n",
    "y = data[:,1:3] ### coge el resto de variables a predecir \n",
    "y[:,1] = y[:,1]**2+data[:,2]\n",
    "np.shape(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "scalerz = StandardScaler()\n",
    "scalerz.fit(z.reshape(-1,1))\n",
    "z = scalerz.transform(z.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((592, 1), (148, 1), (592, 2), (148, 2))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Modificar para incluir phanteon como test\n",
    "split = 0.8\n",
    "ntrain = int(split * len(z))\n",
    "indx = [ntrain]\n",
    "X_train, X_test = np.split(z, indx)\n",
    "Y_train, Y_test = np.split(y, indx)\n",
    "np.shape(X_train), np.shape(X_test), Y_train.shape, Y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss -> val_loss\n",
    "callbacks = [tf.keras.callbacks.EarlyStopping(monitor='val_loss', mode='min',\n",
    "                                   min_delta=0.0,\n",
    "                                   patience=200,\n",
    "                                   restore_best_weights=True, verbose=True)\n",
    "                                   ]\n",
    "\n",
    "n_cols = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "HP_BATCHSIZE = hp.HParam('batch_size', hp.Discrete([2, 4, 8, 16]))\n",
    "HP_LAYERS =    hp.HParam('layers', hp.Discrete([1, 2, 3, 4]))\n",
    "HP_NUM_UNITS = hp.HParam('num_units', hp.Discrete([50, 100, 150, 200]))\n",
    "HP_LEARNING  = hp.HParam('learning_rate', hp.Discrete([1e-4,1e-3]))\n",
    "# HP_NUM_UNITS3 = hp.HParam('num_units3', hp.Discrete([50, 100, 150, 200]))\n",
    "# HP_NUM_UNITS4 = hp.HParam('num_units4', hp.Discrete([2, 5, 10]))\n",
    "# HP_DROPOUT = hp.HParam('dropout', hp.RealInterval(0.0, 0.2))\n",
    "# HP_OPTIMIZER = hp.HParam('optimizer', hp.Discrete(['adam', 'sgd']))\n",
    "# HP_OPTIMIZER = hp.HParam('optimizer', hp.Discrete(['adam', 'Adadelta']))\n",
    "# HP_OPTIMIZER = hp.HParam('optimizer', hp.Discrete(['adam']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs=200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sess = tf.Session()\n",
    "# writer = tf.summary.FileWriter(\"/tmp/tfvgg\", sess.graph)\n",
    "# init = tf.initialize_all_variables()\n",
    "# sess.run(init)\n",
    "# with tf.summary.create_file_writer('logs/hparam_tuning').as_default():\n",
    "#     hp.hparams_config(\n",
    "#         hparams=[HP_NUM_UNITS1, HP_NUM_UNITS2, HP_NUM_UNITS3, HP_NUM_UNITS4,\n",
    "#                  HP_OPTIMIZER, HP_BATCHSIZE],\n",
    "#         metrics=[hp.Metric('loss', display_name=\"Loss\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-16 16:43:52.104427: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-16 16:43:52.104635: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-12-16 16:43:52.104702: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory\n",
      "2022-12-16 16:43:52.104766: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory\n",
      "2022-12-16 16:43:52.104833: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcufft.so.10'; dlerror: libcufft.so.10: cannot open shared object file: No such file or directory\n",
      "2022-12-16 16:43:52.104888: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcurand.so.10'; dlerror: libcurand.so.10: cannot open shared object file: No such file or directory\n",
      "2022-12-16 16:43:52.104946: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory\n",
      "2022-12-16 16:43:52.105025: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory\n",
      "2022-12-16 16:43:52.105087: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2022-12-16 16:43:52.105098: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1934] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2022-12-16 16:43:52.106600: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# METRIC_ACCURACY = 'accuracy'\n",
    "with tf.summary.create_file_writer('logs/hparam_tuning3').as_default():\n",
    "# with tf.summary.FileWriter('logs/hparam_tuning', sess.graph):\n",
    "#     init = tf.initialize_all_variables()\n",
    "#     sess.run(init)\n",
    "    hp.hparams_config(\n",
    "        hparams=[HP_LAYERS,\n",
    "                 HP_NUM_UNITS,\n",
    "                 HP_LEARNING, \n",
    "                 HP_BATCHSIZE],\n",
    "        metrics=[hp.Metric('loss', display_name=\"Loss\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_model(hparams):    \n",
    "    \n",
    "    # Train LSTM model and predict on validation set\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(Dense(int(X_train.shape[1])))\n",
    "#     model.add(Dense(hparams[HP_NUM_UNITS], input_shape=(int(X_train.shape[1]),)))\n",
    "    \n",
    "    for i in range(hparams[HP_LAYERS]):        \n",
    "        model.add(Dense(hparams[HP_NUM_UNITS], activation='relu'))\n",
    "    model.add(Dense(2, activation='linear'))\n",
    "     \n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=hparams[HP_LEARNING], beta_1=0.9, beta_2=0.999, epsilon=1e-3)\n",
    "    model.compile(\n",
    "            optimizer=optimizer,\n",
    "            loss='mse', \n",
    "            metrics=['mean_squared_error'])\n",
    "    \n",
    "    # Run with 1 epoch to speed things up for demo purposes\n",
    "\n",
    "    model.fit(X_train, Y_train, epochs=epochs, validation_data=(X_test, Y_test),\n",
    "              callbacks=callbacks, batch_size=hparams[HP_BATCHSIZE], shuffle=False, verbose=0)\n",
    "\n",
    "    _, loss = model.evaluate(X_test, Y_test)\n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(run_dir, hparams):\n",
    "    with tf.summary.create_file_writer(run_dir).as_default():\n",
    "        hp.hparams(hparams)  # record the values used in this trial\n",
    "        loss = train_test_model(hparams)\n",
    "        tf.summary.scalar(\"loss\", loss, step=1)\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Starting trial: run-0\n",
      "{'layers': 1, 'num_units': 50, 'learning_rate': 0.0001, 'batch_size': 2}\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0621 - mean_squared_error: 0.0621\n",
      "Loss: 0.06205371767282486 Tiempo transcurrido: 98.10645055770874\n",
      "\n",
      "--- Starting trial: run-1\n",
      "{'layers': 1, 'num_units': 50, 'learning_rate': 0.0001, 'batch_size': 4}\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1203 - mean_squared_error: 0.1203\n",
      "Loss: 0.1203412264585495 Tiempo transcurrido: 53.0462965965271\n",
      "\n",
      "--- Starting trial: run-2\n",
      "{'layers': 1, 'num_units': 50, 'learning_rate': 0.0001, 'batch_size': 8}\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2490 - mean_squared_error: 0.2490\n",
      "Loss: 0.24895435571670532 Tiempo transcurrido: 30.353832244873047\n",
      "\n",
      "--- Starting trial: run-3\n",
      "{'layers': 1, 'num_units': 50, 'learning_rate': 0.0001, 'batch_size': 16}\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 6.5854 - mean_squared_error: 6.5854\n",
      "Loss: 6.585424900054932 Tiempo transcurrido: 17.77020835876465\n",
      "\n",
      "--- Starting trial: run-4\n",
      "{'layers': 1, 'num_units': 50, 'learning_rate': 0.001, 'batch_size': 2}\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0404 - mean_squared_error: 0.0404\n",
      "Loss: 0.04041042923927307 Tiempo transcurrido: 142.85898852348328\n",
      "\n",
      "--- Starting trial: run-5\n",
      "{'layers': 1, 'num_units': 50, 'learning_rate': 0.001, 'batch_size': 4}\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0348 - mean_squared_error: 0.0348\n",
      "Loss: 0.03482748568058014 Tiempo transcurrido: 58.83764338493347\n",
      "\n",
      "--- Starting trial: run-6\n",
      "{'layers': 1, 'num_units': 50, 'learning_rate': 0.001, 'batch_size': 8}\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0356 - mean_squared_error: 0.0356\n",
      "Loss: 0.03556438907980919 Tiempo transcurrido: 32.92354226112366\n",
      "\n",
      "--- Starting trial: run-7\n",
      "{'layers': 1, 'num_units': 50, 'learning_rate': 0.001, 'batch_size': 16}\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0407 - mean_squared_error: 0.0407\n",
      "Loss: 0.04065091907978058 Tiempo transcurrido: 20.273613214492798\n",
      "\n",
      "--- Starting trial: run-8\n",
      "{'layers': 1, 'num_units': 100, 'learning_rate': 0.0001, 'batch_size': 2}\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0552 - mean_squared_error: 0.0552\n",
      "Loss: 0.055176716297864914 Tiempo transcurrido: 97.48126149177551\n",
      "\n",
      "--- Starting trial: run-9\n",
      "{'layers': 1, 'num_units': 100, 'learning_rate': 0.0001, 'batch_size': 4}\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2142 - mean_squared_error: 0.2142\n",
      "Loss: 0.21424362063407898 Tiempo transcurrido: 82.9617714881897\n",
      "\n",
      "--- Starting trial: run-10\n",
      "{'layers': 1, 'num_units': 100, 'learning_rate': 0.0001, 'batch_size': 8}\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1451 - mean_squared_error: 0.1451\n",
      "Loss: 0.14512605965137482 Tiempo transcurrido: 32.9144504070282\n",
      "\n",
      "--- Starting trial: run-11\n",
      "{'layers': 1, 'num_units': 100, 'learning_rate': 0.0001, 'batch_size': 16}\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.9998 - mean_squared_error: 0.9998\n",
      "Loss: 0.9997764825820923 Tiempo transcurrido: 20.444350004196167\n",
      "\n",
      "--- Starting trial: run-12\n",
      "{'layers': 1, 'num_units': 100, 'learning_rate': 0.001, 'batch_size': 2}\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0319 - mean_squared_error: 0.0319\n",
      "Loss: 0.03186242654919624 Tiempo transcurrido: 96.33841395378113\n",
      "\n",
      "--- Starting trial: run-13\n",
      "{'layers': 1, 'num_units': 100, 'learning_rate': 0.001, 'batch_size': 4}\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0363 - mean_squared_error: 0.0363\n",
      "Loss: 0.036250289529561996 Tiempo transcurrido: 52.332852602005005\n",
      "\n",
      "--- Starting trial: run-14\n",
      "{'layers': 1, 'num_units': 100, 'learning_rate': 0.001, 'batch_size': 8}\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0364 - mean_squared_error: 0.0364\n",
      "Loss: 0.03637341782450676 Tiempo transcurrido: 28.72354245185852\n",
      "\n",
      "--- Starting trial: run-15\n",
      "{'layers': 1, 'num_units': 100, 'learning_rate': 0.001, 'batch_size': 16}\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0467 - mean_squared_error: 0.0467\n",
      "Loss: 0.04666152223944664 Tiempo transcurrido: 16.754388332366943\n",
      "\n",
      "--- Starting trial: run-16\n",
      "{'layers': 1, 'num_units': 150, 'learning_rate': 0.0001, 'batch_size': 2}\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0613 - mean_squared_error: 0.0613\n",
      "Loss: 0.061288826167583466 Tiempo transcurrido: 100.82583665847778\n",
      "\n",
      "--- Starting trial: run-17\n",
      "{'layers': 1, 'num_units': 150, 'learning_rate': 0.0001, 'batch_size': 4}\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0632 - mean_squared_error: 0.0632\n",
      "Loss: 0.06321732699871063 Tiempo transcurrido: 57.64329171180725\n",
      "\n",
      "--- Starting trial: run-18\n",
      "{'layers': 1, 'num_units': 150, 'learning_rate': 0.0001, 'batch_size': 8}\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0997 - mean_squared_error: 0.0997\n",
      "Loss: 0.09966973215341568 Tiempo transcurrido: 36.10141634941101\n",
      "\n",
      "--- Starting trial: run-19\n",
      "{'layers': 1, 'num_units': 150, 'learning_rate': 0.0001, 'batch_size': 16}\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6250 - mean_squared_error: 0.6250\n",
      "Loss: 0.6250114440917969 Tiempo transcurrido: 22.035711526870728\n",
      "\n",
      "--- Starting trial: run-20\n",
      "{'layers': 1, 'num_units': 150, 'learning_rate': 0.001, 'batch_size': 2}\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0364 - mean_squared_error: 0.0364\n",
      "Loss: 0.03643004223704338 Tiempo transcurrido: 103.48433923721313\n",
      "\n",
      "--- Starting trial: run-21\n",
      "{'layers': 1, 'num_units': 150, 'learning_rate': 0.001, 'batch_size': 4}\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0372 - mean_squared_error: 0.0372\n",
      "Loss: 0.03716033324599266 Tiempo transcurrido: 55.105499505996704\n",
      "\n",
      "--- Starting trial: run-22\n",
      "{'layers': 1, 'num_units': 150, 'learning_rate': 0.001, 'batch_size': 8}\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0373 - mean_squared_error: 0.0373\n",
      "Loss: 0.03727933391928673 Tiempo transcurrido: 35.815168142318726\n",
      "\n",
      "--- Starting trial: run-23\n",
      "{'layers': 1, 'num_units': 150, 'learning_rate': 0.001, 'batch_size': 16}\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0394 - mean_squared_error: 0.0394\n",
      "Loss: 0.03938831016421318 Tiempo transcurrido: 20.815080642700195\n",
      "\n",
      "--- Starting trial: run-24\n",
      "{'layers': 1, 'num_units': 200, 'learning_rate': 0.0001, 'batch_size': 2}\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0598 - mean_squared_error: 0.0598\n",
      "Loss: 0.059781789779663086 Tiempo transcurrido: 98.29932188987732\n",
      "\n",
      "--- Starting trial: run-25\n",
      "{'layers': 1, 'num_units': 200, 'learning_rate': 0.0001, 'batch_size': 4}\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0560 - mean_squared_error: 0.0560\n",
      "Loss: 0.055981460958719254 Tiempo transcurrido: 55.86039972305298\n",
      "\n",
      "--- Starting trial: run-26\n",
      "{'layers': 1, 'num_units': 200, 'learning_rate': 0.0001, 'batch_size': 8}\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0772 - mean_squared_error: 0.0772\n",
      "Loss: 0.07724521309137344 Tiempo transcurrido: 36.73892569541931\n",
      "\n",
      "--- Starting trial: run-27\n",
      "{'layers': 1, 'num_units': 200, 'learning_rate': 0.0001, 'batch_size': 16}\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2113 - mean_squared_error: 0.2113\n",
      "Loss: 0.2112843096256256 Tiempo transcurrido: 21.89050316810608\n",
      "\n",
      "--- Starting trial: run-28\n",
      "{'layers': 1, 'num_units': 200, 'learning_rate': 0.001, 'batch_size': 2}\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0337 - mean_squared_error: 0.0337\n",
      "Loss: 0.03367964178323746 Tiempo transcurrido: 97.20282292366028\n",
      "\n",
      "--- Starting trial: run-29\n",
      "{'layers': 1, 'num_units': 200, 'learning_rate': 0.001, 'batch_size': 4}\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0365 - mean_squared_error: 0.0365\n",
      "Loss: 0.03646397590637207 Tiempo transcurrido: 52.2591016292572\n",
      "\n",
      "--- Starting trial: run-30\n",
      "{'layers': 1, 'num_units': 200, 'learning_rate': 0.001, 'batch_size': 8}\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0400 - mean_squared_error: 0.0400\n",
      "Loss: 0.03999900817871094 Tiempo transcurrido: 34.89444088935852\n",
      "\n",
      "--- Starting trial: run-31\n",
      "{'layers': 1, 'num_units': 200, 'learning_rate': 0.001, 'batch_size': 16}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0395 - mean_squared_error: 0.0395\n",
      "Loss: 0.03949914500117302 Tiempo transcurrido: 20.77964425086975\n",
      "\n",
      "--- Starting trial: run-32\n",
      "{'layers': 2, 'num_units': 50, 'learning_rate': 0.0001, 'batch_size': 2}\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0346 - mean_squared_error: 0.0346\n",
      "Loss: 0.03456685319542885 Tiempo transcurrido: 143.23218274116516\n",
      "\n",
      "--- Starting trial: run-33\n",
      "{'layers': 2, 'num_units': 50, 'learning_rate': 0.0001, 'batch_size': 4}\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0396 - mean_squared_error: 0.0396\n",
      "Loss: 0.039649561047554016 Tiempo transcurrido: 57.16809010505676\n",
      "\n",
      "--- Starting trial: run-34\n",
      "{'layers': 2, 'num_units': 50, 'learning_rate': 0.0001, 'batch_size': 8}\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0674 - mean_squared_error: 0.0674\n",
      "Loss: 0.06735040992498398 Tiempo transcurrido: 36.64599895477295\n",
      "\n",
      "--- Starting trial: run-35\n",
      "{'layers': 2, 'num_units': 50, 'learning_rate': 0.0001, 'batch_size': 16}\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0994 - mean_squared_error: 0.0994\n",
      "Loss: 0.0994093120098114 Tiempo transcurrido: 24.705475330352783\n",
      "\n",
      "--- Starting trial: run-36\n",
      "{'layers': 2, 'num_units': 50, 'learning_rate': 0.001, 'batch_size': 2}\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0527 - mean_squared_error: 0.0527\n",
      "Loss: 0.052696343511343 Tiempo transcurrido: 111.55013871192932\n",
      "\n",
      "--- Starting trial: run-37\n",
      "{'layers': 2, 'num_units': 50, 'learning_rate': 0.001, 'batch_size': 4}\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0363 - mean_squared_error: 0.0363\n",
      "Loss: 0.03625961393117905 Tiempo transcurrido: 52.19295644760132\n",
      "\n",
      "--- Starting trial: run-38\n",
      "{'layers': 2, 'num_units': 50, 'learning_rate': 0.001, 'batch_size': 8}\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0298 - mean_squared_error: 0.0298\n",
      "Loss: 0.02982034534215927 Tiempo transcurrido: 33.51218128204346\n",
      "\n",
      "--- Starting trial: run-39\n",
      "{'layers': 2, 'num_units': 50, 'learning_rate': 0.001, 'batch_size': 16}\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0385 - mean_squared_error: 0.0385\n",
      "Loss: 0.038514576852321625 Tiempo transcurrido: 18.736623287200928\n",
      "\n",
      "--- Starting trial: run-40\n",
      "{'layers': 2, 'num_units': 100, 'learning_rate': 0.0001, 'batch_size': 2}\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0311 - mean_squared_error: 0.0311\n",
      "Loss: 0.031126905232667923 Tiempo transcurrido: 98.01839256286621\n",
      "\n",
      "--- Starting trial: run-41\n",
      "{'layers': 2, 'num_units': 100, 'learning_rate': 0.0001, 'batch_size': 4}\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0373 - mean_squared_error: 0.0373\n",
      "Loss: 0.03727968409657478 Tiempo transcurrido: 56.72949719429016\n",
      "\n",
      "--- Starting trial: run-42\n",
      "{'layers': 2, 'num_units': 100, 'learning_rate': 0.0001, 'batch_size': 8}\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0406 - mean_squared_error: 0.0406\n",
      "Loss: 0.040648628026247025 Tiempo transcurrido: 35.7290518283844\n",
      "\n",
      "--- Starting trial: run-43\n",
      "{'layers': 2, 'num_units': 100, 'learning_rate': 0.0001, 'batch_size': 16}\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0745 - mean_squared_error: 0.0745\n",
      "Loss: 0.07452134042978287 Tiempo transcurrido: 21.273690938949585\n",
      "\n",
      "--- Starting trial: run-44\n",
      "{'layers': 2, 'num_units': 100, 'learning_rate': 0.001, 'batch_size': 2}\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0906 - mean_squared_error: 0.0906\n",
      "Loss: 0.09062563627958298 Tiempo transcurrido: 92.48535084724426\n",
      "\n",
      "--- Starting trial: run-45\n",
      "{'layers': 2, 'num_units': 100, 'learning_rate': 0.001, 'batch_size': 4}\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0656 - mean_squared_error: 0.0656\n",
      "Loss: 0.06562288105487823 Tiempo transcurrido: 50.84422278404236\n",
      "\n",
      "--- Starting trial: run-46\n",
      "{'layers': 2, 'num_units': 100, 'learning_rate': 0.001, 'batch_size': 8}\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0429 - mean_squared_error: 0.0429\n",
      "Loss: 0.04290306568145752 Tiempo transcurrido: 30.616663932800293\n",
      "\n",
      "--- Starting trial: run-47\n",
      "{'layers': 2, 'num_units': 100, 'learning_rate': 0.001, 'batch_size': 16}\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0359 - mean_squared_error: 0.0359\n",
      "Loss: 0.03585685417056084 Tiempo transcurrido: 20.69601082801819\n",
      "\n",
      "--- Starting trial: run-48\n",
      "{'layers': 2, 'num_units': 150, 'learning_rate': 0.0001, 'batch_size': 2}\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0322 - mean_squared_error: 0.0322\n",
      "Loss: 0.032192301005125046 Tiempo transcurrido: 102.70793747901917\n",
      "\n",
      "--- Starting trial: run-49\n",
      "{'layers': 2, 'num_units': 150, 'learning_rate': 0.0001, 'batch_size': 4}\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0369 - mean_squared_error: 0.0369\n",
      "Loss: 0.036884233355522156 Tiempo transcurrido: 44.76235008239746\n",
      "\n",
      "--- Starting trial: run-50\n",
      "{'layers': 2, 'num_units': 150, 'learning_rate': 0.0001, 'batch_size': 8}\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0369 - mean_squared_error: 0.0369\n",
      "Loss: 0.03687223047018051 Tiempo transcurrido: 24.28323221206665\n",
      "\n",
      "--- Starting trial: run-51\n",
      "{'layers': 2, 'num_units': 150, 'learning_rate': 0.0001, 'batch_size': 16}\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0617 - mean_squared_error: 0.0617\n",
      "Loss: 0.061703771352767944 Tiempo transcurrido: 17.909512281417847\n",
      "\n",
      "--- Starting trial: run-52\n",
      "{'layers': 2, 'num_units': 150, 'learning_rate': 0.001, 'batch_size': 2}\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0727 - mean_squared_error: 0.0727\n",
      "Loss: 0.07272297888994217 Tiempo transcurrido: 81.26591682434082\n",
      "\n",
      "--- Starting trial: run-53\n",
      "{'layers': 2, 'num_units': 150, 'learning_rate': 0.001, 'batch_size': 4}\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0358 - mean_squared_error: 0.0358\n",
      "Loss: 0.03583359718322754 Tiempo transcurrido: 45.38303089141846\n",
      "\n",
      "--- Starting trial: run-54\n",
      "{'layers': 2, 'num_units': 150, 'learning_rate': 0.001, 'batch_size': 8}\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0372 - mean_squared_error: 0.0372\n",
      "Loss: 0.03715793043375015 Tiempo transcurrido: 26.007198572158813\n",
      "\n",
      "--- Starting trial: run-55\n",
      "{'layers': 2, 'num_units': 150, 'learning_rate': 0.001, 'batch_size': 16}\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0421 - mean_squared_error: 0.0421\n",
      "Loss: 0.0420602448284626 Tiempo transcurrido: 16.088558673858643\n",
      "\n",
      "--- Starting trial: run-56\n",
      "{'layers': 2, 'num_units': 200, 'learning_rate': 0.0001, 'batch_size': 2}\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0308 - mean_squared_error: 0.0308\n",
      "Loss: 0.030752813443541527 Tiempo transcurrido: 89.2985143661499\n",
      "\n",
      "--- Starting trial: run-57\n",
      "{'layers': 2, 'num_units': 200, 'learning_rate': 0.0001, 'batch_size': 4}\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0360 - mean_squared_error: 0.0360\n",
      "Loss: 0.03601806238293648 Tiempo transcurrido: 46.71971154212952\n",
      "\n",
      "--- Starting trial: run-58\n",
      "{'layers': 2, 'num_units': 200, 'learning_rate': 0.0001, 'batch_size': 8}\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0370 - mean_squared_error: 0.0370\n",
      "Loss: 0.03700636699795723 Tiempo transcurrido: 26.849586248397827\n",
      "\n",
      "--- Starting trial: run-59\n",
      "{'layers': 2, 'num_units': 200, 'learning_rate': 0.0001, 'batch_size': 16}\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0529 - mean_squared_error: 0.0529\n",
      "Loss: 0.05285359546542168 Tiempo transcurrido: 17.42599081993103\n",
      "\n",
      "--- Starting trial: run-60\n",
      "{'layers': 2, 'num_units': 200, 'learning_rate': 0.001, 'batch_size': 2}\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0712 - mean_squared_error: 0.0712\n",
      "Loss: 0.07123202085494995 Tiempo transcurrido: 80.51410508155823\n",
      "\n",
      "--- Starting trial: run-61\n",
      "{'layers': 2, 'num_units': 200, 'learning_rate': 0.001, 'batch_size': 4}\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0470 - mean_squared_error: 0.0470\n",
      "Loss: 0.04696006700396538 Tiempo transcurrido: 43.79397964477539\n",
      "\n",
      "--- Starting trial: run-62\n",
      "{'layers': 2, 'num_units': 200, 'learning_rate': 0.001, 'batch_size': 8}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0322 - mean_squared_error: 0.0322\n",
      "Loss: 0.03223836421966553 Tiempo transcurrido: 23.921727895736694\n",
      "\n",
      "--- Starting trial: run-63\n",
      "{'layers': 2, 'num_units': 200, 'learning_rate': 0.001, 'batch_size': 16}\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0536 - mean_squared_error: 0.0536\n",
      "Loss: 0.05364613980054855 Tiempo transcurrido: 15.992690563201904\n",
      "\n",
      "--- Starting trial: run-64\n",
      "{'layers': 3, 'num_units': 50, 'learning_rate': 0.0001, 'batch_size': 2}\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0309 - mean_squared_error: 0.0309\n",
      "Loss: 0.030946731567382812 Tiempo transcurrido: 61.80705118179321\n",
      "\n",
      "--- Starting trial: run-65\n",
      "{'layers': 3, 'num_units': 50, 'learning_rate': 0.0001, 'batch_size': 4}\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0365 - mean_squared_error: 0.0365\n",
      "Loss: 0.03648320212960243 Tiempo transcurrido: 32.22715711593628\n",
      "\n",
      "--- Starting trial: run-66\n",
      "{'layers': 3, 'num_units': 50, 'learning_rate': 0.0001, 'batch_size': 8}\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0368 - mean_squared_error: 0.0368\n",
      "Loss: 0.03682827204465866 Tiempo transcurrido: 19.229042530059814\n",
      "\n",
      "--- Starting trial: run-67\n",
      "{'layers': 3, 'num_units': 50, 'learning_rate': 0.0001, 'batch_size': 16}\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0650 - mean_squared_error: 0.0650\n",
      "Loss: 0.06499543786048889 Tiempo transcurrido: 12.726301670074463\n",
      "\n",
      "--- Starting trial: run-68\n",
      "{'layers': 3, 'num_units': 50, 'learning_rate': 0.001, 'batch_size': 2}\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0641 - mean_squared_error: 0.0641\n",
      "Loss: 0.06414134055376053 Tiempo transcurrido: 58.173182010650635\n",
      "\n",
      "--- Starting trial: run-69\n",
      "{'layers': 3, 'num_units': 50, 'learning_rate': 0.001, 'batch_size': 4}\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0449 - mean_squared_error: 0.0449\n",
      "Loss: 0.04487201198935509 Tiempo transcurrido: 31.74099564552307\n",
      "\n",
      "--- Starting trial: run-70\n",
      "{'layers': 3, 'num_units': 50, 'learning_rate': 0.001, 'batch_size': 8}\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0335 - mean_squared_error: 0.0335\n",
      "Loss: 0.0334760956466198 Tiempo transcurrido: 19.45838689804077\n",
      "\n",
      "--- Starting trial: run-71\n",
      "{'layers': 3, 'num_units': 50, 'learning_rate': 0.001, 'batch_size': 16}\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0580 - mean_squared_error: 0.0580\n",
      "Loss: 0.05795304849743843 Tiempo transcurrido: 12.41835618019104\n",
      "\n",
      "--- Starting trial: run-72\n",
      "{'layers': 3, 'num_units': 100, 'learning_rate': 0.0001, 'batch_size': 2}\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0333 - mean_squared_error: 0.0333\n",
      "Loss: 0.033338513225317 Tiempo transcurrido: 59.69384288787842\n",
      "\n",
      "--- Starting trial: run-73\n",
      "{'layers': 3, 'num_units': 100, 'learning_rate': 0.0001, 'batch_size': 4}\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0322 - mean_squared_error: 0.0322\n",
      "Loss: 0.03217489644885063 Tiempo transcurrido: 33.04589366912842\n",
      "\n",
      "--- Starting trial: run-74\n",
      "{'layers': 3, 'num_units': 100, 'learning_rate': 0.0001, 'batch_size': 8}\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0360 - mean_squared_error: 0.0360\n",
      "Loss: 0.0360097773373127 Tiempo transcurrido: 19.943415641784668\n",
      "\n",
      "--- Starting trial: run-75\n",
      "{'layers': 3, 'num_units': 100, 'learning_rate': 0.0001, 'batch_size': 16}\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0507 - mean_squared_error: 0.0507\n",
      "Loss: 0.05067414790391922 Tiempo transcurrido: 13.201733827590942\n",
      "\n",
      "--- Starting trial: run-76\n",
      "{'layers': 3, 'num_units': 100, 'learning_rate': 0.001, 'batch_size': 2}\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0673 - mean_squared_error: 0.0673\n",
      "Loss: 0.06727568805217743 Tiempo transcurrido: 60.89993739128113\n",
      "\n",
      "--- Starting trial: run-77\n",
      "{'layers': 3, 'num_units': 100, 'learning_rate': 0.001, 'batch_size': 4}\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0380 - mean_squared_error: 0.0380\n",
      "Loss: 0.038002777844667435 Tiempo transcurrido: 32.94067454338074\n",
      "\n",
      "--- Starting trial: run-78\n",
      "{'layers': 3, 'num_units': 100, 'learning_rate': 0.001, 'batch_size': 8}\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0461 - mean_squared_error: 0.0461\n",
      "Loss: 0.046133093535900116 Tiempo transcurrido: 20.05684232711792\n",
      "\n",
      "--- Starting trial: run-79\n",
      "{'layers': 3, 'num_units': 100, 'learning_rate': 0.001, 'batch_size': 16}\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0826 - mean_squared_error: 0.0826\n",
      "Loss: 0.08257950842380524 Tiempo transcurrido: 12.948185920715332\n",
      "\n",
      "--- Starting trial: run-80\n",
      "{'layers': 3, 'num_units': 150, 'learning_rate': 0.0001, 'batch_size': 2}\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0330 - mean_squared_error: 0.0330\n",
      "Loss: 0.03297610953450203 Tiempo transcurrido: 64.1043770313263\n",
      "\n",
      "--- Starting trial: run-81\n",
      "{'layers': 3, 'num_units': 150, 'learning_rate': 0.0001, 'batch_size': 4}\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0306 - mean_squared_error: 0.0306\n",
      "Loss: 0.030570823699235916 Tiempo transcurrido: 35.03871273994446\n",
      "\n",
      "--- Starting trial: run-82\n",
      "{'layers': 3, 'num_units': 150, 'learning_rate': 0.0001, 'batch_size': 8}\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0450 - mean_squared_error: 0.0450\n",
      "Loss: 0.04502512514591217 Tiempo transcurrido: 21.307605743408203\n",
      "\n",
      "--- Starting trial: run-83\n",
      "{'layers': 3, 'num_units': 150, 'learning_rate': 0.0001, 'batch_size': 16}\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0390 - mean_squared_error: 0.0390\n",
      "Loss: 0.038967739790678024 Tiempo transcurrido: 14.465001106262207\n",
      "\n",
      "--- Starting trial: run-84\n",
      "{'layers': 3, 'num_units': 150, 'learning_rate': 0.001, 'batch_size': 2}\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1094 - mean_squared_error: 0.1094\n",
      "Loss: 0.10938270390033722 Tiempo transcurrido: 64.41470170021057\n",
      "\n",
      "--- Starting trial: run-85\n",
      "{'layers': 3, 'num_units': 150, 'learning_rate': 0.001, 'batch_size': 4}\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0325 - mean_squared_error: 0.0325\n",
      "Loss: 0.03252888843417168 Tiempo transcurrido: 34.96528959274292\n",
      "\n",
      "--- Starting trial: run-86\n",
      "{'layers': 3, 'num_units': 150, 'learning_rate': 0.001, 'batch_size': 8}\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0405 - mean_squared_error: 0.0405\n",
      "Loss: 0.04045137017965317 Tiempo transcurrido: 21.266677379608154\n",
      "\n",
      "--- Starting trial: run-87\n",
      "{'layers': 3, 'num_units': 150, 'learning_rate': 0.001, 'batch_size': 16}\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0444 - mean_squared_error: 0.0444\n",
      "Loss: 0.044394705444574356 Tiempo transcurrido: 13.779430627822876\n",
      "\n",
      "--- Starting trial: run-88\n",
      "{'layers': 3, 'num_units': 200, 'learning_rate': 0.0001, 'batch_size': 2}\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0362 - mean_squared_error: 0.0362\n",
      "Loss: 0.036216650158166885 Tiempo transcurrido: 70.51801204681396\n",
      "\n",
      "--- Starting trial: run-89\n",
      "{'layers': 3, 'num_units': 200, 'learning_rate': 0.0001, 'batch_size': 4}\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0336 - mean_squared_error: 0.0336\n",
      "Loss: 0.03358228877186775 Tiempo transcurrido: 39.69836902618408\n",
      "\n",
      "--- Starting trial: run-90\n",
      "{'layers': 3, 'num_units': 200, 'learning_rate': 0.0001, 'batch_size': 8}\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0520 - mean_squared_error: 0.0520\n",
      "Loss: 0.05199902877211571 Tiempo transcurrido: 23.76507043838501\n",
      "\n",
      "--- Starting trial: run-91\n",
      "{'layers': 3, 'num_units': 200, 'learning_rate': 0.0001, 'batch_size': 16}\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0381 - mean_squared_error: 0.0381\n",
      "Loss: 0.038113173097372055 Tiempo transcurrido: 15.387176036834717\n",
      "\n",
      "--- Starting trial: run-92\n",
      "{'layers': 3, 'num_units': 200, 'learning_rate': 0.001, 'batch_size': 2}\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1206 - mean_squared_error: 0.1206\n",
      "Loss: 0.12062498182058334 Tiempo transcurrido: 72.49196171760559\n",
      "\n",
      "--- Starting trial: run-93\n",
      "{'layers': 3, 'num_units': 200, 'learning_rate': 0.001, 'batch_size': 4}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0319 - mean_squared_error: 0.0319\n",
      "Loss: 0.03194231912493706 Tiempo transcurrido: 39.13094139099121\n",
      "\n",
      "--- Starting trial: run-94\n",
      "{'layers': 3, 'num_units': 200, 'learning_rate': 0.001, 'batch_size': 8}\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0448 - mean_squared_error: 0.0448\n",
      "Loss: 0.044801026582717896 Tiempo transcurrido: 23.628043174743652\n",
      "\n",
      "--- Starting trial: run-95\n",
      "{'layers': 3, 'num_units': 200, 'learning_rate': 0.001, 'batch_size': 16}\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0325 - mean_squared_error: 0.0325\n",
      "Loss: 0.032527852803468704 Tiempo transcurrido: 15.28300929069519\n",
      "\n",
      "--- Starting trial: run-96\n",
      "{'layers': 4, 'num_units': 50, 'learning_rate': 0.0001, 'batch_size': 2}\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0315 - mean_squared_error: 0.0315\n",
      "Loss: 0.03145481273531914 Tiempo transcurrido: 63.310216188430786\n",
      "\n",
      "--- Starting trial: run-97\n",
      "{'layers': 4, 'num_units': 50, 'learning_rate': 0.0001, 'batch_size': 4}\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0358 - mean_squared_error: 0.0358\n",
      "Loss: 0.03576801344752312 Tiempo transcurrido: 33.700523853302\n",
      "\n",
      "--- Starting trial: run-98\n",
      "{'layers': 4, 'num_units': 50, 'learning_rate': 0.0001, 'batch_size': 8}\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0362 - mean_squared_error: 0.0362\n",
      "Loss: 0.03624391183257103 Tiempo transcurrido: 20.120734214782715\n",
      "\n",
      "--- Starting trial: run-99\n",
      "{'layers': 4, 'num_units': 50, 'learning_rate': 0.0001, 'batch_size': 16}\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0370 - mean_squared_error: 0.0370\n",
      "Loss: 0.036961544305086136 Tiempo transcurrido: 13.272430658340454\n",
      "\n",
      "--- Starting trial: run-100\n",
      "{'layers': 4, 'num_units': 50, 'learning_rate': 0.001, 'batch_size': 2}\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1339 - mean_squared_error: 0.1339\n",
      "Loss: 0.13389530777931213 Tiempo transcurrido: 60.76437187194824\n",
      "\n",
      "--- Starting trial: run-101\n",
      "{'layers': 4, 'num_units': 50, 'learning_rate': 0.001, 'batch_size': 4}\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0549 - mean_squared_error: 0.0549\n",
      "Loss: 0.05490570515394211 Tiempo transcurrido: 33.18026804924011\n",
      "\n",
      "--- Starting trial: run-102\n",
      "{'layers': 4, 'num_units': 50, 'learning_rate': 0.001, 'batch_size': 8}\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0449 - mean_squared_error: 0.0449\n",
      "Loss: 0.044865116477012634 Tiempo transcurrido: 19.837762355804443\n",
      "\n",
      "--- Starting trial: run-103\n",
      "{'layers': 4, 'num_units': 50, 'learning_rate': 0.001, 'batch_size': 16}\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0674 - mean_squared_error: 0.0674\n",
      "Loss: 0.06739651411771774 Tiempo transcurrido: 13.515701055526733\n",
      "\n",
      "--- Starting trial: run-104\n",
      "{'layers': 4, 'num_units': 100, 'learning_rate': 0.0001, 'batch_size': 2}\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0335 - mean_squared_error: 0.0335\n",
      "Loss: 0.033479027450084686 Tiempo transcurrido: 64.15229034423828\n",
      "\n",
      "--- Starting trial: run-105\n",
      "{'layers': 4, 'num_units': 100, 'learning_rate': 0.0001, 'batch_size': 4}\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0306 - mean_squared_error: 0.0306\n",
      "Loss: 0.030590882524847984 Tiempo transcurrido: 35.09305286407471\n",
      "\n",
      "--- Starting trial: run-106\n",
      "{'layers': 4, 'num_units': 100, 'learning_rate': 0.0001, 'batch_size': 8}\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0475 - mean_squared_error: 0.0475\n",
      "Loss: 0.04745912179350853 Tiempo transcurrido: 21.267978191375732\n",
      "\n",
      "--- Starting trial: run-107\n",
      "{'layers': 4, 'num_units': 100, 'learning_rate': 0.0001, 'batch_size': 16}\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0395 - mean_squared_error: 0.0395\n",
      "Loss: 0.039463236927986145 Tiempo transcurrido: 14.132246971130371\n",
      "\n",
      "--- Starting trial: run-108\n",
      "{'layers': 4, 'num_units': 100, 'learning_rate': 0.001, 'batch_size': 2}\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1166 - mean_squared_error: 0.1166\n",
      "Loss: 0.11655843257904053 Tiempo transcurrido: 64.33794164657593\n",
      "\n",
      "--- Starting trial: run-109\n",
      "{'layers': 4, 'num_units': 100, 'learning_rate': 0.001, 'batch_size': 4}\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0358 - mean_squared_error: 0.0358\n",
      "Loss: 0.03584089130163193 Tiempo transcurrido: 35.79862093925476\n",
      "\n",
      "--- Starting trial: run-110\n",
      "{'layers': 4, 'num_units': 100, 'learning_rate': 0.001, 'batch_size': 8}\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0355 - mean_squared_error: 0.0355\n",
      "Loss: 0.03546230494976044 Tiempo transcurrido: 21.242900133132935\n",
      "\n",
      "--- Starting trial: run-111\n",
      "{'layers': 4, 'num_units': 100, 'learning_rate': 0.001, 'batch_size': 16}\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0372 - mean_squared_error: 0.0372\n",
      "Loss: 0.03719443082809448 Tiempo transcurrido: 14.016797542572021\n",
      "\n",
      "--- Starting trial: run-112\n",
      "{'layers': 4, 'num_units': 150, 'learning_rate': 0.0001, 'batch_size': 2}\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0359 - mean_squared_error: 0.0359\n",
      "Loss: 0.03586650267243385 Tiempo transcurrido: 69.32891464233398\n",
      "\n",
      "--- Starting trial: run-113\n",
      "{'layers': 4, 'num_units': 150, 'learning_rate': 0.0001, 'batch_size': 4}\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0346 - mean_squared_error: 0.0346\n",
      "Loss: 0.03460782766342163 Tiempo transcurrido: 38.54544973373413\n",
      "\n",
      "--- Starting trial: run-114\n",
      "{'layers': 4, 'num_units': 150, 'learning_rate': 0.0001, 'batch_size': 8}\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0353 - mean_squared_error: 0.0353\n",
      "Loss: 0.035280682146549225 Tiempo transcurrido: 23.24500608444214\n",
      "\n",
      "--- Starting trial: run-115\n",
      "{'layers': 4, 'num_units': 150, 'learning_rate': 0.0001, 'batch_size': 16}\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0355 - mean_squared_error: 0.0355\n",
      "Loss: 0.03546518087387085 Tiempo transcurrido: 15.755800247192383\n",
      "\n",
      "--- Starting trial: run-116\n",
      "{'layers': 4, 'num_units': 150, 'learning_rate': 0.001, 'batch_size': 2}\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0954 - mean_squared_error: 0.0954\n",
      "Loss: 0.09536244720220566 Tiempo transcurrido: 70.22096633911133\n",
      "\n",
      "--- Starting trial: run-117\n",
      "{'layers': 4, 'num_units': 150, 'learning_rate': 0.001, 'batch_size': 4}\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0332 - mean_squared_error: 0.0332\n",
      "Loss: 0.03319332003593445 Tiempo transcurrido: 38.10490965843201\n",
      "\n",
      "--- Starting trial: run-118\n",
      "{'layers': 4, 'num_units': 150, 'learning_rate': 0.001, 'batch_size': 8}\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0349 - mean_squared_error: 0.0349\n",
      "Loss: 0.034922536462545395 Tiempo transcurrido: 23.040149211883545\n",
      "\n",
      "--- Starting trial: run-119\n",
      "{'layers': 4, 'num_units': 150, 'learning_rate': 0.001, 'batch_size': 16}\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0639 - mean_squared_error: 0.0639\n",
      "Loss: 0.06390531361103058 Tiempo transcurrido: 15.171564102172852\n",
      "\n",
      "--- Starting trial: run-120\n",
      "{'layers': 4, 'num_units': 200, 'learning_rate': 0.0001, 'batch_size': 2}\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0353 - mean_squared_error: 0.0353\n",
      "Loss: 0.035325612872838974 Tiempo transcurrido: 78.49631094932556\n",
      "\n",
      "--- Starting trial: run-121\n",
      "{'layers': 4, 'num_units': 200, 'learning_rate': 0.0001, 'batch_size': 4}\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0341 - mean_squared_error: 0.0341\n",
      "Loss: 0.034140609204769135 Tiempo transcurrido: 45.25581359863281\n",
      "\n",
      "--- Starting trial: run-122\n",
      "{'layers': 4, 'num_units': 200, 'learning_rate': 0.0001, 'batch_size': 8}\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0329 - mean_squared_error: 0.0329\n",
      "Loss: 0.03294805809855461 Tiempo transcurrido: 26.866597890853882\n",
      "\n",
      "--- Starting trial: run-123\n",
      "{'layers': 4, 'num_units': 200, 'learning_rate': 0.0001, 'batch_size': 16}\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0350 - mean_squared_error: 0.0350\n",
      "Loss: 0.03497773036360741 Tiempo transcurrido: 16.99622416496277\n",
      "\n",
      "--- Starting trial: run-124\n",
      "{'layers': 4, 'num_units': 200, 'learning_rate': 0.001, 'batch_size': 2}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1034 - mean_squared_error: 0.1034\n",
      "Loss: 0.1034083217382431 Tiempo transcurrido: 82.1416757106781\n",
      "\n",
      "--- Starting trial: run-125\n",
      "{'layers': 4, 'num_units': 200, 'learning_rate': 0.001, 'batch_size': 4}\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0380 - mean_squared_error: 0.0380\n",
      "Loss: 0.03803648427128792 Tiempo transcurrido: 44.59988570213318\n",
      "\n",
      "--- Starting trial: run-126\n",
      "{'layers': 4, 'num_units': 200, 'learning_rate': 0.001, 'batch_size': 8}\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0344 - mean_squared_error: 0.0344\n",
      "Loss: 0.03444308415055275 Tiempo transcurrido: 27.330164194107056\n",
      "\n",
      "--- Starting trial: run-127\n",
      "{'layers': 4, 'num_units': 200, 'learning_rate': 0.001, 'batch_size': 16}\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0445 - mean_squared_error: 0.0445\n",
      "Loss: 0.044546470046043396 Tiempo transcurrido: 16.966399669647217\n",
      "128\n"
     ]
    }
   ],
   "source": [
    "session_num = 0\n",
    "datos = []\n",
    "\n",
    "for deep_layers in HP_LAYERS.domain.values:\n",
    "    for num_units in HP_NUM_UNITS.domain.values:\n",
    "        for learning_rate in HP_LEARNING.domain.values:\n",
    "            for batch_size in HP_BATCHSIZE.domain.values:\n",
    "                t = time.time()\n",
    "                hparams = {\n",
    "\n",
    "                    HP_LAYERS: deep_layers,\n",
    "                    HP_NUM_UNITS: num_units,\n",
    "                    HP_LEARNING: learning_rate,\n",
    "                    HP_BATCHSIZE: batch_size,\n",
    "                }\n",
    "                run_name = \"run-%d\" % session_num\n",
    "                print('\\n--- Starting trial: %s' % run_name)\n",
    "                print({h.name: hparams[h] for h in hparams})\n",
    "                score = run('logs/hparam_tuning3/' + run_name, hparams)\n",
    "                t = time.time()-t\n",
    "                session_num += 1\n",
    "                print(\"Loss:\", score, \"Tiempo transcurrido:\", t)\n",
    "            \n",
    "            datos.append([deep_layers, num_units, learning_rate, batch_size, score, t])\n",
    "\n",
    "print(session_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"historial_jla_tunning.txt\"\n",
    "df = pd.DataFrame(datos, columns = [\"Deep size\", \"Num units\", \"Learning rate\", \"Batch size\", \"MSE\", \"Tiempo de ejecución\"])\n",
    "\n",
    "df.sort_values(by=[\"MSE\", \"Tiempo de ejecución\"], ascending=[True, True], ignore_index=True, inplace=True)\n",
    "\n",
    "df.to_csv(filename, header=True, index=False, sep='\\t', mode='w') # a=append, w=overwrite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Deep size</th>\n",
       "      <th>Num units</th>\n",
       "      <th>Learning rate</th>\n",
       "      <th>Batch size</th>\n",
       "      <th>MSE</th>\n",
       "      <th>Tiempo de ejecución</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>200</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>16</td>\n",
       "      <td>0.032528</td>\n",
       "      <td>15.283009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>200</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>16</td>\n",
       "      <td>0.034978</td>\n",
       "      <td>16.996224</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Deep size  Num units  Learning rate  Batch size       MSE  \\\n",
       "0          3        200         0.0010          16  0.032528   \n",
       "1          4        200         0.0001          16  0.034978   \n",
       "\n",
       "   Tiempo de ejecución  \n",
       "0            15.283009  \n",
       "1            16.996224  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time 9.060 minutes\n"
     ]
    }
   ],
   "source": [
    "total_time = float(np.sum(df[[\"Tiempo de ejecución\"]])/60)\n",
    "\n",
    "print(\"Elapsed time {:.3f} minutes\".format(total_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     15.283009\n",
       "1     16.996224\n",
       "2     15.755800\n",
       "3     20.696011\n",
       "4     13.272431\n",
       "5     14.016798\n",
       "6     15.387176\n",
       "7     18.736623\n",
       "8     14.465001\n",
       "9     20.815081\n",
       "10    14.132247\n",
       "11    20.779644\n",
       "12    20.273613\n",
       "13    16.088559\n",
       "14    13.779431\n",
       "15    16.966400\n",
       "16    16.754388\n",
       "17    13.201734\n",
       "18    17.425991\n",
       "19    15.992691\n",
       "20    12.418356\n",
       "21    17.909512\n",
       "22    15.171564\n",
       "23    12.726302\n",
       "24    13.515701\n",
       "25    21.273691\n",
       "26    12.948186\n",
       "27    24.705475\n",
       "28    21.890503\n",
       "29    22.035712\n",
       "30    20.444350\n",
       "31    17.770208\n",
       "Name: Tiempo de ejecución, dtype: float64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"Tiempo de ejecución\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
