{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load_ext tensorboard\n",
    "# Clear any logs from previous runs\n",
    "# !rm -rf ./logs/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-16 18:55:05.928835: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-12-16 18:55:06.095833: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-12-16 18:55:06.095884: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2022-12-16 18:55:07.224880: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2022-12-16 18:55:07.225016: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2022-12-16 18:55:07.225029: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time, os\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Input, Dense\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorboard.plugins.hparams import api as hp\n",
    "\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split as split\n",
    "\n",
    "import random\n",
    "from math import floor\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import optimizers\n",
    "from scipy.integrate import odeint\n",
    "import scipy\n",
    "import pandas as pd\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(740, 2)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = 'https://raw.githubusercontent.com/igomezv/nnogada/main/data/jla.csv'\n",
    "df=pd.read_csv(url)\n",
    "N = len(df.values)\n",
    "randomize = np.random.permutation(N)\n",
    "data = df.values[randomize]\n",
    "N = len(df.values)\n",
    "z = data[:,0] \n",
    "y = data[:,1:3] ### coge el resto de variables a predecir \n",
    "y[:,1] = y[:,1]**2+data[:,2]\n",
    "np.shape(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "scalerz = StandardScaler()\n",
    "scalerz.fit(z.reshape(-1,1))\n",
    "z = scalerz.transform(z.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((592, 1), (148, 1), (592, 2), (148, 2))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Modificar para incluir phanteon como test\n",
    "split = 0.8\n",
    "ntrain = int(split * len(z))\n",
    "indx = [ntrain]\n",
    "X_train, X_test = np.split(z, indx)\n",
    "Y_train, Y_test = np.split(y, indx)\n",
    "np.shape(X_train), np.shape(X_test), Y_train.shape, Y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss -> val_loss\n",
    "callbacks = [tf.keras.callbacks.EarlyStopping(monitor='val_loss', mode='min',\n",
    "                                   min_delta=0.0,\n",
    "                                   patience=200,\n",
    "                                   restore_best_weights=True, verbose=True)\n",
    "                                   ]\n",
    "\n",
    "n_cols = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "HP_BATCHSIZE = hp.HParam('batch_size', hp.Discrete([2, 4, 8, 16]))\n",
    "HP_LAYERS =    hp.HParam('layers', hp.Discrete([1, 2, 3, 4]))\n",
    "HP_NUM_UNITS = hp.HParam('num_units', hp.Discrete([50, 100, 150, 200]))\n",
    "HP_LEARNING  = hp.HParam('learning_rate', hp.Discrete([1e-4,1e-3]))\n",
    "# HP_NUM_UNITS3 = hp.HParam('num_units3', hp.Discrete([50, 100, 150, 200]))\n",
    "# HP_NUM_UNITS4 = hp.HParam('num_units4', hp.Discrete([2, 5, 10]))\n",
    "# HP_DROPOUT = hp.HParam('dropout', hp.RealInterval(0.0, 0.2))\n",
    "# HP_OPTIMIZER = hp.HParam('optimizer', hp.Discrete(['adam', 'sgd']))\n",
    "# HP_OPTIMIZER = hp.HParam('optimizer', hp.Discrete(['adam', 'Adadelta']))\n",
    "# HP_OPTIMIZER = hp.HParam('optimizer', hp.Discrete(['adam']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs=200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sess = tf.Session()\n",
    "# writer = tf.summary.FileWriter(\"/tmp/tfvgg\", sess.graph)\n",
    "# init = tf.initialize_all_variables()\n",
    "# sess.run(init)\n",
    "# with tf.summary.create_file_writer('logs/hparam_tuning').as_default():\n",
    "#     hp.hparams_config(\n",
    "#         hparams=[HP_NUM_UNITS1, HP_NUM_UNITS2, HP_NUM_UNITS3, HP_NUM_UNITS4,\n",
    "#                  HP_OPTIMIZER, HP_BATCHSIZE],\n",
    "#         metrics=[hp.Metric('loss', display_name=\"Loss\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-16 18:55:08.819376: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-16 18:55:08.819802: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-12-16 18:55:08.819933: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory\n",
      "2022-12-16 18:55:08.820011: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory\n",
      "2022-12-16 18:55:08.820084: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcufft.so.10'; dlerror: libcufft.so.10: cannot open shared object file: No such file or directory\n",
      "2022-12-16 18:55:08.820152: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcurand.so.10'; dlerror: libcurand.so.10: cannot open shared object file: No such file or directory\n",
      "2022-12-16 18:55:08.820221: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory\n",
      "2022-12-16 18:55:08.820291: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory\n",
      "2022-12-16 18:55:08.820360: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2022-12-16 18:55:08.820374: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1934] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2022-12-16 18:55:08.821912: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# METRIC_ACCURACY = 'accuracy'\n",
    "with tf.summary.create_file_writer('logs/hparam_tuning3').as_default():\n",
    "# with tf.summary.FileWriter('logs/hparam_tuning', sess.graph):\n",
    "#     init = tf.initialize_all_variables()\n",
    "#     sess.run(init)\n",
    "    hp.hparams_config(\n",
    "        hparams=[HP_LAYERS,\n",
    "                 HP_NUM_UNITS,\n",
    "                 HP_LEARNING, \n",
    "                 HP_BATCHSIZE],\n",
    "        metrics=[hp.Metric('loss', display_name=\"Loss\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_model(hparams):    \n",
    "    \n",
    "    # Train LSTM model and predict on validation set\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(Dense(int(X_train.shape[1])))\n",
    "#     model.add(Dense(hparams[HP_NUM_UNITS], input_shape=(int(X_train.shape[1]),)))\n",
    "    \n",
    "    for i in range(hparams[HP_LAYERS]):        \n",
    "        model.add(Dense(hparams[HP_NUM_UNITS], activation='relu'))\n",
    "    model.add(Dense(2, activation='linear'))\n",
    "     \n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=hparams[HP_LEARNING], beta_1=0.9, beta_2=0.999, epsilon=1e-3)\n",
    "    model.compile(\n",
    "            optimizer=optimizer,\n",
    "            loss='mse', \n",
    "            metrics=['mean_squared_error'])\n",
    "    \n",
    "    # Run with 1 epoch to speed things up for demo purposes\n",
    "\n",
    "    model.fit(X_train, Y_train, epochs=epochs, validation_data=(X_test, Y_test),\n",
    "              callbacks=callbacks, batch_size=hparams[HP_BATCHSIZE], shuffle=False, verbose=0)\n",
    "\n",
    "    _, loss = model.evaluate(X_test, Y_test)\n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(run_dir, hparams):\n",
    "    with tf.summary.create_file_writer(run_dir).as_default():\n",
    "        hp.hparams(hparams)  # record the values used in this trial\n",
    "        loss = train_test_model(hparams)\n",
    "        tf.summary.scalar(\"loss\", loss, step=1)\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Starting trial: run-0\n",
      "{'layers': 1, 'num_units': 50, 'learning_rate': 0.0001, 'batch_size': 2}\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0583 - mean_squared_error: 0.0583\n",
      "Loss: 0.058343756943941116 Tiempo transcurrido: 106.21527099609375\n",
      "\n",
      "--- Starting trial: run-1\n",
      "{'layers': 1, 'num_units': 50, 'learning_rate': 0.0001, 'batch_size': 4}\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0890 - mean_squared_error: 0.0890\n",
      "Loss: 0.08904992789030075 Tiempo transcurrido: 67.82244348526001\n",
      "\n",
      "--- Starting trial: run-2\n",
      "{'layers': 1, 'num_units': 50, 'learning_rate': 0.0001, 'batch_size': 8}\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6015 - mean_squared_error: 0.6015\n",
      "Loss: 0.6015321016311646 Tiempo transcurrido: 36.575908184051514\n",
      "\n",
      "--- Starting trial: run-3\n",
      "{'layers': 1, 'num_units': 50, 'learning_rate': 0.0001, 'batch_size': 16}\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 5.1450 - mean_squared_error: 5.1450\n",
      "Loss: 5.145018100738525 Tiempo transcurrido: 20.167513132095337\n",
      "\n",
      "--- Starting trial: run-4\n",
      "{'layers': 1, 'num_units': 50, 'learning_rate': 0.001, 'batch_size': 2}\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0300 - mean_squared_error: 0.0300\n",
      "Loss: 0.030038459226489067 Tiempo transcurrido: 97.24144864082336\n",
      "\n",
      "--- Starting trial: run-5\n",
      "{'layers': 1, 'num_units': 50, 'learning_rate': 0.001, 'batch_size': 4}\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0398 - mean_squared_error: 0.0398\n",
      "Loss: 0.03978768736124039 Tiempo transcurrido: 59.513153076171875\n",
      "\n",
      "--- Starting trial: run-6\n",
      "{'layers': 1, 'num_units': 50, 'learning_rate': 0.001, 'batch_size': 8}\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0366 - mean_squared_error: 0.0366\n",
      "Loss: 0.03662218898534775 Tiempo transcurrido: 34.962287187576294\n",
      "\n",
      "--- Starting trial: run-7\n",
      "{'layers': 1, 'num_units': 50, 'learning_rate': 0.001, 'batch_size': 16}\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0493 - mean_squared_error: 0.0493\n",
      "Loss: 0.04930828884243965 Tiempo transcurrido: 20.775002241134644\n",
      "\n",
      "--- Starting trial: run-8\n",
      "{'layers': 1, 'num_units': 100, 'learning_rate': 0.0001, 'batch_size': 2}\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0506 - mean_squared_error: 0.0506\n",
      "Loss: 0.050579532980918884 Tiempo transcurrido: 143.42558813095093\n",
      "\n",
      "--- Starting trial: run-9\n",
      "{'layers': 1, 'num_units': 100, 'learning_rate': 0.0001, 'batch_size': 4}\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0630 - mean_squared_error: 0.0630\n",
      "Loss: 0.06300405412912369 Tiempo transcurrido: 46.342294454574585\n",
      "\n",
      "--- Starting trial: run-10\n",
      "{'layers': 1, 'num_units': 100, 'learning_rate': 0.0001, 'batch_size': 8}\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1297 - mean_squared_error: 0.1297\n",
      "Loss: 0.1297484040260315 Tiempo transcurrido: 28.22781205177307\n",
      "\n",
      "--- Starting trial: run-11\n",
      "{'layers': 1, 'num_units': 100, 'learning_rate': 0.0001, 'batch_size': 16}\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.7374 - mean_squared_error: 1.7374\n",
      "Loss: 1.7374154329299927 Tiempo transcurrido: 21.278331756591797\n",
      "\n",
      "--- Starting trial: run-12\n",
      "{'layers': 1, 'num_units': 100, 'learning_rate': 0.001, 'batch_size': 2}\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0314 - mean_squared_error: 0.0314\n",
      "Loss: 0.03139764443039894 Tiempo transcurrido: 120.78809595108032\n",
      "\n",
      "--- Starting trial: run-13\n",
      "{'layers': 1, 'num_units': 100, 'learning_rate': 0.001, 'batch_size': 4}\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0301 - mean_squared_error: 0.0301\n",
      "Loss: 0.030118001624941826 Tiempo transcurrido: 55.96650171279907\n",
      "\n",
      "--- Starting trial: run-14\n",
      "{'layers': 1, 'num_units': 100, 'learning_rate': 0.001, 'batch_size': 8}\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0416 - mean_squared_error: 0.0416\n",
      "Loss: 0.04163481667637825 Tiempo transcurrido: 30.52420711517334\n",
      "\n",
      "--- Starting trial: run-15\n",
      "{'layers': 1, 'num_units': 100, 'learning_rate': 0.001, 'batch_size': 16}\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0425 - mean_squared_error: 0.0425\n",
      "Loss: 0.042473696172237396 Tiempo transcurrido: 19.488470792770386\n",
      "\n",
      "--- Starting trial: run-16\n",
      "{'layers': 1, 'num_units': 150, 'learning_rate': 0.0001, 'batch_size': 2}\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0468 - mean_squared_error: 0.0468\n",
      "Loss: 0.04675301909446716 Tiempo transcurrido: 102.76168489456177\n",
      "\n",
      "--- Starting trial: run-17\n",
      "{'layers': 1, 'num_units': 150, 'learning_rate': 0.0001, 'batch_size': 4}\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0620 - mean_squared_error: 0.0620\n",
      "Loss: 0.06203373149037361 Tiempo transcurrido: 83.10672807693481\n",
      "\n",
      "--- Starting trial: run-18\n",
      "{'layers': 1, 'num_units': 150, 'learning_rate': 0.0001, 'batch_size': 8}\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0903 - mean_squared_error: 0.0903\n",
      "Loss: 0.09033556282520294 Tiempo transcurrido: 34.65463399887085\n",
      "\n",
      "--- Starting trial: run-19\n",
      "{'layers': 1, 'num_units': 150, 'learning_rate': 0.0001, 'batch_size': 16}\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.2547 - mean_squared_error: 0.2547\n",
      "Loss: 0.2547014653682709 Tiempo transcurrido: 21.82326102256775\n",
      "\n",
      "--- Starting trial: run-20\n",
      "{'layers': 1, 'num_units': 150, 'learning_rate': 0.001, 'batch_size': 2}\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0328 - mean_squared_error: 0.0328\n",
      "Loss: 0.03275563567876816 Tiempo transcurrido: 143.12741684913635\n",
      "\n",
      "--- Starting trial: run-21\n",
      "{'layers': 1, 'num_units': 150, 'learning_rate': 0.001, 'batch_size': 4}\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0307 - mean_squared_error: 0.0307\n",
      "Loss: 0.030680233612656593 Tiempo transcurrido: 56.68417286872864\n",
      "\n",
      "--- Starting trial: run-22\n",
      "{'layers': 1, 'num_units': 150, 'learning_rate': 0.001, 'batch_size': 8}\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0381 - mean_squared_error: 0.0381\n",
      "Loss: 0.03809598833322525 Tiempo transcurrido: 35.549232006073\n",
      "\n",
      "--- Starting trial: run-23\n",
      "{'layers': 1, 'num_units': 150, 'learning_rate': 0.001, 'batch_size': 16}\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0449 - mean_squared_error: 0.0449\n",
      "Loss: 0.04490910470485687 Tiempo transcurrido: 23.069568872451782\n",
      "\n",
      "--- Starting trial: run-24\n",
      "{'layers': 1, 'num_units': 200, 'learning_rate': 0.0001, 'batch_size': 2}\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0436 - mean_squared_error: 0.0436\n",
      "Loss: 0.04359986633062363 Tiempo transcurrido: 109.7585597038269\n",
      "\n",
      "--- Starting trial: run-25\n",
      "{'layers': 1, 'num_units': 200, 'learning_rate': 0.0001, 'batch_size': 4}\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0981 - mean_squared_error: 0.0981\n",
      "Loss: 0.09814727306365967 Tiempo transcurrido: 83.76009583473206\n",
      "\n",
      "--- Starting trial: run-26\n",
      "{'layers': 1, 'num_units': 200, 'learning_rate': 0.0001, 'batch_size': 8}\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0783 - mean_squared_error: 0.0783\n",
      "Loss: 0.07834769785404205 Tiempo transcurrido: 35.107908964157104\n",
      "\n",
      "--- Starting trial: run-27\n",
      "{'layers': 1, 'num_units': 200, 'learning_rate': 0.0001, 'batch_size': 16}\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2411 - mean_squared_error: 0.2411\n",
      "Loss: 0.24108995497226715 Tiempo transcurrido: 21.503358840942383\n",
      "\n",
      "--- Starting trial: run-28\n",
      "{'layers': 1, 'num_units': 200, 'learning_rate': 0.001, 'batch_size': 2}\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0327 - mean_squared_error: 0.0327\n",
      "Loss: 0.032745610922575 Tiempo transcurrido: 106.57318782806396\n",
      "\n",
      "--- Starting trial: run-29\n",
      "{'layers': 1, 'num_units': 200, 'learning_rate': 0.001, 'batch_size': 4}\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0299 - mean_squared_error: 0.0299\n",
      "Loss: 0.029879173263907433 Tiempo transcurrido: 83.25342655181885\n",
      "\n",
      "--- Starting trial: run-30\n",
      "{'layers': 1, 'num_units': 200, 'learning_rate': 0.001, 'batch_size': 8}\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0444 - mean_squared_error: 0.0444\n",
      "Loss: 0.044426385313272476 Tiempo transcurrido: 36.7112603187561\n",
      "\n",
      "--- Starting trial: run-31\n",
      "{'layers': 1, 'num_units': 200, 'learning_rate': 0.001, 'batch_size': 16}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0361 - mean_squared_error: 0.0361\n",
      "Loss: 0.036071211099624634 Tiempo transcurrido: 22.73203468322754\n",
      "\n",
      "--- Starting trial: run-32\n",
      "{'layers': 2, 'num_units': 50, 'learning_rate': 0.0001, 'batch_size': 2}\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0340 - mean_squared_error: 0.0340\n",
      "Loss: 0.03397345542907715 Tiempo transcurrido: 111.16268420219421\n",
      "\n",
      "--- Starting trial: run-33\n",
      "{'layers': 2, 'num_units': 50, 'learning_rate': 0.0001, 'batch_size': 4}\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0395 - mean_squared_error: 0.0395\n",
      "Loss: 0.039484668523073196 Tiempo transcurrido: 64.02147817611694\n",
      "\n",
      "--- Starting trial: run-34\n",
      "{'layers': 2, 'num_units': 50, 'learning_rate': 0.0001, 'batch_size': 8}\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0441 - mean_squared_error: 0.0441\n",
      "Loss: 0.044128332287073135 Tiempo transcurrido: 34.279168367385864\n",
      "\n",
      "--- Starting trial: run-35\n",
      "{'layers': 2, 'num_units': 50, 'learning_rate': 0.0001, 'batch_size': 16}\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1059 - mean_squared_error: 0.1059\n",
      "Loss: 0.1058972179889679 Tiempo transcurrido: 20.855906009674072\n",
      "\n",
      "--- Starting trial: run-36\n",
      "{'layers': 2, 'num_units': 50, 'learning_rate': 0.001, 'batch_size': 2}\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0348 - mean_squared_error: 0.0348\n",
      "Loss: 0.03479582071304321 Tiempo transcurrido: 101.79791378974915\n",
      "\n",
      "--- Starting trial: run-37\n",
      "{'layers': 2, 'num_units': 50, 'learning_rate': 0.001, 'batch_size': 4}\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0370 - mean_squared_error: 0.0370\n",
      "Loss: 0.03704306483268738 Tiempo transcurrido: 57.5799605846405\n",
      "\n",
      "--- Starting trial: run-38\n",
      "{'layers': 2, 'num_units': 50, 'learning_rate': 0.001, 'batch_size': 8}\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0364 - mean_squared_error: 0.0364\n",
      "Loss: 0.03635178506374359 Tiempo transcurrido: 42.37401056289673\n",
      "\n",
      "--- Starting trial: run-39\n",
      "{'layers': 2, 'num_units': 50, 'learning_rate': 0.001, 'batch_size': 16}\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0330 - mean_squared_error: 0.0330\n",
      "Loss: 0.032955754548311234 Tiempo transcurrido: 22.42287302017212\n",
      "\n",
      "--- Starting trial: run-40\n",
      "{'layers': 2, 'num_units': 100, 'learning_rate': 0.0001, 'batch_size': 2}\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0308 - mean_squared_error: 0.0308\n",
      "Loss: 0.030800439417362213 Tiempo transcurrido: 111.7919979095459\n",
      "\n",
      "--- Starting trial: run-41\n",
      "{'layers': 2, 'num_units': 100, 'learning_rate': 0.0001, 'batch_size': 4}\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0365 - mean_squared_error: 0.0365\n",
      "Loss: 0.03648721054196358 Tiempo transcurrido: 49.085773229599\n",
      "\n",
      "--- Starting trial: run-42\n",
      "{'layers': 2, 'num_units': 100, 'learning_rate': 0.0001, 'batch_size': 8}\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0395 - mean_squared_error: 0.0395\n",
      "Loss: 0.039472538977861404 Tiempo transcurrido: 31.58743667602539\n",
      "\n",
      "--- Starting trial: run-43\n",
      "{'layers': 2, 'num_units': 100, 'learning_rate': 0.0001, 'batch_size': 16}\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0690 - mean_squared_error: 0.0690\n",
      "Loss: 0.06902278959751129 Tiempo transcurrido: 21.759260416030884\n",
      "\n",
      "--- Starting trial: run-44\n",
      "{'layers': 2, 'num_units': 100, 'learning_rate': 0.001, 'batch_size': 2}\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0560 - mean_squared_error: 0.0560\n",
      "Loss: 0.05604344606399536 Tiempo transcurrido: 100.18218922615051\n",
      "\n",
      "--- Starting trial: run-45\n",
      "{'layers': 2, 'num_units': 100, 'learning_rate': 0.001, 'batch_size': 4}\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0400 - mean_squared_error: 0.0400\n",
      "Loss: 0.03998064994812012 Tiempo transcurrido: 50.88835668563843\n",
      "\n",
      "--- Starting trial: run-46\n",
      "{'layers': 2, 'num_units': 100, 'learning_rate': 0.001, 'batch_size': 8}\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0304 - mean_squared_error: 0.0304\n",
      "Loss: 0.03044656105339527 Tiempo transcurrido: 33.02135157585144\n",
      "\n",
      "--- Starting trial: run-47\n",
      "{'layers': 2, 'num_units': 100, 'learning_rate': 0.001, 'batch_size': 16}\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0358 - mean_squared_error: 0.0358\n",
      "Loss: 0.035791635513305664 Tiempo transcurrido: 21.119618892669678\n",
      "\n",
      "--- Starting trial: run-48\n",
      "{'layers': 2, 'num_units': 150, 'learning_rate': 0.0001, 'batch_size': 2}\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0310 - mean_squared_error: 0.0310\n",
      "Loss: 0.031032226979732513 Tiempo transcurrido: 99.50580215454102\n",
      "\n",
      "--- Starting trial: run-49\n",
      "{'layers': 2, 'num_units': 150, 'learning_rate': 0.0001, 'batch_size': 4}\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0371 - mean_squared_error: 0.0371\n",
      "Loss: 0.037149716168642044 Tiempo transcurrido: 37.702104330062866\n",
      "\n",
      "--- Starting trial: run-50\n",
      "{'layers': 2, 'num_units': 150, 'learning_rate': 0.0001, 'batch_size': 8}\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0376 - mean_squared_error: 0.0376\n",
      "Loss: 0.03756742924451828 Tiempo transcurrido: 22.273049116134644\n",
      "\n",
      "--- Starting trial: run-51\n",
      "{'layers': 2, 'num_units': 150, 'learning_rate': 0.0001, 'batch_size': 16}\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0547 - mean_squared_error: 0.0547\n",
      "Loss: 0.054661672562360764 Tiempo transcurrido: 14.456393957138062\n",
      "\n",
      "--- Starting trial: run-52\n",
      "{'layers': 2, 'num_units': 150, 'learning_rate': 0.001, 'batch_size': 2}\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0666 - mean_squared_error: 0.0666\n",
      "Loss: 0.06660618633031845 Tiempo transcurrido: 67.69457840919495\n",
      "\n",
      "--- Starting trial: run-53\n",
      "{'layers': 2, 'num_units': 150, 'learning_rate': 0.001, 'batch_size': 4}\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0398 - mean_squared_error: 0.0398\n",
      "Loss: 0.03980525955557823 Tiempo transcurrido: 37.16794204711914\n",
      "\n",
      "--- Starting trial: run-54\n",
      "{'layers': 2, 'num_units': 150, 'learning_rate': 0.001, 'batch_size': 8}\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0412 - mean_squared_error: 0.0412\n",
      "Loss: 0.041242484003305435 Tiempo transcurrido: 22.596659421920776\n",
      "\n",
      "--- Starting trial: run-55\n",
      "{'layers': 2, 'num_units': 150, 'learning_rate': 0.001, 'batch_size': 16}\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0471 - mean_squared_error: 0.0471\n",
      "Loss: 0.04709980636835098 Tiempo transcurrido: 14.618065357208252\n",
      "\n",
      "--- Starting trial: run-56\n",
      "{'layers': 2, 'num_units': 200, 'learning_rate': 0.0001, 'batch_size': 2}\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0308 - mean_squared_error: 0.0308\n",
      "Loss: 0.03081638179719448 Tiempo transcurrido: 72.80709099769592\n",
      "\n",
      "--- Starting trial: run-57\n",
      "{'layers': 2, 'num_units': 200, 'learning_rate': 0.0001, 'batch_size': 4}\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0349 - mean_squared_error: 0.0349\n",
      "Loss: 0.03486018627882004 Tiempo transcurrido: 34.69232988357544\n",
      "\n",
      "--- Starting trial: run-58\n",
      "{'layers': 2, 'num_units': 200, 'learning_rate': 0.0001, 'batch_size': 8}\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0360 - mean_squared_error: 0.0360\n",
      "Loss: 0.03598388284444809 Tiempo transcurrido: 20.792901515960693\n",
      "\n",
      "--- Starting trial: run-59\n",
      "{'layers': 2, 'num_units': 200, 'learning_rate': 0.0001, 'batch_size': 16}\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0547 - mean_squared_error: 0.0547\n",
      "Loss: 0.054683465510606766 Tiempo transcurrido: 13.610148191452026\n",
      "\n",
      "--- Starting trial: run-60\n",
      "{'layers': 2, 'num_units': 200, 'learning_rate': 0.001, 'batch_size': 2}\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0966 - mean_squared_error: 0.0966\n",
      "Loss: 0.09664417058229446 Tiempo transcurrido: 63.25124931335449\n",
      "\n",
      "--- Starting trial: run-61\n",
      "{'layers': 2, 'num_units': 200, 'learning_rate': 0.001, 'batch_size': 4}\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0530 - mean_squared_error: 0.0530\n",
      "Loss: 0.052986592054367065 Tiempo transcurrido: 34.23776292800903\n",
      "\n",
      "--- Starting trial: run-62\n",
      "{'layers': 2, 'num_units': 200, 'learning_rate': 0.001, 'batch_size': 8}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0386 - mean_squared_error: 0.0386\n",
      "Loss: 0.038619693368673325 Tiempo transcurrido: 20.15553307533264\n",
      "\n",
      "--- Starting trial: run-63\n",
      "{'layers': 2, 'num_units': 200, 'learning_rate': 0.001, 'batch_size': 16}\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0489 - mean_squared_error: 0.0489\n",
      "Loss: 0.04886535182595253 Tiempo transcurrido: 13.590122938156128\n",
      "\n",
      "--- Starting trial: run-64\n",
      "{'layers': 3, 'num_units': 50, 'learning_rate': 0.0001, 'batch_size': 2}\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0324 - mean_squared_error: 0.0324\n",
      "Loss: 0.03241182118654251 Tiempo transcurrido: 58.17931389808655\n",
      "\n",
      "--- Starting trial: run-65\n",
      "{'layers': 3, 'num_units': 50, 'learning_rate': 0.0001, 'batch_size': 4}\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0330 - mean_squared_error: 0.0330\n",
      "Loss: 0.03297501429915428 Tiempo transcurrido: 32.09847664833069\n",
      "\n",
      "--- Starting trial: run-66\n",
      "{'layers': 3, 'num_units': 50, 'learning_rate': 0.0001, 'batch_size': 8}\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0377 - mean_squared_error: 0.0377\n",
      "Loss: 0.037707604467868805 Tiempo transcurrido: 19.36863899230957\n",
      "\n",
      "--- Starting trial: run-67\n",
      "{'layers': 3, 'num_units': 50, 'learning_rate': 0.0001, 'batch_size': 16}\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0637 - mean_squared_error: 0.0637\n",
      "Loss: 0.06373343616724014 Tiempo transcurrido: 12.761964797973633\n",
      "\n",
      "--- Starting trial: run-68\n",
      "{'layers': 3, 'num_units': 50, 'learning_rate': 0.001, 'batch_size': 2}\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0945 - mean_squared_error: 0.0945\n",
      "Loss: 0.09450637549161911 Tiempo transcurrido: 58.30877208709717\n",
      "\n",
      "--- Starting trial: run-69\n",
      "{'layers': 3, 'num_units': 50, 'learning_rate': 0.001, 'batch_size': 4}\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0500 - mean_squared_error: 0.0500\n",
      "Loss: 0.04997934401035309 Tiempo transcurrido: 32.08448243141174\n",
      "\n",
      "--- Starting trial: run-70\n",
      "{'layers': 3, 'num_units': 50, 'learning_rate': 0.001, 'batch_size': 8}\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0355 - mean_squared_error: 0.0355\n",
      "Loss: 0.03548271581530571 Tiempo transcurrido: 19.97721576690674\n",
      "\n",
      "--- Starting trial: run-71\n",
      "{'layers': 3, 'num_units': 50, 'learning_rate': 0.001, 'batch_size': 16}\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0426 - mean_squared_error: 0.0426\n",
      "Loss: 0.04260242357850075 Tiempo transcurrido: 12.72231388092041\n",
      "\n",
      "--- Starting trial: run-72\n",
      "{'layers': 3, 'num_units': 100, 'learning_rate': 0.0001, 'batch_size': 2}\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0340 - mean_squared_error: 0.0340\n",
      "Loss: 0.0339786559343338 Tiempo transcurrido: 61.283427715301514\n",
      "\n",
      "--- Starting trial: run-73\n",
      "{'layers': 3, 'num_units': 100, 'learning_rate': 0.0001, 'batch_size': 4}\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0324 - mean_squared_error: 0.0324\n",
      "Loss: 0.032369911670684814 Tiempo transcurrido: 33.213807582855225\n",
      "\n",
      "--- Starting trial: run-74\n",
      "{'layers': 3, 'num_units': 100, 'learning_rate': 0.0001, 'batch_size': 8}\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0388 - mean_squared_error: 0.0388\n",
      "Loss: 0.038808178156614304 Tiempo transcurrido: 20.08840012550354\n",
      "\n",
      "--- Starting trial: run-75\n",
      "{'layers': 3, 'num_units': 100, 'learning_rate': 0.0001, 'batch_size': 16}\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0393 - mean_squared_error: 0.0393\n",
      "Loss: 0.03928912803530693 Tiempo transcurrido: 13.227686643600464\n",
      "\n",
      "--- Starting trial: run-76\n",
      "{'layers': 3, 'num_units': 100, 'learning_rate': 0.001, 'batch_size': 2}\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1008 - mean_squared_error: 0.1008\n",
      "Loss: 0.10078062862157822 Tiempo transcurrido: 61.32632040977478\n",
      "\n",
      "--- Starting trial: run-77\n",
      "{'layers': 3, 'num_units': 100, 'learning_rate': 0.001, 'batch_size': 4}\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0458 - mean_squared_error: 0.0458\n",
      "Loss: 0.045767009258270264 Tiempo transcurrido: 33.348934173583984\n",
      "\n",
      "--- Starting trial: run-78\n",
      "{'layers': 3, 'num_units': 100, 'learning_rate': 0.001, 'batch_size': 8}\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0350 - mean_squared_error: 0.0350\n",
      "Loss: 0.03496779873967171 Tiempo transcurrido: 20.219969987869263\n",
      "\n",
      "--- Starting trial: run-79\n",
      "{'layers': 3, 'num_units': 100, 'learning_rate': 0.001, 'batch_size': 16}\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0602 - mean_squared_error: 0.0602\n",
      "Loss: 0.06015338748693466 Tiempo transcurrido: 13.267422437667847\n",
      "\n",
      "--- Starting trial: run-80\n",
      "{'layers': 3, 'num_units': 150, 'learning_rate': 0.0001, 'batch_size': 2}\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0346 - mean_squared_error: 0.0346\n",
      "Loss: 0.03464343771338463 Tiempo transcurrido: 65.63513326644897\n",
      "\n",
      "--- Starting trial: run-81\n",
      "{'layers': 3, 'num_units': 150, 'learning_rate': 0.0001, 'batch_size': 4}\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0305 - mean_squared_error: 0.0305\n",
      "Loss: 0.030532553791999817 Tiempo transcurrido: 35.396358489990234\n",
      "\n",
      "--- Starting trial: run-82\n",
      "{'layers': 3, 'num_units': 150, 'learning_rate': 0.0001, 'batch_size': 8}\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0407 - mean_squared_error: 0.0407\n",
      "Loss: 0.040660709142684937 Tiempo transcurrido: 21.543888568878174\n",
      "\n",
      "--- Starting trial: run-83\n",
      "{'layers': 3, 'num_units': 150, 'learning_rate': 0.0001, 'batch_size': 16}\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0390 - mean_squared_error: 0.0390\n",
      "Loss: 0.03898859769105911 Tiempo transcurrido: 14.638344764709473\n",
      "\n",
      "--- Starting trial: run-84\n",
      "{'layers': 3, 'num_units': 150, 'learning_rate': 0.001, 'batch_size': 2}\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0820 - mean_squared_error: 0.0820\n",
      "Loss: 0.08203817158937454 Tiempo transcurrido: 65.06783080101013\n",
      "\n",
      "--- Starting trial: run-85\n",
      "{'layers': 3, 'num_units': 150, 'learning_rate': 0.001, 'batch_size': 4}\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0318 - mean_squared_error: 0.0318\n",
      "Loss: 0.031789202243089676 Tiempo transcurrido: 36.278868198394775\n",
      "\n",
      "--- Starting trial: run-86\n",
      "{'layers': 3, 'num_units': 150, 'learning_rate': 0.001, 'batch_size': 8}\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0318 - mean_squared_error: 0.0318\n",
      "Loss: 0.03179984539747238 Tiempo transcurrido: 23.31349515914917\n",
      "\n",
      "--- Starting trial: run-87\n",
      "{'layers': 3, 'num_units': 150, 'learning_rate': 0.001, 'batch_size': 16}\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1019 - mean_squared_error: 0.1019\n",
      "Loss: 0.10194484889507294 Tiempo transcurrido: 15.892750263214111\n",
      "\n",
      "--- Starting trial: run-88\n",
      "{'layers': 3, 'num_units': 200, 'learning_rate': 0.0001, 'batch_size': 2}\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0344 - mean_squared_error: 0.0344\n",
      "Loss: 0.03444922715425491 Tiempo transcurrido: 84.64143538475037\n",
      "\n",
      "--- Starting trial: run-89\n",
      "{'layers': 3, 'num_units': 200, 'learning_rate': 0.0001, 'batch_size': 4}\n",
      "5/5 [==============================] - 1s 2ms/step - loss: 0.0333 - mean_squared_error: 0.0333\n",
      "Loss: 0.03332410752773285 Tiempo transcurrido: 45.889381408691406\n",
      "\n",
      "--- Starting trial: run-90\n",
      "{'layers': 3, 'num_units': 200, 'learning_rate': 0.0001, 'batch_size': 8}\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0459 - mean_squared_error: 0.0459\n",
      "Loss: 0.045884519815444946 Tiempo transcurrido: 28.368180990219116\n",
      "\n",
      "--- Starting trial: run-91\n",
      "{'layers': 3, 'num_units': 200, 'learning_rate': 0.0001, 'batch_size': 16}\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0383 - mean_squared_error: 0.0383\n",
      "Loss: 0.03833214193582535 Tiempo transcurrido: 17.729129314422607\n",
      "\n",
      "--- Starting trial: run-92\n",
      "{'layers': 3, 'num_units': 200, 'learning_rate': 0.001, 'batch_size': 2}\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1455 - mean_squared_error: 0.1455\n",
      "Loss: 0.14548549056053162 Tiempo transcurrido: 84.66302943229675\n",
      "\n",
      "--- Starting trial: run-93\n",
      "{'layers': 3, 'num_units': 200, 'learning_rate': 0.001, 'batch_size': 4}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0373 - mean_squared_error: 0.0373\n",
      "Loss: 0.03734971955418587 Tiempo transcurrido: 44.18431758880615\n",
      "\n",
      "--- Starting trial: run-94\n",
      "{'layers': 3, 'num_units': 200, 'learning_rate': 0.001, 'batch_size': 8}\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0471 - mean_squared_error: 0.0471\n",
      "Loss: 0.04714398831129074 Tiempo transcurrido: 25.178890466690063\n",
      "\n",
      "--- Starting trial: run-95\n",
      "{'layers': 3, 'num_units': 200, 'learning_rate': 0.001, 'batch_size': 16}\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0341 - mean_squared_error: 0.0341\n",
      "Loss: 0.0340907908976078 Tiempo transcurrido: 16.075275897979736\n",
      "\n",
      "--- Starting trial: run-96\n",
      "{'layers': 4, 'num_units': 50, 'learning_rate': 0.0001, 'batch_size': 2}\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0354 - mean_squared_error: 0.0354\n",
      "Loss: 0.035377658903598785 Tiempo transcurrido: 66.72943329811096\n",
      "\n",
      "--- Starting trial: run-97\n",
      "{'layers': 4, 'num_units': 50, 'learning_rate': 0.0001, 'batch_size': 4}\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0338 - mean_squared_error: 0.0338\n",
      "Loss: 0.03378525748848915 Tiempo transcurrido: 36.723928928375244\n",
      "\n",
      "--- Starting trial: run-98\n",
      "{'layers': 4, 'num_units': 50, 'learning_rate': 0.0001, 'batch_size': 8}\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0416 - mean_squared_error: 0.0416\n",
      "Loss: 0.041649676859378815 Tiempo transcurrido: 22.253720998764038\n",
      "\n",
      "--- Starting trial: run-99\n",
      "{'layers': 4, 'num_units': 50, 'learning_rate': 0.0001, 'batch_size': 16}\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0464 - mean_squared_error: 0.0464\n",
      "Loss: 0.04644272103905678 Tiempo transcurrido: 14.704891443252563\n",
      "\n",
      "--- Starting trial: run-100\n",
      "{'layers': 4, 'num_units': 50, 'learning_rate': 0.001, 'batch_size': 2}\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0786 - mean_squared_error: 0.0786\n",
      "Loss: 0.078599713742733 Tiempo transcurrido: 65.6777594089508\n",
      "\n",
      "--- Starting trial: run-101\n",
      "{'layers': 4, 'num_units': 50, 'learning_rate': 0.001, 'batch_size': 4}\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0391 - mean_squared_error: 0.0391\n",
      "Loss: 0.03913324326276779 Tiempo transcurrido: 36.55329942703247\n",
      "\n",
      "--- Starting trial: run-102\n",
      "{'layers': 4, 'num_units': 50, 'learning_rate': 0.001, 'batch_size': 8}\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0393 - mean_squared_error: 0.0393\n",
      "Loss: 0.03932610899209976 Tiempo transcurrido: 22.3371524810791\n",
      "\n",
      "--- Starting trial: run-103\n",
      "{'layers': 4, 'num_units': 50, 'learning_rate': 0.001, 'batch_size': 16}\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0754 - mean_squared_error: 0.0754\n",
      "Loss: 0.0753660649061203 Tiempo transcurrido: 15.381479024887085\n",
      "\n",
      "--- Starting trial: run-104\n",
      "{'layers': 4, 'num_units': 100, 'learning_rate': 0.0001, 'batch_size': 2}\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0352 - mean_squared_error: 0.0352\n",
      "Loss: 0.035188913345336914 Tiempo transcurrido: 71.9375069141388\n",
      "\n",
      "--- Starting trial: run-105\n",
      "{'layers': 4, 'num_units': 100, 'learning_rate': 0.0001, 'batch_size': 4}\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0330 - mean_squared_error: 0.0330\n",
      "Loss: 0.03296375647187233 Tiempo transcurrido: 38.79944562911987\n",
      "\n",
      "--- Starting trial: run-106\n",
      "{'layers': 4, 'num_units': 100, 'learning_rate': 0.0001, 'batch_size': 8}\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0385 - mean_squared_error: 0.0385\n",
      "Loss: 0.03848596662282944 Tiempo transcurrido: 23.85727620124817\n",
      "\n",
      "--- Starting trial: run-107\n",
      "{'layers': 4, 'num_units': 100, 'learning_rate': 0.0001, 'batch_size': 16}\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0369 - mean_squared_error: 0.0369\n",
      "Loss: 0.0368594154715538 Tiempo transcurrido: 15.584155797958374\n",
      "\n",
      "--- Starting trial: run-108\n",
      "{'layers': 4, 'num_units': 100, 'learning_rate': 0.001, 'batch_size': 2}\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1293 - mean_squared_error: 0.1293\n",
      "Loss: 0.12932755053043365 Tiempo transcurrido: 71.74534559249878\n",
      "\n",
      "--- Starting trial: run-109\n",
      "{'layers': 4, 'num_units': 100, 'learning_rate': 0.001, 'batch_size': 4}\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0324 - mean_squared_error: 0.0324\n",
      "Loss: 0.03244595602154732 Tiempo transcurrido: 39.559587478637695\n",
      "\n",
      "--- Starting trial: run-110\n",
      "{'layers': 4, 'num_units': 100, 'learning_rate': 0.001, 'batch_size': 8}\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0331 - mean_squared_error: 0.0331\n",
      "Loss: 0.03307674080133438 Tiempo transcurrido: 24.335368633270264\n",
      "\n",
      "--- Starting trial: run-111\n",
      "{'layers': 4, 'num_units': 100, 'learning_rate': 0.001, 'batch_size': 16}\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0376 - mean_squared_error: 0.0376\n",
      "Loss: 0.037587784230709076 Tiempo transcurrido: 15.75853157043457\n",
      "\n",
      "--- Starting trial: run-112\n",
      "{'layers': 4, 'num_units': 150, 'learning_rate': 0.0001, 'batch_size': 2}\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0352 - mean_squared_error: 0.0352\n",
      "Loss: 0.03515509516000748 Tiempo transcurrido: 79.60826396942139\n",
      "\n",
      "--- Starting trial: run-113\n",
      "{'layers': 4, 'num_units': 150, 'learning_rate': 0.0001, 'batch_size': 4}\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0343 - mean_squared_error: 0.0343\n",
      "Loss: 0.034291286021471024 Tiempo transcurrido: 42.95194101333618\n",
      "\n",
      "--- Starting trial: run-114\n",
      "{'layers': 4, 'num_units': 150, 'learning_rate': 0.0001, 'batch_size': 8}\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0320 - mean_squared_error: 0.0320\n",
      "Loss: 0.032004471868276596 Tiempo transcurrido: 26.136489868164062\n",
      "\n",
      "--- Starting trial: run-115\n",
      "{'layers': 4, 'num_units': 150, 'learning_rate': 0.0001, 'batch_size': 16}\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0325 - mean_squared_error: 0.0325\n",
      "Loss: 0.03245040774345398 Tiempo transcurrido: 17.76902413368225\n",
      "\n",
      "--- Starting trial: run-116\n",
      "{'layers': 4, 'num_units': 150, 'learning_rate': 0.001, 'batch_size': 2}\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0819 - mean_squared_error: 0.0819\n",
      "Loss: 0.0818622037768364 Tiempo transcurrido: 80.34891057014465\n",
      "\n",
      "--- Starting trial: run-117\n",
      "{'layers': 4, 'num_units': 150, 'learning_rate': 0.001, 'batch_size': 4}\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0362 - mean_squared_error: 0.0362\n",
      "Loss: 0.036156170070171356 Tiempo transcurrido: 44.890668630599976\n",
      "\n",
      "--- Starting trial: run-118\n",
      "{'layers': 4, 'num_units': 150, 'learning_rate': 0.001, 'batch_size': 8}\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0419 - mean_squared_error: 0.0419\n",
      "Loss: 0.04189062863588333 Tiempo transcurrido: 28.03874635696411\n",
      "\n",
      "--- Starting trial: run-119\n",
      "{'layers': 4, 'num_units': 150, 'learning_rate': 0.001, 'batch_size': 16}\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0663 - mean_squared_error: 0.0663\n",
      "Loss: 0.06630562245845795 Tiempo transcurrido: 17.891841888427734\n",
      "\n",
      "--- Starting trial: run-120\n",
      "{'layers': 4, 'num_units': 200, 'learning_rate': 0.0001, 'batch_size': 2}\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0348 - mean_squared_error: 0.0348\n",
      "Loss: 0.03477141261100769 Tiempo transcurrido: 101.65534567832947\n",
      "\n",
      "--- Starting trial: run-121\n",
      "{'layers': 4, 'num_units': 200, 'learning_rate': 0.0001, 'batch_size': 4}\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0328 - mean_squared_error: 0.0328\n",
      "Loss: 0.032795924693346024 Tiempo transcurrido: 54.407853841781616\n",
      "\n",
      "--- Starting trial: run-122\n",
      "{'layers': 4, 'num_units': 200, 'learning_rate': 0.0001, 'batch_size': 8}\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0323 - mean_squared_error: 0.0323\n",
      "Loss: 0.03234713152050972 Tiempo transcurrido: 31.941736221313477\n",
      "\n",
      "--- Starting trial: run-123\n",
      "{'layers': 4, 'num_units': 200, 'learning_rate': 0.0001, 'batch_size': 16}\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0353 - mean_squared_error: 0.0353\n",
      "Loss: 0.035330742597579956 Tiempo transcurrido: 20.28155016899109\n",
      "\n",
      "--- Starting trial: run-124\n",
      "{'layers': 4, 'num_units': 200, 'learning_rate': 0.001, 'batch_size': 2}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0916 - mean_squared_error: 0.0916\n",
      "Loss: 0.091644287109375 Tiempo transcurrido: 100.88578534126282\n",
      "\n",
      "--- Starting trial: run-125\n",
      "{'layers': 4, 'num_units': 200, 'learning_rate': 0.001, 'batch_size': 4}\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0540 - mean_squared_error: 0.0540\n",
      "Loss: 0.05404502898454666 Tiempo transcurrido: 48.18780541419983\n",
      "\n",
      "--- Starting trial: run-126\n",
      "{'layers': 4, 'num_units': 200, 'learning_rate': 0.001, 'batch_size': 8}\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0366 - mean_squared_error: 0.0366\n",
      "Loss: 0.036559272557497025 Tiempo transcurrido: 24.20218014717102\n",
      "\n",
      "--- Starting trial: run-127\n",
      "{'layers': 4, 'num_units': 200, 'learning_rate': 0.001, 'batch_size': 16}\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0507 - mean_squared_error: 0.0507\n",
      "Loss: 0.050678834319114685 Tiempo transcurrido: 15.08552074432373\n",
      "128\n"
     ]
    }
   ],
   "source": [
    "session_num = 0\n",
    "datos = []\n",
    "\n",
    "for deep_layers in HP_LAYERS.domain.values:\n",
    "    for num_units in HP_NUM_UNITS.domain.values:\n",
    "        for learning_rate in HP_LEARNING.domain.values:\n",
    "            for batch_size in HP_BATCHSIZE.domain.values:\n",
    "                t = time.time()\n",
    "                hparams = {\n",
    "\n",
    "                    HP_LAYERS: deep_layers,\n",
    "                    HP_NUM_UNITS: num_units,\n",
    "                    HP_LEARNING: learning_rate,\n",
    "                    HP_BATCHSIZE: batch_size,\n",
    "                }\n",
    "                run_name = \"run-%d\" % session_num\n",
    "                print('\\n--- Starting trial: %s' % run_name)\n",
    "                print({h.name: hparams[h] for h in hparams})\n",
    "                score = run('logs/hparam_tuning3/' + run_name, hparams)\n",
    "                t = time.time()-t\n",
    "                session_num += 1\n",
    "                print(\"Loss:\", score, \"Tiempo transcurrido:\", t)\n",
    "            \n",
    "            datos.append([deep_layers, num_units, learning_rate, batch_size, score, t])\n",
    "\n",
    "print(session_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"historial_jla_tunning.txt\"\n",
    "df = pd.DataFrame(datos, columns = [\"Deep size\", \"Num units\", \"Learning rate\", \"Batch size\", \"MSE\", \"Tiempo de ejecución\"])\n",
    "\n",
    "df.sort_values(by=[\"MSE\", \"Tiempo de ejecución\"], ascending=[True, True], ignore_index=True, inplace=True)\n",
    "\n",
    "df.to_csv(filename, header=True, index=False, sep='\\t', mode='w') # a=append, w=overwrite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Deep size</th>\n",
       "      <th>Num units</th>\n",
       "      <th>Learning rate</th>\n",
       "      <th>Batch size</th>\n",
       "      <th>MSE</th>\n",
       "      <th>Tiempo de ejecución</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>150</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>16</td>\n",
       "      <td>0.032450</td>\n",
       "      <td>17.769024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>16</td>\n",
       "      <td>0.032956</td>\n",
       "      <td>22.422873</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Deep size  Num units  Learning rate  Batch size       MSE  \\\n",
       "0          4        150         0.0001          16  0.032450   \n",
       "1          2         50         0.0010          16  0.032956   \n",
       "\n",
       "   Tiempo de ejecución  \n",
       "0            17.769024  \n",
       "1            22.422873  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time 9.367 minutes\n"
     ]
    }
   ],
   "source": [
    "total_time = float(np.sum(df[[\"Tiempo de ejecución\"]])/60)\n",
    "\n",
    "print(\"Elapsed time {:.3f} minutes\".format(total_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     17.769024\n",
       "1     22.422873\n",
       "2     16.075276\n",
       "3     20.281550\n",
       "4     21.119619\n",
       "5     22.732035\n",
       "6     15.584156\n",
       "7     15.758532\n",
       "8     17.729129\n",
       "9     14.638345\n",
       "10    13.227687\n",
       "11    19.488471\n",
       "12    12.722314\n",
       "13    23.069569\n",
       "14    14.704891\n",
       "15    14.618065\n",
       "16    13.590123\n",
       "17    20.775002\n",
       "18    15.085521\n",
       "19    14.456394\n",
       "20    13.610148\n",
       "21    13.267422\n",
       "22    12.761965\n",
       "23    17.891842\n",
       "24    21.759260\n",
       "25    15.381479\n",
       "26    15.892750\n",
       "27    20.855906\n",
       "28    21.503359\n",
       "29    21.823261\n",
       "30    21.278332\n",
       "31    20.167513\n",
       "Name: Tiempo de ejecución, dtype: float64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"Tiempo de ejecución\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
