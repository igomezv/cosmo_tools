{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load_ext tensorboard\n",
    "# Clear any logs from previous runs\n",
    "# !rm -rf ./logs/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-09 16:43:59.472322: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-12-09 16:43:59.563312: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-12-09 16:43:59.563330: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2022-12-09 16:44:00.145127: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2022-12-09 16:44:00.145242: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2022-12-09 16:44:00.145249: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time, os\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Input, Dense\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "from tensorboard.plugins.hparams import api as hp\n",
    "\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "import astropy\n",
    "from astropy.io import fits\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split \n",
    "\n",
    "import random\n",
    "from math import floor\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import optimizers\n",
    "from scipy.integrate import odeint\n",
    "import scipy\n",
    "import pandas as pd\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with fits.open('https://github.com/igomezv/cosmo_tools/blob/main/COB_22/Viviana_Acquaviva/DEEP2_uniq_Terapix_Subaru_v1.fits?raw=true') as data:\n",
    "    df = pd.DataFrame(np.array(data[1].data).byteswap().newbyteorder()) #see https://numpy.org/devdocs/user/basics.byteswapping.html#changing-byte-ordering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>objno_deep2</th>\n",
       "      <th>ra_deep2</th>\n",
       "      <th>dec_deep2</th>\n",
       "      <th>magb</th>\n",
       "      <th>magr</th>\n",
       "      <th>magi</th>\n",
       "      <th>pgal</th>\n",
       "      <th>sfd_ebv</th>\n",
       "      <th>class</th>\n",
       "      <th>subclass</th>\n",
       "      <th>...</th>\n",
       "      <th>ra_subaru</th>\n",
       "      <th>dec_subaru</th>\n",
       "      <th>y</th>\n",
       "      <th>yerr</th>\n",
       "      <th>y_apercor</th>\n",
       "      <th>yerr_aper</th>\n",
       "      <th>yerr_apercor</th>\n",
       "      <th>y(sexflag)</th>\n",
       "      <th>y_radius_arcsec</th>\n",
       "      <th>subaru_source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11001673</td>\n",
       "      <td>213.868704</td>\n",
       "      <td>51.956445</td>\n",
       "      <td>23.487745</td>\n",
       "      <td>23.143082</td>\n",
       "      <td>22.582092</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.010943</td>\n",
       "      <td>b''</td>\n",
       "      <td>b''</td>\n",
       "      <td>...</td>\n",
       "      <td>213.868626</td>\n",
       "      <td>51.956443</td>\n",
       "      <td>21.869627</td>\n",
       "      <td>0.060918</td>\n",
       "      <td>21.926356</td>\n",
       "      <td>0.041955</td>\n",
       "      <td>0.141778</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.656514</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11001699</td>\n",
       "      <td>213.810471</td>\n",
       "      <td>51.942316</td>\n",
       "      <td>22.067692</td>\n",
       "      <td>20.034674</td>\n",
       "      <td>19.545080</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.011014</td>\n",
       "      <td>b'GALAXY'</td>\n",
       "      <td>b''</td>\n",
       "      <td>...</td>\n",
       "      <td>213.810455</td>\n",
       "      <td>51.942321</td>\n",
       "      <td>18.757229</td>\n",
       "      <td>0.005813</td>\n",
       "      <td>18.811085</td>\n",
       "      <td>0.004386</td>\n",
       "      <td>0.050987</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.744269</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11001770</td>\n",
       "      <td>213.848431</td>\n",
       "      <td>51.948876</td>\n",
       "      <td>24.144438</td>\n",
       "      <td>24.103180</td>\n",
       "      <td>24.020006</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.010856</td>\n",
       "      <td>b'GALAXY'</td>\n",
       "      <td>b''</td>\n",
       "      <td>...</td>\n",
       "      <td>-99.000000</td>\n",
       "      <td>-99.000000</td>\n",
       "      <td>-99.000000</td>\n",
       "      <td>-99.000000</td>\n",
       "      <td>-99.000000</td>\n",
       "      <td>-99.000000</td>\n",
       "      <td>-99.000000</td>\n",
       "      <td>-99.0</td>\n",
       "      <td>-99.000000</td>\n",
       "      <td>-99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11001800</td>\n",
       "      <td>213.831758</td>\n",
       "      <td>51.952548</td>\n",
       "      <td>25.336836</td>\n",
       "      <td>23.508480</td>\n",
       "      <td>23.081087</td>\n",
       "      <td>0.509809</td>\n",
       "      <td>0.010823</td>\n",
       "      <td>b'GALAXY'</td>\n",
       "      <td>b''</td>\n",
       "      <td>...</td>\n",
       "      <td>213.831766</td>\n",
       "      <td>51.952544</td>\n",
       "      <td>22.404269</td>\n",
       "      <td>0.088970</td>\n",
       "      <td>22.535600</td>\n",
       "      <td>0.053497</td>\n",
       "      <td>0.094733</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.455820</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11001860</td>\n",
       "      <td>213.832550</td>\n",
       "      <td>51.954174</td>\n",
       "      <td>24.382738</td>\n",
       "      <td>23.401484</td>\n",
       "      <td>22.572845</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.010827</td>\n",
       "      <td>b'GALAXY'</td>\n",
       "      <td>b''</td>\n",
       "      <td>...</td>\n",
       "      <td>213.832574</td>\n",
       "      <td>51.954175</td>\n",
       "      <td>22.242717</td>\n",
       "      <td>0.070760</td>\n",
       "      <td>22.100980</td>\n",
       "      <td>0.033256</td>\n",
       "      <td>0.073067</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.442022</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 78 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   objno_deep2    ra_deep2  dec_deep2       magb       magr       magi  \\\n",
       "0     11001673  213.868704  51.956445  23.487745  23.143082  22.582092   \n",
       "1     11001699  213.810471  51.942316  22.067692  20.034674  19.545080   \n",
       "2     11001770  213.848431  51.948876  24.144438  24.103180  24.020006   \n",
       "3     11001800  213.831758  51.952548  25.336836  23.508480  23.081087   \n",
       "4     11001860  213.832550  51.954174  24.382738  23.401484  22.572845   \n",
       "\n",
       "       pgal   sfd_ebv      class subclass  ...   ra_subaru dec_subaru  \\\n",
       "0  1.000000  0.010943        b''      b''  ...  213.868626  51.956443   \n",
       "1  3.000000  0.011014  b'GALAXY'      b''  ...  213.810455  51.942321   \n",
       "2  3.000000  0.010856  b'GALAXY'      b''  ...  -99.000000 -99.000000   \n",
       "3  0.509809  0.010823  b'GALAXY'      b''  ...  213.831766  51.952544   \n",
       "4  3.000000  0.010827  b'GALAXY'      b''  ...  213.832574  51.954175   \n",
       "\n",
       "           y       yerr  y_apercor  yerr_aper  yerr_apercor  y(sexflag)  \\\n",
       "0  21.869627   0.060918  21.926356   0.041955      0.141778         3.0   \n",
       "1  18.757229   0.005813  18.811085   0.004386      0.050987         3.0   \n",
       "2 -99.000000 -99.000000 -99.000000 -99.000000    -99.000000       -99.0   \n",
       "3  22.404269   0.088970  22.535600   0.053497      0.094733         0.0   \n",
       "4  22.242717   0.070760  22.100980   0.033256      0.073067         0.0   \n",
       "\n",
       "   y_radius_arcsec  subaru_source  \n",
       "0         0.656514              1  \n",
       "1         0.744269              1  \n",
       "2       -99.000000            -99  \n",
       "3         0.455820              1  \n",
       "4         0.442022              1  \n",
       "\n",
       "[5 rows x 78 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>u_apercor</th>\n",
       "      <th>g_apercor</th>\n",
       "      <th>r_apercor</th>\n",
       "      <th>i_apercor</th>\n",
       "      <th>z_apercor</th>\n",
       "      <th>y_apercor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>23.543491</td>\n",
       "      <td>23.430495</td>\n",
       "      <td>23.100311</td>\n",
       "      <td>22.768970</td>\n",
       "      <td>22.223810</td>\n",
       "      <td>21.926356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30.848978</td>\n",
       "      <td>28.989668</td>\n",
       "      <td>19.027422</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>18.811085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>24.324670</td>\n",
       "      <td>24.273606</td>\n",
       "      <td>24.150319</td>\n",
       "      <td>23.446252</td>\n",
       "      <td>23.574236</td>\n",
       "      <td>-99.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>99.000000</td>\n",
       "      <td>24.804309</td>\n",
       "      <td>23.636544</td>\n",
       "      <td>23.009222</td>\n",
       "      <td>22.689591</td>\n",
       "      <td>22.535600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>24.362068</td>\n",
       "      <td>24.136913</td>\n",
       "      <td>23.490342</td>\n",
       "      <td>22.777181</td>\n",
       "      <td>22.319676</td>\n",
       "      <td>22.100980</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   u_apercor  g_apercor  r_apercor  i_apercor  z_apercor  y_apercor\n",
       "0  23.543491  23.430495  23.100311  22.768970  22.223810  21.926356\n",
       "1  30.848978  28.989668  19.027422  99.000000  99.000000  18.811085\n",
       "2  24.324670  24.273606  24.150319  23.446252  23.574236 -99.000000\n",
       "3  99.000000  24.804309  23.636544  23.009222  22.689591  22.535600\n",
       "4  24.362068  24.136913  23.490342  22.777181  22.319676  22.100980"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = df[['u_apercor', 'g_apercor', 'r_apercor', 'i_apercor', 'z_apercor','y_apercor']]\n",
    "features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1.115261\n",
       "1    0.290608\n",
       "2    0.605744\n",
       "3    1.306796\n",
       "4    0.957669\n",
       "Name: zhelio, dtype: float32"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target = df['zhelio']\n",
    "target.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "mags = df[['u_apercor', 'g_apercor', 'r_apercor', 'i_apercor', 'z_apercor','y_apercor','zquality','cfhtls_source']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16857, 8)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mags = mags[mags['zquality'] >= 3]\n",
    "\n",
    "mags.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "mags = mags[mags > -10].dropna()\n",
    "mags = mags[mags < 90].dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "mags = mags[mags['cfhtls_source'] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = ['u_apercor', 'g_apercor', 'r_apercor', 'i_apercor', 'z_apercor','y_apercor']\n",
    "features_ext = mags.copy()\n",
    "for i, name1 in enumerate(params):\n",
    "    for j, name2 in enumerate(params):\n",
    "        if i >=j: continue #build only one pair, avoid zero colors\n",
    "        features_ext[name1 + '-' + name2] = features[name1] - features[name2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>u_apercor</th>\n",
       "      <th>g_apercor</th>\n",
       "      <th>r_apercor</th>\n",
       "      <th>i_apercor</th>\n",
       "      <th>z_apercor</th>\n",
       "      <th>y_apercor</th>\n",
       "      <th>zquality</th>\n",
       "      <th>cfhtls_source</th>\n",
       "      <th>u_apercor-g_apercor</th>\n",
       "      <th>u_apercor-r_apercor</th>\n",
       "      <th>...</th>\n",
       "      <th>g_apercor-r_apercor</th>\n",
       "      <th>g_apercor-i_apercor</th>\n",
       "      <th>g_apercor-z_apercor</th>\n",
       "      <th>g_apercor-y_apercor</th>\n",
       "      <th>r_apercor-i_apercor</th>\n",
       "      <th>r_apercor-z_apercor</th>\n",
       "      <th>r_apercor-y_apercor</th>\n",
       "      <th>i_apercor-z_apercor</th>\n",
       "      <th>i_apercor-y_apercor</th>\n",
       "      <th>z_apercor-y_apercor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1251</th>\n",
       "      <td>24.244393</td>\n",
       "      <td>23.979583</td>\n",
       "      <td>23.522136</td>\n",
       "      <td>22.911041</td>\n",
       "      <td>22.525773</td>\n",
       "      <td>22.329098</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.264811</td>\n",
       "      <td>0.722258</td>\n",
       "      <td>...</td>\n",
       "      <td>0.457447</td>\n",
       "      <td>1.068542</td>\n",
       "      <td>1.453810</td>\n",
       "      <td>1.650485</td>\n",
       "      <td>0.611094</td>\n",
       "      <td>0.996362</td>\n",
       "      <td>1.193037</td>\n",
       "      <td>0.385268</td>\n",
       "      <td>0.581943</td>\n",
       "      <td>0.196675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1253</th>\n",
       "      <td>24.489104</td>\n",
       "      <td>23.916151</td>\n",
       "      <td>22.923651</td>\n",
       "      <td>21.873752</td>\n",
       "      <td>21.306495</td>\n",
       "      <td>21.251440</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.572953</td>\n",
       "      <td>1.565453</td>\n",
       "      <td>...</td>\n",
       "      <td>0.992500</td>\n",
       "      <td>2.042399</td>\n",
       "      <td>2.609656</td>\n",
       "      <td>2.664711</td>\n",
       "      <td>1.049899</td>\n",
       "      <td>1.617157</td>\n",
       "      <td>1.672212</td>\n",
       "      <td>0.567258</td>\n",
       "      <td>0.622312</td>\n",
       "      <td>0.055055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1261</th>\n",
       "      <td>24.873959</td>\n",
       "      <td>22.973893</td>\n",
       "      <td>21.465850</td>\n",
       "      <td>20.788420</td>\n",
       "      <td>20.462283</td>\n",
       "      <td>20.413696</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.900066</td>\n",
       "      <td>3.408108</td>\n",
       "      <td>...</td>\n",
       "      <td>1.508042</td>\n",
       "      <td>2.185473</td>\n",
       "      <td>2.511610</td>\n",
       "      <td>2.560196</td>\n",
       "      <td>0.677430</td>\n",
       "      <td>1.003568</td>\n",
       "      <td>1.052154</td>\n",
       "      <td>0.326138</td>\n",
       "      <td>0.374724</td>\n",
       "      <td>0.048586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1271</th>\n",
       "      <td>24.529042</td>\n",
       "      <td>24.338631</td>\n",
       "      <td>23.891189</td>\n",
       "      <td>23.206102</td>\n",
       "      <td>22.989344</td>\n",
       "      <td>23.112382</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.190411</td>\n",
       "      <td>0.637853</td>\n",
       "      <td>...</td>\n",
       "      <td>0.447442</td>\n",
       "      <td>1.132529</td>\n",
       "      <td>1.349287</td>\n",
       "      <td>1.226250</td>\n",
       "      <td>0.685087</td>\n",
       "      <td>0.901845</td>\n",
       "      <td>0.778808</td>\n",
       "      <td>0.216758</td>\n",
       "      <td>0.093721</td>\n",
       "      <td>-0.123037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1272</th>\n",
       "      <td>23.641180</td>\n",
       "      <td>23.387447</td>\n",
       "      <td>22.975301</td>\n",
       "      <td>22.235199</td>\n",
       "      <td>21.809658</td>\n",
       "      <td>21.559483</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.253733</td>\n",
       "      <td>0.665879</td>\n",
       "      <td>...</td>\n",
       "      <td>0.412146</td>\n",
       "      <td>1.152248</td>\n",
       "      <td>1.577789</td>\n",
       "      <td>1.827964</td>\n",
       "      <td>0.740102</td>\n",
       "      <td>1.165643</td>\n",
       "      <td>1.415818</td>\n",
       "      <td>0.425541</td>\n",
       "      <td>0.675717</td>\n",
       "      <td>0.250175</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      u_apercor  g_apercor  r_apercor  i_apercor  z_apercor  y_apercor  \\\n",
       "1251  24.244393  23.979583  23.522136  22.911041  22.525773  22.329098   \n",
       "1253  24.489104  23.916151  22.923651  21.873752  21.306495  21.251440   \n",
       "1261  24.873959  22.973893  21.465850  20.788420  20.462283  20.413696   \n",
       "1271  24.529042  24.338631  23.891189  23.206102  22.989344  23.112382   \n",
       "1272  23.641180  23.387447  22.975301  22.235199  21.809658  21.559483   \n",
       "\n",
       "      zquality  cfhtls_source  u_apercor-g_apercor  u_apercor-r_apercor  ...  \\\n",
       "1251         4            0.0             0.264811             0.722258  ...   \n",
       "1253         4            0.0             0.572953             1.565453  ...   \n",
       "1261         3            0.0             1.900066             3.408108  ...   \n",
       "1271         4            0.0             0.190411             0.637853  ...   \n",
       "1272         4            0.0             0.253733             0.665879  ...   \n",
       "\n",
       "      g_apercor-r_apercor  g_apercor-i_apercor  g_apercor-z_apercor  \\\n",
       "1251             0.457447             1.068542             1.453810   \n",
       "1253             0.992500             2.042399             2.609656   \n",
       "1261             1.508042             2.185473             2.511610   \n",
       "1271             0.447442             1.132529             1.349287   \n",
       "1272             0.412146             1.152248             1.577789   \n",
       "\n",
       "      g_apercor-y_apercor  r_apercor-i_apercor  r_apercor-z_apercor  \\\n",
       "1251             1.650485             0.611094             0.996362   \n",
       "1253             2.664711             1.049899             1.617157   \n",
       "1261             2.560196             0.677430             1.003568   \n",
       "1271             1.226250             0.685087             0.901845   \n",
       "1272             1.827964             0.740102             1.165643   \n",
       "\n",
       "      r_apercor-y_apercor  i_apercor-z_apercor  i_apercor-y_apercor  \\\n",
       "1251             1.193037             0.385268             0.581943   \n",
       "1253             1.672212             0.567258             0.622312   \n",
       "1261             1.052154             0.326138             0.374724   \n",
       "1271             0.778808             0.216758             0.093721   \n",
       "1272             1.415818             0.425541             0.675717   \n",
       "\n",
       "      z_apercor-y_apercor  \n",
       "1251             0.196675  \n",
       "1253             0.055055  \n",
       "1261             0.048586  \n",
       "1271            -0.123037  \n",
       "1272             0.250175  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_ext.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = target[features_ext.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_paper = features_ext[['u_apercor-g_apercor','g_apercor-r_apercor', \\\n",
    "            'r_apercor-i_apercor','i_apercor-z_apercor','z_apercor-y_apercor','i_apercor']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, Y_train, Y_val = train_test_split(features_paper, target, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss -> val_loss\n",
    "callbacks = [tf.keras.callbacks.EarlyStopping(monitor='val_loss', mode='min',\n",
    "                                   min_delta=0.0,\n",
    "                                   patience=200,\n",
    "                                   restore_best_weights=True, verbose=False)\n",
    "                                   ]\n",
    "\n",
    "n_cols = 1\n",
    "epochs=200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "HP_BATCHSIZE = hp.HParam('batch_size', hp.Discrete([8, 16, 32, 64]))\n",
    "HP_LAYERS =    hp.HParam('layers', hp.Discrete([3, 4]))\n",
    "HP_NUM_UNITS = hp.HParam('num_units', hp.Discrete([100, 200]))\n",
    "HP_LEARNING  = hp.HParam('learning_rate', hp.Discrete([1e-4, 1e-3]))\n",
    "# HP_NUM_UNITS3 = hp.HParam('num_units3', hp.Discrete([50, 100, 150, 200]))\n",
    "# HP_NUM_UNITS4 = hp.HParam('num_units4', hp.Discrete([2, 5, 10]))\n",
    "# HP_DROPOUT = hp.HParam('dropout', hp.RealInterval(0.0, 0.2))\n",
    "# HP_OPTIMIZER = hp.HParam('optimizer', hp.Discrete(['adam', 'sgd']))\n",
    "# HP_OPTIMIZER = hp.HParam('optimizer', hp.Discrete(['adam', 'Adadelta']))\n",
    "# HP_OPTIMIZER = hp.HParam('optimizer', hp.Discrete(['adam']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# METRIC_ACCURACY = 'accuracy'\n",
    "with tf.summary.create_file_writer('logs/hparam_tuning3').as_default():\n",
    "# with tf.summary.FileWriter('logs/hparam_tuning', sess.graph):\n",
    "#     init = tf.initialize_all_variables()\n",
    "#     sess.run(init)\n",
    "    hp.hparams_config(\n",
    "        hparams=[HP_LAYERS,\n",
    "                 HP_NUM_UNITS,\n",
    "                 HP_LEARNING, \n",
    "                 HP_BATCHSIZE],\n",
    "        metrics=[hp.Metric('loss', display_name=\"Loss\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_model(hparams):    \n",
    "    \n",
    "    # Train LSTM model and predict on validation set\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(Dense(int(X_train.shape[1])))\n",
    "#     model.add(Dense(hparams[HP_NUM_UNITS], input_shape=(int(X_train.shape[1]),)))\n",
    "    \n",
    "    for i in range(hparams[HP_LAYERS]):        \n",
    "        model.add(Dense(hparams[HP_NUM_UNITS], activation='relu'))\n",
    "    model.add(Dense(2, activation='linear'))\n",
    "     \n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=hparams[HP_LEARNING], beta_1=0.9, beta_2=0.999, epsilon=1e-3)\n",
    "    model.compile(\n",
    "            optimizer=optimizer,\n",
    "            loss='mse', \n",
    "            metrics=['mean_squared_error'])\n",
    "    \n",
    "    # Run with 1 epoch to speed things up for demo purposes\n",
    "\n",
    "    model.fit(X_train, Y_train, epochs=epochs, validation_data=(X_val, Y_val),\n",
    "              callbacks=callbacks, batch_size=hparams[HP_BATCHSIZE], shuffle=False, verbose=0)\n",
    "\n",
    "    _, loss = model.evaluate(X_val, Y_val)\n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(run_dir, hparams):\n",
    "    with tf.summary.create_file_writer(run_dir).as_default():\n",
    "        hp.hparams(hparams)  # record the values used in this trial\n",
    "        loss = train_test_model(hparams)\n",
    "        tf.summary.scalar(\"loss\", loss, step=1)\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Starting trial: run-0\n",
      "{'layers': 3, 'num_units': 100, 'learning_rate': 0.0001, 'batch_size': 8}\n",
      "40/40 [==============================] - 0s 955us/step - loss: 0.0399 - mean_squared_error: 0.0399\n",
      "Loss: 0.039879266172647476 Tiempo transcurrido: 137.21259999275208\n",
      "\n",
      "--- Starting trial: run-1\n",
      "{'layers': 3, 'num_units': 100, 'learning_rate': 0.0001, 'batch_size': 16}\n",
      "40/40 [==============================] - 0s 842us/step - loss: 0.0391 - mean_squared_error: 0.0391\n",
      "Loss: 0.03907215595245361 Tiempo transcurrido: 75.11359119415283\n",
      "\n",
      "--- Starting trial: run-2\n",
      "{'layers': 3, 'num_units': 100, 'learning_rate': 0.0001, 'batch_size': 32}\n",
      "40/40 [==============================] - 0s 813us/step - loss: 0.0322 - mean_squared_error: 0.0322\n",
      "Loss: 0.03218049928545952 Tiempo transcurrido: 40.83356690406799\n",
      "\n",
      "--- Starting trial: run-3\n",
      "{'layers': 3, 'num_units': 100, 'learning_rate': 0.0001, 'batch_size': 64}\n",
      "40/40 [==============================] - 0s 836us/step - loss: 0.0396 - mean_squared_error: 0.0396\n",
      "Loss: 0.03964512422680855 Tiempo transcurrido: 24.484121084213257\n",
      "\n",
      "--- Starting trial: run-4\n",
      "{'layers': 3, 'num_units': 100, 'learning_rate': 0.001, 'batch_size': 8}\n",
      "40/40 [==============================] - 0s 852us/step - loss: 0.0194 - mean_squared_error: 0.0194\n",
      "Loss: 0.01937730610370636 Tiempo transcurrido: 141.23653507232666\n",
      "\n",
      "--- Starting trial: run-5\n",
      "{'layers': 3, 'num_units': 100, 'learning_rate': 0.001, 'batch_size': 16}\n",
      "40/40 [==============================] - 0s 920us/step - loss: 0.0318 - mean_squared_error: 0.0318\n",
      "Loss: 0.03184770792722702 Tiempo transcurrido: 75.40174221992493\n",
      "\n",
      "--- Starting trial: run-6\n",
      "{'layers': 3, 'num_units': 100, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "40/40 [==============================] - 0s 875us/step - loss: 0.0211 - mean_squared_error: 0.0211\n",
      "Loss: 0.021121157333254814 Tiempo transcurrido: 42.62192678451538\n",
      "\n",
      "--- Starting trial: run-7\n",
      "{'layers': 3, 'num_units': 100, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "40/40 [==============================] - 0s 893us/step - loss: 0.0263 - mean_squared_error: 0.0263\n",
      "Loss: 0.026304589584469795 Tiempo transcurrido: 25.105375289916992\n",
      "\n",
      "--- Starting trial: run-8\n",
      "{'layers': 3, 'num_units': 200, 'learning_rate': 0.0001, 'batch_size': 8}\n",
      "40/40 [==============================] - 0s 771us/step - loss: 0.0528 - mean_squared_error: 0.0528\n",
      "Loss: 0.05280010774731636 Tiempo transcurrido: 171.20098209381104\n",
      "\n",
      "--- Starting trial: run-9\n",
      "{'layers': 3, 'num_units': 200, 'learning_rate': 0.0001, 'batch_size': 16}\n",
      "40/40 [==============================] - 0s 912us/step - loss: 0.0428 - mean_squared_error: 0.0428\n",
      "Loss: 0.0427747517824173 Tiempo transcurrido: 89.48044109344482\n",
      "\n",
      "--- Starting trial: run-10\n",
      "{'layers': 3, 'num_units': 200, 'learning_rate': 0.0001, 'batch_size': 32}\n",
      "40/40 [==============================] - 0s 949us/step - loss: 0.0329 - mean_squared_error: 0.0329\n",
      "Loss: 0.03287568315863609 Tiempo transcurrido: 51.533223390579224\n",
      "\n",
      "--- Starting trial: run-11\n",
      "{'layers': 3, 'num_units': 200, 'learning_rate': 0.0001, 'batch_size': 64}\n",
      "40/40 [==============================] - 0s 767us/step - loss: 0.0375 - mean_squared_error: 0.0375\n",
      "Loss: 0.037530746310949326 Tiempo transcurrido: 32.98024606704712\n",
      "\n",
      "--- Starting trial: run-12\n",
      "{'layers': 3, 'num_units': 200, 'learning_rate': 0.001, 'batch_size': 8}\n",
      "40/40 [==============================] - 0s 956us/step - loss: 0.0295 - mean_squared_error: 0.0295\n",
      "Loss: 0.02945685014128685 Tiempo transcurrido: 163.28568243980408\n",
      "\n",
      "--- Starting trial: run-13\n",
      "{'layers': 3, 'num_units': 200, 'learning_rate': 0.001, 'batch_size': 16}\n",
      "40/40 [==============================] - 0s 696us/step - loss: 0.0270 - mean_squared_error: 0.0270\n",
      "Loss: 0.027017394080758095 Tiempo transcurrido: 90.08484029769897\n",
      "\n",
      "--- Starting trial: run-14\n",
      "{'layers': 3, 'num_units': 200, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "40/40 [==============================] - 0s 858us/step - loss: 0.0400 - mean_squared_error: 0.0400\n",
      "Loss: 0.0399792306125164 Tiempo transcurrido: 49.51284837722778\n",
      "\n",
      "--- Starting trial: run-15\n",
      "{'layers': 3, 'num_units': 200, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "40/40 [==============================] - 0s 772us/step - loss: 0.0335 - mean_squared_error: 0.0335\n",
      "Loss: 0.033454783260822296 Tiempo transcurrido: 31.389439821243286\n",
      "\n",
      "--- Starting trial: run-16\n",
      "{'layers': 4, 'num_units': 100, 'learning_rate': 0.0001, 'batch_size': 8}\n",
      "40/40 [==============================] - 0s 930us/step - loss: 0.0542 - mean_squared_error: 0.0542\n",
      "Loss: 0.05417313426733017 Tiempo transcurrido: 149.59527683258057\n",
      "\n",
      "--- Starting trial: run-17\n",
      "{'layers': 4, 'num_units': 100, 'learning_rate': 0.0001, 'batch_size': 16}\n",
      "40/40 [==============================] - 0s 869us/step - loss: 0.0472 - mean_squared_error: 0.0472\n",
      "Loss: 0.04722566530108452 Tiempo transcurrido: 79.79600930213928\n",
      "\n",
      "--- Starting trial: run-18\n",
      "{'layers': 4, 'num_units': 100, 'learning_rate': 0.0001, 'batch_size': 32}\n",
      "40/40 [==============================] - 0s 755us/step - loss: 0.0454 - mean_squared_error: 0.0454\n",
      "Loss: 0.04537427797913551 Tiempo transcurrido: 44.709662675857544\n",
      "\n",
      "--- Starting trial: run-19\n",
      "{'layers': 4, 'num_units': 100, 'learning_rate': 0.0001, 'batch_size': 64}\n",
      "40/40 [==============================] - 0s 858us/step - loss: 0.0384 - mean_squared_error: 0.0384\n",
      "Loss: 0.03843485563993454 Tiempo transcurrido: 27.168419122695923\n",
      "\n",
      "--- Starting trial: run-20\n",
      "{'layers': 4, 'num_units': 100, 'learning_rate': 0.001, 'batch_size': 8}\n",
      "40/40 [==============================] - 0s 861us/step - loss: 0.0295 - mean_squared_error: 0.0295\n",
      "Loss: 0.029490439221262932 Tiempo transcurrido: 150.23329782485962\n",
      "\n",
      "--- Starting trial: run-21\n",
      "{'layers': 4, 'num_units': 100, 'learning_rate': 0.001, 'batch_size': 16}\n",
      "40/40 [==============================] - 0s 923us/step - loss: 0.0226 - mean_squared_error: 0.0226\n",
      "Loss: 0.02262873575091362 Tiempo transcurrido: 80.10892081260681\n",
      "\n",
      "--- Starting trial: run-22\n",
      "{'layers': 4, 'num_units': 100, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "40/40 [==============================] - 0s 852us/step - loss: 0.0179 - mean_squared_error: 0.0179\n",
      "Loss: 0.017949501052498817 Tiempo transcurrido: 44.79517388343811\n",
      "\n",
      "--- Starting trial: run-23\n",
      "{'layers': 4, 'num_units': 100, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.0237 - mean_squared_error: 0.0237\n",
      "Loss: 0.023668620735406876 Tiempo transcurrido: 28.649291276931763\n",
      "\n",
      "--- Starting trial: run-24\n",
      "{'layers': 4, 'num_units': 200, 'learning_rate': 0.0001, 'batch_size': 8}\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.0493 - mean_squared_error: 0.0493\n",
      "Loss: 0.0492560900747776 Tiempo transcurrido: 205.76589965820312\n",
      "\n",
      "--- Starting trial: run-25\n",
      "{'layers': 4, 'num_units': 200, 'learning_rate': 0.0001, 'batch_size': 16}\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.0378 - mean_squared_error: 0.0378\n",
      "Loss: 0.03775054216384888 Tiempo transcurrido: 104.02362751960754\n",
      "\n",
      "--- Starting trial: run-26\n",
      "{'layers': 4, 'num_units': 200, 'learning_rate': 0.0001, 'batch_size': 32}\n",
      "40/40 [==============================] - 0s 911us/step - loss: 0.0405 - mean_squared_error: 0.0405\n",
      "Loss: 0.04046545922756195 Tiempo transcurrido: 58.85435676574707\n",
      "\n",
      "--- Starting trial: run-27\n",
      "{'layers': 4, 'num_units': 200, 'learning_rate': 0.0001, 'batch_size': 64}\n",
      "40/40 [==============================] - 0s 997us/step - loss: 0.0431 - mean_squared_error: 0.0431\n",
      "Loss: 0.04310934990644455 Tiempo transcurrido: 38.493699073791504\n",
      "\n",
      "--- Starting trial: run-28\n",
      "{'layers': 4, 'num_units': 200, 'learning_rate': 0.001, 'batch_size': 8}\n",
      "40/40 [==============================] - 0s 861us/step - loss: 0.0449 - mean_squared_error: 0.0449\n",
      "Loss: 0.04488250985741615 Tiempo transcurrido: 193.19756412506104\n",
      "\n",
      "--- Starting trial: run-29\n",
      "{'layers': 4, 'num_units': 200, 'learning_rate': 0.001, 'batch_size': 16}\n",
      "40/40 [==============================] - 0s 784us/step - loss: 0.0253 - mean_squared_error: 0.0253\n",
      "Loss: 0.02526777796447277 Tiempo transcurrido: 96.35818290710449\n",
      "\n",
      "--- Starting trial: run-30\n",
      "{'layers': 4, 'num_units': 200, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "40/40 [==============================] - 0s 770us/step - loss: 0.0272 - mean_squared_error: 0.0272\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.02720065601170063 Tiempo transcurrido: 46.750805616378784\n",
      "\n",
      "--- Starting trial: run-31\n",
      "{'layers': 4, 'num_units': 200, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "40/40 [==============================] - 0s 747us/step - loss: 0.0229 - mean_squared_error: 0.0229\n",
      "Loss: 0.022859521210193634 Tiempo transcurrido: 32.78250789642334\n",
      "32\n"
     ]
    }
   ],
   "source": [
    "session_num = 0\n",
    "datos = []\n",
    "\n",
    "for deep_layers in HP_LAYERS.domain.values:\n",
    "    for num_units in HP_NUM_UNITS.domain.values:\n",
    "        for learning_rate in HP_LEARNING.domain.values:\n",
    "            for batch_size in HP_BATCHSIZE.domain.values:\n",
    "                t = time.time()\n",
    "                hparams = {\n",
    "\n",
    "                    HP_LAYERS: deep_layers,\n",
    "                    HP_NUM_UNITS: num_units,\n",
    "                    HP_LEARNING: learning_rate,\n",
    "                    HP_BATCHSIZE: batch_size,\n",
    "                }\n",
    "                run_name = \"run-%d\" % session_num\n",
    "                print('\\n--- Starting trial: %s' % run_name)\n",
    "                print({h.name: hparams[h] for h in hparams})\n",
    "                score = run('logs/hparam_tuning3/' + run_name, hparams)\n",
    "                t = time.time()-t\n",
    "                session_num += 1\n",
    "                print(\"Loss:\", score, \"Tiempo transcurrido:\", t)\n",
    "            \n",
    "            datos.append([deep_layers, num_units, learning_rate, batch_size, score, t])\n",
    "\n",
    "print(session_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"historial_photoz_tunning.txt\"\n",
    "df = pd.DataFrame(datos, columns = [\"Deep size\", \"Num units\", \"Learning rate\", \"Batch size\", \"MSE\", \"Tiempo de ejecución\"])\n",
    "\n",
    "df.sort_values(by=[\"MSE\", \"Tiempo de ejecución\"], ascending=[True, True], ignore_index=True, inplace=True)\n",
    "\n",
    "df.to_csv(filename, header=True, index=False, sep='\\t', mode='w') # a=append, w=overwrite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Deep size</th>\n",
       "      <th>Num units</th>\n",
       "      <th>Learning rate</th>\n",
       "      <th>Batch size</th>\n",
       "      <th>MSE</th>\n",
       "      <th>Tiempo de ejecución</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>200</td>\n",
       "      <td>0.001</td>\n",
       "      <td>64</td>\n",
       "      <td>0.022860</td>\n",
       "      <td>32.782508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>100</td>\n",
       "      <td>0.001</td>\n",
       "      <td>64</td>\n",
       "      <td>0.023669</td>\n",
       "      <td>28.649291</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Deep size  Num units  Learning rate  Batch size       MSE  \\\n",
       "0          4        200          0.001          64  0.022860   \n",
       "1          4        100          0.001          64  0.023669   \n",
       "\n",
       "   Tiempo de ejecución  \n",
       "0            32.782508  \n",
       "1            28.649291  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time 4.018 minutes\n"
     ]
    }
   ],
   "source": [
    "total_time = float(np.sum(df[[\"Tiempo de ejecución\"]])/60)\n",
    "\n",
    "print(\"Elapsed time {:.3f} minutes\".format(total_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    32.782508\n",
       "1    28.649291\n",
       "2    25.105375\n",
       "3    31.389440\n",
       "4    32.980246\n",
       "5    27.168419\n",
       "6    24.484121\n",
       "7    38.493699\n",
       "Name: Tiempo de ejecución, dtype: float64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"Tiempo de ejecución\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
