{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import time, os\n",
    "import random\n",
    "import seaborn as sns\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Input, Dense, LeakyReLU\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorboard.plugins.hparams import api as hp\n",
    "\n",
    "from tensorflow.keras import activations\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "import random\n",
    "from math import floor\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import optimizers\n",
    "from scipy.integrate import odeint\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split as split\n",
    "from scipy.stats import bernoulli\n",
    "\n",
    "# import deap\n",
    "from deap import base, creator, tools, algorithms\n",
    "\n",
    "from bitstring import BitArray\n",
    "\n",
    "# from elitism import eaSimpleWithElitism, main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "\n",
    "# tf.config.optimizer.set_jit(True)\n",
    "# scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "url = 'https://raw.githubusercontent.com/igomezv/nnogada/main/data/jla.csv'\n",
    "df=pd.read_csv(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = len(df.values)\n",
    "randomize = np.random.permutation(N)\n",
    "data = df.values[randomize]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(740, 2)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N = len(df.values)\n",
    "z = data[:,0] \n",
    "y = data[:,1:3] ### coge el resto de variables a predecir \n",
    "y[:,1] = y[:,1]**2+data[:,2]\n",
    "np.shape(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "scalerz = StandardScaler()\n",
    "scalerz.fit(z.reshape(-1,1))\n",
    "z = scalerz.transform(z.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((592, 1), (148, 1), (592, 2), (148, 2))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Modificar para incluir phanteon como test\n",
    "split = 0.8\n",
    "ntrain = int(split * len(z))\n",
    "indx = [ntrain]\n",
    "X_train, X_val = np.split(z, indx)\n",
    "Y_train, Y_val = np.split(y, indx)\n",
    "# X_train, X_test = np.split(z, indx)\n",
    "# Y_train, Y_test = np.split(y, indx)\n",
    "np.shape(X_train), np.shape(X_val), Y_train.shape, Y_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "SC_DEEP       = np.array([1,2,3,4])                           # Number of deep layers (8)\n",
    "SC_NUM_UNITS  = np.array([50,100,150,200]) # Number of fully conected neurons (16)\n",
    "SC_LEARNING   = np.array([1e-4,5e-3])   # Learning rates (8)\n",
    "SC_BATCH      = np.array([2, 4, 8, 16])                            # Batch sizes (4)\n",
    "# SC_ACTIVATION = [f1, f2, f3, f4]                                      # Activation function layers (2)\n",
    "\n",
    "my_callbacks = [tf.keras.callbacks.EarlyStopping(\n",
    "                               monitor='val_loss', mode='min',\n",
    "                               min_delta=0, \n",
    "                               patience=200,\n",
    "                               verbose=1,\n",
    "                            #    baseline=0,\n",
    "                               restore_best_weights=True)\n",
    "#                 keras.callbacks.TensorBoard(\n",
    "#                                log_dir='./logs'),\n",
    "#                 keras.callbacks.ReduceLROnPlateau(\n",
    "#                                monitor='val_loss', factor=0.5,\n",
    "#                                patience=6, min_lr=0,\n",
    "#                                verbose=1)\n",
    "               ] \n",
    "    \n",
    "epochs = 200\n",
    "# epochs = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_evaluate(ga_individual_solution):   \n",
    "    t = time.time()\n",
    "    t_total = 0\n",
    "    \n",
    "    # Decode GA solution to integer for window_size and num_units\n",
    "    deep_layers_bits   = BitArray(ga_individual_solution[0:2])     # (8)\n",
    "    num_units_bits     = BitArray(ga_individual_solution[2:4])     # (16)\n",
    "    learning_rate_bits = BitArray(ga_individual_solution[4:5])    # (8)\n",
    "    batch_size_bits    = BitArray(ga_individual_solution[5:7])   # (4)\n",
    "# #     activation_f_bits  = BitArray(ga_individual_solution[12:13])   # (2)   Solo se consideran las 2 primeras\n",
    "    \n",
    "    deep_layers   = SC_DEEP[deep_layers_bits.uint]\n",
    "    num_units     = SC_NUM_UNITS[num_units_bits.uint]\n",
    "    learning_rate = SC_LEARNING[learning_rate_bits.uint]\n",
    "    batch_size   = SC_BATCH[batch_size_bits.uint]\n",
    "#     activation_f  = SC_ACTIVATION[activation_f_bits.uint]\n",
    "\n",
    "    \n",
    "    print('\\n--------------- Starting trial:', population_size*(max_generations+1)-len(ss), \"---------------\")\n",
    "    print('Deep layers:',deep_layers,', Number of neurons:',num_units,\", Learning rate:\",learning_rate)\n",
    "#     print(\"-------------------------------------------------\")\n",
    "    \n",
    "    # Train model and predict on validation set\n",
    "    model = tf.keras.Sequential()\n",
    "#     model.add(Input(shape=(int(X_train.shape[1]),)))\n",
    "    model.add(Dense(int(X_train.shape[1])))\n",
    "    \n",
    "    for i in range(deep_layers):        \n",
    "        model.add(Dense(num_units, activation='relu'))\n",
    "#             model.add(keras.layers.Dropout(0.3))\n",
    "    model.add(Dense(2, activation='linear'))\n",
    "    \n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate, beta_1=0.9, beta_2=0.999, epsilon=1e-3)\n",
    "    model.compile(optimizer=optimizer, loss='mse', metrics=['mean_squared_error'])\n",
    "    model.fit(X_train, Y_train, epochs=epochs, validation_data=(X_val, Y_val),\n",
    "              callbacks=my_callbacks, batch_size=batch_size, shuffle=False, verbose=0)\n",
    "    \n",
    "    loss, score = model.evaluate(X_val, Y_val)    \n",
    "    t = time.time()-t\n",
    "    ss.pop(0)\n",
    "    print(\"Loss:\", score, \", Elapsed time:\", t)\n",
    "    print(\"-------------------------------------------------\\n\")\n",
    "#     print(loss, score)\n",
    "\n",
    "    datos.append([deep_layers, num_units, learning_rate, batch_size, loss, score, t])\n",
    "    \n",
    "    return loss,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deap import tools\n",
    "from deap import algorithms\n",
    "\n",
    "def eaSimpleWithElitism(population, toolbox, cxpb, mutpb, ngen, stats=None,\n",
    "             halloffame=None, verbose=__debug__):\n",
    "    \"\"\"This algorithm is similar to DEAP eaSimple() algorithm, with the modification that\n",
    "    halloffame is used to implement an elitism mechanism. The individuals contained in the\n",
    "    halloffame are directly injected into the next generation and are not subject to the\n",
    "    genetic operators of selection, crossover and mutation.\n",
    "    \"\"\"\n",
    "    logbook = tools.Logbook()\n",
    "    logbook.header = ['gen', 'nevals'] + (stats.fields if stats else [])\n",
    "\n",
    "    # Evaluate the individuals with an invalid fitness\n",
    "    invalid_ind = [ind for ind in population if not ind.fitness.valid]\n",
    "    fitnesses = toolbox.map(toolbox.evaluate, invalid_ind)\n",
    "    for ind, fit in zip(invalid_ind, fitnesses):\n",
    "        ind.fitness.values = fit\n",
    "\n",
    "    if halloffame is None:\n",
    "        raise ValueError(\"halloffame parameter must not be empty!\")\n",
    "\n",
    "    halloffame.update(population)\n",
    "    hof_size = len(halloffame.items) if halloffame.items else 0\n",
    "\n",
    "    record = stats.compile(population) if stats else {}\n",
    "    logbook.record(gen=0, nevals=len(invalid_ind), **record)\n",
    "    if verbose:\n",
    "        print(logbook.stream)\n",
    "\n",
    "    # Begin the generational process\n",
    "    for gen in range(1, ngen + 1):\n",
    "\n",
    "        # Select the next generation individuals\n",
    "        offspring = toolbox.select(population, len(population) - hof_size)\n",
    "\n",
    "        # Vary the pool of individuals\n",
    "        offspring = algorithms.varAnd(offspring, toolbox, cxpb, mutpb)\n",
    "\n",
    "        # Evaluate the individuals with an invalid fitness\n",
    "        invalid_ind = [ind for ind in offspring if not ind.fitness.valid]\n",
    "        fitnesses = toolbox.map(toolbox.evaluate, invalid_ind)\n",
    "        for ind, fit in zip(invalid_ind, fitnesses):\n",
    "            ind.fitness.values = fit\n",
    "\n",
    "        # add the best back to population:\n",
    "        offspring.extend(halloffame.items)\n",
    "\n",
    "        # Update the hall of fame with the generated individuals\n",
    "        halloffame.update(offspring)\n",
    "\n",
    "        # Replace the current population by the offspring\n",
    "        population[:] = offspring\n",
    "\n",
    "        # Append the current generation statistics to the logbook\n",
    "        record = stats.compile(population) if stats else {}\n",
    "        logbook.record(gen=gen, nevals=len(invalid_ind), **record)\n",
    "        if verbose:\n",
    "            print(logbook.stream)\n",
    "\n",
    "    return population, logbook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def geneticAlgorithm_with_elitism(population_size, max_generations, gene_length, k):\n",
    "    \n",
    "    # Genetic Algorithm constants:\n",
    "    P_CROSSOVER = 0.5        # probability for crossover\n",
    "    P_MUTATION = 0.5         # probability for mutating an individual\n",
    "    HALL_OF_FAME_SIZE = 1    # Best individuals that pass to the other generation\n",
    "    \n",
    "    # set the random seed:\n",
    "    toolbox = base.Toolbox()\n",
    "\n",
    "    # As we are trying to minimize the RMSE score, that's why using -1.0. \n",
    "    # In case, when you want to maximize accuracy for instance, use 1.0\n",
    "    creator.create('FitnessMin', base.Fitness, weights = [-1.0])\n",
    "    creator.create('Individual', list , fitness = creator.FitnessMin)\n",
    "\n",
    "    # create the individual operator to fill up an Individual instance:\n",
    "    toolbox.register('binary', bernoulli.rvs, 0.5)\n",
    "    toolbox.register('individual', tools.initRepeat, creator.Individual, toolbox.binary, n = gene_length)\n",
    "\n",
    "    # create the population operator to generate a list of individuals:\n",
    "    toolbox.register('population', tools.initRepeat, list , toolbox.individual)\n",
    "\n",
    "    # genetic operators:\n",
    "    toolbox.register('evaluate', train_evaluate)\n",
    "    toolbox.register('select', tools.selTournament, tournsize = 2)\n",
    "    toolbox.register('mutate', tools.mutFlipBit, indpb = 0.11)\n",
    "    toolbox.register('mate', tools.cxUniform, indpb = 0.5)\n",
    "    \n",
    "    # create initial population (generation 0):\n",
    "    population = toolbox.population(n=population_size)\n",
    "\n",
    "    # prepare the statistics object:\n",
    "    stats = tools.Statistics(lambda ind: ind.fitness.values)\n",
    "    stats.register(\"min\", np.min)\n",
    "    stats.register(\"avg\", np.mean)\n",
    "    stats.register(\"max\", np.max)\n",
    "\n",
    "    # define the hall-of-fame object:\n",
    "    hof = tools.HallOfFame(HALL_OF_FAME_SIZE)\n",
    "\n",
    "    # Genetic Algorithm flow with elitism:\n",
    "    population, logbook = eaSimpleWithElitism(population, toolbox, cxpb=P_CROSSOVER, mutpb=P_MUTATION,\n",
    "                                              ngen=max_generations, stats=stats, halloffame=hof, verbose=True)\n",
    "\n",
    "    # print info for best solution found:\n",
    "    best = hof.items[0]\n",
    "    print(\"-- Best Individual = \", best)\n",
    "    print(\"-- Best Fitness = \", best.fitness.values[0])\n",
    "\n",
    "    # extract statistics:\n",
    "    minFitnessValues, meanFitnessValues, maxFitnessValues = logbook.select(\"min\", \"max\", \"avg\")\n",
    "\n",
    "    # plot statistics:\n",
    "    sns.set_style(\"whitegrid\")\n",
    "    plt.plot(minFitnessValues, color='blue', label=\"Min\")\n",
    "    plt.plot(meanFitnessValues, color='green', label=\"Mean\")\n",
    "    plt.plot(maxFitnessValues, color='red', label=\"Max\")\n",
    "    plt.xlabel('Generation'); plt.ylabel('Max / Min / Average Fitness')\n",
    "    plt.legend()\n",
    "    plt.title('Max, Min and Average fitness over Generations')\n",
    "    plt.show()\n",
    "    \n",
    "    best_population = tools.selBest(population,k = k)\n",
    "    return best_population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------------- Starting trial: 1 ---------------\n",
      "Deep layers: 3 , Number of neurons: 100 , Learning rate: 0.005\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1228 - mean_squared_error: 0.1228\n",
      "Loss: 0.12283805757761002 , Elapsed time: 113.110036611557\n",
      "-------------------------------------------------\n",
      "\n",
      "\n",
      "--------------- Starting trial: 2 ---------------\n",
      "Deep layers: 2 , Number of neurons: 200 , Learning rate: 0.0001\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0484 - mean_squared_error: 0.0484\n",
      "Loss: 0.04844190925359726 , Elapsed time: 18.708677530288696\n",
      "-------------------------------------------------\n",
      "\n",
      "\n",
      "--------------- Starting trial: 3 ---------------\n",
      "Deep layers: 4 , Number of neurons: 200 , Learning rate: 0.005\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0728 - mean_squared_error: 0.0728\n",
      "Loss: 0.07281669229269028 , Elapsed time: 28.79032826423645\n",
      "-------------------------------------------------\n",
      "\n",
      "\n",
      "--------------- Starting trial: 4 ---------------\n",
      "Deep layers: 1 , Number of neurons: 100 , Learning rate: 0.0001\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0687 - mean_squared_error: 0.0687\n",
      "Loss: 0.06871004402637482 , Elapsed time: 46.93321657180786\n",
      "-------------------------------------------------\n",
      "\n",
      "\n",
      "--------------- Starting trial: 5 ---------------\n",
      "Deep layers: 2 , Number of neurons: 100 , Learning rate: 0.0001\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0354 - mean_squared_error: 0.0354\n",
      "Loss: 0.03538600355386734 , Elapsed time: 51.04583501815796\n",
      "-------------------------------------------------\n",
      "\n",
      "gen\tnevals\tmin     \tavg      \tmax     \n",
      "0  \t5     \t0.035386\t0.0696385\t0.122838\n",
      "\n",
      "--------------- Starting trial: 6 ---------------\n",
      "Deep layers: 2 , Number of neurons: 200 , Learning rate: 0.0001\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0558 - mean_squared_error: 0.0558\n",
      "Loss: 0.05578117072582245 , Elapsed time: 19.823768615722656\n",
      "-------------------------------------------------\n",
      "\n",
      "\n",
      "--------------- Starting trial: 7 ---------------\n",
      "Deep layers: 1 , Number of neurons: 100 , Learning rate: 0.0001\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.3462 - mean_squared_error: 0.3462\n",
      "Loss: 0.3462088704109192 , Elapsed time: 44.35984563827515\n",
      "-------------------------------------------------\n",
      "\n",
      "\n",
      "--------------- Starting trial: 8 ---------------\n",
      "Deep layers: 2 , Number of neurons: 100 , Learning rate: 0.0001\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0373 - mean_squared_error: 0.0373\n",
      "Loss: 0.03727918863296509 , Elapsed time: 55.32290506362915\n",
      "-------------------------------------------------\n",
      "\n",
      "1  \t3     \t0.035386\t0.104619 \t0.346209\n",
      "\n",
      "--------------- Starting trial: 9 ---------------\n",
      "Deep layers: 2 , Number of neurons: 100 , Learning rate: 0.0001\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0664 - mean_squared_error: 0.0664\n",
      "Loss: 0.06644780933856964 , Elapsed time: 18.415823936462402\n",
      "-------------------------------------------------\n",
      "\n",
      "\n",
      "--------------- Starting trial: 10 ---------------\n",
      "Deep layers: 2 , Number of neurons: 100 , Learning rate: 0.0001\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0804 - mean_squared_error: 0.0804\n",
      "Loss: 0.08038114011287689 , Elapsed time: 18.340229272842407\n",
      "-------------------------------------------------\n",
      "\n",
      "\n",
      "--------------- Starting trial: 11 ---------------\n",
      "Deep layers: 2 , Number of neurons: 200 , Learning rate: 0.0001\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0368 - mean_squared_error: 0.0368\n",
      "Loss: 0.0368298701941967 , Elapsed time: 59.09944033622742\n",
      "-------------------------------------------------\n",
      "\n",
      "2  \t3     \t0.035386\t0.0512648\t0.0803811\n",
      "\n",
      "--------------- Starting trial: 12 ---------------\n",
      "Deep layers: 1 , Number of neurons: 50 , Learning rate: 0.0001\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1768 - mean_squared_error: 0.1768\n",
      "Loss: 0.17677807807922363 , Elapsed time: 52.23544430732727\n",
      "-------------------------------------------------\n",
      "\n",
      "\n",
      "--------------- Starting trial: 13 ---------------\n",
      "Deep layers: 2 , Number of neurons: 200 , Learning rate: 0.0001\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0357 - mean_squared_error: 0.0357\n",
      "Loss: 0.03573475033044815 , Elapsed time: 68.82313585281372\n",
      "-------------------------------------------------\n",
      "\n",
      "3  \t2     \t0.035386\t0.0731118\t0.176778 \n",
      "\n",
      "--------------- Starting trial: 14 ---------------\n",
      "Deep layers: 2 , Number of neurons: 100 , Learning rate: 0.0001\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0371 - mean_squared_error: 0.0371\n",
      "Loss: 0.03714406490325928 , Elapsed time: 63.06417107582092\n",
      "-------------------------------------------------\n",
      "\n",
      "\n",
      "--------------- Starting trial: 15 ---------------\n",
      "Deep layers: 2 , Number of neurons: 100 , Learning rate: 0.0001\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0360 - mean_squared_error: 0.0360\n",
      "Loss: 0.035995639860630035 , Elapsed time: 50.50686955451965\n",
      "-------------------------------------------------\n",
      "\n",
      "\n",
      "--------------- Starting trial: 16 ---------------\n",
      "Deep layers: 1 , Number of neurons: 100 , Learning rate: 0.0001\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.5766 - mean_squared_error: 0.5766\n",
      "Loss: 0.576583743095398 , Elapsed time: 28.276280164718628\n",
      "-------------------------------------------------\n",
      "\n",
      "\n",
      "--------------- Starting trial: 17 ---------------\n",
      "Deep layers: 2 , Number of neurons: 50 , Learning rate: 0.0001\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0355 - mean_squared_error: 0.0355\n",
      "Loss: 0.03547946363687515 , Elapsed time: 51.361793994903564\n",
      "-------------------------------------------------\n",
      "\n",
      "4  \t4     \t0.035386\t0.144118 \t0.576584 \n",
      "\n",
      "--------------- Starting trial: 18 ---------------\n",
      "Deep layers: 2 , Number of neurons: 50 , Learning rate: 0.0001\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0421 - mean_squared_error: 0.0421\n",
      "Loss: 0.04208362475037575 , Elapsed time: 48.8734917640686\n",
      "-------------------------------------------------\n",
      "\n",
      "\n",
      "--------------- Starting trial: 19 ---------------\n",
      "Deep layers: 2 , Number of neurons: 150 , Learning rate: 0.0001\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0359 - mean_squared_error: 0.0359\n",
      "Loss: 0.03589465841650963 , Elapsed time: 56.65526008605957\n",
      "-------------------------------------------------\n",
      "\n",
      "\n",
      "--------------- Starting trial: 20 ---------------\n",
      "Deep layers: 2 , Number of neurons: 100 , Learning rate: 0.0001\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0352 - mean_squared_error: 0.0352\n",
      "Loss: 0.035183750092983246 , Elapsed time: 65.11465573310852\n",
      "-------------------------------------------------\n",
      "\n",
      "\n",
      "--------------- Starting trial: 21 ---------------\n",
      "Deep layers: 2 , Number of neurons: 50 , Learning rate: 0.005\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0504 - mean_squared_error: 0.0504\n",
      "Loss: 0.050420910120010376 , Elapsed time: 66.28792119026184\n",
      "-------------------------------------------------\n",
      "\n",
      "5  \t4     \t0.0351838\t0.0397938\t0.0504209\n",
      "\n",
      "--------------- Starting trial: 22 ---------------\n",
      "Deep layers: 2 , Number of neurons: 100 , Learning rate: 0.0001\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0317 - mean_squared_error: 0.0317\n",
      "Loss: 0.03171353042125702 , Elapsed time: 151.76647782325745\n",
      "-------------------------------------------------\n",
      "\n",
      "\n",
      "--------------- Starting trial: 23 ---------------\n",
      "Deep layers: 2 , Number of neurons: 100 , Learning rate: 0.0001\n",
      "5/5 [==============================] - 1s 7ms/step - loss: 0.0383 - mean_squared_error: 0.0383\n",
      "Loss: 0.038295432925224304 , Elapsed time: 84.84090900421143\n",
      "-------------------------------------------------\n",
      "\n",
      "\n",
      "--------------- Starting trial: 24 ---------------\n",
      "Deep layers: 2 , Number of neurons: 100 , Learning rate: 0.0001\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0364 - mean_squared_error: 0.0364\n",
      "Loss: 0.036390744149684906 , Elapsed time: 59.904362201690674\n",
      "-------------------------------------------------\n",
      "\n",
      "6  \t3     \t0.0317135\t0.0367739\t0.0420836\n",
      "\n",
      "--------------- Starting trial: 25 ---------------\n",
      "Deep layers: 3 , Number of neurons: 50 , Learning rate: 0.0001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0346 - mean_squared_error: 0.0346\n",
      "Loss: 0.034578390419483185 , Elapsed time: 54.09233617782593\n",
      "-------------------------------------------------\n",
      "\n",
      "\n",
      "--------------- Starting trial: 26 ---------------\n",
      "Deep layers: 2 , Number of neurons: 100 , Learning rate: 0.0001\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0363 - mean_squared_error: 0.0363\n",
      "Loss: 0.03630172088742256 , Elapsed time: 56.388999938964844\n",
      "-------------------------------------------------\n",
      "\n",
      "7  \t2     \t0.0317135\t0.0341396\t0.0363907\n",
      "\n",
      "--------------- Starting trial: 27 ---------------\n",
      "Deep layers: 2 , Number of neurons: 100 , Learning rate: 0.0001\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0319 - mean_squared_error: 0.0319\n",
      "Loss: 0.03191196545958519 , Elapsed time: 127.387366771698\n",
      "-------------------------------------------------\n",
      "\n",
      "8  \t1     \t0.0317135\t0.0323262\t0.0345784\n",
      "\n",
      "--------------- Starting trial: 28 ---------------\n",
      "Deep layers: 2 , Number of neurons: 100 , Learning rate: 0.0001\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0313 - mean_squared_error: 0.0313\n",
      "Loss: 0.031317077577114105 , Elapsed time: 149.58278155326843\n",
      "-------------------------------------------------\n",
      "\n",
      "\n",
      "--------------- Starting trial: 29 ---------------\n",
      "Deep layers: 2 , Number of neurons: 100 , Learning rate: 0.0001\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0310 - mean_squared_error: 0.0310\n",
      "Loss: 0.03095630742609501 , Elapsed time: 137.84876370429993\n",
      "-------------------------------------------------\n",
      "\n",
      "\n",
      "--------------- Starting trial: 30 ---------------\n",
      "Deep layers: 1 , Number of neurons: 50 , Learning rate: 0.0001\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0634 - mean_squared_error: 0.0634\n",
      "Loss: 0.06342639774084091 , Elapsed time: 111.18540406227112\n",
      "-------------------------------------------------\n",
      "\n",
      "\n",
      "--------------- Starting trial: 31 ---------------\n",
      "Deep layers: 4 , Number of neurons: 100 , Learning rate: 0.0001\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0342 - mean_squared_error: 0.0342\n",
      "Loss: 0.03423634171485901 , Elapsed time: 147.76775765419006\n",
      "-------------------------------------------------\n",
      "\n",
      "9  \t4     \t0.0309563\t0.0383299\t0.0634264\n",
      "\n",
      "--------------- Starting trial: 32 ---------------\n",
      "Deep layers: 2 , Number of neurons: 50 , Learning rate: 0.0001\n",
      "5/5 [==============================] - 1s 3ms/step - loss: 0.0342 - mean_squared_error: 0.0342\n",
      "Loss: 0.034173883497714996 , Elapsed time: 129.80946350097656\n",
      "-------------------------------------------------\n",
      "\n",
      "\n",
      "--------------- Starting trial: 33 ---------------\n",
      "Deep layers: 4 , Number of neurons: 100 , Learning rate: 0.0001\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0348 - mean_squared_error: 0.0348\n",
      "Loss: 0.03484886884689331 , Elapsed time: 153.83967304229736\n",
      "-------------------------------------------------\n",
      "\n",
      "10 \t2     \t0.0309563\t0.0331858\t0.0348489\n",
      "-- Best Individual =  [0, 1, 0, 1, 0, 0, 0]\n",
      "-- Best Fitness =  0.03171353042125702\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total elapsed time: 39.832755200068156 minutes\n"
     ]
    }
   ],
   "source": [
    "population_size = 5   # max of individuals per generation\n",
    "max_generations = 10  # number of generations\n",
    "gene_length = 7      # lenght of the gene, depends on how many hiperparameters are tested  \n",
    "k = 1;                 # num. of finalist individuals\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    t = time.time(); \n",
    "    datos = [];\n",
    "    ss = [i for i in range(1,population_size*(max_generations+1))]\n",
    "    best_population = geneticAlgorithm_with_elitism(population_size, max_generations, gene_length, k)\n",
    "    print(\"Total elapsed time:\", (time.time()-t)/60, \"minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k= 1 \n",
      "Deep layers: 1 , Number of neurons: 100\n",
      "Batch size 4 , Learning rate: 0.0001\n"
     ]
    }
   ],
   "source": [
    "best_deep_layers   = []\n",
    "best_num_units     = []\n",
    "best_learning_rate = []\n",
    "best_batch_size    = []\n",
    "# best_activation_f  = []\n",
    "best_f_names       = []\n",
    "\n",
    "t = 0\n",
    "\n",
    "for bi in best_population:\n",
    "    deep_layers_bits   = BitArray(bi[0:1])    # (8)\n",
    "    num_units_bits     = BitArray(bi[1:2])    # (16)\n",
    "    learning_rate_bits = BitArray(bi[2:3])   # (8)\n",
    "    batch_size_bits    = BitArray(bi[3:4])  # (4)\n",
    "#     activation_f_bits  = BitArray(bi[12:13])  # (2)\n",
    "    t += 1 \n",
    "    \n",
    "    best_deep_layers.append(SC_DEEP[deep_layers_bits.uint])\n",
    "    best_num_units.append(SC_NUM_UNITS[num_units_bits.uint])\n",
    "    best_learning_rate.append(SC_LEARNING[learning_rate_bits.uint])\n",
    "    best_batch_size.append(SC_BATCH[batch_size_bits.uint])\n",
    "#     best_activation_f.append(SC_ACTIVATION[activation_f_bits.uint])\n",
    "#     best_f_names.append(f_names[activation_f_bits.uint])\n",
    "    print('k=',t,'\\nDeep layers:', best_deep_layers[-1], ', Number of neurons:', best_num_units[-1])\n",
    "    print('Batch size', best_batch_size[-1], ', Learning rate:', best_learning_rate[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Deep layers</th>\n",
       "      <th>Num units</th>\n",
       "      <th>Learning rate</th>\n",
       "      <th>Batch size</th>\n",
       "      <th>Loss</th>\n",
       "      <th>Score</th>\n",
       "      <th>Elapsed time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>2</td>\n",
       "      <td>0.030956</td>\n",
       "      <td>0.030956</td>\n",
       "      <td>137.848764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>2</td>\n",
       "      <td>0.031317</td>\n",
       "      <td>0.031317</td>\n",
       "      <td>149.582782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>2</td>\n",
       "      <td>0.031714</td>\n",
       "      <td>0.031714</td>\n",
       "      <td>151.766478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>2</td>\n",
       "      <td>0.031912</td>\n",
       "      <td>0.031912</td>\n",
       "      <td>127.387367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>2</td>\n",
       "      <td>0.034174</td>\n",
       "      <td>0.034174</td>\n",
       "      <td>129.809464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>2</td>\n",
       "      <td>0.034236</td>\n",
       "      <td>0.034236</td>\n",
       "      <td>147.767758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3</td>\n",
       "      <td>50</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>4</td>\n",
       "      <td>0.034578</td>\n",
       "      <td>0.034578</td>\n",
       "      <td>54.092336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>2</td>\n",
       "      <td>0.034849</td>\n",
       "      <td>0.034849</td>\n",
       "      <td>153.839673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>4</td>\n",
       "      <td>0.035184</td>\n",
       "      <td>0.035184</td>\n",
       "      <td>65.114656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>4</td>\n",
       "      <td>0.035386</td>\n",
       "      <td>0.035386</td>\n",
       "      <td>51.045835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>4</td>\n",
       "      <td>0.035479</td>\n",
       "      <td>0.035479</td>\n",
       "      <td>51.361794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2</td>\n",
       "      <td>200</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>4</td>\n",
       "      <td>0.035735</td>\n",
       "      <td>0.035735</td>\n",
       "      <td>68.823136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2</td>\n",
       "      <td>150</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>4</td>\n",
       "      <td>0.035895</td>\n",
       "      <td>0.035895</td>\n",
       "      <td>56.655260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>4</td>\n",
       "      <td>0.035996</td>\n",
       "      <td>0.035996</td>\n",
       "      <td>50.506870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>4</td>\n",
       "      <td>0.036302</td>\n",
       "      <td>0.036302</td>\n",
       "      <td>56.389000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>4</td>\n",
       "      <td>0.036391</td>\n",
       "      <td>0.036391</td>\n",
       "      <td>59.904362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2</td>\n",
       "      <td>200</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>4</td>\n",
       "      <td>0.036830</td>\n",
       "      <td>0.036830</td>\n",
       "      <td>59.099440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>4</td>\n",
       "      <td>0.037144</td>\n",
       "      <td>0.037144</td>\n",
       "      <td>63.064171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>4</td>\n",
       "      <td>0.037279</td>\n",
       "      <td>0.037279</td>\n",
       "      <td>55.322905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>4</td>\n",
       "      <td>0.038295</td>\n",
       "      <td>0.038295</td>\n",
       "      <td>84.840909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>4</td>\n",
       "      <td>0.042084</td>\n",
       "      <td>0.042084</td>\n",
       "      <td>48.873492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2</td>\n",
       "      <td>200</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>16</td>\n",
       "      <td>0.048442</td>\n",
       "      <td>0.048442</td>\n",
       "      <td>18.708678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>0.0050</td>\n",
       "      <td>4</td>\n",
       "      <td>0.050421</td>\n",
       "      <td>0.050421</td>\n",
       "      <td>66.287921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2</td>\n",
       "      <td>200</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>16</td>\n",
       "      <td>0.055781</td>\n",
       "      <td>0.055781</td>\n",
       "      <td>19.823769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>2</td>\n",
       "      <td>0.063426</td>\n",
       "      <td>0.063426</td>\n",
       "      <td>111.185404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>16</td>\n",
       "      <td>0.066448</td>\n",
       "      <td>0.066448</td>\n",
       "      <td>18.415824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>4</td>\n",
       "      <td>0.068710</td>\n",
       "      <td>0.068710</td>\n",
       "      <td>46.933217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>4</td>\n",
       "      <td>200</td>\n",
       "      <td>0.0050</td>\n",
       "      <td>16</td>\n",
       "      <td>0.072817</td>\n",
       "      <td>0.072817</td>\n",
       "      <td>28.790328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>16</td>\n",
       "      <td>0.080381</td>\n",
       "      <td>0.080381</td>\n",
       "      <td>18.340229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0050</td>\n",
       "      <td>2</td>\n",
       "      <td>0.122838</td>\n",
       "      <td>0.122838</td>\n",
       "      <td>113.110037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>4</td>\n",
       "      <td>0.176778</td>\n",
       "      <td>0.176778</td>\n",
       "      <td>52.235444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>4</td>\n",
       "      <td>0.346209</td>\n",
       "      <td>0.346209</td>\n",
       "      <td>44.359846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>8</td>\n",
       "      <td>0.576584</td>\n",
       "      <td>0.576584</td>\n",
       "      <td>28.276280</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Deep layers  Num units  Learning rate  Batch size      Loss     Score  \\\n",
       "0             2        100         0.0001           2  0.030956  0.030956   \n",
       "1             2        100         0.0001           2  0.031317  0.031317   \n",
       "2             2        100         0.0001           2  0.031714  0.031714   \n",
       "3             2        100         0.0001           2  0.031912  0.031912   \n",
       "4             2         50         0.0001           2  0.034174  0.034174   \n",
       "5             4        100         0.0001           2  0.034236  0.034236   \n",
       "6             3         50         0.0001           4  0.034578  0.034578   \n",
       "7             4        100         0.0001           2  0.034849  0.034849   \n",
       "8             2        100         0.0001           4  0.035184  0.035184   \n",
       "9             2        100         0.0001           4  0.035386  0.035386   \n",
       "10            2         50         0.0001           4  0.035479  0.035479   \n",
       "11            2        200         0.0001           4  0.035735  0.035735   \n",
       "12            2        150         0.0001           4  0.035895  0.035895   \n",
       "13            2        100         0.0001           4  0.035996  0.035996   \n",
       "14            2        100         0.0001           4  0.036302  0.036302   \n",
       "15            2        100         0.0001           4  0.036391  0.036391   \n",
       "16            2        200         0.0001           4  0.036830  0.036830   \n",
       "17            2        100         0.0001           4  0.037144  0.037144   \n",
       "18            2        100         0.0001           4  0.037279  0.037279   \n",
       "19            2        100         0.0001           4  0.038295  0.038295   \n",
       "20            2         50         0.0001           4  0.042084  0.042084   \n",
       "21            2        200         0.0001          16  0.048442  0.048442   \n",
       "22            2         50         0.0050           4  0.050421  0.050421   \n",
       "23            2        200         0.0001          16  0.055781  0.055781   \n",
       "24            1         50         0.0001           2  0.063426  0.063426   \n",
       "25            2        100         0.0001          16  0.066448  0.066448   \n",
       "26            1        100         0.0001           4  0.068710  0.068710   \n",
       "27            4        200         0.0050          16  0.072817  0.072817   \n",
       "28            2        100         0.0001          16  0.080381  0.080381   \n",
       "29            3        100         0.0050           2  0.122838  0.122838   \n",
       "30            1         50         0.0001           4  0.176778  0.176778   \n",
       "31            1        100         0.0001           4  0.346209  0.346209   \n",
       "32            1        100         0.0001           8  0.576584  0.576584   \n",
       "\n",
       "    Elapsed time  \n",
       "0     137.848764  \n",
       "1     149.582782  \n",
       "2     151.766478  \n",
       "3     127.387367  \n",
       "4     129.809464  \n",
       "5     147.767758  \n",
       "6      54.092336  \n",
       "7     153.839673  \n",
       "8      65.114656  \n",
       "9      51.045835  \n",
       "10     51.361794  \n",
       "11     68.823136  \n",
       "12     56.655260  \n",
       "13     50.506870  \n",
       "14     56.389000  \n",
       "15     59.904362  \n",
       "16     59.099440  \n",
       "17     63.064171  \n",
       "18     55.322905  \n",
       "19     84.840909  \n",
       "20     48.873492  \n",
       "21     18.708678  \n",
       "22     66.287921  \n",
       "23     19.823769  \n",
       "24    111.185404  \n",
       "25     18.415824  \n",
       "26     46.933217  \n",
       "27     28.790328  \n",
       "28     18.340229  \n",
       "29    113.110037  \n",
       "30     52.235444  \n",
       "31     44.359846  \n",
       "32     28.276280  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename = \"historial_genetic_jla1.txt\"\n",
    "df = pd.DataFrame(datos, columns = [\"Deep layers\", \"Num units\", \"Learning rate\", \"Batch size\", \"Loss\", \"Score\", \"Elapsed time\"])\n",
    "\n",
    "df.sort_values(by=[\"Loss\", \"Elapsed time\"], ascending=[True, True], ignore_index=True, inplace=True)\n",
    "\n",
    "df.to_csv(filename, header=True, index=False, sep='\\t', mode='w') # a=append, w=overwrite\n",
    "df.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time 39.826 minutes\n"
     ]
    }
   ],
   "source": [
    "total_time = float(np.sum(df[[\"Elapsed time\"]])/60)\n",
    "\n",
    "print(\"Elapsed time {:.3f} minutes\".format(total_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
